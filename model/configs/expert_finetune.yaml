# Expert Label Fine-tuning Configuration
# Stage 3: Fine-tune on expert labels (200-300 segments)

data:
  # Annotation paths
  train_path: data/annotations/expert_labels_train.jsonl
  val_path: data/annotations/expert_labels_val.jsonl
  test_path: data/annotations/expert_labels_test.jsonl

  # Dimensions (all 10 dimensions)
  dimensions:
    - note_accuracy
    - rhythmic_precision
    - dynamics_control
    - articulation_quality
    - pedaling_technique
    - tone_quality
    - phrasing
    - musicality
    - overall_quality
    - expressiveness

  # Audio settings
  audio_sample_rate: 24000
  max_audio_length: 240000  # 10 seconds at 24kHz
  max_midi_events: 512

  # DataLoader settings
  batch_size: 8
  num_workers: 4
  pin_memory: true

  # Augmentation (lighter for fine-tuning)
  augmentation:
    enabled: true
    pitch_shift:
      enabled: true
      probability: 0.2
      min_semitones: -1
      max_semitones: 1
    time_stretch:
      enabled: true
      probability: 0.2
      min_rate: 0.90
      max_rate: 1.10
    add_noise:
      enabled: true
      probability: 0.15
      min_snr_db: 30
      max_snr_db: 40
    room_acoustics:
      enabled: true
      probability: 0.15
      num_room_types: 5
    compress_audio:
      enabled: true
      probability: 0.10
      bitrates: [192, 256, 320]
    gain_variation:
      enabled: true
      probability: 0.2
      min_db: -3
      max_db: 3
    max_transforms: 2  # Less aggressive augmentation

model:
  # Architecture dimensions
  audio_dim: 768
  midi_dim: 256
  fusion_dim: 1024
  aggregator_dim: 512
  num_dimensions: 10  # All dimensions

  # Encoder settings
  mert_model_name: m-a-p/MERT-v1-95M
  freeze_audio_encoder: false
  gradient_checkpointing: true

  # MIDI encoder
  midi_hidden_size: 256
  midi_num_layers: 6
  midi_num_heads: 4

  # Fusion
  fusion_num_heads: 8
  fusion_dropout: 0.1

  # Aggregator
  lstm_hidden: 256
  lstm_layers: 2
  attention_heads: 4
  aggregator_dropout: 0.2

  # MTL Head
  shared_hidden: 256
  task_hidden: 128
  mtl_dropout: 0.1

training:
  # Training duration
  max_epochs: 50
  precision: 16  # Mixed precision (FP16)

  # Optimization (lower LR for fine-tuning)
  optimizer: AdamW
  learning_rate: 5e-6  # Default (not used, see backbone_lr and heads_lr)
  backbone_lr: 5e-6  # Even lower for fine-tuning pre-trained model
  heads_lr: 5e-4  # Higher LR for task heads
  weight_decay: 0.01

  # Learning rate schedule
  scheduler: cosine
  warmup_steps: 500
  min_lr: 1e-6

  # Gradient settings
  gradient_clip_val: 1.0
  accumulate_grad_batches: 4  # Effective batch size = 8 * 4 = 32

  # Validation
  val_check_interval: 1.0  # Check every epoch
  limit_val_batches: 1.0  # Use full val set

callbacks:
  # Model checkpointing
  checkpoint:
    monitor: val_loss
    mode: min
    save_top_k: 3
    save_last: true
    dirpath: checkpoints/expert_finetune
    filename: expert-{epoch:02d}-{val_loss:.4f}

  # Early stopping (more patient for fine-tuning)
  early_stopping:
    monitor: val_loss
    mode: min
    patience: 10
    min_delta: 0.0005

  # Learning rate monitoring
  lr_monitor:
    logging_interval: step

logging:
  # Logging frequency
  log_every_n_steps: 20

  # WandB (optional)
  use_wandb: false
  wandb_project: piano-eval-mvp
  wandb_entity: null
  wandb_run_name: expert-finetune

  # TensorBoard
  use_tensorboard: true
  tensorboard_logdir: logs/expert_finetune

# Resume from checkpoint
resume_from_checkpoint: checkpoints/pseudo_pretrain/pseudo-best.ckpt

seed: 42
