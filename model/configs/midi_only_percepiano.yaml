# MIDI-only model training configuration for PercePiano dataset
# Target: xAI Hackathon - train in 5 days

# Model Architecture
model:
  type: midi_only

  # MIDI Encoder (MIDIBert-style)
  midi_encoder:
    hidden_dim: 256
    num_layers: 6
    num_heads: 8
    max_seq_length: 1024
    dropout: 0.1

  # Temporal Aggregation (BiLSTM + Attention)
  aggregation:
    lstm_hidden: 256
    lstm_layers: 2
    attention_heads: 4
    dropout: 0.2

  # Multi-task Head
  mtl_head:
    shared_hidden: 256
    task_hidden: 128
    dropout: 0.1

  # Output dimensions (8 for PercePiano)
  dimensions:
    - timing_stability
    - note_accuracy
    - dynamic_range
    - articulation
    - pedal_technique
    - expression
    - tone_quality
    - overall

# Training Configuration
training:
  # Batch size (adjust based on GPU memory)
  # T4 (16GB): batch_size=16
  # A100 (40GB): batch_size=32
  batch_size: 16
  gradient_accumulation_steps: 1

  # Learning rate
  learning_rate: 1.0e-4
  weight_decay: 0.01
  warmup_ratio: 0.1

  # Training duration
  max_epochs: 30
  early_stopping_patience: 7
  early_stopping_metric: val/mean_r
  early_stopping_mode: max

  # Precision (mixed precision for speed)
  precision: 16-mixed

  # Gradient clipping
  gradient_clip_val: 1.0

# Data Configuration
data:
  dataset: percepiano
  data_dir: data/processed

  # Sequence length
  max_seq_length: 1024
  segment_seconds: 30.0

  # Augmentation (training only)
  augment: true

  # Data loading
  num_workers: 4
  pin_memory: true
  cache_midi: true

# Logging
logging:
  project: crescendai-hackathon
  name: midi-only-percepiano
  log_every_n_steps: 10
  save_top_k: 3
  monitor: val/mean_r
  mode: max

# Checkpointing
checkpoints:
  dirpath: checkpoints/midi_only
  filename: "midi_only-{epoch:02d}-{val_mean_r:.3f}"
  save_last: true

# Hardware
hardware:
  accelerator: auto
  devices: auto
  strategy: auto
