{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priority Signal Validation Experiment\n",
    "\n",
    "Validates whether masterclass teaching moments (STOP/CONTINUE) can be predicted from audio.\n",
    "\n",
    "- **Model B:** Logistic regression on 19 PercePiano quality scores\n",
    "- **Model A:** Logistic regression on 2048-dim MuQ embeddings\n",
    "- **Evaluation:** Leave-one-video-out cross-validation (5 folds)\n",
    "\n",
    "Design doc: `docs/plans/2026-02-14-priority-signal-validation-design.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Add src to path\n",
    "MODEL_ROOT = Path(\"../..\").resolve()\n",
    "sys.path.insert(0, str(MODEL_ROOT / \"src\"))\n",
    "\n",
    "from masterclass_experiments.data import load_moments, identify_segments, extract_audio_segments\n",
    "from masterclass_experiments.features import extract_muq_features, extract_quality_scores, stats_pool\n",
    "from masterclass_experiments.evaluation import leave_one_video_out_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOMENTS_PATH = Path(\"../../../../tools/masterclass-pipeline/all_moments.jsonl\").resolve()\n",
    "WAV_DIR = Path(\"../../../../tools/masterclass-pipeline/data/audio\").resolve()\n",
    "CACHE_DIR = MODEL_ROOT / \"data\" / \"masterclass_cache\"\n",
    "SEGMENT_DIR = CACHE_DIR / \"segments\"\n",
    "MUQ_CACHE_DIR = CACHE_DIR / \"muq_embeddings\"\n",
    "CHECKPOINT_PATH = MODEL_ROOT / \"data\" / \"checkpoints\" / \"percepiano\" / \"fold0_best.ckpt\"\n",
    "\n",
    "for d in [SEGMENT_DIR, MUQ_CACHE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Moments: {MOMENTS_PATH}\")\n",
    "print(f\"WAV dir: {WAV_DIR}\")\n",
    "print(f\"Checkpoint: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore moments\n",
    "moments = load_moments(MOMENTS_PATH)\n",
    "print(f\"Loaded {len(moments)} moments\")\n",
    "\n",
    "# Identify segments\n",
    "segments = identify_segments(moments)\n",
    "stop_segments = [s for s in segments if s.label == \"stop\"]\n",
    "cont_segments = [s for s in segments if s.label == \"continue\"]\n",
    "print(f\"STOP segments: {len(stop_segments)}\")\n",
    "print(f\"CONTINUE segments: {len(cont_segments)}\")\n",
    "\n",
    "# Duration stats\n",
    "for label, segs in [(\"STOP\", stop_segments), (\"CONTINUE\", cont_segments)]:\n",
    "    durations = [s.end_time - s.start_time for s in segs]\n",
    "    print(f\"{label}: mean={np.mean(durations):.1f}s, median={np.median(durations):.1f}s, \"\n",
    "          f\"min={np.min(durations):.1f}s, max={np.max(durations):.1f}s\")\n",
    "\n",
    "# Extract audio segments\n",
    "extract_audio_segments(segments, WAV_DIR, SEGMENT_DIR)\n",
    "print(f\"Audio segments saved to {SEGMENT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MuQ embeddings (this takes a few minutes)\n",
    "print(\"Extracting MuQ features...\")\n",
    "muq_features = extract_muq_features(segments, SEGMENT_DIR, MUQ_CACHE_DIR)\n",
    "print(f\"Extracted MuQ features for {len(muq_features)} segments\")\n",
    "\n",
    "# Also keep raw embeddings for PercePiano inference\n",
    "from audio_experiments.extractors.muq import MuQExtractor\n",
    "extractor = MuQExtractor(cache_dir=MUQ_CACHE_DIR)\n",
    "raw_embeddings = {}\n",
    "for seg in segments:\n",
    "    wav_path = SEGMENT_DIR / f\"{seg.segment_id}.wav\"\n",
    "    raw_embeddings[seg.segment_id] = extractor.extract_from_file(wav_path)\n",
    "\n",
    "# Extract quality scores\n",
    "print(\"Running PercePiano inference...\")\n",
    "quality_scores = extract_quality_scores(raw_embeddings, CHECKPOINT_PATH)\n",
    "print(f\"Extracted quality scores for {len(quality_scores)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_experiments.constants import PERCEPIANO_DIMENSIONS\n",
    "\n",
    "# Build feature matrices\n",
    "segment_ids = np.array([s.segment_id for s in segments])\n",
    "video_ids = np.array([s.video_id for s in segments])\n",
    "labels = np.array([1 if s.label == \"stop\" else 0 for s in segments])\n",
    "\n",
    "# Model B features: 19 quality scores\n",
    "X_quality = np.stack([quality_scores[sid].numpy() for sid in segment_ids])\n",
    "print(f\"Model B features: {X_quality.shape}\")\n",
    "\n",
    "# Model A features: 2048-dim MuQ embeddings\n",
    "X_muq = np.stack([muq_features[sid].numpy() for sid in segment_ids])\n",
    "print(f\"Model A features: {X_muq.shape}\")\n",
    "\n",
    "# Run leave-one-video-out CV\n",
    "print(\"\\n--- Model B (Quality Scores) ---\")\n",
    "results_b = leave_one_video_out_cv(X_quality, labels, video_ids, segment_ids)\n",
    "print(f\"AUC: {results_b['auc']:.3f}\")\n",
    "print(f\"Accuracy: {results_b['accuracy']:.3f}\")\n",
    "print(f\"Precision: {results_b['precision']:.3f}\")\n",
    "print(f\"Recall: {results_b['recall']:.3f}\")\n",
    "print(f\"Samples: {results_b['n_samples']} ({results_b['n_stop']} stop, {results_b['n_continue']} continue)\")\n",
    "\n",
    "print(\"\\n--- Model A (MuQ Embeddings) ---\")\n",
    "results_a = leave_one_video_out_cv(X_muq, labels, video_ids, segment_ids)\n",
    "print(f\"AUC: {results_a['auc']:.3f}\")\n",
    "print(f\"Accuracy: {results_a['accuracy']:.3f}\")\n",
    "print(f\"Precision: {results_a['precision']:.3f}\")\n",
    "print(f\"Recall: {results_a['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from masterclass_experiments.models import train_classifier\n",
    "\n",
    "# Comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "metrics = [\"auc\", \"accuracy\", \"precision\", \"recall\"]\n",
    "model_b_vals = [results_b[m] for m in metrics]\n",
    "model_a_vals = [results_a[m] for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "axes[0].bar(x - width/2, model_b_vals, width, label=\"Model B (Quality)\")\n",
    "axes[0].bar(x + width/2, model_a_vals, width, label=\"Model A (MuQ)\")\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics)\n",
    "axes[0].set_ylabel(\"Score\")\n",
    "axes[0].set_title(\"Model Comparison\")\n",
    "axes[0].legend()\n",
    "axes[0].axhline(y=0.5, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Qualitative: worst false negatives (teacher stopped but model said continue)\n",
    "print(\"\\n--- False Negatives (Model B) ---\")\n",
    "fn = [s for s in results_b[\"per_segment\"] if s[\"y_true\"] == 1 and s[\"y_pred_proba\"] < 0.5]\n",
    "fn.sort(key=lambda s: s[\"y_pred_proba\"])\n",
    "for s in fn[:5]:\n",
    "    print(f\"  {s['segment_id']} (video {s['video_id']}): proba={s['y_pred_proba']:.3f}\")\n",
    "\n",
    "print(\"\\n--- False Positives (Model B) ---\")\n",
    "fp = [s for s in results_b[\"per_segment\"] if s[\"y_true\"] == 0 and s[\"y_pred_proba\"] > 0.5]\n",
    "fp.sort(key=lambda s: -s[\"y_pred_proba\"])\n",
    "for s in fp[:5]:\n",
    "    print(f\"  {s['segment_id']} (video {s['video_id']}): proba={s['y_pred_proba']:.3f}\")\n",
    "\n",
    "# Model B coefficient analysis\n",
    "print(\"\\n--- Model B: Which quality dimensions predict STOP? ---\")\n",
    "full_result = train_classifier(\n",
    "    X_quality, labels, list(range(len(labels))), list(range(len(labels)))\n",
    ")\n",
    "coefs = full_result[\"coefficients\"]\n",
    "sorted_idx = np.argsort(np.abs(coefs))[::-1]\n",
    "for i in sorted_idx:\n",
    "    print(f\"  {PERCEPIANO_DIMENSIONS[i]:25s}: {coefs[i]:+.3f}\")\n",
    "\n",
    "axes[1].barh(\n",
    "    range(19),\n",
    "    coefs[sorted_idx],\n",
    "    tick_label=[PERCEPIANO_DIMENSIONS[i] for i in sorted_idx],\n",
    ")\n",
    "axes[1].set_xlabel(\"Coefficient\")\n",
    "axes[1].set_title(\"Model B: Quality Dimension Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}