{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxonomy Derivation\n",
    "\n",
    "Discovers natural feedback categories from open-ended teacher descriptions via\n",
    "sentence-transformer embedding and HDBSCAN clustering, then scores, selects,\n",
    "and organizes them into a hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data/masterclass_pipeline\")\n",
    "CACHE_DIR = Path(\"data/masterclass_cache\")\n",
    "OUTPUT_DIR = Path(\"data/composite_labels\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load open-ended descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from masterclass_experiments.clustering import load_open_descriptions\n",
    "\n",
    "moment_ids, descriptions = load_open_descriptions(DATA_DIR / \"open_moments.jsonl\")\n",
    "print(f\"Loaded {len(descriptions)} open descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from masterclass_experiments.clustering import embed_descriptions, cluster_descriptions, summarize_clusters\n",
    "\n",
    "embeddings = embed_descriptions(descriptions)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "labels, clusterer = cluster_descriptions(embeddings, min_cluster_size=15)\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = (labels == -1).sum()\n",
    "print(f\"Found {n_clusters} clusters, {n_noise} noise points ({n_noise/len(labels)*100:.1f}%)\")\n",
    "\n",
    "summary = summarize_clusters(descriptions, labels)\n",
    "for s in summary:\n",
    "    print(f\"\\nCluster {s['cluster_id']} (n={s['size']}, freq={s['frequency']:.1%}):\")\n",
    "    for ex in s['examples'][:5]:\n",
    "        print(f\"  - {ex}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "coords = reducer.fit_transform(embeddings)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "scatter = ax.scatter(coords[:, 0], coords[:, 1], c=labels, cmap='tab20', s=10, alpha=0.6)\n",
    "ax.set_title(\"HDBSCAN Clusters of Teaching Moment Descriptions\")\n",
    "plt.colorbar(scatter, label=\"Cluster ID\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUTPUT_DIR / \"cluster_umap.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-signal scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from masterclass_experiments.scoring import (\n",
    "    compute_teacher_frequency,\n",
    "    compute_muq_predictability,\n",
    "    select_dimensions,\n",
    "    PERCEPIANO_MUQ_R2,\n",
    ")\n",
    "\n",
    "freq = compute_teacher_frequency(labels)\n",
    "print(\"Teacher frequency per cluster:\")\n",
    "for cid, f in sorted(freq.items()):\n",
    "    print(f\"  Cluster {cid}: {f:.1%}\")\n",
    "\n",
    "# Manual step: after reviewing cluster examples, define PercePiano mappings\n",
    "# This dict maps cluster_id -> list of PercePiano dimension names\n",
    "# Fill in after reviewing Cell 3 output\n",
    "PP_MAPPING = {\n",
    "    # Example (fill in based on cluster review):\n",
    "    # 0: [\"dynamic_range\"],\n",
    "    # 1: [\"pedal_amount\", \"pedal_clarity\"],\n",
    "    # ...\n",
    "}\n",
    "\n",
    "muq_scores = compute_muq_predictability(PP_MAPPING, PERCEPIANO_MUQ_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP contribution (requires masterclass feature pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute STOP AUC delta per cluster.\n",
    "# For each cluster, compare STOP AUC with vs without that cluster's\n",
    "# PercePiano proxy dimensions in the feature vector.\n",
    "\n",
    "from masterclass_experiments.data import load_moments, identify_segments\n",
    "from masterclass_experiments.features import extract_muq_features, extract_quality_scores\n",
    "from masterclass_experiments.evaluation import leave_one_video_out_cv\n",
    "\n",
    "moments = load_moments(DATA_DIR / \"all_moments.jsonl\")\n",
    "segments = identify_segments(moments)\n",
    "\n",
    "# Load pre-computed features\n",
    "# ... (use existing muq_embeddings from masterclass_cache)\n",
    "# Compute STOP AUC with full 19-dim quality scores as baseline\n",
    "# Then for each cluster, zero out its proxy dims and re-compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection and hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build candidate scores dict and run selection\n",
    "candidates = {}\n",
    "for cid in freq:\n",
    "    candidates[cid] = {\n",
    "        \"frequency\": freq[cid],\n",
    "        \"muq_r2\": muq_scores.get(cid, 0.0),\n",
    "        \"stop_delta_auc\": 0.0,  # Fill from Cell 6\n",
    "    }\n",
    "\n",
    "kept, dropped = select_dimensions(candidates)\n",
    "print(f\"\\nKept {len(kept)} dimensions, dropped {len(dropped)}\")\n",
    "for cid, scores in kept.items():\n",
    "    print(f\"  Cluster {cid}: freq={scores['frequency']:.1%}, muq_r2={scores['muq_r2']:.3f}\")\n",
    "\n",
    "# Build hierarchy from kept clusters\n",
    "from masterclass_experiments.scoring import build_hierarchy\n",
    "\n",
    "kept_dims = []\n",
    "for cid in kept:\n",
    "    mask = labels == cid\n",
    "    centroid = embeddings[mask].mean(axis=0)\n",
    "    kept_dims.append({\"name\": f\"cluster_{cid}\", \"centroid\": centroid})  # Rename after review\n",
    "\n",
    "hierarchy = build_hierarchy(kept_dims, n_groups=4)\n",
    "print(\"\\nHierarchy:\")\n",
    "for group in hierarchy:\n",
    "    print(f\"  {group['group_name']}: {group['dimensions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name dimensions and build quote bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from masterclass_experiments.quote_bank import build_quote_bank\n",
    "\n",
    "# Manual step: name each kept cluster based on review\n",
    "# DIMENSION_NAMES = {cluster_id: \"human_readable_name\", ...}\n",
    "# Fill in after reviewing clusters\n",
    "\n",
    "# Build moment -> dimension assignments\n",
    "open_moments = []\n",
    "with open(DATA_DIR / \"open_moments.jsonl\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            open_moments.append(json.loads(line))\n",
    "\n",
    "assignments = {}\n",
    "for mid, label in zip(moment_ids, labels):\n",
    "    if label >= 0 and label in kept:\n",
    "        # assignments[mid] = DIMENSION_NAMES[label]\n",
    "        assignments[mid] = f\"dim_{label}\"  # Replace with real names\n",
    "\n",
    "bank = build_quote_bank(open_moments, assignments)\n",
    "for dim, quotes in bank.items():\n",
    "    print(f\"\\n{dim}: {len(quotes)} quotes\")\n",
    "    for q in quotes[:3]:\n",
    "        print(f\"  [{q['severity']}] {q['teacher']}: {q['feedback_summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save taxonomy artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_output = {\n",
    "    \"dimensions\": {},  # Fill with final named dimensions + descriptions\n",
    "    \"hierarchy\": hierarchy,\n",
    "    \"cluster_summary\": summary,\n",
    "    \"selection_scores\": {str(k): v for k, v in candidates.items()},\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / \"dimension_definitions.json\", \"w\") as f:\n",
    "    json.dump(taxonomy_output, f, indent=2)\n",
    "\n",
    "with open(OUTPUT_DIR / \"quote_bank.json\", \"w\") as f:\n",
    "    json.dump(bank, f, indent=2)\n",
    "\n",
    "print(f\"Saved to {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}