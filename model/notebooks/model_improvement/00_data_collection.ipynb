{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 00: Data Collection (T2, T3, T4)\n",
    "\n",
    "Run on Thunder Compute (A100, 500GB storage). Downloads raw audio, segments into\n",
    "30s clips, extracts MuQ embeddings, then syncs only embeddings + metadata back to\n",
    "GDrive. Raw audio is discarded after processing.\n",
    "\n",
    "**Tiers:**\n",
    "- **T2** Competition: Chopin 2021 -- ordinal ranking signal (~2,000 segments, ~760MB embeddings)\n",
    "- **T3** MAESTRO audio: cross-performer contrastive signal (~10,000 segments, ~3.8GB embeddings)\n",
    "- **T4** YouTube piano: augmentation invariance signal (~50,000 segments, ~38GB embeddings) -- optional, run if needed\n",
    "\n",
    "**Storage budget on remote:**\n",
    "- MAESTRO audio download: ~200GB (temporary)\n",
    "- Competition audio: ~50GB (temporary)\n",
    "- YouTube audio: ~100GB (temporary, only if running T4)\n",
    "- Embeddings to keep: ~4.6GB (T2+T3) or ~42GB (T2+T3+T4)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E '(successfully|already)' || echo 'rclone installed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Jai-Dhiman/crescendAI.git /workspace/crescendai\n",
    "%cd /workspace/crescendai/model\n",
    "\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "!uv pip install -e /workspace/crescendai/model --python {sys.executable} --system\n",
    "!apt-get update && apt-get install -y ffmpeg\n",
    "os.environ[\"HF_TOKEN\"] = \"\"\n",
    "\n",
    "# Sync existing data from GDrive (percepiano labels, pretrain cache metadata, etc.)\n",
    "!rclone copy gdrive:crescendai_data/model_improvement/data/percepiano_cache ./data/percepiano_cache --progress\n",
    "!rclone copy gdrive:crescendai_data/model_improvement/data/percepiano_midi ./data/percepiano_midi --progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    ")\n",
    "\n",
    "DATA_DIR = Path('/workspace/crescendai/model/data')\n",
    "print(f'Data directory: {DATA_DIR}')\n",
    "print('GPU: ', end='')\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. T2: Competition Recordings (Chopin 2021)\n",
    "\n",
    "Scrapes metadata from Wikipedia, discovers YouTube URLs from Chopin Institute\n",
    "playlists, downloads audio, segments into 30s clips, extracts MuQ embeddings.\n",
    "\n",
    "**Expected output:** ~2,000 segments, ~760MB embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_improvement.competition import (\n",
    "    scrape_chopin_results,\n",
    "    discover_youtube_urls,\n",
    "    download_competition_audio,\n",
    "    segment_and_embed_competition,\n",
    "    load_competition_metadata,\n",
    ")\n",
    "from model_improvement.data import CompetitionPairSampler\n",
    "\n",
    "comp_cache = DATA_DIR / 'competition_cache' / 'chopin2021'\n",
    "comp_metadata = comp_cache / 'recordings.jsonl'\n",
    "\n",
    "print('Step 1: Scraping competition results...')\n",
    "results = scrape_chopin_results(comp_cache)\n",
    "print(f'Found {len(results)} performers')\n",
    "\n",
    "print('Step 2: Discovering YouTube URLs...')\n",
    "url_mapping = discover_youtube_urls(comp_cache, results)\n",
    "total_videos = sum(len(vids) for rounds in url_mapping.values() for vids in rounds.values())\n",
    "print(f'Found {total_videos} videos for {len(url_mapping)} performers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Download audio\n",
    "print('Step 3: Downloading audio...')\n",
    "records = download_competition_audio(url_mapping, results, comp_cache, comp_metadata)\n",
    "print(f'Downloaded {len(records)} new recordings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Segment and extract MuQ embeddings\n",
    "print('Step 4: Segmenting and extracting MuQ embeddings...')\n",
    "n_segments = segment_and_embed_competition(comp_cache)\n",
    "print(f'Processed {n_segments} new segments')\n",
    "\n",
    "# Summary\n",
    "all_records = load_competition_metadata(comp_cache)\n",
    "emb_dir = comp_cache / 'muq_embeddings'\n",
    "n_emb = len(list(emb_dir.glob('*.pt'))) if emb_dir.exists() else 0\n",
    "print(f'Total metadata records: {len(all_records)}')\n",
    "print(f'Total MuQ embeddings: {n_emb}')\n",
    "\n",
    "if all_records:\n",
    "    sampler = CompetitionPairSampler(all_records)\n",
    "    print(f'Within-piece pairs: {sampler.n_within_piece_pairs}')\n",
    "    print(f'Cross-round pairs: {sampler.n_cross_round_pairs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync T2 embeddings + metadata to GDrive (not raw audio)\n",
    "!rclone copy {comp_cache}/metadata.jsonl gdrive:crescendai_data/model_improvement/data/competition_cache/chopin2021/ --progress\n",
    "!rclone copy {comp_cache}/recordings.jsonl gdrive:crescendai_data/model_improvement/data/competition_cache/chopin2021/ --progress\n",
    "!rclone sync {comp_cache}/muq_embeddings/ gdrive:crescendai_data/model_improvement/data/competition_cache/chopin2021/muq_embeddings/ --progress\n",
    "print('T2 synced to GDrive')\n",
    "\n",
    "# Delete raw audio to free space for T3\n",
    "import shutil\n",
    "audio_dir = comp_cache / 'audio'\n",
    "if audio_dir.exists():\n",
    "    size_gb = sum(f.stat().st_size for f in audio_dir.rglob('*')) / 1e9\n",
    "    shutil.rmtree(audio_dir)\n",
    "    print(f'Deleted {size_gb:.1f}GB of raw competition audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 3. T3: MAESTRO Audio (Contrastive Learning)\n",
    "\n",
    "Downloads MAESTRO v3 audio (~200GB), segments into 30s clips, extracts MuQ\n",
    "embeddings, builds piece-performer contrastive mapping.\n",
    "\n",
    "**Expected output:** ~10,000 segments, ~3.8GB embeddings, ~150 contrastive pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MAESTRO v3 audio\n",
    "maestro_raw = DATA_DIR / 'maestro_raw'\n",
    "maestro_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "maestro_zip = maestro_raw / 'maestro-v3.0.0.zip'\n",
    "maestro_dir = maestro_raw / 'maestro-v3.0.0'\n",
    "\n",
    "if not maestro_dir.exists():\n",
    "    print('Downloading MAESTRO v3 audio (~200GB)... this will take a while.')\n",
    "    !wget -c -O {maestro_zip} https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0.zip\n",
    "    print('Extracting...')\n",
    "    !unzip -q {maestro_zip} -d {maestro_raw}\n",
    "    # Remove zip to free ~200GB\n",
    "    maestro_zip.unlink(missing_ok=True)\n",
    "    print('MAESTRO extracted, zip deleted')\n",
    "else:\n",
    "    print(f'MAESTRO already extracted at {maestro_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from model_improvement.maestro import (\n",
    "    parse_maestro_audio_metadata,\n",
    "    segment_and_embed_maestro,\n",
    "    build_piece_performer_mapping,\n",
    ")\n",
    "\n",
    "maestro_cache = DATA_DIR / 'maestro_cache'\n",
    "\n",
    "# Step 1: Parse metadata\n",
    "print('Step 1: Parsing MAESTRO metadata...')\n",
    "records = parse_maestro_audio_metadata(maestro_dir)\n",
    "n_exists = sum(1 for r in records if (maestro_dir / r['audio_filename']).exists())\n",
    "print(f'Found {len(records)} records, {n_exists} audio files on disk')\n",
    "\n",
    "if n_exists == 0:\n",
    "    raise FileNotFoundError('No MAESTRO audio files found. Check download.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Segment and extract MuQ embeddings\n",
    "print('Step 2: Segmenting and extracting MuQ embeddings...')\n",
    "n_segments = segment_and_embed_maestro(maestro_dir, maestro_cache, segment_duration=30.0)\n",
    "print(f'Processed {n_segments} new segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build contrastive mapping\n",
    "print('Step 3: Building contrastive mapping...')\n",
    "mapping = build_piece_performer_mapping(maestro_cache)\n",
    "print(f'Contrastive pairs: {len(mapping)} pieces with 2+ recordings')\n",
    "print(f'Total segments in contrastive set: {sum(len(v) for v in mapping.values())}')\n",
    "\n",
    "mapping_path = maestro_cache / 'contrastive_mapping.json'\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump(mapping, f, indent=2)\n",
    "print(f'Saved mapping to {mapping_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync T3 embeddings + metadata to GDrive\n",
    "!rclone copy {maestro_cache}/metadata.jsonl gdrive:crescendai_data/model_improvement/data/maestro_cache/ --progress\n",
    "!rclone copy {maestro_cache}/contrastive_mapping.json gdrive:crescendai_data/model_improvement/data/maestro_cache/ --progress\n",
    "!rclone sync {maestro_cache}/muq_embeddings/ gdrive:crescendai_data/model_improvement/data/maestro_cache/muq_embeddings/ --progress\n",
    "print('T3 synced to GDrive')\n",
    "\n",
    "# Delete MAESTRO raw audio to free ~200GB\n",
    "import shutil\n",
    "if maestro_raw.exists():\n",
    "    print('Deleting MAESTRO raw audio...')\n",
    "    shutil.rmtree(maestro_raw)\n",
    "    print('Deleted MAESTRO raw audio (~200GB freed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 4. T4: YouTube Piano (Optional)\n",
    "\n",
    "**Only run this section if robustness metrics fall below target** (augmented pairwise\n",
    "accuracy drop > 10% or cross-condition Pearson r < 0.9). T4 is additive.\n",
    "\n",
    "Downloads audio from 22 curated YouTube channels, segments, extracts clean + augmented\n",
    "MuQ embedding pairs.\n",
    "\n",
    "**Expected output:** ~50,000 segments, ~38GB embeddings (clean + augmented)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_improvement.youtube_piano import (\n",
    "    load_channel_list,\n",
    "    discover_channel_videos,\n",
    "    download_piano_audio,\n",
    "    segment_and_embed_piano,\n",
    ")\n",
    "from model_improvement.augmentation import augment_and_embed_piano\n",
    "\n",
    "yt_cache = DATA_DIR / 'youtube_piano_cache'\n",
    "channels_file = yt_cache / 'channels.yaml'\n",
    "\n",
    "# Step 1: Discover videos\n",
    "channels = load_channel_list(channels_file)\n",
    "print(f'Loaded {len(channels)} channels')\n",
    "\n",
    "all_videos = []\n",
    "for ch in channels:\n",
    "    videos = discover_channel_videos(ch['url'], max_videos=100)\n",
    "    for v in videos:\n",
    "        v['channel'] = ch['name']\n",
    "    all_videos.extend(videos)\n",
    "    print(f'  {ch[\"name\"]}: {len(videos)} videos')\n",
    "print(f'Total videos: {len(all_videos)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Download audio\n",
    "records = download_piano_audio(all_videos, yt_cache)\n",
    "print(f'Downloaded {len(records)} new recordings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Segment and extract clean MuQ embeddings\n",
    "n = segment_and_embed_piano(yt_cache)\n",
    "print(f'Processed {n} new segments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate augmented embeddings\n",
    "n_aug = augment_and_embed_piano(yt_cache)\n",
    "print(f'Generated {n_aug} augmented embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Sync T4 to GDrive and cleanup\n",
    "!rclone copy {yt_cache}/metadata.jsonl gdrive:crescendai_data/model_improvement/data/youtube_piano_cache/ --progress\n",
    "!rclone copy {yt_cache}/recordings.jsonl gdrive:crescendai_data/model_improvement/data/youtube_piano_cache/ --progress\n",
    "!rclone sync {yt_cache}/muq_embeddings/ gdrive:crescendai_data/model_improvement/data/youtube_piano_cache/muq_embeddings/ --progress\n",
    "!rclone sync {yt_cache}/muq_embeddings_augmented/ gdrive:crescendai_data/model_improvement/data/youtube_piano_cache/muq_embeddings_augmented/ --progress\n",
    "print('T4 synced to GDrive')\n",
    "\n",
    "# Delete raw audio\n",
    "import shutil\n",
    "audio_dir = yt_cache / 'audio'\n",
    "if audio_dir.exists():\n",
    "    shutil.rmtree(audio_dir)\n",
    "    print('Deleted YouTube raw audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print('Data Collection Summary')\n",
    "print('=' * 60)\n",
    "\n",
    "# T2\n",
    "comp_emb = DATA_DIR / 'competition_cache' / 'chopin2021' / 'muq_embeddings'\n",
    "n_comp = len(list(comp_emb.glob('*.pt'))) if comp_emb.exists() else 0\n",
    "print(f'T2 Competition embeddings: {n_comp}')\n",
    "\n",
    "# T3\n",
    "maestro_emb = DATA_DIR / 'maestro_cache' / 'muq_embeddings'\n",
    "n_maestro = len(list(maestro_emb.glob('*.pt'))) if maestro_emb.exists() else 0\n",
    "maestro_map = DATA_DIR / 'maestro_cache' / 'contrastive_mapping.json'\n",
    "n_contrastive = 0\n",
    "if maestro_map.exists():\n",
    "    import json\n",
    "    with open(maestro_map) as f:\n",
    "        n_contrastive = len(json.load(f))\n",
    "print(f'T3 MAESTRO embeddings: {n_maestro} ({n_contrastive} contrastive pieces)')\n",
    "\n",
    "# T4\n",
    "yt_emb = DATA_DIR / 'youtube_piano_cache' / 'muq_embeddings'\n",
    "yt_aug = DATA_DIR / 'youtube_piano_cache' / 'muq_embeddings_augmented'\n",
    "n_yt = len(list(yt_emb.glob('*.pt'))) if yt_emb.exists() else 0\n",
    "n_yt_aug = len(list(yt_aug.glob('*.pt'))) if yt_aug.exists() else 0\n",
    "print(f'T4 YouTube clean embeddings: {n_yt}')\n",
    "print(f'T4 YouTube augmented embeddings: {n_yt_aug}')\n",
    "\n",
    "print()\n",
    "print('GDrive contents after sync:')\n",
    "!rclone lsd gdrive:crescendai_data/model_improvement/data/ 2>/dev/null\n",
    "print()\n",
    "!rclone size gdrive:crescendai_data/model_improvement/data/ 2>/dev/null\n",
    "\n",
    "print()\n",
    "print('Local disk usage:')\n",
    "!du -sh {DATA_DIR}/*/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
