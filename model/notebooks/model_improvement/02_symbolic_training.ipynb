{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Symbolic Encoder Training (S1, S2, S3)\n",
    "\n",
    "Train three symbolic encoder strategies on Thunder Compute:\n",
    "- **S1**: BERT-style Transformer on REMI tokens (TransformerSymbolicEncoder)\n",
    "- **S2**: GNN on score graph (GNNSymbolicEncoder)\n",
    "- **S3**: 1D-CNN + Transformer on continuous features (ContinuousSymbolicEncoder)\n",
    "\n",
    "Each model has a pretrain stage (self-supervised) and finetune stage (supervised ranking).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Jai-Dhiman/crescendAI.git /workspace/crescendai\n",
    "%cd /workspace/crescendai/model\n",
    "\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!uv sync\n",
    "\n",
    "!rclone sync gdrive:crescendai_data/model_improvement/data ./data --progress\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "IS_REMOTE = os.environ.get('THUNDER_COMPUTE', False)\n",
    "if IS_REMOTE:\n",
    "    DATA_DIR = Path('/workspace/crescendai/model/data')\n",
    "    CHECKPOINT_DIR = Path('/workspace/crescendai/model/checkpoints/model_improvement')\n",
    "else:\n",
    "    DATA_DIR = Path('../data')\n",
    "    CHECKPOINT_DIR = Path('../checkpoints/model_improvement')\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport numpy as np\nimport torch\nimport pytorch_lightning as pl\nfrom functools import partial\nfrom torch.utils.data import DataLoader\n\nsys.path.insert(0, 'src')\n\nfrom model_improvement.symbolic_encoders import (\n    TransformerSymbolicEncoder,\n    GNNSymbolicEncoder,\n    GNNHeteroSymbolicEncoder,\n    ContinuousSymbolicEncoder,\n)\nfrom model_improvement.tokenizer import PianoTokenizer, extract_continuous_features\nfrom model_improvement.data import (\n    MIDIPretrainingDataset,\n    PairedPerformanceDataset,\n    ScoreGraphPretrainingDataset,\n    ContinuousPretrainDataset,\n    HeteroPretrainDataset,\n    graph_pair_collate_fn,\n    symbolic_collate_fn,\n    continuous_collate_fn,\n    hetero_graph_collate_fn,\n    multi_task_collate_fn,\n)\nfrom model_improvement.graph import midi_to_graph, midi_to_hetero_graph\nfrom model_improvement.training import train_model, upload_checkpoint"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = DATA_DIR / 'percepiano_cache'\n",
    "\n",
    "with open(cache_dir / 'labels.json') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "with open(cache_dir / 'folds.json') as f:\n",
    "    folds = json.load(f)\n",
    "\n",
    "with open(cache_dir / 'piece_mapping.json') as f:\n",
    "    piece_to_keys = json.load(f)\n",
    "\n",
    "midi_dir = DATA_DIR / 'percepiano_midi'\n",
    "\n",
    "print(f'Loaded {len(labels)} labeled segments')\n",
    "print(f'Folds: {len(folds)}')\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f'  Fold {i}: {len(fold[\"train\"])} train, {len(fold[\"val\"])} val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Symbolic Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Loading pretrain cache for S1 (tokenized sequences)...')\n\npretrain_dir = DATA_DIR / 'pretrain_cache'\nif not pretrain_dir.exists():\n    raise FileNotFoundError(\n        f'Pretrain cache not found at {pretrain_dir}. '\n        'Run 00_data_preparation.ipynb first, or sync from GDrive.'\n    )\n\nall_tokens = torch.load(pretrain_dir / 'tokens' / 'all_tokens.pt', map_location='cpu', weights_only=False)\nprint(f'Loaded {len(all_tokens)} tokenized sequences for pretraining')\n\n# PercePiano tokens for finetune (strip prefix for label compatibility)\ntoken_sequences = {k.replace('percepiano__', ''): v for k, v in all_tokens.items() if k.startswith('percepiano__')}\n\n# Full pretrain corpus as a flat list (all sources)\npretrain_token_list = list(all_tokens.values())\n\ntokenizer = PianoTokenizer(max_seq_len=2048)  # for vocab_size\nprint(f'PercePiano: {len(token_sequences)}, Total pretrain: {len(pretrain_token_list)}')\nprint(f'Vocab size: {tokenizer.vocab_size}')\nprint(f'Average sequence length: {np.mean([len(t) for t in token_sequences.values()]):.0f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Loading pretrain cache for S3 (continuous features)...')\n\nall_features = torch.load(pretrain_dir / 'features' / 'all_features.pt', map_location='cpu', weights_only=False)\nprint(f'Loaded {len(all_features)} continuous feature sets for pretraining')\n\n# PercePiano features for finetune\ncontinuous_features = {k.replace('percepiano__', ''): v for k, v in all_features.items() if k.startswith('percepiano__')}\n\n# Full pretrain corpus: keys and dict for ContinuousPretrainDataset\npretrain_feature_keys = list(all_features.keys())\npretrain_features_dict = all_features\n\nprint(f'PercePiano: {len(continuous_features)}, Total pretrain: {len(pretrain_feature_keys)}')\nif continuous_features:\n    sample = next(iter(continuous_features.values()))\n    print(f'Feature shape: {sample.shape} (T, D={sample.shape[1]})')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Loading pretrain cache for S2 (score graphs)...')\n\nall_graphs = torch.load(pretrain_dir / 'graphs' / 'all_graphs.pt', map_location='cpu', weights_only=False)\nall_hetero = torch.load(pretrain_dir / 'graphs' / 'all_hetero_graphs.pt', map_location='cpu', weights_only=False)\nprint(f'Loaded {len(all_graphs)} graphs and {len(all_hetero)} hetero graphs for pretraining')\n\n# PercePiano graphs for finetune\nscore_graphs = {k.replace('percepiano__', ''): v for k, v in all_graphs.items() if k.startswith('percepiano__')}\nhetero_graphs = {k.replace('percepiano__', ''): v for k, v in all_hetero.items() if k.startswith('percepiano__')}\n\n# Full pretrain corpus for ScoreGraphPretrainingDataset / HeteroPretrainDataset\npretrain_graph_list = list(all_graphs.values())\npretrain_graph_keys = list(all_graphs.keys())\n\nprint(f'PercePiano: {len(score_graphs)} graphs, Total pretrain: {len(pretrain_graph_list)}')\nif score_graphs:\n    sample = next(iter(score_graphs.values()))\n    print(f'Sample graph: {sample.x.shape[0]} nodes, {sample.edge_index.shape[1]} edges')\n    print(f'Node features: {sample.x.shape[1]}')\n    edge_types = sample.edge_type.unique().tolist()\n    type_names = {0: 'onset', 1: 'during', 2: 'follow', 3: 'silence'}\n    for t in edge_types:\n        count = (sample.edge_type == t).sum().item()\n        print(f'  {type_names.get(t, t)}: {count} edges')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# train_model and upload_checkpoint imported from model_improvement.training\n# train_model now takes checkpoint_dir as an explicit parameter\nprint(f'Checkpoint dir: {CHECKPOINT_DIR}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train S1: Transformer on REMI Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import random\n\nS1_CONFIG = {\n    'vocab_size': tokenizer.vocab_size + 1,  # +1 for mask token\n    'd_model': 512,\n    'nhead': 8,\n    'num_layers': 6,\n    'hidden_dim': 512,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS = 50\nFINETUNE_EPOCHS = 150\n\nprint('Training S1: Transformer on REMI Tokens')\nprint('=' * 50)\n\n# --- Pretrain once on full corpus (all sources) ---\nprint(f'\\nPretraining on {len(pretrain_token_list)} sequences from full corpus')\n\nrandom.seed(42)\nrandom.shuffle(pretrain_token_list)\nsplit = int(0.95 * len(pretrain_token_list))\npt_train_tokens = pretrain_token_list[:split]\npt_val_tokens = pretrain_token_list[split:]\n\npretrain_ds = MIDIPretrainingDataset(\n    token_sequences=pt_train_tokens,\n    max_seq_len=2048,\n    mask_prob=0.15,\n    vocab_size=tokenizer.vocab_size,\n)\npretrain_val_ds = MIDIPretrainingDataset(\n    token_sequences=pt_val_tokens,\n    max_seq_len=2048,\n    mask_prob=0.15,\n    vocab_size=tokenizer.vocab_size,\n)\n\npretrain_loader = DataLoader(pretrain_ds, batch_size=8, shuffle=True, num_workers=2)\npretrain_val_loader = DataLoader(pretrain_val_ds, batch_size=8, shuffle=False, num_workers=2)\n\nmodel = TransformerSymbolicEncoder(**S1_CONFIG, stage='pretrain')\ntrainer_pt = train_model(\n    model, pretrain_loader, pretrain_val_loader,\n    'S1_pretrain', fold_idx=0, checkpoint_dir=CHECKPOINT_DIR,\n    max_epochs=PRETRAIN_EPOCHS, monitor='val_mlm_loss',\n    upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n)\npretrained_s1_state = model.state_dict()\nprint(f'  Pretrain complete. Saved {len(pretrained_s1_state)} parameters.')\n\n# --- Finetune per-fold on PercePiano ---\ns1_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}: Finetune on PercePiano')\n\n    model = TransformerSymbolicEncoder(**S1_CONFIG, stage='finetune')\n    model.load_state_dict(pretrained_s1_state, strict=False)\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in token_sequences],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in token_sequences],\n    )\n\n    collate = partial(symbolic_collate_fn, token_sequences=token_sequences)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S1', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s1_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train S2: GNN on Score Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "S2_CONFIG = {\n    'node_features': 6,\n    'hidden_dim': 512,\n    'num_layers': 4,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS_S2 = 50\nFINETUNE_EPOCHS_S2 = 150\n\nprint('Training S2: GNN on Score Graph')\nprint('=' * 50)\n\nfrom torch_geometric.loader import DataLoader as PyGDataLoader\n\n# --- Pretrain once on full corpus ---\nprint(f'\\nPretraining on {len(pretrain_graph_list)} graphs from full corpus')\n\nrandom.seed(42)\nrandom.shuffle(pretrain_graph_list)\nsplit_s2 = int(0.95 * len(pretrain_graph_list))\n\npretrain_ds = ScoreGraphPretrainingDataset(pretrain_graph_list[:split_s2], mask_fraction=0.15)\npretrain_val_ds = ScoreGraphPretrainingDataset(pretrain_graph_list[split_s2:], mask_fraction=0.15)\n\npretrain_loader = PyGDataLoader(pretrain_ds, batch_size=8, shuffle=True, num_workers=2)\npretrain_val_loader = PyGDataLoader(pretrain_val_ds, batch_size=8, shuffle=False, num_workers=2)\n\nmodel = GNNSymbolicEncoder(**S2_CONFIG, stage='pretrain')\ntrainer_pt = train_model(\n    model, pretrain_loader, pretrain_val_loader,\n    'S2_pretrain', fold_idx=0, checkpoint_dir=CHECKPOINT_DIR,\n    max_epochs=PRETRAIN_EPOCHS_S2, monitor='val_link_loss',\n    upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n)\npretrained_s2_state = model.state_dict()\nprint(f'  Pretrain complete. Saved {len(pretrained_s2_state)} parameters.')\n\n# --- Finetune per-fold on PercePiano ---\ns2_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}: Finetune on PercePiano')\n\n    model = GNNSymbolicEncoder(**S2_CONFIG, stage='finetune')\n    model.load_state_dict(pretrained_s2_state, strict=False)\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in score_graphs],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in score_graphs],\n    )\n\n    graph_collate = partial(graph_pair_collate_fn, graphs=score_graphs)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=graph_collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=graph_collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S2', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS_S2,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s2_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')"
  },
  {
   "cell_type": "markdown",
   "source": "## 6b. Train S2-hetero: Heterogeneous GNN on Score Graph",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "S2H_CONFIG = {\n    'node_features': 6,\n    'hidden_dim': 512,\n    'num_layers': 3,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS_S2H = 50\nFINETUNE_EPOCHS_S2H = 150\n\nprint('Training S2-hetero: Heterogeneous GNN on Score Graph')\nprint('=' * 50)\n\n# --- Pretrain once on full corpus ---\nprint(f'\\nPretraining on {len(pretrain_graph_keys)} hetero graphs from full corpus')\n\nrandom.seed(42)\nrandom.shuffle(pretrain_graph_keys)\nsplit_s2h = int(0.95 * len(pretrain_graph_keys))\npt_train_keys = pretrain_graph_keys[:split_s2h]\npt_val_keys = pretrain_graph_keys[split_s2h:]\n\npretrain_ds = HeteroPretrainDataset(pt_train_keys, all_graphs, all_hetero)\npretrain_val_ds = HeteroPretrainDataset(pt_val_keys, all_graphs, all_hetero)\n\n# batch_size=1 required: HeteroPretrainDataset returns nested dicts that\n# default collation cannot batch. Use num_workers=0 accordingly.\npretrain_loader = DataLoader(pretrain_ds, batch_size=1, shuffle=True, num_workers=0)\npretrain_val_loader = DataLoader(pretrain_val_ds, batch_size=1, shuffle=False, num_workers=0)\n\nmodel = GNNHeteroSymbolicEncoder(**S2H_CONFIG, stage='pretrain')\ntrainer_pt = train_model(\n    model, pretrain_loader, pretrain_val_loader,\n    'S2H_pretrain', fold_idx=0, checkpoint_dir=CHECKPOINT_DIR,\n    max_epochs=PRETRAIN_EPOCHS_S2H, monitor='val_link_loss',\n    upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n)\npretrained_s2h_state = model.state_dict()\nprint(f'  Pretrain complete. Saved {len(pretrained_s2h_state)} parameters.')\n\n# --- Finetune per-fold on PercePiano ---\ns2h_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}: Finetune on PercePiano')\n\n    model = GNNHeteroSymbolicEncoder(**S2H_CONFIG, stage='finetune')\n    model.load_state_dict(pretrained_s2h_state, strict=False)\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in hetero_graphs],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in hetero_graphs],\n    )\n\n    collate = partial(hetero_graph_collate_fn, hetero_graphs=hetero_graphs)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S2H', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS_S2H,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s2h_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train S3: Continuous Feature Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "S3_CONFIG = {\n    'input_channels': 5,  # pitch, velocity, density, pedal, IOI\n    'hidden_dim': 512,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS_S3 = 50\nFINETUNE_EPOCHS_S3 = 150\n\nprint('Training S3: Continuous Feature Encoder')\nprint('=' * 50)\n\n# --- Pretrain once on full corpus ---\nprint(f'\\nPretraining on {len(pretrain_feature_keys)} feature sets from full corpus')\n\nrandom.seed(42)\nrandom.shuffle(pretrain_feature_keys)\nsplit_s3 = int(0.95 * len(pretrain_feature_keys))\npt_train_keys_s3 = pretrain_feature_keys[:split_s3]\npt_val_keys_s3 = pretrain_feature_keys[split_s3:]\n\npretrain_ds = ContinuousPretrainDataset(pt_train_keys_s3, pretrain_features_dict)\npretrain_val_ds = ContinuousPretrainDataset(pt_val_keys_s3, pretrain_features_dict)\n\npretrain_loader = DataLoader(pretrain_ds, batch_size=8, shuffle=True, num_workers=2)\npretrain_val_loader = DataLoader(pretrain_val_ds, batch_size=8, shuffle=False, num_workers=2)\n\nmodel = ContinuousSymbolicEncoder(**S3_CONFIG, stage='pretrain')\ntrainer_pt = train_model(\n    model, pretrain_loader, pretrain_val_loader,\n    'S3_pretrain', fold_idx=0, checkpoint_dir=CHECKPOINT_DIR,\n    max_epochs=PRETRAIN_EPOCHS_S3, monitor='val_contrastive_loss',\n    upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n)\npretrained_s3_state = model.state_dict()\nprint(f'  Pretrain complete. Saved {len(pretrained_s3_state)} parameters.')\n\n# --- Finetune per-fold on PercePiano ---\ns3_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}: Finetune on PercePiano')\n\n    model = ContinuousSymbolicEncoder(**S3_CONFIG, stage='finetune')\n    model.load_state_dict(pretrained_s3_state, strict=False)\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in continuous_features],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in continuous_features],\n    )\n\n    collate = partial(continuous_collate_fn, features_dict=continuous_features)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S3', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS_S3,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s3_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Symbolic Encoder Training Summary')\nprint('=' * 60)\nprint(f'Pretrain corpus: {len(pretrain_token_list)} sequences (ASAP + MAESTRO + ATEPP + PercePiano)')\nprint(f'Finetune corpus: {len(token_sequences)} PercePiano sequences')\nprint()\nprint(f'{\"Model\":<12} {\"Fold\":<6} {\"Val Loss\":<12} {\"Pairwise Acc\":<14}')\nprint('-' * 60)\n\nfor name, trainers in [('S1', s1_trainers), ('S2', s2_trainers), ('S2-hetero', s2h_trainers), ('S3', s3_trainers)]:\n    for fold_idx, trainer in enumerate(trainers):\n        val_loss = trainer.callback_metrics.get('val_loss', float('nan'))\n        val_acc = trainer.callback_metrics.get('val_pairwise_acc', float('nan'))\n        print(f'{name:<12} {fold_idx:<6} {val_loss:<12.4f} {val_acc:<14.4f}')\n\nprint('\\nCheckpoints saved to:', CHECKPOINT_DIR)\nprint('Checkpoints synced to Google Drive via rclone')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Upload Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for model_name in ['S1', 'S1_pretrain', 'S2', 'S2_pretrain', 'S2H', 'S2H_pretrain', 'S3', 'S3_pretrain']:\n    local = CHECKPOINT_DIR / model_name\n    if local.exists():\n        upload_checkpoint(local, model_name)\n        print(f'Uploaded {model_name} checkpoints')\n\nprint('\\nAll symbolic encoder training complete.')\nprint('Run 04_symbolic_comparison.ipynb to evaluate and compare results.')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}