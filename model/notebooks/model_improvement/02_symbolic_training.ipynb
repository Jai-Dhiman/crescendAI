{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Symbolic Encoder Training (S1, S2, S3)\n",
    "\n",
    "Train three symbolic encoder strategies on Thunder Compute:\n",
    "- **S1**: BERT-style Transformer on REMI tokens (TransformerSymbolicEncoder)\n",
    "- **S2**: GNN on score graph (GNNSymbolicEncoder)\n",
    "- **S3**: 1D-CNN + Transformer on continuous features (ContinuousSymbolicEncoder)\n",
    "\n",
    "Each model has a pretrain stage (self-supervised) and finetune stage (supervised ranking).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Jai-Dhiman/crescendAI.git /workspace/crescendai\n",
    "%cd /workspace/crescendai/model\n",
    "\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!uv sync\n",
    "\n",
    "!rclone sync gdrive:crescendai_data/model_improvement/data ./data --progress\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "IS_REMOTE = os.environ.get('THUNDER_COMPUTE', False)\n",
    "if IS_REMOTE:\n",
    "    DATA_DIR = Path('/workspace/crescendai/model/data')\n",
    "    CHECKPOINT_DIR = Path('/workspace/crescendai/model/checkpoints/model_improvement')\n",
    "else:\n",
    "    DATA_DIR = Path('../data')\n",
    "    CHECKPOINT_DIR = Path('../checkpoints/model_improvement')\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport numpy as np\nimport torch\nimport pytorch_lightning as pl\nfrom functools import partial\nfrom torch.utils.data import DataLoader\n\nsys.path.insert(0, 'src')\n\nfrom model_improvement.symbolic_encoders import (\n    TransformerSymbolicEncoder,\n    GNNSymbolicEncoder,\n    GNNHeteroSymbolicEncoder,\n    ContinuousSymbolicEncoder,\n)\nfrom model_improvement.tokenizer import PianoTokenizer, extract_continuous_features\nfrom model_improvement.data import (\n    MIDIPretrainingDataset,\n    PairedPerformanceDataset,\n    ScoreGraphPretrainingDataset,\n    ContinuousPretrainDataset,\n    HeteroPretrainDataset,\n    graph_pair_collate_fn,\n    symbolic_collate_fn,\n    continuous_collate_fn,\n    hetero_graph_collate_fn,\n    multi_task_collate_fn,\n)\nfrom model_improvement.graph import midi_to_graph, midi_to_hetero_graph\nfrom model_improvement.training import train_model, upload_checkpoint"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = DATA_DIR / 'percepiano_cache'\n",
    "\n",
    "with open(cache_dir / 'labels.json') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "with open(cache_dir / 'folds.json') as f:\n",
    "    folds = json.load(f)\n",
    "\n",
    "with open(cache_dir / 'piece_mapping.json') as f:\n",
    "    piece_to_keys = json.load(f)\n",
    "\n",
    "midi_dir = DATA_DIR / 'percepiano_midi'\n",
    "\n",
    "print(f'Loaded {len(labels)} labeled segments')\n",
    "print(f'Folds: {len(folds)}')\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f'  Fold {i}: {len(fold[\"train\"])} train, {len(fold[\"val\"])} val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Symbolic Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tokenizing MIDI files for S1...')\n",
    "tokenizer = PianoTokenizer(max_seq_len=2048)\n",
    "\n",
    "token_sequences = {}\n",
    "for key in labels:\n",
    "    midi_path = midi_dir / f'{key}.mid'\n",
    "    if midi_path.exists():\n",
    "        tokens = tokenizer.encode(midi_path)\n",
    "        token_sequences[key] = tokens\n",
    "\n",
    "print(f'Tokenized {len(token_sequences)} MIDI files')\n",
    "print(f'Vocab size: {tokenizer.vocab_size}')\n",
    "print(f'Average sequence length: {np.mean([len(t) for t in token_sequences.values()]):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracting continuous features for S3...')\n",
    "\n",
    "continuous_features = {}\n",
    "for key in labels:\n",
    "    midi_path = midi_dir / f'{key}.mid'\n",
    "    if midi_path.exists():\n",
    "        features = extract_continuous_features(midi_path, frame_rate=50)\n",
    "        continuous_features[key] = torch.from_numpy(features).float()\n",
    "\n",
    "print(f'Extracted features for {len(continuous_features)} files')\n",
    "if continuous_features:\n",
    "    sample = next(iter(continuous_features.values()))\n",
    "    print(f'Feature shape: {sample.shape} (T, D={sample.shape[1]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Building score graphs for S2...')\n\nscore_graphs = {}\nhetero_graphs = {}\nfor key in labels:\n    midi_path = midi_dir / f'{key}.mid'\n    if midi_path.exists():\n        try:\n            score_graphs[key] = midi_to_graph(midi_path)\n            hetero_graphs[key] = midi_to_hetero_graph(midi_path)\n        except ValueError:\n            continue\n\nprint(f'Built graphs for {len(score_graphs)} MIDI files')\nif score_graphs:\n    sample = next(iter(score_graphs.values()))\n    print(f'Sample graph: {sample.x.shape[0]} nodes, {sample.edge_index.shape[1]} edges')\n    print(f'Node features: {sample.x.shape[1]}')\n    edge_types = sample.edge_type.unique().tolist()\n    type_names = {0: 'onset', 1: 'during', 2: 'follow', 3: 'silence'}\n    for t in edge_types:\n        count = (sample.edge_type == t).sum().item()\n        print(f'  {type_names.get(t, t)}: {count} edges')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# train_model and upload_checkpoint imported from model_improvement.training\n# train_model now takes checkpoint_dir as an explicit parameter\nprint(f'Checkpoint dir: {CHECKPOINT_DIR}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train S1: Transformer on REMI Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "S1_CONFIG = {\n    'vocab_size': tokenizer.vocab_size + 1,  # +1 for mask token\n    'd_model': 512,\n    'nhead': 8,\n    'num_layers': 6,\n    'hidden_dim': 512,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS = 50\nFINETUNE_EPOCHS = 150\n\nprint('Training S1: Transformer on REMI Tokens')\nprint('=' * 50)\n\ns1_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}')\n\n    # --- Pretrain: Masked Language Modeling ---\n    print('  Pretrain: Masked token prediction')\n\n    train_tokens = [token_sequences[k] for k in fold['train'] if k in token_sequences]\n    val_tokens = [token_sequences[k] for k in fold['val'] if k in token_sequences]\n\n    pretrain_ds = MIDIPretrainingDataset(\n        token_sequences=train_tokens,\n        max_seq_len=2048,\n        mask_prob=0.15,\n        vocab_size=tokenizer.vocab_size,\n    )\n    pretrain_val_ds = MIDIPretrainingDataset(\n        token_sequences=val_tokens,\n        max_seq_len=2048,\n        mask_prob=0.15,\n        vocab_size=tokenizer.vocab_size,\n    )\n\n    pretrain_loader = DataLoader(pretrain_ds, batch_size=8, shuffle=True, num_workers=2)\n    pretrain_val_loader = DataLoader(pretrain_val_ds, batch_size=8, shuffle=False, num_workers=2)\n\n    model = TransformerSymbolicEncoder(**S1_CONFIG, stage='pretrain')\n    trainer_pt = train_model(\n        model, pretrain_loader, pretrain_val_loader,\n        'S1_pretrain', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=PRETRAIN_EPOCHS, monitor='val_mlm_loss',\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n\n    # --- Finetune: Pairwise Ranking ---\n    print('  Finetune: Pairwise ranking')\n    model.stage = 'finetune'\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in token_sequences],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in token_sequences],\n    )\n\n    collate = partial(symbolic_collate_fn, token_sequences=token_sequences)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S1', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s1_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train S2: GNN on Score Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "S2_CONFIG = {\n    'node_features': 6,\n    'hidden_dim': 512,\n    'num_layers': 4,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS_S2 = 50\nFINETUNE_EPOCHS_S2 = 150\n\nprint('Training S2: GNN on Score Graph')\nprint('=' * 50)\n\nfrom torch_geometric.loader import DataLoader as PyGDataLoader\n\ns2_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}')\n\n    # --- Pretrain: Link Prediction ---\n    print('  Pretrain: Link prediction')\n\n    train_graphs = [score_graphs[k] for k in fold['train'] if k in score_graphs]\n    val_graphs = [score_graphs[k] for k in fold['val'] if k in score_graphs]\n\n    pretrain_ds = ScoreGraphPretrainingDataset(train_graphs, mask_fraction=0.15)\n    pretrain_val_ds = ScoreGraphPretrainingDataset(val_graphs, mask_fraction=0.15)\n\n    pretrain_loader = PyGDataLoader(pretrain_ds, batch_size=8, shuffle=True, num_workers=2)\n    pretrain_val_loader = PyGDataLoader(pretrain_val_ds, batch_size=8, shuffle=False, num_workers=2)\n\n    model = GNNSymbolicEncoder(**S2_CONFIG, stage='pretrain')\n    trainer_pt = train_model(\n        model, pretrain_loader, pretrain_val_loader,\n        'S2_pretrain', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=PRETRAIN_EPOCHS_S2, monitor='val_link_loss',\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n\n    # --- Finetune: Pairwise Ranking ---\n    print('  Finetune: Pairwise ranking')\n    model.stage = 'finetune'\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in score_graphs],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in score_graphs],\n    )\n\n    graph_collate = partial(graph_pair_collate_fn, graphs=score_graphs)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=graph_collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=graph_collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S2', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS_S2,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s2_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')"
  },
  {
   "cell_type": "markdown",
   "source": "## 6b. Train S2-hetero: Heterogeneous GNN on Score Graph",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "S2H_CONFIG = {\n    'node_features': 6,\n    'hidden_dim': 512,\n    'num_layers': 3,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS_S2H = 50\nFINETUNE_EPOCHS_S2H = 150\n\nprint('Training S2-hetero: Heterogeneous GNN on Score Graph')\nprint('=' * 50)\n\ns2h_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}')\n\n    # --- Pretrain: Link Prediction on hetero graphs ---\n    print('  Pretrain: Link prediction (heterogeneous)')\n\n    pretrain_ds = HeteroPretrainDataset(fold['train'], score_graphs, hetero_graphs)\n    pretrain_val_ds = HeteroPretrainDataset(fold['val'], score_graphs, hetero_graphs)\n\n    pretrain_loader = DataLoader(pretrain_ds, batch_size=1, shuffle=True, num_workers=0)\n    pretrain_val_loader = DataLoader(pretrain_val_ds, batch_size=1, shuffle=False, num_workers=0)\n\n    model = GNNHeteroSymbolicEncoder(**S2H_CONFIG, stage='pretrain')\n    trainer_pt = train_model(\n        model, pretrain_loader, pretrain_val_loader,\n        'S2H_pretrain', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=PRETRAIN_EPOCHS_S2H, monitor='val_link_loss',\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n\n    # --- Finetune: Pairwise ranking ---\n    print('  Finetune: Pairwise ranking (heterogeneous)')\n    model.stage = 'finetune'\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in hetero_graphs],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in hetero_graphs],\n    )\n\n    collate = partial(hetero_graph_collate_fn, hetero_graphs=hetero_graphs)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S2H', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS_S2H,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s2h_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train S3: Continuous Feature Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "S3_CONFIG = {\n    'input_channels': 5,  # pitch, velocity, density, pedal, IOI\n    'hidden_dim': 512,\n    'num_labels': 19,\n    'max_epochs': 200,\n}\n\nPRETRAIN_EPOCHS_S3 = 50\nFINETUNE_EPOCHS_S3 = 150\n\nprint('Training S3: Continuous Feature Encoder')\nprint('=' * 50)\n\ns3_trainers = []\nfor fold_idx, fold in enumerate(folds):\n    print(f'\\nFold {fold_idx}/{len(folds)-1}')\n\n    # --- Pretrain: Contrastive with Gumbel codebook ---\n    print('  Pretrain: Contrastive + codebook quantization')\n\n    train_keys = [k for k in fold['train'] if k in continuous_features]\n    val_keys = [k for k in fold['val'] if k in continuous_features]\n\n    pretrain_ds = ContinuousPretrainDataset(train_keys, continuous_features)\n    pretrain_val_ds = ContinuousPretrainDataset(val_keys, continuous_features)\n\n    pretrain_loader = DataLoader(pretrain_ds, batch_size=8, shuffle=True, num_workers=2)\n    pretrain_val_loader = DataLoader(pretrain_val_ds, batch_size=8, shuffle=False, num_workers=2)\n\n    model = ContinuousSymbolicEncoder(**S3_CONFIG, stage='pretrain')\n    trainer_pt = train_model(\n        model, pretrain_loader, pretrain_val_loader,\n        'S3_pretrain', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=PRETRAIN_EPOCHS_S3, monitor='val_contrastive_loss',\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n\n    # --- Finetune: Pairwise ranking ---\n    print('  Finetune: Pairwise ranking')\n    model.stage = 'finetune'\n\n    finetune_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['train'] if k in continuous_features],\n    )\n    finetune_val_ds = PairedPerformanceDataset(\n        cache_dir=cache_dir, labels=labels, piece_to_keys=piece_to_keys,\n        keys=[k for k in fold['val'] if k in continuous_features],\n    )\n\n    collate = partial(continuous_collate_fn, features_dict=continuous_features)\n    finetune_loader = DataLoader(finetune_ds, batch_size=8, shuffle=True, collate_fn=collate, num_workers=2)\n    finetune_val_loader = DataLoader(finetune_val_ds, batch_size=8, shuffle=False, collate_fn=collate, num_workers=2)\n\n    trainer_ft = train_model(\n        model, finetune_loader, finetune_val_loader,\n        'S3', fold_idx, checkpoint_dir=CHECKPOINT_DIR,\n        max_epochs=FINETUNE_EPOCHS_S3,\n        upload_remote='gdrive:crescendai_data/model_improvement/checkpoints',\n    )\n    s3_trainers.append(trainer_ft)\n\n    best_val = trainer_ft.callback_metrics.get('val_loss', float('inf'))\n    best_acc = trainer_ft.callback_metrics.get('val_pairwise_acc', 0.0)\n    print(f'  Best val_loss={best_val:.4f}, val_pairwise_acc={best_acc:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Symbolic Encoder Training Summary')\nprint('=' * 60)\nprint(f'{\"Model\":<12} {\"Fold\":<6} {\"Val Loss\":<12} {\"Pairwise Acc\":<14}')\nprint('-' * 60)\n\nfor name, trainers in [('S1', s1_trainers), ('S2', s2_trainers), ('S2-hetero', s2h_trainers), ('S3', s3_trainers)]:\n    for fold_idx, trainer in enumerate(trainers):\n        val_loss = trainer.callback_metrics.get('val_loss', float('nan'))\n        val_acc = trainer.callback_metrics.get('val_pairwise_acc', float('nan'))\n        print(f'{name:<12} {fold_idx:<6} {val_loss:<12.4f} {val_acc:<14.4f}')\n\nprint('\\nCheckpoints saved to:', CHECKPOINT_DIR)\nprint('Checkpoints synced to Google Drive via rclone')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Upload Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for model_name in ['S1', 'S1_pretrain', 'S2', 'S2_pretrain', 'S2H', 'S2H_pretrain', 'S3', 'S3_pretrain']:\n    local = CHECKPOINT_DIR / model_name\n    if local.exists():\n        upload_checkpoint(local, model_name)\n        print(f'Uploaded {model_name} checkpoints')\n\nprint('\\nAll symbolic encoder training complete.')\nprint('Run 04_symbolic_comparison.ipynb to evaluate and compare results.')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}