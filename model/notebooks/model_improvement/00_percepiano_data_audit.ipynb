{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 00: PercePiano Data Quality Audit\n",
    "\n",
    "Comprehensive investigation of PercePiano's 19 quality dimensions:\n",
    "- Which dimensions are redundant or noisy?\n",
    "- How many independent factors do the labels encode?\n",
    "- Which dimensions are \"audible\" (predictable from MuQ embeddings)?\n",
    "- Can a reduced dimension set improve downstream STOP prediction?\n",
    "\n",
    "Runs locally on CPU. No GPU or cloud compute required.\n",
    "\n",
    "Design doc: `docs/plans/2026-02-15-percepiano-data-audit-design.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 dimensions: ['timing', 'articulation_length', 'articulation_touch', 'pedal_amount', 'pedal_clarity', 'timbre_variety', 'timbre_depth', 'timbre_brightness', 'timbre_loudness', 'dynamic_range', 'tempo', 'space', 'balance', 'drama', 'mood_valence', 'mood_energy', 'mood_imagination', 'sophistication', 'interpretation']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from scipy import stats as sp_stats\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import umap\n",
    "\n",
    "MODEL_ROOT = Path('../..').resolve()\n",
    "sys.path.insert(0, str(MODEL_ROOT / 'src'))\n",
    "\n",
    "from audio_experiments.constants import PERCEPIANO_DIMENSIONS, DIMENSION_CATEGORIES\n",
    "\n",
    "CACHE_DIR = MODEL_ROOT / 'data' / 'percepiano_cache'\n",
    "MASTERCLASS_CACHE = MODEL_ROOT / 'data' / 'masterclass_cache'\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "DIM_NAMES = PERCEPIANO_DIMENSIONS\n",
    "N_DIMS = len(DIM_NAMES)\n",
    "print(f'{N_DIMS} dimensions: {DIM_NAMES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jdhiman/Documents/crescendai/model/data/percepiano_cache/muq_embeddings.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(CACHE_DIR / \u001b[33m'\u001b[39m\u001b[33mfolds.json\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      6\u001b[39m     folds = json.load(f)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m embeddings = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCACHE_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmuq_embeddings.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Build aligned arrays\u001b[39;00m\n\u001b[32m     11\u001b[39m keys = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_labels.keys()) & \u001b[38;5;28mset\u001b[39m(embeddings.keys()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/crescendai/model/.venv/lib/python3.12/site-packages/torch/serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/crescendai/model/.venv/lib/python3.12/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/crescendai/model/.venv/lib/python3.12/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/jdhiman/Documents/crescendai/model/data/percepiano_cache/muq_embeddings.pt'"
     ]
    }
   ],
   "source": [
    "# Load PercePiano labels and embeddings\n",
    "with open(CACHE_DIR / 'labels.json') as f:\n",
    "    raw_labels = json.load(f)\n",
    "\n",
    "with open(CACHE_DIR / 'folds.json') as f:\n",
    "    folds = json.load(f)\n",
    "\n",
    "embeddings = torch.load(CACHE_DIR / 'muq_embeddings.pt', map_location='cpu', weights_only=True)\n",
    "\n",
    "# Build aligned arrays\n",
    "keys = sorted(set(raw_labels.keys()) & set(embeddings.keys()))\n",
    "Y = np.array([raw_labels[k][:19] for k in keys])  # [N, 19]\n",
    "\n",
    "# Stats-pool MuQ embeddings: mean + std -> [2048]\n",
    "X_muq = np.stack([\n",
    "    torch.cat([embeddings[k].mean(dim=0), embeddings[k].std(dim=0)]).numpy()\n",
    "    for k in keys\n",
    "])\n",
    "\n",
    "print(f'Samples: {len(keys)}')\n",
    "print(f'Labels shape: {Y.shape}')\n",
    "print(f'MuQ features shape: {X_muq.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Correlation & Redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap with hierarchical clustering\n",
    "corr = np.corrcoef(Y.T)  # [19, 19]\n",
    "\n",
    "g = sns.clustermap(\n",
    "    corr,\n",
    "    xticklabels=DIM_NAMES,\n",
    "    yticklabels=DIM_NAMES,\n",
    "    cmap='RdBu_r',\n",
    "    vmin=-1, vmax=1,\n",
    "    figsize=(10, 9),\n",
    "    annot=True, fmt='.2f', annot_kws={'size': 6},\n",
    "    dendrogram_ratio=0.12,\n",
    ")\n",
    "g.ax_heatmap.set_title('PercePiano Dimension Correlations (hierarchically clustered)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print cluster ordering\n",
    "cluster_order = [DIM_NAMES[i] for i in g.dendrogram_row.reordered_ind]\n",
    "print(f'Cluster ordering: {cluster_order}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top correlated pairs\n",
    "pairs = []\n",
    "for i in range(N_DIMS):\n",
    "    for j in range(i + 1, N_DIMS):\n",
    "        pairs.append((DIM_NAMES[i], DIM_NAMES[j], corr[i, j]))\n",
    "pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "print('Top 15 correlated pairs:')\n",
    "for d1, d2, r in pairs[:15]:\n",
    "    print(f'  {d1:25s} <-> {d2:25s}  r = {r:+.3f}')\n",
    "\n",
    "n_high = sum(1 for _, _, r in pairs if abs(r) > 0.7)\n",
    "n_moderate = sum(1 for _, _, r in pairs if 0.5 < abs(r) <= 0.7)\n",
    "print(f'\\nPairs with |r| > 0.7: {n_high}/{len(pairs)}')\n",
    "print(f'Pairs with 0.5 < |r| <= 0.7: {n_moderate}/{len(pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Inflation Factors\n",
    "Y_std = StandardScaler().fit_transform(Y)\n",
    "vifs = [variance_inflation_factor(Y_std, i) for i in range(N_DIMS)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sorted_idx = np.argsort(vifs)[::-1]\n",
    "colors = ['#e53935' if v > 10 else '#fb8c00' if v > 5 else '#43a047' for v in np.array(vifs)[sorted_idx]]\n",
    "ax.barh(range(N_DIMS), np.array(vifs)[sorted_idx], color=colors)\n",
    "ax.set_yticks(range(N_DIMS))\n",
    "ax.set_yticklabels([DIM_NAMES[i] for i in sorted_idx])\n",
    "ax.set_xlabel('VIF')\n",
    "ax.set_title('Variance Inflation Factors (red > 10 = severe, orange > 5 = moderate)')\n",
    "ax.axvline(10, color='red', linestyle='--', alpha=0.5)\n",
    "ax.axvline(5, color='orange', linestyle='--', alpha=0.5)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('VIF per dimension:')\n",
    "for i in sorted_idx:\n",
    "    flag = ' *** SEVERE' if vifs[i] > 10 else ' ** moderate' if vifs[i] > 5 else ''\n",
    "    print(f'  {DIM_NAMES[i]:25s}: {vifs[i]:8.2f}{flag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Factor Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on standardized labels\n",
    "pca = PCA(n_components=N_DIMS)\n",
    "pca.fit(Y_std)\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "cumulative = np.cumsum(explained)\n",
    "\n",
    "# Parallel analysis: Monte Carlo simulation for significant components\n",
    "n_simulations = 1000\n",
    "rng = np.random.default_rng(42)\n",
    "random_eigenvalues = np.zeros((n_simulations, N_DIMS))\n",
    "for i in range(n_simulations):\n",
    "    random_data = rng.standard_normal((len(keys), N_DIMS))\n",
    "    random_pca = PCA(n_components=N_DIMS)\n",
    "    random_pca.fit(random_data)\n",
    "    random_eigenvalues[i] = random_pca.explained_variance_\n",
    "\n",
    "# 95th percentile of random eigenvalues\n",
    "threshold_eigenvalues = np.percentile(random_eigenvalues, 95, axis=0)\n",
    "n_significant = np.sum(pca.explained_variance_ > threshold_eigenvalues)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scree plot with parallel analysis\n",
    "components = np.arange(1, N_DIMS + 1)\n",
    "axes[0].plot(components, pca.explained_variance_, 'o-', label='Observed eigenvalues')\n",
    "axes[0].plot(components, threshold_eigenvalues, 's--', color='red', label='95th pctl random (parallel analysis)')\n",
    "axes[0].axvline(n_significant + 0.5, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[0].set_xlabel('Component')\n",
    "axes[0].set_ylabel('Eigenvalue')\n",
    "axes[0].set_title(f'Scree Plot + Parallel Analysis ({n_significant} significant factors)')\n",
    "axes[0].legend()\n",
    "axes[0].set_xticks(components)\n",
    "\n",
    "# Cumulative variance\n",
    "axes[1].bar(components, explained, alpha=0.6, label='Individual')\n",
    "axes[1].plot(components, cumulative, 'o-', color='red', label='Cumulative')\n",
    "axes[1].axhline(0.90, color='gray', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "n_90 = np.searchsorted(cumulative, 0.90) + 1\n",
    "axes[1].set_xlabel('Component')\n",
    "axes[1].set_ylabel('Explained Variance Ratio')\n",
    "axes[1].set_title(f'Cumulative Variance ({n_90} components for 90%)')\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks(components)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Parallel analysis: {n_significant} statistically significant factors')\n",
    "print(f'Components for 90% variance: {n_90}')\n",
    "print(f'Components for 95% variance: {np.searchsorted(cumulative, 0.95) + 1}')\n",
    "print(f'\\nExplained variance per component:')\n",
    "for i, (e, c) in enumerate(zip(explained, cumulative)):\n",
    "    marker = ' <-- cutoff' if i + 1 == n_significant else ''\n",
    "    print(f'  PC{i+1}: {e:.3f} (cumulative: {c:.3f}){marker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor loadings heatmap (only significant components)\n",
    "loadings = pca.components_[:n_significant].T  # [19, n_significant]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(loadings, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\n",
    "ax.set_yticks(range(N_DIMS))\n",
    "ax.set_yticklabels(DIM_NAMES, fontsize=9)\n",
    "ax.set_xticks(range(n_significant))\n",
    "ax.set_xticklabels([f'PC{i+1}\\n({explained[i]:.1%})' for i in range(n_significant)])\n",
    "ax.set_title(f'Factor Loadings ({n_significant} significant components)')\n",
    "fig.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "# Annotate loadings\n",
    "for i in range(N_DIMS):\n",
    "    for j in range(n_significant):\n",
    "        val = loadings[i, j]\n",
    "        if abs(val) > 0.3:\n",
    "            ax.text(j, i, f'{val:.2f}', ha='center', va='center', fontsize=7,\n",
    "                    color='white' if abs(val) > 0.6 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpret factors\n",
    "print('Factor interpretations (|loading| > 0.3):')\n",
    "for j in range(n_significant):\n",
    "    strong = [(DIM_NAMES[i], loadings[i, j]) for i in range(N_DIMS) if abs(loadings[i, j]) > 0.3]\n",
    "    strong.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    dims_str = ', '.join(f'{name}({v:+.2f})' for name, v in strong)\n",
    "    print(f'  PC{j+1} ({explained[j]:.1%}): {dims_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Per-Dimension Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "flagged = []\n",
    "for i in range(N_DIMS):\n",
    "    ax = axes[i]\n",
    "    vals = Y[:, i]\n",
    "    ax.hist(vals, bins=30, alpha=0.7, edgecolor='black', linewidth=0.3)\n",
    "    ax.set_title(DIM_NAMES[i], fontsize=9)\n",
    "    ax.set_xlim(-0.05, 1.05)\n",
    "\n",
    "    var = np.var(vals)\n",
    "    skew = sp_stats.skew(vals)\n",
    "    floor_pct = np.mean(vals < 0.05)\n",
    "    ceil_pct = np.mean(vals > 0.95)\n",
    "\n",
    "    flags = []\n",
    "    if var < 0.01:\n",
    "        flags.append(f'low var ({var:.4f})')\n",
    "    if abs(skew) > 1:\n",
    "        flags.append(f'skew ({skew:+.2f})')\n",
    "    if floor_pct > 0.5:\n",
    "        flags.append(f'floor ({floor_pct:.0%})')\n",
    "    if ceil_pct > 0.5:\n",
    "        flags.append(f'ceil ({ceil_pct:.0%})')\n",
    "\n",
    "    subtitle = f'var={var:.3f}, skew={skew:+.2f}'\n",
    "    ax.set_xlabel(subtitle, fontsize=7)\n",
    "\n",
    "    if flags:\n",
    "        ax.patch.set_facecolor('#fff3e0')\n",
    "        flagged.append((DIM_NAMES[i], flags))\n",
    "\n",
    "# Hide last subplot if odd number of dims\n",
    "for j in range(N_DIMS, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "fig.suptitle('Per-Dimension Distributions (orange = flagged)', fontsize=12, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if flagged:\n",
    "    print('Flagged dimensions:')\n",
    "    for name, flags in flagged:\n",
    "        print(f'  {name}: {\" | \".join(flags)}')\n",
    "else:\n",
    "    print('No dimensions flagged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differential entropy per dimension (informativeness score)\n",
    "entropies = []\n",
    "for i in range(N_DIMS):\n",
    "    vals = Y[:, i]\n",
    "    # Use KDE-based entropy estimate\n",
    "    kde = sp_stats.gaussian_kde(vals)\n",
    "    # Sample points for entropy estimation\n",
    "    x_grid = np.linspace(vals.min() - 0.1, vals.max() + 0.1, 500)\n",
    "    pdf = kde(x_grid)\n",
    "    # Numerical integration of -p*log(p)\n",
    "    pdf = pdf[pdf > 0]\n",
    "    dx = x_grid[1] - x_grid[0]\n",
    "    entropy = -np.sum(pdf * np.log(pdf) * dx)\n",
    "    entropies.append(entropy)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sorted_idx = np.argsort(entropies)\n",
    "ax.barh(range(N_DIMS), np.array(entropies)[sorted_idx])\n",
    "ax.set_yticks(range(N_DIMS))\n",
    "ax.set_yticklabels([DIM_NAMES[i] for i in sorted_idx])\n",
    "ax.set_xlabel('Differential Entropy (nats)')\n",
    "ax.set_title('Per-Dimension Informativeness (higher = more spread/informative)')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Entropy ranking (least to most informative):')\n",
    "for i in sorted_idx:\n",
    "    print(f'  {DIM_NAMES[i]:25s}: {entropies[i]:.3f} nats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. MuQ Probing (per-dimension audibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dimension, train Ridge regression: MuQ -> score, 4-fold CV\n",
    "# Build fold indices aligned to our sorted keys\n",
    "key_to_idx = {k: i for i, k in enumerate(keys)}\n",
    "\n",
    "r2_per_dim = np.zeros(N_DIMS)\n",
    "r2_per_dim_per_fold = np.zeros((N_DIMS, len(folds)))\n",
    "\n",
    "for dim_i in range(N_DIMS):\n",
    "    y_dim = Y[:, dim_i]\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for fold_i, fold in enumerate(folds):\n",
    "        train_idx = [key_to_idx[k] for k in fold['train'] if k in key_to_idx]\n",
    "        val_idx = [key_to_idx[k] for k in fold['val'] if k in key_to_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_muq[train_idx])\n",
    "        X_va = scaler.transform(X_muq[val_idx])\n",
    "\n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(X_tr, y_dim[train_idx])\n",
    "        preds = ridge.predict(X_va)\n",
    "\n",
    "        r2_fold = r2_score(y_dim[val_idx], preds)\n",
    "        r2_per_dim_per_fold[dim_i, fold_i] = r2_fold\n",
    "\n",
    "        all_true.extend(y_dim[val_idx])\n",
    "        all_pred.extend(preds)\n",
    "\n",
    "    r2_per_dim[dim_i] = r2_score(all_true, all_pred)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sorted_idx = np.argsort(r2_per_dim)[::-1]\n",
    "colors = ['#2196F3' if r > 0.3 else '#FF9800' if r > 0.1 else '#e53935' for r in r2_per_dim[sorted_idx]]\n",
    "bars = ax.barh(range(N_DIMS), r2_per_dim[sorted_idx], color=colors, xerr=r2_per_dim_per_fold[sorted_idx].std(axis=1), capsize=3)\n",
    "ax.set_yticks(range(N_DIMS))\n",
    "ax.set_yticklabels([DIM_NAMES[i] for i in sorted_idx])\n",
    "ax.set_xlabel('R2 (4-fold CV)')\n",
    "ax.set_title('MuQ Probing: Which dimensions are audible?\\n(blue > 0.3 = audible, orange > 0.1 = partial, red < 0.1 = not audible)')\n",
    "ax.axvline(0, color='gray', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Per-dimension R2 (MuQ -> PercePiano score):')\n",
    "for i in sorted_idx:\n",
    "    fold_str = ' '.join(f'{r2_per_dim_per_fold[i, f]:.3f}' for f in range(len(folds)))\n",
    "    label = 'AUDIBLE' if r2_per_dim[i] > 0.3 else 'partial' if r2_per_dim[i] > 0.1 else 'NOT AUDIBLE'\n",
    "    print(f'  {DIM_NAMES[i]:25s}: R2={r2_per_dim[i]:.3f} [{label}]  folds: [{fold_str}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. MuQ Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear map: MuQ -> all 19 dims simultaneously\n",
    "scaler_full = StandardScaler()\n",
    "X_muq_std = scaler_full.fit_transform(X_muq)\n",
    "\n",
    "ridge_multi = Ridge(alpha=1.0)\n",
    "ridge_multi.fit(X_muq_std, Y)\n",
    "Y_pred = ridge_multi.predict(X_muq_std)\n",
    "\n",
    "# Residuals: what PercePiano labels capture that MuQ can't explain\n",
    "residuals = Y - Y_pred  # [N, 19]\n",
    "\n",
    "# PCA on residuals to check if structured\n",
    "pca_resid = PCA(n_components=N_DIMS)\n",
    "pca_resid.fit(residuals)\n",
    "resid_explained = pca_resid.explained_variance_ratio_\n",
    "resid_cumulative = np.cumsum(resid_explained)\n",
    "\n",
    "# Compare to random noise baseline\n",
    "random_residuals = rng.standard_normal(residuals.shape) * residuals.std(axis=0)\n",
    "pca_random = PCA(n_components=N_DIMS)\n",
    "pca_random.fit(random_residuals)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scree comparison\n",
    "components = np.arange(1, N_DIMS + 1)\n",
    "axes[0].plot(components, pca_resid.explained_variance_, 'o-', label='Residual eigenvalues')\n",
    "axes[0].plot(components, pca_random.explained_variance_, 's--', color='gray', label='Random noise baseline')\n",
    "axes[0].set_xlabel('Component')\n",
    "axes[0].set_ylabel('Eigenvalue')\n",
    "axes[0].set_title('Residual Structure: Is what MuQ misses structured or noise?')\n",
    "axes[0].legend()\n",
    "axes[0].set_xticks(components)\n",
    "\n",
    "# Per-dimension residual variance\n",
    "resid_var = residuals.var(axis=0)\n",
    "total_var = Y.var(axis=0)\n",
    "unexplained_frac = resid_var / total_var  # 1 - R2 per dim\n",
    "\n",
    "sorted_idx = np.argsort(unexplained_frac)[::-1]\n",
    "axes[1].barh(range(N_DIMS), unexplained_frac[sorted_idx])\n",
    "axes[1].set_yticks(range(N_DIMS))\n",
    "axes[1].set_yticklabels([DIM_NAMES[i] for i in sorted_idx])\n",
    "axes[1].set_xlabel('Fraction of variance unexplained by MuQ')\n",
    "axes[1].set_title('What MuQ cannot explain (high = symbolic/subjective)')\n",
    "axes[1].axvline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual correlation structure\n",
    "resid_corr = np.corrcoef(residuals.T)\n",
    "n_structured = np.sum(pca_resid.explained_variance_ > pca_random.explained_variance_)\n",
    "print(f'Structured residual components (above noise floor): {n_structured}')\n",
    "print(f'\\nPer-dimension unexplained variance:')\n",
    "for i in sorted_idx:\n",
    "    print(f'  {DIM_NAMES[i]:25s}: {unexplained_frac[i]:.3f} unexplained')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 7. UMAP Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP on stats-pooled MuQ embeddings\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "embedding_2d = reducer.fit_transform(X_muq_std)\n",
    "\n",
    "# Select top-5 most audible and top-5 least audible dimensions\n",
    "audibility_rank = np.argsort(r2_per_dim)[::-1]\n",
    "top_audible = audibility_rank[:5]\n",
    "least_audible = audibility_rank[-5:]\n",
    "dims_to_show = np.concatenate([top_audible, least_audible])\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for plot_i, dim_i in enumerate(dims_to_show):\n",
    "    row = plot_i // 5\n",
    "    col = plot_i % 5\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        embedding_2d[:, 0], embedding_2d[:, 1],\n",
    "        c=Y[:, dim_i], cmap='viridis', s=5, alpha=0.6,\n",
    "    )\n",
    "    ax.set_title(f'{DIM_NAMES[dim_i]}\\nR2={r2_per_dim[dim_i]:.3f}', fontsize=9)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.colorbar(scatter, ax=ax, shrink=0.7)\n",
    "\n",
    "axes[0, 0].set_ylabel('Top 5 most audible', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Top 5 least audible', fontsize=11)\n",
    "fig.suptitle('UMAP of MuQ Embeddings colored by PercePiano dimensions', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 8. Canonical Correlation Analysis (CCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA between MuQ embeddings and PercePiano labels\n",
    "# Reduce MuQ dimensionality first via PCA (CCA needs n_samples > n_features)\n",
    "n_cca_components = min(N_DIMS, 19)  # Match label dimensionality\n",
    "pca_muq = PCA(n_components=50)  # Reduce 2048 -> 50\n",
    "X_muq_pca = pca_muq.fit_transform(X_muq_std)\n",
    "print(f'MuQ PCA: {pca_muq.explained_variance_ratio_.sum():.1%} variance retained in 50 components')\n",
    "\n",
    "cca = CCA(n_components=n_cca_components)\n",
    "X_c, Y_c = cca.fit_transform(X_muq_pca, Y)\n",
    "\n",
    "# Canonical correlations\n",
    "canonical_corrs = [np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1] for i in range(n_cca_components)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(range(1, n_cca_components + 1), canonical_corrs)\n",
    "ax.set_xlabel('Canonical Variate')\n",
    "ax.set_ylabel('Canonical Correlation')\n",
    "ax.set_title('CCA: Shared Information between MuQ and PercePiano Labels')\n",
    "ax.set_xticks(range(1, n_cca_components + 1))\n",
    "ax.axhline(0.3, color='gray', linestyle='--', alpha=0.5, label='r=0.3 threshold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "n_significant_cca = sum(1 for c in canonical_corrs if c > 0.3)\n",
    "print(f'Canonical correlations: {[f\"{c:.3f}\" for c in canonical_corrs]}')\n",
    "print(f'Significant canonical variates (r > 0.3): {n_significant_cca}/{n_cca_components}')\n",
    "print(f'Total shared variance (sum r^2): {sum(c**2 for c in canonical_corrs):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 9. Downstream: STOP Prediction with Reduced Dims\n",
    "\n",
    "Reuse the masterclass 98-segment STOP/CONTINUE data to test whether reduced dimension sets improve or hurt prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masterclass_experiments.data import load_moments, identify_segments\n",
    "from masterclass_experiments.features import stats_pool\n",
    "from masterclass_experiments.evaluation import leave_one_video_out_cv\n",
    "\n",
    "REPO_ROOT = MODEL_ROOT.parent\n",
    "MOMENTS_PATH = REPO_ROOT / 'tools' / 'masterclass-pipeline' / 'all_moments.jsonl'\n",
    "SEGMENT_DIR = MASTERCLASS_CACHE / 'segments'\n",
    "MUQ_CACHE_DIR = MASTERCLASS_CACHE / 'muq_embeddings'\n",
    "CHECKPOINT_DIR = MODEL_ROOT / 'data' / 'checkpoints' / 'percepiano'\n",
    "CHECKPOINT_PATHS = sorted(CHECKPOINT_DIR.glob('fold*_best.ckpt'))\n",
    "\n",
    "# Load masterclass data\n",
    "moments = load_moments(MOMENTS_PATH)\n",
    "segments = identify_segments(moments)\n",
    "segment_ids = np.array([s.segment_id for s in segments])\n",
    "video_ids = np.array([s.video_id for s in segments])\n",
    "stop_labels = np.array([1 if s.label == 'stop' else 0 for s in segments])\n",
    "\n",
    "print(f'Masterclass segments: {len(segments)} ({stop_labels.sum()} STOP, {(1-stop_labels).sum()} CONTINUE)')\n",
    "print(f'PercePiano checkpoints: {len(CHECKPOINT_PATHS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MuQ embeddings for masterclass segments (cached)\n",
    "from audio_experiments.extractors.muq import MuQExtractor\n",
    "from masterclass_experiments.features import extract_quality_scores\n",
    "\n",
    "extractor = MuQExtractor(cache_dir=MUQ_CACHE_DIR)\n",
    "mc_raw_embeddings = {}\n",
    "for seg in segments:\n",
    "    wav_path = SEGMENT_DIR / f'{seg.segment_id}.wav'\n",
    "    mc_raw_embeddings[seg.segment_id] = extractor.extract_from_file(wav_path)\n",
    "\n",
    "# Get 19-dim quality scores\n",
    "mc_quality = extract_quality_scores(mc_raw_embeddings, CHECKPOINT_PATHS)\n",
    "X_mc_quality = np.stack([mc_quality[sid].numpy() for sid in segment_ids])  # [98, 19]\n",
    "print(f'Quality scores shape: {X_mc_quality.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare STOP prediction with different dimension reduction strategies\n",
    "results = {}\n",
    "\n",
    "# 1. All 19 dims (baseline)\n",
    "r = leave_one_video_out_cv(X_mc_quality, stop_labels, video_ids, segment_ids)\n",
    "results['All 19 dims'] = r['auc']\n",
    "\n",
    "# 2. PCA-reduced (use n_significant from parallel analysis)\n",
    "pca_mc = PCA(n_components=n_significant)\n",
    "X_mc_pca = pca_mc.fit_transform(StandardScaler().fit_transform(X_mc_quality))\n",
    "r = leave_one_video_out_cv(X_mc_pca, stop_labels, video_ids, segment_ids)\n",
    "results[f'PCA ({n_significant} components)'] = r['auc']\n",
    "\n",
    "# 3. Top audible dims only (R2 > 0.1 from probing)\n",
    "audible_mask = r2_per_dim > 0.1\n",
    "audible_dims = [DIM_NAMES[i] for i in range(N_DIMS) if audible_mask[i]]\n",
    "X_mc_audible = X_mc_quality[:, audible_mask]\n",
    "r = leave_one_video_out_cv(X_mc_audible, stop_labels, video_ids, segment_ids)\n",
    "results[f'Audible only ({sum(audible_mask)} dims)'] = r['auc']\n",
    "\n",
    "# 4. Non-audible dims only (R2 < 0.1) -- the \"symbolic\" ones\n",
    "non_audible_mask = ~audible_mask\n",
    "if non_audible_mask.sum() > 0:\n",
    "    non_audible_dims = [DIM_NAMES[i] for i in range(N_DIMS) if non_audible_mask[i]]\n",
    "    X_mc_non_audible = X_mc_quality[:, non_audible_mask]\n",
    "    r = leave_one_video_out_cv(X_mc_non_audible, stop_labels, video_ids, segment_ids)\n",
    "    results[f'Non-audible only ({sum(non_audible_mask)} dims)'] = r['auc']\n",
    "\n",
    "# 5. Category-level means (collapse correlated groups)\n",
    "category_features = []\n",
    "category_names = []\n",
    "for cat_name, cat_dims in DIMENSION_CATEGORIES.items():\n",
    "    cat_idx = [DIM_NAMES.index(d) for d in cat_dims]\n",
    "    category_features.append(X_mc_quality[:, cat_idx].mean(axis=1))\n",
    "    category_names.append(cat_name)\n",
    "X_mc_cats = np.column_stack(category_features)\n",
    "r = leave_one_video_out_cv(X_mc_cats, stop_labels, video_ids, segment_ids)\n",
    "results[f'Category means ({len(category_names)} cats)'] = r['auc']\n",
    "\n",
    "# 6. Top-5 by probing R2\n",
    "top5_idx = np.argsort(r2_per_dim)[::-1][:5]\n",
    "top5_dims = [DIM_NAMES[i] for i in top5_idx]\n",
    "X_mc_top5 = X_mc_quality[:, top5_idx]\n",
    "r = leave_one_video_out_cv(X_mc_top5, stop_labels, video_ids, segment_ids)\n",
    "results[f'Top-5 audible ({top5_dims})'] = r['auc']\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "names = list(results.keys())\n",
    "aucs = list(results.values())\n",
    "sorted_pairs = sorted(zip(aucs, names), reverse=True)\n",
    "aucs_sorted = [a for a, _ in sorted_pairs]\n",
    "names_sorted = [n for _, n in sorted_pairs]\n",
    "\n",
    "colors = ['#2196F3' if a >= max(aucs) - 0.01 else '#90CAF9' for a in aucs_sorted]\n",
    "ax.barh(range(len(names_sorted)), aucs_sorted, color=colors)\n",
    "ax.set_yticks(range(len(names_sorted)))\n",
    "ax.set_yticklabels(names_sorted)\n",
    "ax.set_xlabel('LOVO AUC')\n",
    "ax.set_title('STOP Prediction: Which dimension subsets work best?')\n",
    "ax.set_xlim(0.4, 1.0)\n",
    "for i, v in enumerate(aucs_sorted):\n",
    "    ax.text(v + 0.005, i, f'{v:.3f}', va='center', fontsize=9)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('STOP prediction AUC by dimension subset:')\n",
    "for name, auc in sorted_pairs:\n",
    "    delta = auc - results['All 19 dims']\n",
    "    print(f'  {name:40s}: AUC={auc:.3f} (delta={delta:+.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 10. Competition Validation (T2 -- deferred)\n",
    "\n",
    "Placeholder for Spearman correlation between PercePiano dimensions and competition ordinal placement. Requires T2 data to be synced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load T2 competition data and compute per-dimension Spearman correlation\n",
    "# with ordinal placement (1st > 2nd > semifinal > eliminated).\n",
    "#\n",
    "# Expected analysis:\n",
    "# - For each PercePiano dimension, compute Spearman rho with placement rank\n",
    "# - Dimensions that correlate with competition outcomes provide external validity\n",
    "# - Dimensions with no correlation may be noisy or subjective\n",
    "print('T2 competition data not yet available. Sync from GDrive to proceed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('PERCEPIANO DATA QUALITY AUDIT -- SUMMARY')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'\\n1. REDUNDANCY')\n",
    "print(f'   Pairs with |r| > 0.7: {n_high}/{len(pairs)}')\n",
    "severe_vif = sum(1 for v in vifs if v > 10)\n",
    "print(f'   Dimensions with VIF > 10: {severe_vif}/{N_DIMS}')\n",
    "\n",
    "print(f'\\n2. FACTOR STRUCTURE')\n",
    "print(f'   Parallel analysis: {n_significant} significant factors')\n",
    "print(f'   Components for 90% variance: {n_90}')\n",
    "\n",
    "print(f'\\n3. DISTRIBUTION FLAGS')\n",
    "if flagged:\n",
    "    for name, flags in flagged:\n",
    "        print(f'   {name}: {\", \".join(flags)}')\n",
    "else:\n",
    "    print('   None flagged')\n",
    "\n",
    "print(f'\\n4. AUDIBILITY (MuQ probing R2)')\n",
    "for i in np.argsort(r2_per_dim)[::-1]:\n",
    "    label = 'AUDIBLE' if r2_per_dim[i] > 0.3 else 'partial' if r2_per_dim[i] > 0.1 else 'NOT AUDIBLE'\n",
    "    print(f'   {DIM_NAMES[i]:25s}: R2={r2_per_dim[i]:.3f} [{label}]')\n",
    "\n",
    "print(f'\\n5. RESIDUAL STRUCTURE')\n",
    "print(f'   Structured residual components: {n_structured}')\n",
    "\n",
    "print(f'\\n6. CCA')\n",
    "print(f'   Significant canonical variates: {n_significant_cca}')\n",
    "print(f'   Total shared variance: {sum(c**2 for c in canonical_corrs):.3f}')\n",
    "\n",
    "print(f'\\n7. STOP PREDICTION')\n",
    "for auc_val, name in sorted_pairs:\n",
    "    print(f'   {name:40s}: AUC={auc_val:.3f}')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
