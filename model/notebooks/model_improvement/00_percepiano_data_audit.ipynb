{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 00: PercePiano Data Quality Audit\n",
    "\n",
    "Comprehensive investigation of PercePiano's 19 quality dimensions:\n",
    "- Which dimensions are redundant or noisy?\n",
    "- How many independent factors do the labels encode?\n",
    "- Which dimensions are \"audible\" (predictable from MuQ embeddings)?\n",
    "- Does attention-pooling or nonlinear probing improve audibility?\n",
    "- Can a reduced dimension set improve downstream STOP prediction?\n",
    "\n",
    "Runs locally on CPU/MPS. No cloud GPU required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import stats as sp_stats\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "MODEL_ROOT = Path('../..').resolve()\n",
    "sys.path.insert(0, str(MODEL_ROOT / 'src'))\n",
    "\n",
    "from audio_experiments.constants import PERCEPIANO_DIMENSIONS, DIMENSION_CATEGORIES\n",
    "\n",
    "CACHE_DIR = MODEL_ROOT / 'data' / 'percepiano_cache'\n",
    "MASTERCLASS_CACHE = MODEL_ROOT / 'data' / 'masterclass_cache'\n",
    "\n",
    "DIM_NAMES = PERCEPIANO_DIMENSIONS\n",
    "N_DIMS = len(DIM_NAMES)\n",
    "\n",
    "# Collect all results for consolidated output\n",
    "audit_results = {}\n",
    "\n",
    "print(f'{N_DIMS} dimensions: {DIM_NAMES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PercePiano labels\n",
    "with open(CACHE_DIR / 'labels.json') as f:\n",
    "    raw_labels = json.load(f)\n",
    "\n",
    "with open(CACHE_DIR / 'folds.json') as f:\n",
    "    folds = json.load(f)\n",
    "\n",
    "# Build label array (all 1,202 segments)\n",
    "all_keys = sorted(raw_labels.keys())\n",
    "Y = np.array([raw_labels[k][:19] for k in all_keys])  # [N, 19]\n",
    "Y_std = StandardScaler().fit_transform(Y)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "print(f'Samples: {len(all_keys)}, Labels shape: {Y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Correlation & Redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix with hierarchical clustering order\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "corr = np.corrcoef(Y.T)  # [19, 19]\n",
    "\n",
    "# Get hierarchical cluster ordering\n",
    "Z = linkage(1 - corr, method='average')\n",
    "cluster_order = [DIM_NAMES[i] for i in leaves_list(Z)]\n",
    "\n",
    "print(f'Cluster ordering: {cluster_order}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top correlated pairs\n",
    "pairs = []\n",
    "for i in range(N_DIMS):\n",
    "    for j in range(i + 1, N_DIMS):\n",
    "        pairs.append((DIM_NAMES[i], DIM_NAMES[j], corr[i, j]))\n",
    "pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "n_high = sum(1 for _, _, r in pairs if abs(r) > 0.7)\n",
    "n_moderate = sum(1 for _, _, r in pairs if 0.5 < abs(r) <= 0.7)\n",
    "\n",
    "# VIF\n",
    "vifs = [variance_inflation_factor(Y_std, i) for i in range(N_DIMS)]\n",
    "severe_vif = sum(1 for v in vifs if v > 10)\n",
    "\n",
    "audit_results['correlation'] = {\n",
    "    'top_pairs': [(d1, d2, float(r)) for d1, d2, r in pairs[:15]],\n",
    "    'n_high_corr': n_high,\n",
    "    'n_moderate_corr': n_moderate,\n",
    "    'total_pairs': len(pairs),\n",
    "    'vifs': {DIM_NAMES[i]: float(vifs[i]) for i in range(N_DIMS)},\n",
    "    'severe_vif_count': severe_vif,\n",
    "    'cluster_order': cluster_order,\n",
    "}\n",
    "\n",
    "print(f'Pairs |r|>0.7: {n_high}/{len(pairs)}, 0.5<|r|<=0.7: {n_moderate}, VIF>10: {severe_vif}/{N_DIMS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Factor Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on standardized labels + parallel analysis\n",
    "pca = PCA(n_components=N_DIMS)\n",
    "pca.fit(Y_std)\n",
    "\n",
    "explained = pca.explained_variance_ratio_\n",
    "cumulative = np.cumsum(explained)\n",
    "\n",
    "# Parallel analysis: Monte Carlo simulation for significant components\n",
    "n_simulations = 1000\n",
    "random_eigenvalues = np.zeros((n_simulations, N_DIMS))\n",
    "for i in range(n_simulations):\n",
    "    random_data = rng.standard_normal((len(all_keys), N_DIMS))\n",
    "    random_pca = PCA(n_components=N_DIMS)\n",
    "    random_pca.fit(random_data)\n",
    "    random_eigenvalues[i] = random_pca.explained_variance_\n",
    "\n",
    "threshold_eigenvalues = np.percentile(random_eigenvalues, 95, axis=0)\n",
    "n_significant = int(np.sum(pca.explained_variance_ > threshold_eigenvalues))\n",
    "n_90 = int(np.searchsorted(cumulative, 0.90) + 1)\n",
    "n_95 = int(np.searchsorted(cumulative, 0.95) + 1)\n",
    "\n",
    "# Factor loadings for significant components\n",
    "loadings = pca.components_[:n_significant].T  # [19, n_significant]\n",
    "factor_interpretations = {}\n",
    "for j in range(n_significant):\n",
    "    strong = [(DIM_NAMES[i], float(loadings[i, j])) for i in range(N_DIMS) if abs(loadings[i, j]) > 0.3]\n",
    "    strong.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    factor_interpretations[f'PC{j+1}'] = {\n",
    "        'explained_variance': float(explained[j]),\n",
    "        'loadings': strong,\n",
    "    }\n",
    "\n",
    "audit_results['pca'] = {\n",
    "    'n_significant': n_significant,\n",
    "    'n_90_variance': n_90,\n",
    "    'n_95_variance': n_95,\n",
    "    'explained_variance': [float(e) for e in explained],\n",
    "    'cumulative_variance': [float(c) for c in cumulative],\n",
    "    'factor_interpretations': factor_interpretations,\n",
    "}\n",
    "\n",
    "print(f'Parallel analysis: {n_significant} significant factors, {n_90} for 90%, {n_95} for 95%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Per-Dimension Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-dimension distribution statistics\n",
    "flagged = []\n",
    "dim_stats = {}\n",
    "for i in range(N_DIMS):\n",
    "    vals = Y[:, i]\n",
    "    var = float(np.var(vals))\n",
    "    skew = float(sp_stats.skew(vals))\n",
    "    floor_pct = float(np.mean(vals < 0.05))\n",
    "    ceil_pct = float(np.mean(vals > 0.95))\n",
    "\n",
    "    flags = []\n",
    "    if var < 0.01:\n",
    "        flags.append(f'low var ({var:.4f})')\n",
    "    if abs(skew) > 1:\n",
    "        flags.append(f'skew ({skew:+.2f})')\n",
    "    if floor_pct > 0.5:\n",
    "        flags.append(f'floor ({floor_pct:.0%})')\n",
    "    if ceil_pct > 0.5:\n",
    "        flags.append(f'ceil ({ceil_pct:.0%})')\n",
    "\n",
    "    dim_stats[DIM_NAMES[i]] = {'var': var, 'skew': skew, 'floor_pct': floor_pct, 'ceil_pct': ceil_pct}\n",
    "    if flags:\n",
    "        flagged.append((DIM_NAMES[i], flags))\n",
    "\n",
    "# Differential entropy per dimension\n",
    "entropies = {}\n",
    "for i in range(N_DIMS):\n",
    "    vals = Y[:, i]\n",
    "    kde = sp_stats.gaussian_kde(vals)\n",
    "    x_grid = np.linspace(vals.min() - 0.1, vals.max() + 0.1, 500)\n",
    "    pdf = kde(x_grid)\n",
    "    pdf = pdf[pdf > 0]\n",
    "    dx = x_grid[1] - x_grid[0]\n",
    "    entropy = float(-np.sum(pdf * np.log(pdf) * dx))\n",
    "    entropies[DIM_NAMES[i]] = entropy\n",
    "\n",
    "audit_results['distributions'] = {\n",
    "    'dim_stats': dim_stats,\n",
    "    'flagged': flagged,\n",
    "    'entropies': entropies,\n",
    "}\n",
    "\n",
    "print(f'Flagged dimensions: {len(flagged)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ofvbwu6ux08",
   "metadata": {},
   "source": [
    "## -- Load MuQ Embeddings (required for sections 5-9) --\n",
    "\n",
    "Run `scripts/extract_percepiano_muq.py` first if `muq_embeddings.pt` does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9nv2bdmuizn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-extracted MuQ embeddings\n",
    "emb_path = CACHE_DIR / 'muq_embeddings.pt'\n",
    "embeddings = torch.load(emb_path, map_location='cpu', weights_only=True)\n",
    "\n",
    "# Align keys: only keep segments that have both labels and embeddings\n",
    "keys = sorted(set(all_keys) & set(embeddings.keys()))\n",
    "Y = np.array([raw_labels[k][:19] for k in keys])  # overwrite with aligned subset\n",
    "Y_std = StandardScaler().fit_transform(Y)\n",
    "\n",
    "# Stats-pool MuQ embeddings: mean + std -> [2048]\n",
    "X_muq = np.stack([\n",
    "    torch.cat([embeddings[k].mean(dim=0), embeddings[k].std(dim=0)]).numpy()\n",
    "    for k in keys\n",
    "])\n",
    "\n",
    "print(f'Aligned samples (labels + embeddings): {len(keys)}')\n",
    "print(f'Labels shape: {Y.shape}')\n",
    "print(f'MuQ features shape: {X_muq.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. MuQ Probing (per-dimension audibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-dimension Ridge probing: MuQ stats-pooled -> PercePiano score, 4-fold CV\n",
    "key_to_idx = {k: i for i, k in enumerate(keys)}\n",
    "\n",
    "r2_per_dim = np.zeros(N_DIMS)\n",
    "r2_per_dim_per_fold = np.zeros((N_DIMS, len(folds)))\n",
    "\n",
    "for dim_i in range(N_DIMS):\n",
    "    y_dim = Y[:, dim_i]\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for fold_i, fold in enumerate(folds):\n",
    "        train_idx = [key_to_idx[k] for k in fold['train'] if k in key_to_idx]\n",
    "        val_idx = [key_to_idx[k] for k in fold['val'] if k in key_to_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_muq[train_idx])\n",
    "        X_va = scaler.transform(X_muq[val_idx])\n",
    "\n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(X_tr, y_dim[train_idx])\n",
    "        preds = ridge.predict(X_va)\n",
    "\n",
    "        r2_fold = r2_score(y_dim[val_idx], preds)\n",
    "        r2_per_dim_per_fold[dim_i, fold_i] = r2_fold\n",
    "\n",
    "        all_true.extend(y_dim[val_idx])\n",
    "        all_pred.extend(preds)\n",
    "\n",
    "    r2_per_dim[dim_i] = r2_score(all_true, all_pred)\n",
    "\n",
    "audit_results['ridge_probing'] = {\n",
    "    DIM_NAMES[i]: {\n",
    "        'r2': float(r2_per_dim[i]),\n",
    "        'fold_r2': [float(r2_per_dim_per_fold[i, f]) for f in range(len(folds))],\n",
    "    }\n",
    "    for i in range(N_DIMS)\n",
    "}\n",
    "\n",
    "print(f'Stats-pooled Ridge probing complete. Best R2: {r2_per_dim.max():.3f} ({DIM_NAMES[r2_per_dim.argmax()]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wjhppm0t8x9",
   "metadata": {},
   "source": [
    "## 5b. Attention-Pooled Probing\n",
    "\n",
    "Learn a lightweight attention layer over MuQ frame embeddings instead of\n",
    "stats-pooling. Joint attention + linear head trained in PyTorch, 4-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xbmfeje5joq",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooler(nn.Module):\n",
    "    \"\"\"Learnable attention pooling + multi-output head for probing.\"\"\"\n",
    "    def __init__(self, input_dim=1024, attn_hidden=128, n_targets=19):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(input_dim, attn_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(attn_hidden, 1),\n",
    "        )\n",
    "        self.head = nn.Linear(input_dim, n_targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [T, 1024] (single sample, variable-length frames)\n",
    "        weights = torch.softmax(self.attn(x), dim=0)  # [T, 1]\n",
    "        pooled = (x * weights).sum(dim=0)  # [1024]\n",
    "        return self.head(pooled)  # [n_targets]\n",
    "\n",
    "    def pool(self, x):\n",
    "        weights = torch.softmax(self.attn(x), dim=0)\n",
    "        return (x * weights).sum(dim=0)  # [1024]\n",
    "\n",
    "\n",
    "def train_attention_pooler(emb_list, targets_matrix, n_epochs=50, lr=1e-3, wd=1e-3):\n",
    "    \"\"\"Train attention pooler on all 19 dims jointly. targets_matrix: [N, 19].\"\"\"\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    n_targets = targets_matrix.shape[1] if hasattr(targets_matrix, 'shape') else len(targets_matrix[0])\n",
    "    model = AttentionPooler(n_targets=n_targets).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(len(emb_list))\n",
    "        for idx in perm:\n",
    "            x = emb_list[idx].to(device)\n",
    "            y = torch.tensor(targets_matrix[idx], dtype=torch.float32, device=device)\n",
    "            pred = model(x)\n",
    "            loss = ((pred - y) ** 2).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Attention-pooled probing: train multi-target model per fold, then Ridge per dimension\n",
    "attn_r2_per_dim = np.zeros(N_DIMS)\n",
    "attn_r2_per_fold = np.zeros((N_DIMS, len(folds)))\n",
    "\n",
    "for fold_i, fold in enumerate(folds):\n",
    "    train_keys = [k for k in fold['train'] if k in key_to_idx]\n",
    "    val_keys = [k for k in fold['val'] if k in key_to_idx]\n",
    "    train_idx = [key_to_idx[k] for k in train_keys]\n",
    "    val_idx = [key_to_idx[k] for k in val_keys]\n",
    "\n",
    "    # Train attention pooler on all 19 dims jointly\n",
    "    train_embs = [embeddings[k] for k in train_keys]\n",
    "    model = train_attention_pooler(train_embs, Y[train_idx])\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Pool all samples with trained attention\n",
    "    with torch.no_grad():\n",
    "        X_tr_attn = np.stack([model.pool(embeddings[k].to(device)).cpu().numpy() for k in train_keys])\n",
    "        X_va_attn = np.stack([model.pool(embeddings[k].to(device)).cpu().numpy() for k in val_keys])\n",
    "\n",
    "    # Ridge per dimension on attention-pooled features\n",
    "    for dim_i in range(N_DIMS):\n",
    "        scaler = StandardScaler()\n",
    "        X_tr_s = scaler.fit_transform(X_tr_attn)\n",
    "        X_va_s = scaler.transform(X_va_attn)\n",
    "\n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(X_tr_s, Y[train_idx, dim_i])\n",
    "        preds = ridge.predict(X_va_s)\n",
    "        attn_r2_per_fold[dim_i, fold_i] = r2_score(Y[val_idx, dim_i], preds)\n",
    "\n",
    "    print(f'  Fold {fold_i+1}/{len(folds)} done')\n",
    "\n",
    "# Aggregate across folds\n",
    "for dim_i in range(N_DIMS):\n",
    "    all_true, all_pred = [], []\n",
    "    for fold_i, fold in enumerate(folds):\n",
    "        val_keys = [k for k in fold['val'] if k in key_to_idx]\n",
    "        val_idx = [key_to_idx[k] for k in val_keys]\n",
    "        all_true.extend(Y[val_idx, dim_i])\n",
    "        # Use fold mean as approximate R2\n",
    "    attn_r2_per_dim[dim_i] = float(attn_r2_per_fold[dim_i].mean())\n",
    "\n",
    "audit_results['attention_probing'] = {\n",
    "    DIM_NAMES[i]: {\n",
    "        'r2': float(attn_r2_per_dim[i]),\n",
    "        'fold_r2': [float(attn_r2_per_fold[i, f]) for f in range(len(folds))],\n",
    "        'delta_vs_ridge': float(attn_r2_per_dim[i] - r2_per_dim[i]),\n",
    "    }\n",
    "    for i in range(N_DIMS)\n",
    "}\n",
    "\n",
    "improved = sum(1 for i in range(N_DIMS) if attn_r2_per_dim[i] > r2_per_dim[i])\n",
    "print(f'Attention probing complete. Improved over Ridge: {improved}/{N_DIMS} dims')\n",
    "print(f'Best R2: {attn_r2_per_dim.max():.3f} ({DIM_NAMES[attn_r2_per_dim.argmax()]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fi2z16qsa5",
   "metadata": {},
   "source": [
    "## 5c. Nonlinear Probing (MLP)\n",
    "\n",
    "2-layer MLP on stats-pooled features. If MLP R2 >> Ridge R2, the\n",
    "relationship between MuQ representations and the dimension is nonlinear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4r0dy0gyj83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPProber(nn.Module):\n",
    "    \"\"\"2-layer MLP for single-dimension probing on stats-pooled features.\"\"\"\n",
    "    def __init__(self, input_dim=2048, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "\n",
    "def train_mlp_prober(X_train, y_train, n_epochs=80, lr=1e-3, wd=1e-3, batch_size=64):\n",
    "    \"\"\"Train MLP prober on stats-pooled features.\"\"\"\n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    model = MLPProber(input_dim=X_train.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    X_t = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "    y_t = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "\n",
    "    n = len(X_train)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(n, device=device)\n",
    "        for start in range(0, n, batch_size):\n",
    "            idx = perm[start:start + batch_size]\n",
    "            pred = model(X_t[idx])\n",
    "            loss = ((pred - y_t[idx]) ** 2).mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# MLP probing: 4-fold CV per dimension\n",
    "mlp_r2_per_dim = np.zeros(N_DIMS)\n",
    "mlp_r2_per_fold = np.zeros((N_DIMS, len(folds)))\n",
    "\n",
    "for dim_i in range(N_DIMS):\n",
    "    y_dim = Y[:, dim_i]\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for fold_i, fold in enumerate(folds):\n",
    "        train_idx = [key_to_idx[k] for k in fold['train'] if k in key_to_idx]\n",
    "        val_idx = [key_to_idx[k] for k in fold['val'] if k in key_to_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_muq[train_idx])\n",
    "        X_va = scaler.transform(X_muq[val_idx])\n",
    "\n",
    "        model = train_mlp_prober(X_tr, y_dim[train_idx])\n",
    "        model.eval()\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            X_va_t = torch.tensor(X_va, dtype=torch.float32, device=device)\n",
    "            preds = model(X_va_t).cpu().numpy()\n",
    "\n",
    "        r2_fold = r2_score(y_dim[val_idx], preds)\n",
    "        mlp_r2_per_fold[dim_i, fold_i] = r2_fold\n",
    "        all_true.extend(y_dim[val_idx])\n",
    "        all_pred.extend(preds)\n",
    "\n",
    "    mlp_r2_per_dim[dim_i] = r2_score(all_true, all_pred)\n",
    "\n",
    "    if (dim_i + 1) % 5 == 0:\n",
    "        print(f'  MLP probing: {dim_i+1}/{N_DIMS} dims done')\n",
    "\n",
    "audit_results['mlp_probing'] = {\n",
    "    DIM_NAMES[i]: {\n",
    "        'r2': float(mlp_r2_per_dim[i]),\n",
    "        'fold_r2': [float(mlp_r2_per_fold[i, f]) for f in range(len(folds))],\n",
    "        'delta_vs_ridge': float(mlp_r2_per_dim[i] - r2_per_dim[i]),\n",
    "    }\n",
    "    for i in range(N_DIMS)\n",
    "}\n",
    "\n",
    "nonlinear_dims = sum(1 for i in range(N_DIMS) if mlp_r2_per_dim[i] > r2_per_dim[i] + 0.05)\n",
    "print(f'MLP probing complete. Substantially nonlinear (MLP R2 > Ridge R2 + 0.05): {nonlinear_dims}/{N_DIMS}')\n",
    "print(f'Best R2: {mlp_r2_per_dim.max():.3f} ({DIM_NAMES[mlp_r2_per_dim.argmax()]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m0n9i064st",
   "metadata": {},
   "source": [
    "## 5d. Factor-Level Probing\n",
    "\n",
    "Project Y onto significant PCA components from section 3. Ridge regression\n",
    "MuQ -> PC scores. If factor-level R2 > individual dimension R2, consolidation\n",
    "into factors is validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eskjhdhypxe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project labels onto significant PCA components\n",
    "Y_pc = pca.transform(Y_std)[:, :n_significant]  # [N, n_significant]\n",
    "\n",
    "factor_r2 = np.zeros(n_significant)\n",
    "factor_r2_per_fold = np.zeros((n_significant, len(folds)))\n",
    "\n",
    "for pc_i in range(n_significant):\n",
    "    y_pc = Y_pc[:, pc_i]\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for fold_i, fold in enumerate(folds):\n",
    "        train_idx = [key_to_idx[k] for k in fold['train'] if k in key_to_idx]\n",
    "        val_idx = [key_to_idx[k] for k in fold['val'] if k in key_to_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X_muq[train_idx])\n",
    "        X_va = scaler.transform(X_muq[val_idx])\n",
    "\n",
    "        ridge = Ridge(alpha=1.0)\n",
    "        ridge.fit(X_tr, y_pc[train_idx])\n",
    "        preds = ridge.predict(X_va)\n",
    "\n",
    "        r2_fold = r2_score(y_pc[val_idx], preds)\n",
    "        factor_r2_per_fold[pc_i, fold_i] = r2_fold\n",
    "        all_true.extend(y_pc[val_idx])\n",
    "        all_pred.extend(preds)\n",
    "\n",
    "    factor_r2[pc_i] = r2_score(all_true, all_pred)\n",
    "\n",
    "# Compare: mean factor R2 vs mean individual dimension R2\n",
    "mean_factor_r2 = float(factor_r2.mean())\n",
    "mean_dim_r2 = float(r2_per_dim.mean())\n",
    "\n",
    "audit_results['factor_probing'] = {\n",
    "    f'PC{i+1}': {\n",
    "        'r2': float(factor_r2[i]),\n",
    "        'fold_r2': [float(factor_r2_per_fold[i, f]) for f in range(len(folds))],\n",
    "        'explained_variance': float(explained[i]),\n",
    "    }\n",
    "    for i in range(n_significant)\n",
    "}\n",
    "audit_results['factor_probing']['mean_factor_r2'] = mean_factor_r2\n",
    "audit_results['factor_probing']['mean_dim_r2'] = mean_dim_r2\n",
    "audit_results['factor_probing']['consolidation_validated'] = mean_factor_r2 > mean_dim_r2\n",
    "\n",
    "print(f'Factor-level probing: mean R2={mean_factor_r2:.3f} vs individual dims mean R2={mean_dim_r2:.3f}')\n",
    "print(f'Consolidation validated: {mean_factor_r2 > mean_dim_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. MuQ Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MuQ residual analysis: what PercePiano labels capture that MuQ can't explain\n",
    "scaler_full = StandardScaler()\n",
    "X_muq_std = scaler_full.fit_transform(X_muq)\n",
    "\n",
    "ridge_multi = Ridge(alpha=1.0)\n",
    "ridge_multi.fit(X_muq_std, Y)\n",
    "Y_pred = ridge_multi.predict(X_muq_std)\n",
    "\n",
    "residuals = Y - Y_pred  # [N, 19]\n",
    "\n",
    "# PCA on residuals\n",
    "pca_resid = PCA(n_components=N_DIMS)\n",
    "pca_resid.fit(residuals)\n",
    "\n",
    "# Compare to random noise baseline\n",
    "random_residuals = rng.standard_normal(residuals.shape) * residuals.std(axis=0)\n",
    "pca_random = PCA(n_components=N_DIMS)\n",
    "pca_random.fit(random_residuals)\n",
    "\n",
    "n_structured = int(np.sum(pca_resid.explained_variance_ > pca_random.explained_variance_))\n",
    "\n",
    "# Per-dimension unexplained variance\n",
    "resid_var = residuals.var(axis=0)\n",
    "total_var = Y.var(axis=0)\n",
    "unexplained_frac = resid_var / total_var\n",
    "\n",
    "audit_results['residuals'] = {\n",
    "    'n_structured_components': n_structured,\n",
    "    'unexplained_fraction': {DIM_NAMES[i]: float(unexplained_frac[i]) for i in range(N_DIMS)},\n",
    "}\n",
    "\n",
    "print(f'Structured residual components (above noise floor): {n_structured}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 7. Canonical Correlation Analysis (CCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA between MuQ embeddings and PercePiano labels\n",
    "n_cca_components = min(N_DIMS, 19)\n",
    "pca_muq = PCA(n_components=50)\n",
    "X_muq_pca = pca_muq.fit_transform(X_muq_std)\n",
    "\n",
    "cca = CCA(n_components=n_cca_components)\n",
    "X_c, Y_c = cca.fit_transform(X_muq_pca, Y)\n",
    "\n",
    "canonical_corrs = [float(np.corrcoef(X_c[:, i], Y_c[:, i])[0, 1]) for i in range(n_cca_components)]\n",
    "n_significant_cca = sum(1 for c in canonical_corrs if c > 0.3)\n",
    "\n",
    "audit_results['cca'] = {\n",
    "    'canonical_correlations': canonical_corrs,\n",
    "    'n_significant': n_significant_cca,\n",
    "    'total_shared_variance': float(sum(c**2 for c in canonical_corrs)),\n",
    "    'muq_pca_variance_retained': float(pca_muq.explained_variance_ratio_.sum()),\n",
    "}\n",
    "\n",
    "print(f'CCA: {n_significant_cca}/{n_cca_components} significant variates, shared var={sum(c**2 for c in canonical_corrs):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 8. Downstream: STOP Prediction with Reduced Dims\n",
    "\n",
    "Reuse the masterclass 98-segment STOP/CONTINUE data to test whether reduced dimension sets improve or hurt prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masterclass_experiments.data import load_moments, identify_segments\n",
    "from masterclass_experiments.features import stats_pool\n",
    "from masterclass_experiments.evaluation import leave_one_video_out_cv\n",
    "\n",
    "REPO_ROOT = MODEL_ROOT.parent\n",
    "MOMENTS_PATH = REPO_ROOT / 'tools' / 'masterclass-pipeline' / 'all_moments.jsonl'\n",
    "SEGMENT_DIR = MASTERCLASS_CACHE / 'segments'\n",
    "MUQ_CACHE_DIR = MASTERCLASS_CACHE / 'muq_embeddings'\n",
    "CHECKPOINT_DIR = MODEL_ROOT / 'data' / 'checkpoints' / 'percepiano'\n",
    "CHECKPOINT_PATHS = sorted(CHECKPOINT_DIR.glob('fold*_best.ckpt'))\n",
    "\n",
    "# Load masterclass data\n",
    "moments = load_moments(MOMENTS_PATH)\n",
    "segments = identify_segments(moments)\n",
    "segment_ids = np.array([s.segment_id for s in segments])\n",
    "video_ids = np.array([s.video_id for s in segments])\n",
    "stop_labels = np.array([1 if s.label == 'stop' else 0 for s in segments])\n",
    "\n",
    "print(f'Masterclass segments: {len(segments)} ({stop_labels.sum()} STOP, {(1-stop_labels).sum()} CONTINUE)')\n",
    "print(f'PercePiano checkpoints: {len(CHECKPOINT_PATHS)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MuQ embeddings for masterclass segments (cached)\n",
    "from audio_experiments.extractors.muq import MuQExtractor\n",
    "from masterclass_experiments.features import extract_quality_scores\n",
    "\n",
    "extractor = MuQExtractor(cache_dir=MUQ_CACHE_DIR)\n",
    "mc_raw_embeddings = {}\n",
    "for seg in segments:\n",
    "    wav_path = SEGMENT_DIR / f'{seg.segment_id}.wav'\n",
    "    mc_raw_embeddings[seg.segment_id] = extractor.extract_from_file(wav_path)\n",
    "\n",
    "# Get 19-dim quality scores\n",
    "mc_quality = extract_quality_scores(mc_raw_embeddings, CHECKPOINT_PATHS)\n",
    "X_mc_quality = np.stack([mc_quality[sid].numpy() for sid in segment_ids])  # [98, 19]\n",
    "print(f'Quality scores shape: {X_mc_quality.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare STOP prediction with different dimension reduction strategies\n",
    "stop_results = {}\n",
    "\n",
    "def safe_lovo(X_sub, label, stop_labels, video_ids, segment_ids):\n",
    "    \"\"\"Run LOVO CV with guard for 0-feature subsets.\"\"\"\n",
    "    if X_sub.shape[1] == 0:\n",
    "        return None\n",
    "    try:\n",
    "        r = leave_one_video_out_cv(X_sub, stop_labels, video_ids, segment_ids)\n",
    "        return r['auc']\n",
    "    except Exception as e:\n",
    "        print(f'  WARNING: {label} failed: {e}')\n",
    "        return None\n",
    "\n",
    "# 1. All 19 dims (baseline)\n",
    "auc = safe_lovo(X_mc_quality, 'All 19 dims', stop_labels, video_ids, segment_ids)\n",
    "if auc is not None:\n",
    "    stop_results['All 19 dims'] = auc\n",
    "\n",
    "# 2. PCA-reduced (n_significant components from parallel analysis)\n",
    "pca_mc = PCA(n_components=n_significant)\n",
    "X_mc_pca = pca_mc.fit_transform(StandardScaler().fit_transform(X_mc_quality))\n",
    "auc = safe_lovo(X_mc_pca, f'PCA ({n_significant} components)', stop_labels, video_ids, segment_ids)\n",
    "if auc is not None:\n",
    "    stop_results[f'PCA ({n_significant} components)'] = auc\n",
    "\n",
    "# 3. Category-level means (8 categories from DIMENSION_CATEGORIES)\n",
    "category_features = []\n",
    "category_names = []\n",
    "for cat_name, cat_dims in DIMENSION_CATEGORIES.items():\n",
    "    cat_idx = [DIM_NAMES.index(d) for d in cat_dims]\n",
    "    category_features.append(X_mc_quality[:, cat_idx].mean(axis=1))\n",
    "    category_names.append(cat_name)\n",
    "X_mc_cats = np.column_stack(category_features)\n",
    "auc = safe_lovo(X_mc_cats, f'Category means ({len(category_names)} cats)', stop_labels, video_ids, segment_ids)\n",
    "if auc is not None:\n",
    "    stop_results[f'Category means ({len(category_names)} cats)'] = auc\n",
    "\n",
    "# 4. Top-5 by highest R2 (least negative)\n",
    "top5_idx = np.argsort(r2_per_dim)[::-1][:5]\n",
    "top5_dims = [DIM_NAMES[i] for i in top5_idx]\n",
    "X_mc_top5 = X_mc_quality[:, top5_idx]\n",
    "auc = safe_lovo(X_mc_top5, f'Top-5 by R2', stop_labels, video_ids, segment_ids)\n",
    "if auc is not None:\n",
    "    stop_results[f'Top-5 by R2 ({top5_dims})'] = auc\n",
    "\n",
    "# 5. Bottom-5 by R2\n",
    "bottom5_idx = np.argsort(r2_per_dim)[:5]\n",
    "bottom5_dims = [DIM_NAMES[i] for i in bottom5_idx]\n",
    "X_mc_bottom5 = X_mc_quality[:, bottom5_idx]\n",
    "auc = safe_lovo(X_mc_bottom5, f'Bottom-5 by R2', stop_labels, video_ids, segment_ids)\n",
    "if auc is not None:\n",
    "    stop_results[f'Bottom-5 by R2 ({bottom5_dims})'] = auc\n",
    "\n",
    "# 6. Attention-pooled MuQ features\n",
    "# Train attention pooler on all PercePiano data, then pool masterclass segments\n",
    "attn_model = train_attention_pooler(\n",
    "    [embeddings[k] for k in keys],\n",
    "    Y,  # all 19 dims jointly\n",
    "    n_epochs=50,\n",
    ")\n",
    "attn_model.eval()\n",
    "attn_device = next(attn_model.parameters()).device\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_mc_attn = np.stack([\n",
    "        attn_model.pool(mc_raw_embeddings[sid].to(attn_device)).cpu().numpy()\n",
    "        for sid in segment_ids\n",
    "    ])\n",
    "\n",
    "auc = safe_lovo(X_mc_attn, 'Attention-pooled MuQ', stop_labels, video_ids, segment_ids)\n",
    "if auc is not None:\n",
    "    stop_results['Attention-pooled MuQ (1024d)'] = auc\n",
    "\n",
    "# Sort results\n",
    "sorted_pairs = sorted(stop_results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "audit_results['stop_prediction'] = {\n",
    "    'results': {name: float(auc_val) for name, auc_val in sorted_pairs},\n",
    "    'baseline_auc': stop_results.get('All 19 dims'),\n",
    "    'n_segments': len(segments),\n",
    "    'n_stop': int(stop_labels.sum()),\n",
    "    'n_continue': int((1 - stop_labels).sum()),\n",
    "}\n",
    "\n",
    "print(f'STOP prediction complete. {len(stop_results)} configurations tested.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4lqe771bb",
   "metadata": {},
   "source": [
    "## 10. Competition Validation\n",
    "\n",
    "Spearman correlation between PercePiano quality predictions and Chopin 2021 competition placement.\n",
    "Negative rho = higher PercePiano score correlates with better placement (lower number).\n",
    "\n",
    "Requires running `scripts/collect_competition_data.py` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "csyyzsvfq9v",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Competition Validation: Spearman correlation between\n",
    "# PercePiano quality predictions and competition placement\n",
    "\n",
    "import jsonlines\n",
    "from model_improvement.competition import load_competition_metadata\n",
    "\n",
    "COMP_CACHE = MODEL_ROOT / 'data' / 'competition_cache' / 'chopin2021'\n",
    "metadata_path = COMP_CACHE / 'metadata.jsonl'\n",
    "\n",
    "if metadata_path.exists():\n",
    "    # Load competition metadata\n",
    "    comp_records = load_competition_metadata(COMP_CACHE)\n",
    "\n",
    "    # Load MuQ embeddings for competition recordings\n",
    "    comp_emb_dir = COMP_CACHE / 'muq_embeddings'\n",
    "    comp_embeddings = {\n",
    "        p.stem: torch.load(p, map_location='cpu', weights_only=True)\n",
    "        for p in comp_emb_dir.glob('*.pt')\n",
    "    }\n",
    "\n",
    "    # Get PercePiano quality predictions for competition recordings\n",
    "    comp_quality = extract_quality_scores(comp_embeddings, CHECKPOINT_PATHS)\n",
    "\n",
    "    # Build arrays aligned by recording_id\n",
    "    valid_records = [r for r in comp_records if r['recording_id'] in comp_quality]\n",
    "    placements = np.array([r['placement'] for r in valid_records])\n",
    "    quality_scores = np.stack([\n",
    "        comp_quality[r['recording_id']].numpy() for r in valid_records\n",
    "    ])  # [N, 19]\n",
    "\n",
    "    # Per-dimension Spearman correlation (negative rho = higher quality -> lower placement number)\n",
    "    competition_correlations = {}\n",
    "    for dim_i in range(N_DIMS):\n",
    "        rho, pval = sp_stats.spearmanr(quality_scores[:, dim_i], placements)\n",
    "        competition_correlations[DIM_NAMES[dim_i]] = {'rho': float(rho), 'pval': float(pval)}\n",
    "\n",
    "    # Overall correlation\n",
    "    mean_quality = quality_scores.mean(axis=1)\n",
    "    overall_rho, overall_pval = sp_stats.spearmanr(mean_quality, placements)\n",
    "\n",
    "    audit_results['competition_validation'] = {\n",
    "        'overall_rho': float(overall_rho),\n",
    "        'overall_pval': float(overall_pval),\n",
    "        'per_dimension': competition_correlations,\n",
    "        'n_recordings': len(valid_records),\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(f'Competition validation: {len(valid_records)} recordings')\n",
    "    print(f'Overall Spearman rho: {overall_rho:.3f} (p={overall_pval:.4f})')\n",
    "    print(f'(Negative rho = higher PercePiano score correlates with better placement)')\n",
    "    print()\n",
    "    for dim_name in sorted(competition_correlations, key=lambda d: competition_correlations[d]['rho']):\n",
    "        info = competition_correlations[dim_name]\n",
    "        sig = '*' if info['pval'] < 0.05 else ''\n",
    "        print(f'  {dim_name:25s}: rho={info[\"rho\"]:+.3f}  p={info[\"pval\"]:.4f} {sig}')\n",
    "else:\n",
    "    print('Competition data not yet collected. Run scripts/collect_competition_data.py first.')\n",
    "    audit_results['competition_validation'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Consolidated Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as _json\n",
    "\n",
    "print('=' * 70)\n",
    "print('PERCEPIANO DATA QUALITY AUDIT -- CONSOLIDATED RESULTS')\n",
    "print('=' * 70)\n",
    "\n",
    "# --- 1. CORRELATION & REDUNDANCY ---\n",
    "cr = audit_results['correlation']\n",
    "print(f'\\n## 1. CORRELATION & REDUNDANCY')\n",
    "print(f'Pairs with |r| > 0.7: {cr[\"n_high_corr\"]}/{cr[\"total_pairs\"]}')\n",
    "print(f'Pairs with 0.5 < |r| <= 0.7: {cr[\"n_moderate_corr\"]}')\n",
    "print(f'Dimensions with VIF > 10 (severe multicollinearity): {cr[\"severe_vif_count\"]}/{N_DIMS}')\n",
    "print(f'Hierarchical cluster order: {cr[\"cluster_order\"]}')\n",
    "print(f'\\nTop 15 correlated pairs:')\n",
    "for d1, d2, r in cr['top_pairs']:\n",
    "    print(f'  {d1:25s} <-> {d2:25s}  r = {r:+.3f}')\n",
    "print(f'\\nVIF per dimension:')\n",
    "for name in sorted(cr['vifs'], key=cr['vifs'].get, reverse=True):\n",
    "    v = cr['vifs'][name]\n",
    "    flag = ' *** SEVERE' if v > 10 else ' ** moderate' if v > 5 else ''\n",
    "    print(f'  {name:25s}: {v:8.2f}{flag}')\n",
    "\n",
    "# --- 2. FACTOR STRUCTURE ---\n",
    "pc = audit_results['pca']\n",
    "print(f'\\n## 2. FACTOR STRUCTURE (PCA)')\n",
    "print(f'Parallel analysis: {pc[\"n_significant\"]} statistically significant factors')\n",
    "print(f'Components for 90% variance: {pc[\"n_90_variance\"]}')\n",
    "print(f'Components for 95% variance: {pc[\"n_95_variance\"]}')\n",
    "print(f'\\nExplained variance per component:')\n",
    "for i, (e, c) in enumerate(zip(pc['explained_variance'], pc['cumulative_variance'])):\n",
    "    marker = ' <-- significant cutoff' if i + 1 == pc['n_significant'] else ''\n",
    "    print(f'  PC{i+1}: {e:.3f} (cumulative: {c:.3f}){marker}')\n",
    "print(f'\\nFactor interpretations (|loading| > 0.3):')\n",
    "for pc_name, info in pc['factor_interpretations'].items():\n",
    "    dims_str = ', '.join(f'{name}({v:+.2f})' for name, v in info['loadings'])\n",
    "    print(f'  {pc_name} ({info[\"explained_variance\"]:.1%}): {dims_str}')\n",
    "\n",
    "# --- 3. DISTRIBUTION FLAGS ---\n",
    "dist = audit_results['distributions']\n",
    "print(f'\\n## 3. DISTRIBUTION FLAGS')\n",
    "if dist['flagged']:\n",
    "    for name, flags in dist['flagged']:\n",
    "        print(f'  {name}: {\", \".join(flags)}')\n",
    "else:\n",
    "    print('  No dimensions flagged.')\n",
    "print(f'\\nEntropy ranking (least to most informative):')\n",
    "for name in sorted(dist['entropies'], key=dist['entropies'].get):\n",
    "    print(f'  {name:25s}: {dist[\"entropies\"][name]:.3f} nats')\n",
    "\n",
    "# --- 4. PROBING COMPARISON (Ridge vs Attention vs MLP) ---\n",
    "print(f'\\n## 4. MuQ PROBING COMPARISON (4-fold CV R2)')\n",
    "print(f'{\"Dimension\":25s}  {\"Ridge\":>8s}  {\"Attention\":>10s}  {\"MLP\":>8s}  {\"Best\":>10s}')\n",
    "print(f'{\"-\"*25}  {\"-\"*8}  {\"-\"*10}  {\"-\"*8}  {\"-\"*10}')\n",
    "for i in np.argsort(r2_per_dim)[::-1]:\n",
    "    name = DIM_NAMES[i]\n",
    "    ridge_r2 = r2_per_dim[i]\n",
    "    attn_r2 = attn_r2_per_dim[i]\n",
    "    mlp_r2 = mlp_r2_per_dim[i]\n",
    "    best_val = max(ridge_r2, attn_r2, mlp_r2)\n",
    "    best_method = ['Ridge', 'Attention', 'MLP'][[ridge_r2, attn_r2, mlp_r2].index(best_val)]\n",
    "    print(f'  {name:25s}  {ridge_r2:+8.3f}  {attn_r2:+10.3f}  {mlp_r2:+8.3f}  {best_method:>10s}')\n",
    "\n",
    "# --- 5. FACTOR-LEVEL PROBING ---\n",
    "fp = audit_results['factor_probing']\n",
    "print(f'\\n## 5. FACTOR-LEVEL PROBING')\n",
    "print(f'Mean factor R2: {fp[\"mean_factor_r2\"]:.3f} vs mean individual dim R2: {fp[\"mean_dim_r2\"]:.3f}')\n",
    "print(f'Consolidation validated: {fp[\"consolidation_validated\"]}')\n",
    "for key in sorted(k for k in fp if k.startswith('PC')):\n",
    "    info = fp[key]\n",
    "    print(f'  {key}: R2={info[\"r2\"]:.3f} (explains {info[\"explained_variance\"]:.1%} of label variance)')\n",
    "\n",
    "# --- 6. RESIDUAL STRUCTURE ---\n",
    "res = audit_results['residuals']\n",
    "print(f'\\n## 6. RESIDUAL STRUCTURE')\n",
    "print(f'Structured residual components (above noise floor): {res[\"n_structured_components\"]}')\n",
    "print(f'Per-dimension unexplained fraction (what MuQ cannot explain):')\n",
    "for name in sorted(res['unexplained_fraction'], key=res['unexplained_fraction'].get, reverse=True):\n",
    "    print(f'  {name:25s}: {res[\"unexplained_fraction\"][name]:.3f}')\n",
    "\n",
    "# --- 7. CCA ---\n",
    "cc = audit_results['cca']\n",
    "print(f'\\n## 7. CCA (MuQ <-> Labels)')\n",
    "print(f'Significant canonical variates (r > 0.3): {cc[\"n_significant\"]}/{len(cc[\"canonical_correlations\"])}')\n",
    "print(f'Total shared variance (sum r^2): {cc[\"total_shared_variance\"]:.3f}')\n",
    "print(f'MuQ PCA variance retained (50 components): {cc[\"muq_pca_variance_retained\"]:.1%}')\n",
    "print(f'Canonical correlations: {[f\"{c:.3f}\" for c in cc[\"canonical_correlations\"]]}')\n",
    "\n",
    "# --- 8. STOP PREDICTION ---\n",
    "sp = audit_results.get('stop_prediction', {})\n",
    "print(f'\\n## 8. STOP PREDICTION (LOVO AUC)')\n",
    "print(f'Segments: {sp.get(\"n_segments\", \"?\")} ({sp.get(\"n_stop\", \"?\")} STOP, {sp.get(\"n_continue\", \"?\")} CONTINUE)')\n",
    "baseline = sp.get('baseline_auc')\n",
    "for name, auc_val in sp.get('results', {}).items():\n",
    "    delta = f' (delta={auc_val - baseline:+.3f})' if baseline is not None else ''\n",
    "    print(f'  {name:45s}: AUC={auc_val:.3f}{delta}')\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('END OF AUDIT')\n",
    "print('=' * 70)\n",
    "\n",
    "# Also dump as JSON for programmatic consumption\n",
    "print('\\n\\n--- JSON (for programmatic use) ---')\n",
    "print(_json.dumps(audit_results, indent=2, default=str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
