{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Fusion Experiments\n",
        "\n",
        "Multimodal fusion: Audio (MERT) + Symbolic (MIDI) for ISMIR paper.\n",
        "\n",
        "## Experiments\n",
        "- **S0-S2**: Statistical tests (bootstrap, paired tests, multiple corrections)\n",
        "- **F0-F4**: Fusion strategies (simple, weighted, ridge, confidence)\n",
        "- **A0-A2**: Ablations (weight stability, category fusion, error correlation)\n",
        "\n",
        "## Requirements\n",
        "- rclone configured with `gdrive:` remote\n",
        "- Audio/symbolic predictions from Phase 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "import torch\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(success|already)\" || echo \"rclone ok\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers librosa soundfile pytorch_lightning scipy scikit-learn --quiet\n",
        "\n",
        "REPO_DIR = '/tmp/crescendai'\n",
        "if os.path.exists(REPO_DIR):\n",
        "    !cd {REPO_DIR} && git pull origin main\n",
        "else:\n",
        "    !git clone https://github.com/jai-dhiman/crescendai.git {REPO_DIR}\n",
        "print(f\"Repo: {REPO_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, f'{REPO_DIR}/model/src')\n",
        "\n",
        "import json\n",
        "import subprocess\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from audio_experiments import PERCEPIANO_DIMENSIONS, SEED\n",
        "from audio_experiments.training import (\n",
        "    should_run_experiment, sync_experiment_to_gdrive,\n",
        "    get_completed_experiments, print_experiment_status,\n",
        "    run_bootstrap_experiment, run_paired_tests_experiment,\n",
        "    run_multiple_correction_experiment, run_simple_fusion_experiment,\n",
        "    run_weighted_fusion_experiment, run_ridge_fusion_experiment,\n",
        "    run_confidence_fusion_experiment, run_weight_stability_experiment,\n",
        "    run_category_fusion_experiment, run_error_correlation_experiment,\n",
        "    save_fusion_experiment,\n",
        ")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pl.seed_everything(SEED, workers=True)\n",
        "print(\"Imports: OK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_ROOT = Path('/tmp/phase3')\n",
        "RESULTS_DIR = DATA_ROOT / 'results'\n",
        "CHECKPOINT_ROOT = DATA_ROOT / 'checkpoints'\n",
        "\n",
        "GDRIVE_LABELS = 'gdrive:crescendai_data/percepiano_labels'\n",
        "GDRIVE_FOLDS = 'gdrive:crescendai_data/audio_baseline/audio_fold_assignments.json'\n",
        "GDRIVE_SYMBOLIC = 'gdrive:crescendai_data/analysis/symbolic_predictions.json'\n",
        "GDRIVE_AUDIO = 'gdrive:crescendai_data/analysis/checkpoints/audio/cv_predictions.json'\n",
        "GDRIVE_RESULTS = 'gdrive:crescendai_data/checkpoints/fusion_phase3'\n",
        "\n",
        "for d in [DATA_ROOT, RESULTS_DIR, CHECKPOINT_ROOT]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def rclone(cmd, desc):\n",
        "    print(f\"{desc}...\")\n",
        "    subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "# Check rclone\n",
        "r = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
        "if 'gdrive:' not in r.stdout:\n",
        "    raise RuntimeError(\"rclone gdrive not configured\")\n",
        "\n",
        "# Download data\n",
        "LABEL_DIR = DATA_ROOT / 'labels'\n",
        "LABEL_DIR.mkdir(exist_ok=True)\n",
        "rclone(['rclone', 'copy', GDRIVE_LABELS, str(LABEL_DIR)], \"Labels\")\n",
        "rclone(['rclone', 'copyto', GDRIVE_FOLDS, str(DATA_ROOT / 'folds.json')], \"Folds\")\n",
        "rclone(['rclone', 'copyto', GDRIVE_SYMBOLIC, str(DATA_ROOT / 'symbolic.json')], \"Symbolic\")\n",
        "rclone(['rclone', 'copyto', GDRIVE_AUDIO, str(DATA_ROOT / 'audio.json')], \"Audio\")\n",
        "\n",
        "print(\"Data downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(LABEL_DIR / 'label_2round_mean_reg_19_with0_rm_highstd0.json') as f:\n",
        "    LABELS = json.load(f)\n",
        "with open(DATA_ROOT / 'folds.json') as f:\n",
        "    FOLD_ASSIGNMENTS = json.load(f)\n",
        "with open(DATA_ROOT / 'symbolic.json') as f:\n",
        "    SYMBOLIC_RAW = json.load(f)\n",
        "with open(DATA_ROOT / 'audio.json') as f:\n",
        "    AUDIO_RAW = json.load(f)\n",
        "\n",
        "SAMPLE_KEYS = sorted(set(LABELS) & set(SYMBOLIC_RAW) & set(AUDIO_RAW) & set(FOLD_ASSIGNMENTS))\n",
        "print(f\"Aligned: {len(SAMPLE_KEYS)} samples\")\n",
        "\n",
        "LABELS_ARR = np.array([[LABELS[k][d] for d in PERCEPIANO_DIMENSIONS] for k in SAMPLE_KEYS])\n",
        "SYMBOLIC_ARR = np.array([SYMBOLIC_RAW[k] for k in SAMPLE_KEYS])\n",
        "AUDIO_ARR = np.array([AUDIO_RAW[k] for k in SAMPLE_KEYS])\n",
        "\n",
        "print(f\"Shapes: labels={LABELS_ARR.shape}, audio={AUDIO_ARR.shape}, symbolic={SYMBOLIC_ARR.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ALL_RESULTS = {}\n",
        "ALL_EXPERIMENT_IDS = [\n",
        "    'S0_bootstrap', 'S1_paired_tests', 'S2_multiple_correction',\n",
        "    'F0_simple', 'F1_weighted', 'F2_ridge', 'F3_confidence',\n",
        "    'A0_stability', 'A1_category', 'A2_error_corr',\n",
        "]\n",
        "\n",
        "COMPLETED_CACHE = get_completed_experiments(GDRIVE_RESULTS)\n",
        "print_experiment_status(ALL_EXPERIMENT_IDS, COMPLETED_CACHE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Statistical Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# S0: Bootstrap CIs\n",
        "if should_run_experiment('S0_bootstrap', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['S0_bootstrap'] = run_bootstrap_experiment(\n",
        "        'S0_bootstrap', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR, n_bootstrap=10000\n",
        "    )\n",
        "    save_fusion_experiment('S0_bootstrap', ALL_RESULTS['S0_bootstrap'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('S0_bootstrap', ALL_RESULTS['S0_bootstrap'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# S1: Paired Tests\n",
        "if should_run_experiment('S1_paired_tests', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['S1_paired_tests'] = run_paired_tests_experiment(\n",
        "        'S1_paired_tests', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR\n",
        "    )\n",
        "    save_fusion_experiment('S1_paired_tests', ALL_RESULTS['S1_paired_tests'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('S1_paired_tests', ALL_RESULTS['S1_paired_tests'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# S2: Multiple Correction\n",
        "if should_run_experiment('S2_multiple_correction', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    # Requires S1 results\n",
        "    if 'S1_paired_tests' not in ALL_RESULTS:\n",
        "        with open(RESULTS_DIR / 'S1_paired_tests.json') as f:\n",
        "            ALL_RESULTS['S1_paired_tests'] = json.load(f)\n",
        "    \n",
        "    ALL_RESULTS['S2_multiple_correction'] = run_multiple_correction_experiment(\n",
        "        'S2_multiple_correction', ALL_RESULTS['S1_paired_tests']\n",
        "    )\n",
        "    save_fusion_experiment('S2_multiple_correction', ALL_RESULTS['S2_multiple_correction'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('S2_multiple_correction', ALL_RESULTS['S2_multiple_correction'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Fusion Strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# F0: Simple Average\n",
        "if should_run_experiment('F0_simple', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['F0_simple'] = run_simple_fusion_experiment(\n",
        "        'F0_simple', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR\n",
        "    )\n",
        "    save_fusion_experiment('F0_simple', ALL_RESULTS['F0_simple'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('F0_simple', ALL_RESULTS['F0_simple'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# F1: Weighted Fusion (CV)\n",
        "if should_run_experiment('F1_weighted', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['F1_weighted'] = run_weighted_fusion_experiment(\n",
        "        'F1_weighted', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR,\n",
        "        FOLD_ASSIGNMENTS, SAMPLE_KEYS\n",
        "    )\n",
        "    save_fusion_experiment('F1_weighted', ALL_RESULTS['F1_weighted'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('F1_weighted', ALL_RESULTS['F1_weighted'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# F2: Ridge Stacking\n",
        "if should_run_experiment('F2_ridge', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['F2_ridge'] = run_ridge_fusion_experiment(\n",
        "        'F2_ridge', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR,\n",
        "        FOLD_ASSIGNMENTS, SAMPLE_KEYS\n",
        "    )\n",
        "    save_fusion_experiment('F2_ridge', ALL_RESULTS['F2_ridge'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('F2_ridge', ALL_RESULTS['F2_ridge'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# F3: Confidence Weighted\n",
        "if should_run_experiment('F3_confidence', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['F3_confidence'] = run_confidence_fusion_experiment(\n",
        "        'F3_confidence', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR\n",
        "    )\n",
        "    save_fusion_experiment('F3_confidence', ALL_RESULTS['F3_confidence'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('F3_confidence', ALL_RESULTS['F3_confidence'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Ablations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A0: Weight Stability\n",
        "if should_run_experiment('A0_stability', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    # Requires F1 results\n",
        "    if 'F1_weighted' not in ALL_RESULTS:\n",
        "        with open(RESULTS_DIR / 'F1_weighted.json') as f:\n",
        "            ALL_RESULTS['F1_weighted'] = json.load(f)\n",
        "    \n",
        "    ALL_RESULTS['A0_stability'] = run_weight_stability_experiment(\n",
        "        'A0_stability', ALL_RESULTS['F1_weighted']['fold_weights']\n",
        "    )\n",
        "    save_fusion_experiment('A0_stability', ALL_RESULTS['A0_stability'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('A0_stability', ALL_RESULTS['A0_stability'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A1: Category Fusion\n",
        "if should_run_experiment('A1_category', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['A1_category'] = run_category_fusion_experiment(\n",
        "        'A1_category', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR,\n",
        "        FOLD_ASSIGNMENTS, SAMPLE_KEYS\n",
        "    )\n",
        "    save_fusion_experiment('A1_category', ALL_RESULTS['A1_category'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('A1_category', ALL_RESULTS['A1_category'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A2: Error Correlation\n",
        "if should_run_experiment('A2_error_corr', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
        "    ALL_RESULTS['A2_error_corr'] = run_error_correlation_experiment(\n",
        "        'A2_error_corr', AUDIO_ARR, SYMBOLIC_ARR, LABELS_ARR\n",
        "    )\n",
        "    save_fusion_experiment('A2_error_corr', ALL_RESULTS['A2_error_corr'], RESULTS_DIR, ALL_RESULTS)\n",
        "    sync_experiment_to_gdrive('A2_error_corr', ALL_RESULTS['A2_error_corr'], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print results table\n",
        "print(\"=\"*80)\n",
        "print(\"PHASE 3 FUSION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load any missing results from disk\n",
        "for exp_id in ALL_EXPERIMENT_IDS:\n",
        "    if exp_id not in ALL_RESULTS:\n",
        "        result_file = RESULTS_DIR / f\"{exp_id}.json\"\n",
        "        if result_file.exists():\n",
        "            with open(result_file) as f:\n",
        "                ALL_RESULTS[exp_id] = json.load(f)\n",
        "\n",
        "# Get baseline R2s\n",
        "audio_r2 = ALL_RESULTS.get('S0_bootstrap', {}).get('audio', {}).get('overall', {}).get('r2', 0)\n",
        "symbolic_r2 = ALL_RESULTS.get('S0_bootstrap', {}).get('symbolic', {}).get('overall', {}).get('r2', 0)\n",
        "\n",
        "print(f\"\\n{'Model':<25} {'R2':>10} {'95% CI':>25} {'vs Best':>12}\")\n",
        "print(\"-\"*75)\n",
        "\n",
        "best_single = max(audio_r2, symbolic_r2)\n",
        "\n",
        "# Baselines\n",
        "if 'S0_bootstrap' in ALL_RESULTS:\n",
        "    s0 = ALL_RESULTS['S0_bootstrap']\n",
        "    a = s0['audio']['overall']\n",
        "    print(f\"{'Audio':<25} {a['r2']:>10.4f} [{a['ci_lower']:.3f}, {a['ci_upper']:.3f}] {'---':>12}\")\n",
        "    s = s0['symbolic']['overall']\n",
        "    print(f\"{'Symbolic':<25} {s['r2']:>10.4f} [{s['ci_lower']:.3f}, {s['ci_upper']:.3f}] {'---':>12}\")\n",
        "\n",
        "print(\"-\"*75)\n",
        "\n",
        "# Fusion strategies\n",
        "fusion_exps = [('F0_simple', 'Simple Average'), ('F1_weighted', 'Weighted CV'),\n",
        "               ('F2_ridge', 'Ridge Stacking'), ('F3_confidence', 'Confidence')]\n",
        "for exp_id, name in fusion_exps:\n",
        "    if exp_id in ALL_RESULTS:\n",
        "        r = ALL_RESULTS[exp_id]\n",
        "        r2 = r['overall_r2']\n",
        "        b = r['bootstrap']['overall']\n",
        "        diff = r2 - best_single\n",
        "        print(f\"{name:<25} {r2:>10.4f} [{b['ci_lower']:.3f}, {b['ci_upper']:.3f}] {diff:>+12.4f}\")\n",
        "\n",
        "print(\"=\"*75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final sync\n",
        "with open(RESULTS_DIR / 'phase3_all_results.json', 'w') as f:\n",
        "    json.dump(ALL_RESULTS, f, indent=2, default=str)\n",
        "\n",
        "subprocess.run(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS], capture_output=True)\n",
        "print(f\"Done! Results at: {GDRIVE_RESULTS}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
