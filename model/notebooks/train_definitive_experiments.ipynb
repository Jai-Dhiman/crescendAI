{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Definitive Experiments\n",
    "\n",
    "## Parts\n",
    "1. **M1a-M1d**: MuQ Layer Ablation (find optimal layers)\n",
    "2. **F8-F11**: MuQ + Symbolic Fusion\n",
    "3. **D9a-D9c**: MERT + MuQ Audio Fusion\n",
    "4. **X1-X3**: Cross-Dataset Validation (PianoVAM, ASAP, PSyllabus)\n",
    "5. **S3-S4**: Statistical Rigor (Bootstrap, Bonferroni)\n",
    "6. **A3-A7**: Analysis (Error correlation, dimensions, calibration)\n",
    "7. **Export**: Save all results to GDrive\n",
    "\n",
    "## Requirements\n",
    "- Compute: A100 (80GB VRAM)\n",
    "- rclone configured with `gdrive:` remote\n",
    "- External datasets: PianoVAM, ASAP, PSyllabus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: CUDA setup (must be before any CUDA operations)\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    raise RuntimeError(\"GPU required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Install dependencies and clone repo\n",
    "!pip install transformers librosa soundfile pytorch_lightning nnAudio scipy scikit-learn muq requests tqdm --quiet\n",
    "\n",
    "import os\n",
    "REPO_DIR = '/tmp/crescendai'\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull origin main\n",
    "else:\n",
    "    !git clone https://github.com/jai-dhiman/crescendai.git {REPO_DIR}\n",
    "\n",
    "print(f\"Repo: {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Imports\n",
    "import sys\n",
    "sys.path.insert(0, f'{REPO_DIR}/model/src')\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from audio_experiments import PERCEPIANO_DIMENSIONS, DIMENSION_CATEGORIES, BASE_CONFIG, SEED\n",
    "from audio_experiments.extractors import (\n",
    "    extract_mert_for_layer_range,\n",
    "    extract_muq_embeddings,\n",
    ")\n",
    "from audio_experiments.models import (\n",
    "    MuQStatsModel,\n",
    "    MuQBaseModel,\n",
    "    MERTMuQEnsemble,\n",
    "    MERTMuQConcatModel,\n",
    "    AsymmetricGatedFusion,\n",
    ")\n",
    "from audio_experiments.training import (\n",
    "    run_4fold_mert_experiment,\n",
    "    run_4fold_dual_experiment,\n",
    "    restore_all_from_gdrive,\n",
    "    should_run_experiment,\n",
    "    sync_experiment_to_gdrive,\n",
    "    get_completed_experiments,\n",
    "    print_experiment_status,\n",
    "    # Fusion runners\n",
    "    run_simple_fusion_experiment,\n",
    "    run_weighted_fusion_experiment,\n",
    "    run_ridge_fusion_experiment,\n",
    "    run_confidence_fusion_experiment,\n",
    "    run_error_correlation_experiment,\n",
    "    save_fusion_experiment,\n",
    "    # Statistics\n",
    "    bootstrap_r2_extended,\n",
    "    bootstrap_r2_comparison,\n",
    "    paired_ttest_per_sample,\n",
    "    wilcoxon_test,\n",
    "    cohens_d,\n",
    "    bonferroni_correction,\n",
    "    fdr_correction,\n",
    "    # Fusion strategies\n",
    "    simple_average_fusion,\n",
    "    weighted_fusion_grid_search,\n",
    "    compute_error_correlation,\n",
    "    compute_per_dimension_comparison,\n",
    ")\n",
    "from audio_experiments.training.sync import numpy_serializer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Imports: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Path configuration\n",
    "DATA_ROOT = Path('/tmp/definitive_experiments')\n",
    "AUDIO_DIR = DATA_ROOT / 'audio'\n",
    "LABEL_DIR = DATA_ROOT / 'labels'\n",
    "MUQ_CACHE_ROOT = DATA_ROOT / 'muq_cache'\n",
    "MERT_CACHE_ROOT = DATA_ROOT / 'mert_cache'\n",
    "CHECKPOINT_ROOT = DATA_ROOT / 'checkpoints'\n",
    "RESULTS_DIR = DATA_ROOT / 'results'\n",
    "LOG_DIR = DATA_ROOT / 'logs'\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "\n",
    "# Cross-dataset directories\n",
    "PIANOVAM_DIR = DATA_ROOT / 'pianovam'\n",
    "ASAP_DIR = DATA_ROOT / 'asap'\n",
    "PSYLLABUS_DIR = DATA_ROOT / 'psyllabus'\n",
    "\n",
    "# GDrive paths\n",
    "GDRIVE_AUDIO = 'gdrive:crescendai_data/audio_baseline/percepiano_rendered'\n",
    "GDRIVE_LABELS = 'gdrive:crescendai_data/percepiano_labels'\n",
    "GDRIVE_FOLDS = 'gdrive:crescendai_data/percepiano_fold_assignments.json'\n",
    "GDRIVE_MERT_CACHE = 'gdrive:crescendai_data/audio_baseline/mert_embeddings/L7-12'\n",
    "GDRIVE_MUQ_CACHE = 'gdrive:crescendai_data/audio_baseline/muq_embeddings'\n",
    "GDRIVE_RESULTS = 'gdrive:crescendai_data/checkpoints/definitive_experiments'\n",
    "GDRIVE_SYMBOLIC = 'gdrive:crescendai_data/checkpoints/aligned_fusion/symbolic_predictions.json'\n",
    "\n",
    "for d in [AUDIO_DIR, LABEL_DIR, MUQ_CACHE_ROOT, MERT_CACHE_ROOT, CHECKPOINT_ROOT,\n",
    "          RESULTS_DIR, LOG_DIR, FIGURES_DIR, PIANOVAM_DIR, ASAP_DIR, PSYLLABUS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_rclone(cmd, desc=\"\"):\n",
    "    if desc:\n",
    "        print(f\"{desc}...\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return result\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "if 'gdrive:' not in result.stdout:\n",
    "    raise RuntimeError(\"rclone 'gdrive' not configured\")\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"GDrive results: {GDRIVE_RESULTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Download data\n",
    "run_rclone(['rclone', 'copy', GDRIVE_AUDIO, str(AUDIO_DIR), '--progress'], \"Downloading audio\")\n",
    "run_rclone(['rclone', 'copy', GDRIVE_LABELS, str(LABEL_DIR)], \"Downloading labels\")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'folds.json'\n",
    "run_rclone(['rclone', 'copyto', GDRIVE_FOLDS, str(FOLD_FILE)], \"Downloading folds\")\n",
    "\n",
    "# Load labels and folds\n",
    "LABEL_FILE = LABEL_DIR / 'label_2round_mean_reg_19_with0_rm_highstd0.json'\n",
    "with open(LABEL_FILE) as f:\n",
    "    LABELS = json.load(f)\n",
    "with open(FOLD_FILE) as f:\n",
    "    FOLD_ASSIGNMENTS = json.load(f)\n",
    "\n",
    "# Create key->fold_id mapping\n",
    "FOLD_BY_KEY = {}\n",
    "for fold_id in range(4):\n",
    "    for key in FOLD_ASSIGNMENTS.get(f\"fold_{fold_id}\", []):\n",
    "        FOLD_BY_KEY[key] = fold_id\n",
    "\n",
    "ALL_KEYS = sorted(FOLD_BY_KEY.keys())\n",
    "print(f\"Samples per fold: {[len(FOLD_ASSIGNMENTS.get(f'fold_{i}', [])) for i in range(4)]}\")\n",
    "print(f\"Total samples: {len(ALL_KEYS)}\")\n",
    "print(f\"Audio files: {len(list(AUDIO_DIR.glob('*.wav')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Initialize results tracking\n",
    "ALL_RESULTS = {}\n",
    "\n",
    "# Get completed experiments from GDrive\n",
    "print(\"Checking GDrive for completed experiments...\")\n",
    "COMPLETED_CACHE = get_completed_experiments(GDRIVE_RESULTS)\n",
    "print(f\"Found {len(COMPLETED_CACHE)} completed experiments\")\n",
    "\n",
    "# Define experiment IDs\n",
    "EXPERIMENT_IDS = [\n",
    "    # Part 1: MuQ Layer Ablation\n",
    "    'M1a_muq_L1-6',\n",
    "    'M1b_muq_L7-12',\n",
    "    'M1c_muq_L13-24',\n",
    "    'M1d_muq_L1-24',\n",
    "    # Part 2: MuQ + Symbolic Fusion\n",
    "    'F8_muq_symbolic_simple',\n",
    "    'F9_muq_symbolic_weighted',\n",
    "    'F10_muq_symbolic_ridge',\n",
    "    'F11_muq_symbolic_confidence',\n",
    "    # Part 3: MERT + MuQ Fusion\n",
    "    'D9a_mert_muq_ensemble',\n",
    "    'D9b_mert_muq_concat',\n",
    "    'D9c_mert_muq_gated',\n",
    "    # Part 4: Cross-Dataset\n",
    "    'X1_pianovam_skill',\n",
    "    'X2_asap_multiperformer',\n",
    "    'X3_psyllabus_difficulty',\n",
    "    # Part 5: Statistics\n",
    "    'S3_bootstrap_all',\n",
    "    'S4_significance_tests',\n",
    "    # Part 6: Analysis\n",
    "    'A3_error_correlation',\n",
    "    'A4_dimension_breakdown',\n",
    "    'A5_failure_cases',\n",
    "    'A6_calibration',\n",
    "    'A7_gate_visualization',\n",
    "]\n",
    "\n",
    "print_experiment_status(EXPERIMENT_IDS, COMPLETED_CACHE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: MuQ Layer Ablation (M1a-M1d)\n",
    "\n",
    "Find optimal MuQ layer range, parallel to MERT experiments B1a-d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: MuQ Layer Configurations\n",
    "MUQ_LAYER_CONFIGS = {\n",
    "    'M1a_muq_L1-6': {'layer_start': 1, 'layer_end': 7, 'desc': 'MuQ layers 1-6 (early acoustic)'},\n",
    "    'M1b_muq_L7-12': {'layer_start': 7, 'layer_end': 13, 'desc': 'MuQ layers 7-12 (mid perceptual)'},\n",
    "    'M1c_muq_L13-24': {'layer_start': 13, 'layer_end': 25, 'desc': 'MuQ layers 13-24 (late semantic)'},\n",
    "    'M1d_muq_L1-24': {'layer_start': 1, 'layer_end': 25, 'desc': 'MuQ all layers 1-24'},\n",
    "}\n",
    "\n",
    "# MuQ Stats pooling config (proven best in prior experiments)\n",
    "MUQ_CONFIG = {\n",
    "    **BASE_CONFIG,\n",
    "    'input_dim': 1024,\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'pooling_stats': 'mean_std',  # 2x input dim\n",
    "}\n",
    "\n",
    "def make_muq_stats_model(cfg):\n",
    "    return MuQStatsModel(\n",
    "        input_dim=cfg['input_dim'],\n",
    "        hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling_stats=cfg['pooling_stats'],\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "print(\"MuQ layer ablation configs ready\")\n",
    "for exp_id, cfg in MUQ_LAYER_CONFIGS.items():\n",
    "    print(f\"  {exp_id}: layers {cfg['layer_start']}-{cfg['layer_end']-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: M1a - MuQ Layers 1-6\n",
    "exp_id = 'M1a_muq_L1-6'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Create layer-specific cache\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extract embeddings\n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: M1b - MuQ Layers 7-12\n",
    "exp_id = 'M1b_muq_L7-12'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: M1c - MuQ Layers 13-24\n",
    "exp_id = 'M1c_muq_L13-24'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: M1d - MuQ All Layers\n",
    "exp_id = 'M1d_muq_L1-24'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: MuQ Layer Ablation Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MuQ LAYER ABLATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Experiment':<25} {'Layers':<12} {'R2':>10} {'Std':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "best_muq_exp = None\n",
    "best_muq_r2 = 0\n",
    "\n",
    "for exp_id in ['M1a_muq_L1-6', 'M1b_muq_L7-12', 'M1c_muq_L13-24', 'M1d_muq_L1-24']:\n",
    "    # Load from disk if not in memory\n",
    "    if exp_id not in ALL_RESULTS:\n",
    "        result_file = RESULTS_DIR / f\"{exp_id}.json\"\n",
    "        if result_file.exists():\n",
    "            with open(result_file) as f:\n",
    "                ALL_RESULTS[exp_id] = json.load(f)\n",
    "    \n",
    "    if exp_id in ALL_RESULTS:\n",
    "        r = ALL_RESULTS[exp_id]\n",
    "        r2 = r['summary']['avg_r2']\n",
    "        std = r['summary']['std_r2']\n",
    "        cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "        layers = f\"{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "        print(f\"{exp_id:<25} {layers:<12} {r2:>10.4f} {std:>10.4f}\")\n",
    "        \n",
    "        if r2 > best_muq_r2:\n",
    "            best_muq_r2 = r2\n",
    "            best_muq_exp = exp_id\n",
    "\n",
    "print(\"-\"*70)\n",
    "if best_muq_exp:\n",
    "    print(f\"BEST: {best_muq_exp} (R2={best_muq_r2:.4f})\")\n",
    "    BEST_MUQ_CONFIG = MUQ_LAYER_CONFIGS[best_muq_exp]\n",
    "    BEST_MUQ_CACHE = MUQ_CACHE_ROOT / f\"L{BEST_MUQ_CONFIG['layer_start']}-{BEST_MUQ_CONFIG['layer_end']-1}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: MuQ + Symbolic Fusion (F8-F11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Load Symbolic Predictions\n",
    "SYMBOLIC_PRED_FILE = DATA_ROOT / 'symbolic_predictions.json'\n",
    "run_rclone(['rclone', 'copyto', GDRIVE_SYMBOLIC, str(SYMBOLIC_PRED_FILE)], \"Downloading symbolic predictions\")\n",
    "\n",
    "with open(SYMBOLIC_PRED_FILE) as f:\n",
    "    SYMBOLIC_PREDICTIONS = json.load(f)\n",
    "\n",
    "print(f\"Loaded symbolic predictions for {len(SYMBOLIC_PREDICTIONS)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Generate MuQ Predictions\n",
    "def generate_muq_predictions(checkpoint_dir: Path, cache_dir: Path, fold_assignments: Dict, labels: Dict) -> Dict[str, List[float]]:\n",
    "    \"\"\"Generate CV predictions from trained MuQ models.\"\"\"\n",
    "    from audio_experiments.data import MERTDataset, mert_collate_fn\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    predictions = {}\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    for fold in range(4):\n",
    "        ckpt_path = checkpoint_dir / f\"fold{fold}_best.ckpt\"\n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"Warning: checkpoint not found: {ckpt_path}\")\n",
    "            continue\n",
    "        \n",
    "        model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "        model = model.to(device).eval()\n",
    "        \n",
    "        # Get validation keys for this fold\n",
    "        val_keys = fold_assignments.get(f\"fold_{fold}\", [])\n",
    "        val_ds = MERTDataset(cache_dir, labels, fold_assignments, fold, \"val\", max_frames=1000)\n",
    "        val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=mert_collate_fn)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                pred = model(batch['embeddings'].to(device), batch['attention_mask'].to(device))\n",
    "                for key, p in zip(batch['keys'], pred.cpu().numpy()):\n",
    "                    predictions[key] = p.tolist()\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Generate predictions from best MuQ model\n",
    "if best_muq_exp:\n",
    "    print(f\"Generating MuQ predictions from {best_muq_exp}...\")\n",
    "    MUQ_PREDICTIONS = generate_muq_predictions(\n",
    "        CHECKPOINT_ROOT / best_muq_exp,\n",
    "        BEST_MUQ_CACHE,\n",
    "        FOLD_ASSIGNMENTS,\n",
    "        LABELS\n",
    "    )\n",
    "    print(f\"Generated predictions for {len(MUQ_PREDICTIONS)} samples\")\n",
    "else:\n",
    "    print(\"WARNING: No MuQ model trained yet\")\n",
    "    MUQ_PREDICTIONS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Align predictions\n",
    "# Find common keys\n",
    "FUSION_KEYS = sorted(\n",
    "    set(MUQ_PREDICTIONS.keys()) &\n",
    "    set(SYMBOLIC_PREDICTIONS.keys()) &\n",
    "    set(LABELS.keys())\n",
    ")\n",
    "print(f\"Aligned samples: {len(FUSION_KEYS)}\")\n",
    "\n",
    "# Create aligned arrays\n",
    "MUQ_ARR = np.array([MUQ_PREDICTIONS[k] for k in FUSION_KEYS])\n",
    "SYMBOLIC_ARR = np.array([SYMBOLIC_PREDICTIONS[k] for k in FUSION_KEYS])\n",
    "LABELS_ARR = np.array([LABELS[k][:19] for k in FUSION_KEYS])\n",
    "\n",
    "print(f\"MuQ shape: {MUQ_ARR.shape}\")\n",
    "print(f\"Symbolic shape: {SYMBOLIC_ARR.shape}\")\n",
    "print(f\"Labels shape: {LABELS_ARR.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: F8 - Simple Average Fusion\n",
    "exp_id = 'F8_muq_symbolic_simple'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_simple_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: F9 - Weighted Fusion\n",
    "exp_id = 'F9_muq_symbolic_weighted'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_weighted_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, FOLD_BY_KEY, FUSION_KEYS, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: F10 - Ridge Stacking\n",
    "exp_id = 'F10_muq_symbolic_ridge'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_ridge_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, FOLD_BY_KEY, FUSION_KEYS, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: F11 - Confidence Weighted\n",
    "exp_id = 'F11_muq_symbolic_confidence'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_confidence_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: MERT + MuQ Audio Fusion (D9a-D9c)\n",
    "\n",
    "Test if two audio encoders provide complementary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Extract MERT embeddings (layers 7-12, best from prior ablation)\n",
    "MERT_CACHE = MERT_CACHE_ROOT / 'L7-12'\n",
    "MERT_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Try to download from GDrive first\n",
    "run_rclone(['rclone', 'copy', GDRIVE_MERT_CACHE, str(MERT_CACHE)], \"Downloading MERT cache\")\n",
    "\n",
    "# Extract any missing\n",
    "extract_mert_for_layer_range(7, 13, AUDIO_DIR, MERT_CACHE, ALL_KEYS)\n",
    "print(f\"MERT embeddings ready: {len(list(MERT_CACHE.glob('*.pt')))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Ensure MuQ embeddings for best config\n",
    "if best_muq_exp:\n",
    "    MUQ_CACHE = BEST_MUQ_CACHE\n",
    "else:\n",
    "    # Default to all layers if no ablation done yet\n",
    "    MUQ_CACHE = MUQ_CACHE_ROOT / 'L1-24'\n",
    "    MUQ_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "    extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE, ALL_KEYS, layer_start=1, layer_end=25)\n",
    "\n",
    "print(f\"MuQ cache: {MUQ_CACHE}\")\n",
    "print(f\"MuQ embeddings: {len(list(MUQ_CACHE.glob('*.pt')))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: D9a - MERT+MuQ Ensemble (Late Fusion)\n",
    "exp_id = 'D9a_mert_muq_ensemble'\n",
    "\n",
    "DUAL_CONFIG = {\n",
    "    **BASE_CONFIG,\n",
    "    'input_dim': 1024,\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'fusion_weight': 0.5,\n",
    "}\n",
    "\n",
    "def make_ensemble_model(cfg):\n",
    "    return MERTMuQEnsemble(\n",
    "        input_dim=cfg['input_dim'],\n",
    "        hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling='attention',\n",
    "        fusion_weight=cfg['fusion_weight'],\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_4fold_dual_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description='MERT+MuQ late fusion ensemble',\n",
    "        model_factory=make_ensemble_model,\n",
    "        mert_cache_dir=MERT_CACHE,\n",
    "        muq_cache_dir=MUQ_CACHE,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=DUAL_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 27: D9b - MERT+MuQ Concat (Early Fusion)\n",
    "exp_id = 'D9b_mert_muq_concat'\n",
    "\n",
    "def make_concat_model(cfg):\n",
    "    return MERTMuQConcatModel(\n",
    "        mert_dim=cfg['input_dim'],\n",
    "        muq_dim=cfg['input_dim'],\n",
    "        hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling='attention',\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_4fold_dual_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description='MERT+MuQ early fusion concat',\n",
    "        model_factory=make_concat_model,\n",
    "        mert_cache_dir=MERT_CACHE,\n",
    "        muq_cache_dir=MUQ_CACHE,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=DUAL_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: D9c - MERT+MuQ Gated Fusion\n",
    "exp_id = 'D9c_mert_muq_gated'\n",
    "\n",
    "def make_gated_model(cfg):\n",
    "    return AsymmetricGatedFusion(\n",
    "        mert_dim=cfg['input_dim'],\n",
    "        muq_dim=cfg['input_dim'],\n",
    "        mert_hidden=cfg['hidden_dim'],\n",
    "        shared_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling='attention',\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_4fold_dual_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description='MERT+MuQ asymmetric gated fusion',\n",
    "        model_factory=make_gated_model,\n",
    "        mert_cache_dir=MERT_CACHE,\n",
    "        muq_cache_dir=MUQ_CACHE,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=DUAL_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Extract gate weights from D9c\n",
    "exp_id = 'D9c_mert_muq_gated'\n",
    "ckpt_path = CHECKPOINT_ROOT / exp_id / 'fold0_best.ckpt'\n",
    "\n",
    "if ckpt_path.exists():\n",
    "    from audio_experiments.data import DualEmbeddingDataset, dual_collate_fn\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    model = AsymmetricGatedFusion.load_from_checkpoint(ckpt_path)\n",
    "    model = model.to('cuda').eval()\n",
    "    \n",
    "    # Get sample batch for gate extraction\n",
    "    val_keys = FOLD_ASSIGNMENTS.get('fold_0', [])[:32]\n",
    "    ds = DualEmbeddingDataset(MERT_CACHE, MUQ_CACHE, LABELS, val_keys, max_frames=1000)\n",
    "    dl = DataLoader(ds, batch_size=32, collate_fn=dual_collate_fn)\n",
    "    batch = next(iter(dl))\n",
    "    \n",
    "    gate_info = model.get_learned_gates(\n",
    "        batch['mert_embeddings'].cuda(),\n",
    "        batch['muq_embeddings'].cuda(),\n",
    "        batch['mert_mask'].cuda(),\n",
    "        batch['muq_mask'].cuda(),\n",
    "    )\n",
    "    \n",
    "    # Store gate weights per dimension\n",
    "    GATE_WEIGHTS = {\n",
    "        dim: float(gate_info['mert_weight_per_dim'][i])\n",
    "        for i, dim in enumerate(PERCEPIANO_DIMENSIONS)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nLearned Gate Weights (higher = more MERT):\")\n",
    "    for dim, weight in sorted(GATE_WEIGHTS.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {dim:<25}: {weight:.3f}\")\n",
    "    \n",
    "    # Save to results\n",
    "    if exp_id in ALL_RESULTS:\n",
    "        ALL_RESULTS[exp_id]['gate_weights'] = GATE_WEIGHTS\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    GATE_WEIGHTS = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Cross-Dataset Validation (X1-X3)\n",
    "\n",
    "Validate model generalization on external datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 31: X1 - PianoVAM Skill Level Validation\n",
    "# Dataset: https://yonghyunk1m.github.io/PianoVAM\n",
    "# 106 recordings, 10 amateur pianists, 3 skill levels\n",
    "\n",
    "exp_id = 'X1_pianovam_skill'\n",
    "\n",
    "def download_pianovam(data_dir: Path) -> Tuple[List[Path], np.ndarray, List[str]]:\n",
    "    \"\"\"Download PianoVAM dataset and return audio paths with skill levels.\"\"\"\n",
    "    import requests\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    # PianoVAM metadata\n",
    "    # Note: Replace with actual download URL when available\n",
    "    metadata_url = \"https://raw.githubusercontent.com/yonghyunk1m/PianoVAM/main/metadata.json\"\n",
    "    audio_base = \"https://github.com/yonghyunk1m/PianoVAM/releases/download/v1.0/\"\n",
    "    \n",
    "    audio_dir = data_dir / 'audio'\n",
    "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Try to download metadata\n",
    "    try:\n",
    "        resp = requests.get(metadata_url, timeout=10)\n",
    "        metadata = resp.json()\n",
    "    except:\n",
    "        print(\"PianoVAM metadata not accessible. Using local data if available.\")\n",
    "        # Check for local files\n",
    "        local_audio = list(audio_dir.glob('*.wav'))\n",
    "        if local_audio:\n",
    "            # Assume skill levels from filename pattern\n",
    "            audio_paths = local_audio\n",
    "            skill_levels = []\n",
    "            keys = []\n",
    "            for p in audio_paths:\n",
    "                name = p.stem.lower()\n",
    "                if 'advanced' in name:\n",
    "                    skill_levels.append(2)\n",
    "                elif 'intermediate' in name:\n",
    "                    skill_levels.append(1)\n",
    "                else:\n",
    "                    skill_levels.append(0)\n",
    "                keys.append(p.stem)\n",
    "            return audio_paths, np.array(skill_levels), keys\n",
    "        raise FileNotFoundError(\"PianoVAM data not found\")\n",
    "    \n",
    "    # Download audio files\n",
    "    audio_paths = []\n",
    "    skill_levels = []\n",
    "    keys = []\n",
    "    \n",
    "    for item in tqdm(metadata['recordings'], desc='Downloading PianoVAM'):\n",
    "        audio_url = audio_base + item['filename']\n",
    "        audio_path = audio_dir / item['filename']\n",
    "        \n",
    "        if not audio_path.exists():\n",
    "            resp = requests.get(audio_url)\n",
    "            if resp.status_code == 200:\n",
    "                with open(audio_path, 'wb') as f:\n",
    "                    f.write(resp.content)\n",
    "        \n",
    "        if audio_path.exists():\n",
    "            audio_paths.append(audio_path)\n",
    "            skill_map = {'Beginner': 0, 'Intermediate': 1, 'Advanced': 2}\n",
    "            skill_levels.append(skill_map.get(item['skill_level'], 0))\n",
    "            keys.append(audio_path.stem)\n",
    "    \n",
    "    return audio_paths, np.array(skill_levels), keys\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    try:\n",
    "        # Download dataset\n",
    "        vam_audio_paths, vam_skill_levels, vam_keys = download_pianovam(PIANOVAM_DIR)\n",
    "        print(f\"PianoVAM: {len(vam_audio_paths)} recordings\")\n",
    "        print(f\"Skill distribution: Beginner={sum(vam_skill_levels==0)}, Intermediate={sum(vam_skill_levels==1)}, Advanced={sum(vam_skill_levels==2)}\")\n",
    "        \n",
    "        # Extract MuQ embeddings\n",
    "        vam_cache = PIANOVAM_DIR / 'muq_cache'\n",
    "        vam_cache.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if best_muq_exp:\n",
    "            cfg = BEST_MUQ_CONFIG\n",
    "            extract_muq_embeddings(\n",
    "                PIANOVAM_DIR / 'audio', vam_cache, vam_keys,\n",
    "                layer_start=cfg['layer_start'], layer_end=cfg['layer_end']\n",
    "            )\n",
    "        \n",
    "        # Load trained model and predict\n",
    "        ckpt_path = CHECKPOINT_ROOT / best_muq_exp / 'fold0_best.ckpt'\n",
    "        model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "        model = model.to('cuda').eval()\n",
    "        \n",
    "        vam_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for key in vam_keys:\n",
    "                emb_path = vam_cache / f\"{key}.pt\"\n",
    "                if emb_path.exists():\n",
    "                    emb = torch.load(emb_path).unsqueeze(0).cuda()\n",
    "                    mask = torch.ones(1, emb.shape[1], dtype=torch.bool).cuda()\n",
    "                    pred = model(emb, mask).cpu().numpy()[0]\n",
    "                    vam_predictions.append(pred)\n",
    "                else:\n",
    "                    vam_predictions.append(np.zeros(19))\n",
    "        \n",
    "        vam_predictions = np.array(vam_predictions)\n",
    "        \n",
    "        # Compute mean predictions per skill level\n",
    "        skill_means = {}\n",
    "        for skill in [0, 1, 2]:\n",
    "            mask = vam_skill_levels == skill\n",
    "            skill_means[skill] = vam_predictions[mask].mean(axis=0)\n",
    "        \n",
    "        # ANOVA test\n",
    "        beginner_preds = vam_predictions[vam_skill_levels == 0].mean(axis=1)  # Mean across dims\n",
    "        intermediate_preds = vam_predictions[vam_skill_levels == 1].mean(axis=1)\n",
    "        advanced_preds = vam_predictions[vam_skill_levels == 2].mean(axis=1)\n",
    "        \n",
    "        f_stat, p_value = stats.f_oneway(beginner_preds, intermediate_preds, advanced_preds)\n",
    "        \n",
    "        # Effect size (eta-squared)\n",
    "        all_preds = np.concatenate([beginner_preds, intermediate_preds, advanced_preds])\n",
    "        group_means = [beginner_preds.mean(), intermediate_preds.mean(), advanced_preds.mean()]\n",
    "        grand_mean = all_preds.mean()\n",
    "        ss_between = sum(len(g) * (m - grand_mean)**2 for g, m in zip(\n",
    "            [beginner_preds, intermediate_preds, advanced_preds], group_means))\n",
    "        ss_total = ((all_preds - grand_mean)**2).sum()\n",
    "        eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'n_samples': len(vam_keys),\n",
    "            'skill_distribution': {\n",
    "                'beginner': int(sum(vam_skill_levels == 0)),\n",
    "                'intermediate': int(sum(vam_skill_levels == 1)),\n",
    "                'advanced': int(sum(vam_skill_levels == 2)),\n",
    "            },\n",
    "            'mean_predictions': {\n",
    "                'beginner': float(beginner_preds.mean()),\n",
    "                'intermediate': float(intermediate_preds.mean()),\n",
    "                'advanced': float(advanced_preds.mean()),\n",
    "            },\n",
    "            'anova': {\n",
    "                'f_statistic': float(f_stat),\n",
    "                'p_value': float(p_value),\n",
    "                'significant': p_value < 0.01,\n",
    "            },\n",
    "            'eta_squared': float(eta_squared),\n",
    "            'monotonic': advanced_preds.mean() > intermediate_preds.mean() > beginner_preds.mean(),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nPianoVAM Results:\")\n",
    "        print(f\"  F-statistic: {f_stat:.2f}\")\n",
    "        print(f\"  p-value: {p_value:.4f}\")\n",
    "        print(f\"  Eta-squared: {eta_squared:.4f}\")\n",
    "        print(f\"  Monotonic ordering: {ALL_RESULTS[exp_id]['monotonic']}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"SKIP {exp_id}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {exp_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 32: X2 - ASAP Multi-Performer Analysis\n",
    "# Dataset: https://github.com/fosfrancesco/asap-dataset\n",
    "\n",
    "exp_id = 'X2_asap_multiperformer'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    try:\n",
    "        # ASAP requires MAESTRO audio - check if available\n",
    "        asap_audio = ASAP_DIR / 'audio'\n",
    "        if not asap_audio.exists() or len(list(asap_audio.glob('*.wav'))) == 0:\n",
    "            print(\"ASAP audio not available. Please run: python initialize_dataset.py -m [maestro_path]\")\n",
    "            raise FileNotFoundError(\"ASAP audio not found\")\n",
    "        \n",
    "        # Load ASAP metadata\n",
    "        asap_metadata = ASAP_DIR / 'metadata.json'\n",
    "        if not asap_metadata.exists():\n",
    "            raise FileNotFoundError(\"ASAP metadata not found\")\n",
    "        \n",
    "        with open(asap_metadata) as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        # Find pieces with 5+ performances\n",
    "        piece_to_performances = {}\n",
    "        for item in metadata['performances']:\n",
    "            piece_id = item['piece_id']\n",
    "            if piece_id not in piece_to_performances:\n",
    "                piece_to_performances[piece_id] = []\n",
    "            piece_to_performances[piece_id].append(item)\n",
    "        \n",
    "        multi_performer_pieces = {\n",
    "            p: perfs for p, perfs in piece_to_performances.items() if len(perfs) >= 5\n",
    "        }\n",
    "        \n",
    "        print(f\"Found {len(multi_performer_pieces)} pieces with 5+ performances\")\n",
    "        \n",
    "        # Extract embeddings and predict\n",
    "        asap_cache = ASAP_DIR / 'muq_cache'\n",
    "        asap_cache.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Load model\n",
    "        ckpt_path = CHECKPOINT_ROOT / best_muq_exp / 'fold0_best.ckpt'\n",
    "        model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "        model = model.to('cuda').eval()\n",
    "        \n",
    "        piece_variances = {}\n",
    "        for piece_id, performances in list(multi_performer_pieces.items())[:10]:  # Limit for speed\n",
    "            piece_preds = []\n",
    "            for perf in performances:\n",
    "                audio_path = asap_audio / perf['audio_filename']\n",
    "                key = audio_path.stem\n",
    "                \n",
    "                # Extract embedding if needed\n",
    "                emb_path = asap_cache / f\"{key}.pt\"\n",
    "                if not emb_path.exists() and audio_path.exists():\n",
    "                    extract_muq_embeddings(\n",
    "                        audio_path.parent, asap_cache, [key],\n",
    "                        layer_start=BEST_MUQ_CONFIG['layer_start'],\n",
    "                        layer_end=BEST_MUQ_CONFIG['layer_end']\n",
    "                    )\n",
    "                \n",
    "                if emb_path.exists():\n",
    "                    with torch.no_grad():\n",
    "                        emb = torch.load(emb_path).unsqueeze(0).cuda()\n",
    "                        mask = torch.ones(1, emb.shape[1], dtype=torch.bool).cuda()\n",
    "                        pred = model(emb, mask).cpu().numpy()[0]\n",
    "                        piece_preds.append(pred)\n",
    "            \n",
    "            if len(piece_preds) >= 2:\n",
    "                piece_preds = np.array(piece_preds)\n",
    "                piece_variances[piece_id] = {\n",
    "                    'n_performances': len(piece_preds),\n",
    "                    'mean_pred': float(piece_preds.mean()),\n",
    "                    'std_pred': float(piece_preds.mean(axis=1).std()),\n",
    "                    'per_dim_std': piece_preds.std(axis=0).tolist(),\n",
    "                }\n",
    "        \n",
    "        # Compute overall statistics\n",
    "        all_stds = [v['std_pred'] for v in piece_variances.values()]\n",
    "        mean_intra_piece_std = np.mean(all_stds) if all_stds else 0\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'n_pieces': len(piece_variances),\n",
    "            'mean_intra_piece_std': float(mean_intra_piece_std),\n",
    "            'meaningful_variation': mean_intra_piece_std > 0.05,\n",
    "            'piece_details': piece_variances,\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nASAP Multi-Performer Results:\")\n",
    "        print(f\"  Pieces analyzed: {len(piece_variances)}\")\n",
    "        print(f\"  Mean intra-piece std: {mean_intra_piece_std:.4f}\")\n",
    "        print(f\"  Meaningful variation: {ALL_RESULTS[exp_id]['meaningful_variation']}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"SKIP {exp_id}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {exp_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 33: X3 - PSyllabus Difficulty Correlation\n",
    "# Dataset: https://zenodo.org/records/14794592\n",
    "\n",
    "exp_id = 'X3_psyllabus_difficulty'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    try:\n",
    "        # Check for PSyllabus data\n",
    "        psyllabus_metadata = PSYLLABUS_DIR / 'metadata.json'\n",
    "        psyllabus_audio = PSYLLABUS_DIR / 'audio'\n",
    "        \n",
    "        if not psyllabus_metadata.exists():\n",
    "            print(\"PSyllabus metadata not found. Please download from Zenodo.\")\n",
    "            raise FileNotFoundError(\"PSyllabus data not found\")\n",
    "        \n",
    "        with open(psyllabus_metadata) as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        # Sample pieces across difficulty levels\n",
    "        pieces_by_difficulty = {i: [] for i in range(1, 12)}  # Levels 1-11\n",
    "        for item in metadata['pieces']:\n",
    "            diff = item.get('difficulty', 0)\n",
    "            if 1 <= diff <= 11:\n",
    "                pieces_by_difficulty[diff].append(item)\n",
    "        \n",
    "        # Sample up to 50 per difficulty level\n",
    "        sampled_pieces = []\n",
    "        for diff, pieces in pieces_by_difficulty.items():\n",
    "            sampled_pieces.extend(pieces[:50])\n",
    "        \n",
    "        print(f\"PSyllabus: {len(sampled_pieces)} pieces sampled\")\n",
    "        \n",
    "        # Extract embeddings and predict\n",
    "        psyllabus_cache = PSYLLABUS_DIR / 'muq_cache'\n",
    "        psyllabus_cache.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        ckpt_path = CHECKPOINT_ROOT / best_muq_exp / 'fold0_best.ckpt'\n",
    "        model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "        model = model.to('cuda').eval()\n",
    "        \n",
    "        difficulties = []\n",
    "        predictions = []\n",
    "        \n",
    "        for piece in sampled_pieces:\n",
    "            audio_path = psyllabus_audio / piece['audio_filename']\n",
    "            key = audio_path.stem\n",
    "            \n",
    "            emb_path = psyllabus_cache / f\"{key}.pt\"\n",
    "            if not emb_path.exists() and audio_path.exists():\n",
    "                extract_muq_embeddings(\n",
    "                    audio_path.parent, psyllabus_cache, [key],\n",
    "                    layer_start=BEST_MUQ_CONFIG['layer_start'],\n",
    "                    layer_end=BEST_MUQ_CONFIG['layer_end']\n",
    "                )\n",
    "            \n",
    "            if emb_path.exists():\n",
    "                with torch.no_grad():\n",
    "                    emb = torch.load(emb_path).unsqueeze(0).cuda()\n",
    "                    mask = torch.ones(1, emb.shape[1], dtype=torch.bool).cuda()\n",
    "                    pred = model(emb, mask).cpu().numpy()[0]\n",
    "                    predictions.append(pred.mean())  # Mean across dimensions\n",
    "                    difficulties.append(piece['difficulty'])\n",
    "        \n",
    "        if len(predictions) > 10:\n",
    "            # Compute Spearman correlation\n",
    "            rho, p_value = stats.spearmanr(difficulties, predictions)\n",
    "            \n",
    "            ALL_RESULTS[exp_id] = {\n",
    "                'exp_id': exp_id,\n",
    "                'n_samples': len(predictions),\n",
    "                'spearman_rho': float(rho),\n",
    "                'p_value': float(p_value),\n",
    "                'significant': p_value < 0.05,\n",
    "                'weak_positive': rho > 0.2,\n",
    "                'difficulty_range': [int(min(difficulties)), int(max(difficulties))],\n",
    "            }\n",
    "            \n",
    "            print(f\"\\nPSyllabus Results:\")\n",
    "            print(f\"  Samples: {len(predictions)}\")\n",
    "            print(f\"  Spearman rho: {rho:.4f}\")\n",
    "            print(f\"  p-value: {p_value:.4f}\")\n",
    "            \n",
    "            save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "            sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)\n",
    "        else:\n",
    "            print(\"Insufficient data for correlation analysis\")\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"SKIP {exp_id}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {exp_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Statistical Rigor (S3-S4)\n",
    "\n",
    "Bootstrap CIs and significance tests for all comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 35: S3 - Bootstrap CIs for all comparisons\n",
    "exp_id = 'S3_bootstrap_all'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    bootstrap_results = {}\n",
    "    \n",
    "    # MuQ vs Symbolic\n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        print(\"Computing MuQ vs Symbolic bootstrap...\")\n",
    "        bootstrap_results['muq_vs_symbolic'] = bootstrap_r2_comparison(\n",
    "            LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR, n_bootstrap=10000\n",
    "        )\n",
    "        print(f\"  MuQ: {bootstrap_results['muq_vs_symbolic']['r2_a']:.4f}\")\n",
    "        print(f\"  Symbolic: {bootstrap_results['muq_vs_symbolic']['r2_b']:.4f}\")\n",
    "        print(f\"  Diff: {bootstrap_results['muq_vs_symbolic']['difference']:.4f}\")\n",
    "        print(f\"  MuQ significantly better: {bootstrap_results['muq_vs_symbolic']['a_significantly_better']}\")\n",
    "    \n",
    "    # MuQ CIs\n",
    "    if len(MUQ_ARR) > 0:\n",
    "        print(\"\\nComputing MuQ bootstrap CIs...\")\n",
    "        bootstrap_results['muq_ci'] = bootstrap_r2_extended(LABELS_ARR, MUQ_ARR, n_bootstrap=10000)\n",
    "        print(f\"  R2: {bootstrap_results['muq_ci']['overall']['r2']:.4f}\")\n",
    "        print(f\"  95% CI: [{bootstrap_results['muq_ci']['overall']['ci_lower']:.4f}, {bootstrap_results['muq_ci']['overall']['ci_upper']:.4f}]\")\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = {\n",
    "        'exp_id': exp_id,\n",
    "        'n_bootstrap': 10000,\n",
    "        'comparisons': bootstrap_results,\n",
    "    }\n",
    "    \n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 36: S4 - Significance Tests\n",
    "exp_id = 'S4_significance_tests'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    significance_results = {}\n",
    "    \n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        # Paired t-test\n",
    "        ttest = paired_ttest_per_sample(LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR)\n",
    "        significance_results['paired_ttest'] = ttest\n",
    "        print(f\"Paired t-test: t={ttest['t_stat']:.4f}, p={ttest['p_value']:.2e}\")\n",
    "        \n",
    "        # Wilcoxon\n",
    "        wilcox = wilcoxon_test(LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR)\n",
    "        significance_results['wilcoxon'] = wilcox\n",
    "        print(f\"Wilcoxon: stat={wilcox['stat']:.4f}, p={wilcox['p_value']:.2e}\")\n",
    "        \n",
    "        # Cohen's d\n",
    "        d = cohens_d(LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR)\n",
    "        significance_results['cohens_d'] = d\n",
    "        print(f\"Cohen's d: {d:.4f}\")\n",
    "        \n",
    "        # Per-dimension tests with Bonferroni\n",
    "        per_dim_p = []\n",
    "        for i in range(19):\n",
    "            t = paired_ttest_per_sample(\n",
    "                LABELS_ARR[:, i:i+1],\n",
    "                MUQ_ARR[:, i:i+1],\n",
    "                SYMBOLIC_ARR[:, i:i+1]\n",
    "            )\n",
    "            per_dim_p.append(t['p_value'])\n",
    "        \n",
    "        bonf_corrected, bonf_sig = bonferroni_correction(np.array(per_dim_p))\n",
    "        significance_results['per_dimension'] = {\n",
    "            dim: {\n",
    "                'raw_p': per_dim_p[i],\n",
    "                'corrected_p': float(bonf_corrected[i]),\n",
    "                'significant': bool(bonf_sig[i]),\n",
    "            }\n",
    "            for i, dim in enumerate(PERCEPIANO_DIMENSIONS)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nBonferroni correction: {sum(bonf_sig)}/19 dimensions significant\")\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = {\n",
    "        'exp_id': exp_id,\n",
    "        'tests': significance_results,\n",
    "    }\n",
    "    \n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Analysis (A3-A7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 38: A3 - Error Correlation Analysis\n",
    "exp_id = 'A3_error_correlation'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        ALL_RESULTS[exp_id] = run_error_correlation_experiment(\n",
    "            exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR\n",
    "        )\n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 39: A4 - Per-Dimension Breakdown\n",
    "exp_id = 'A4_dimension_breakdown'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        fused = simple_average_fusion(MUQ_ARR, SYMBOLIC_ARR)\n",
    "        \n",
    "        dim_comparison = {}\n",
    "        for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n",
    "            muq_r2 = r2_score(LABELS_ARR[:, i], MUQ_ARR[:, i])\n",
    "            symbolic_r2 = r2_score(LABELS_ARR[:, i], SYMBOLIC_ARR[:, i])\n",
    "            fusion_r2 = r2_score(LABELS_ARR[:, i], fused[:, i])\n",
    "            \n",
    "            # Determine category\n",
    "            category = None\n",
    "            for cat, dims in DIMENSION_CATEGORIES.items():\n",
    "                if dim in dims:\n",
    "                    category = cat\n",
    "                    break\n",
    "            \n",
    "            dim_comparison[dim] = {\n",
    "                'muq_r2': float(muq_r2),\n",
    "                'symbolic_r2': float(symbolic_r2),\n",
    "                'fusion_r2': float(fusion_r2),\n",
    "                'winner': 'muq' if muq_r2 > symbolic_r2 else 'symbolic',\n",
    "                'muq_advantage': float(muq_r2 - symbolic_r2),\n",
    "                'category': category,\n",
    "            }\n",
    "        \n",
    "        # Count winners by category\n",
    "        category_summary = {}\n",
    "        for cat in DIMENSION_CATEGORIES:\n",
    "            cat_dims = [d for d, v in dim_comparison.items() if v['category'] == cat]\n",
    "            muq_wins = sum(1 for d in cat_dims if dim_comparison[d]['winner'] == 'muq')\n",
    "            category_summary[cat] = {\n",
    "                'total': len(cat_dims),\n",
    "                'muq_wins': muq_wins,\n",
    "                'symbolic_wins': len(cat_dims) - muq_wins,\n",
    "            }\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'per_dimension': dim_comparison,\n",
    "            'category_summary': category_summary,\n",
    "            'muq_total_wins': sum(1 for v in dim_comparison.values() if v['winner'] == 'muq'),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nDimension Breakdown:\")\n",
    "        print(f\"  MuQ wins: {ALL_RESULTS[exp_id]['muq_total_wins']}/19 dimensions\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 40: A5 - Failure Cases\n",
    "exp_id = 'A5_failure_cases'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0:\n",
    "        # Compute per-sample MSE\n",
    "        mse_per_sample = ((LABELS_ARR - MUQ_ARR) ** 2).mean(axis=1)\n",
    "        \n",
    "        # Find worst predictions\n",
    "        worst_indices = np.argsort(mse_per_sample)[-10:]\n",
    "        \n",
    "        failure_cases = []\n",
    "        for idx in worst_indices:\n",
    "            key = FUSION_KEYS[idx]\n",
    "            sample_mse = mse_per_sample[idx]\n",
    "            \n",
    "            # Find worst dimensions for this sample\n",
    "            dim_errors = np.abs(LABELS_ARR[idx] - MUQ_ARR[idx])\n",
    "            worst_dims = np.argsort(dim_errors)[-3:]\n",
    "            \n",
    "            failure_cases.append({\n",
    "                'key': key,\n",
    "                'mse': float(sample_mse),\n",
    "                'worst_dimensions': [PERCEPIANO_DIMENSIONS[i] for i in worst_dims],\n",
    "                'predicted': MUQ_ARR[idx].tolist(),\n",
    "                'actual': LABELS_ARR[idx].tolist(),\n",
    "            })\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'n_samples': len(mse_per_sample),\n",
    "            'mean_mse': float(mse_per_sample.mean()),\n",
    "            'max_mse': float(mse_per_sample.max()),\n",
    "            'failure_cases': failure_cases,\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nFailure Case Analysis:\")\n",
    "        print(f\"  Mean MSE: {ALL_RESULTS[exp_id]['mean_mse']:.4f}\")\n",
    "        print(f\"  Max MSE: {ALL_RESULTS[exp_id]['max_mse']:.4f}\")\n",
    "        print(f\"  Worst samples: {[f['key'] for f in failure_cases[:3]]}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 41: A6 - Calibration\n",
    "exp_id = 'A6_calibration'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0:\n",
    "        # Compute calibration by decile\n",
    "        n_bins = 10\n",
    "        calibration = []\n",
    "        \n",
    "        # Flatten for overall calibration\n",
    "        preds_flat = MUQ_ARR.flatten()\n",
    "        labels_flat = LABELS_ARR.flatten()\n",
    "        \n",
    "        # Bin by predicted values\n",
    "        bins = np.linspace(0, 1, n_bins + 1)\n",
    "        for i in range(n_bins):\n",
    "            mask = (preds_flat >= bins[i]) & (preds_flat < bins[i+1])\n",
    "            if mask.sum() > 0:\n",
    "                calibration.append({\n",
    "                    'bin': i,\n",
    "                    'bin_range': [float(bins[i]), float(bins[i+1])],\n",
    "                    'count': int(mask.sum()),\n",
    "                    'mean_predicted': float(preds_flat[mask].mean()),\n",
    "                    'mean_actual': float(labels_flat[mask].mean()),\n",
    "                    'error': float(preds_flat[mask].mean() - labels_flat[mask].mean()),\n",
    "                })\n",
    "        \n",
    "        # Dispersion ratio\n",
    "        pred_std = MUQ_ARR.std()\n",
    "        label_std = LABELS_ARR.std()\n",
    "        dispersion_ratio = pred_std / label_std if label_std > 0 else 0\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'calibration_bins': calibration,\n",
    "            'dispersion_ratio': float(dispersion_ratio),\n",
    "            'pred_std': float(pred_std),\n",
    "            'label_std': float(label_std),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nCalibration Analysis:\")\n",
    "        print(f\"  Dispersion ratio: {dispersion_ratio:.4f}\")\n",
    "        print(f\"  Prediction std: {pred_std:.4f}\")\n",
    "        print(f\"  Label std: {label_std:.4f}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 42: A7 - Gate Weight Visualization\n",
    "exp_id = 'A7_gate_visualization'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if GATE_WEIGHTS:\n",
    "        # Sort by MERT preference\n",
    "        sorted_dims = sorted(GATE_WEIGHTS.items(), key=lambda x: -x[1])\n",
    "        \n",
    "        # Group by category\n",
    "        category_gates = {}\n",
    "        for cat, dims in DIMENSION_CATEGORIES.items():\n",
    "            cat_weights = [GATE_WEIGHTS.get(d, 0.5) for d in dims]\n",
    "            category_gates[cat] = {\n",
    "                'mean_mert_weight': float(np.mean(cat_weights)),\n",
    "                'dimensions': {d: GATE_WEIGHTS.get(d, 0.5) for d in dims},\n",
    "            }\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'gate_weights': GATE_WEIGHTS,\n",
    "            'mert_preferred_dims': [d for d, w in sorted_dims[:5]],\n",
    "            'muq_preferred_dims': [d for d, w in sorted_dims[-5:]],\n",
    "            'category_summary': category_gates,\n",
    "            'mean_gate': float(np.mean(list(GATE_WEIGHTS.values()))),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nGate Weight Analysis:\")\n",
    "        print(f\"  Mean gate (0.5=balanced): {ALL_RESULTS[exp_id]['mean_gate']:.3f}\")\n",
    "        print(f\"  MERT-preferred: {ALL_RESULTS[exp_id]['mert_preferred_dims']}\")\n",
    "        print(f\"  MuQ-preferred: {ALL_RESULTS[exp_id]['muq_preferred_dims']}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)\n",
    "    else:\n",
    "        print(\"No gate weights available (D9c not trained)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Results Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 44: Export all results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load any missing results from disk\n",
    "for exp_id in EXPERIMENT_IDS:\n",
    "    if exp_id not in ALL_RESULTS:\n",
    "        result_file = RESULTS_DIR / f\"{exp_id}.json\"\n",
    "        if result_file.exists():\n",
    "            with open(result_file) as f:\n",
    "                ALL_RESULTS[exp_id] = json.load(f)\n",
    "\n",
    "# Save aggregate results\n",
    "aggregate_file = RESULTS_DIR / 'definitive_all_results.json'\n",
    "with open(aggregate_file, 'w') as f:\n",
    "    json.dump(ALL_RESULTS, f, indent=2, default=numpy_serializer)\n",
    "print(f\"Saved: {aggregate_file}\")\n",
    "\n",
    "# Sync to GDrive\n",
    "run_rclone(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS], \"Syncing results to GDrive\")\n",
    "print(f\"Synced to: {GDRIVE_RESULTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 45: Final Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEFINITIVE EXPERIMENTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Part 1: MuQ Layer Ablation\n",
    "print(\"\\nPart 1: MuQ Layer Ablation\")\n",
    "print(\"-\"*40)\n",
    "for exp_id in ['M1a_muq_L1-6', 'M1b_muq_L7-12', 'M1c_muq_L13-24', 'M1d_muq_L1-24']:\n",
    "    if exp_id in ALL_RESULTS and 'summary' in ALL_RESULTS[exp_id]:\n",
    "        r2 = ALL_RESULTS[exp_id]['summary']['avg_r2']\n",
    "        print(f\"  {exp_id}: R2={r2:.4f}\")\n",
    "\n",
    "# Part 2: MuQ + Symbolic Fusion\n",
    "print(\"\\nPart 2: MuQ + Symbolic Fusion\")\n",
    "print(\"-\"*40)\n",
    "for exp_id in ['F8_muq_symbolic_simple', 'F9_muq_symbolic_weighted', 'F10_muq_symbolic_ridge', 'F11_muq_symbolic_confidence']:\n",
    "    if exp_id in ALL_RESULTS and 'overall_r2' in ALL_RESULTS[exp_id]:\n",
    "        r2 = ALL_RESULTS[exp_id]['overall_r2']\n",
    "        print(f\"  {exp_id}: R2={r2:.4f}\")\n",
    "\n",
    "# Part 3: MERT + MuQ Fusion\n",
    "print(\"\\nPart 3: MERT + MuQ Audio Fusion\")\n",
    "print(\"-\"*40)\n",
    "for exp_id in ['D9a_mert_muq_ensemble', 'D9b_mert_muq_concat', 'D9c_mert_muq_gated']:\n",
    "    if exp_id in ALL_RESULTS and 'summary' in ALL_RESULTS[exp_id]:\n",
    "        r2 = ALL_RESULTS[exp_id]['summary']['avg_r2']\n",
    "        print(f\"  {exp_id}: R2={r2:.4f}\")\n",
    "\n",
    "# Part 4: Cross-Dataset\n",
    "print(\"\\nPart 4: Cross-Dataset Validation\")\n",
    "print(\"-\"*40)\n",
    "if 'X1_pianovam_skill' in ALL_RESULTS:\n",
    "    r = ALL_RESULTS['X1_pianovam_skill']\n",
    "    if 'anova' in r:\n",
    "        print(f\"  PianoVAM: F={r['anova']['f_statistic']:.2f}, p={r['anova']['p_value']:.4f}\")\n",
    "if 'X2_asap_multiperformer' in ALL_RESULTS:\n",
    "    r = ALL_RESULTS['X2_asap_multiperformer']\n",
    "    print(f\"  ASAP: intra-piece std={r.get('mean_intra_piece_std', 0):.4f}\")\n",
    "if 'X3_psyllabus_difficulty' in ALL_RESULTS:\n",
    "    r = ALL_RESULTS['X3_psyllabus_difficulty']\n",
    "    print(f\"  PSyllabus: rho={r.get('spearman_rho', 0):.4f}\")\n",
    "\n",
    "# Completion stats\n",
    "completed = sum(1 for e in EXPERIMENT_IDS if e in ALL_RESULTS)\n",
    "print(f\"\\nCompleted: {completed}/{len(EXPERIMENT_IDS)} experiments\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
