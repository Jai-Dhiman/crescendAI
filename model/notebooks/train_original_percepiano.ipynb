{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Original PercePiano Code\n",
    "\n",
    "Use the ORIGINAL PercePiano model with properly preprocessed data.\n",
    "\n",
    "## Data\n",
    "- Preprocessed using their `m2pf_dataset_compositionfold.py`\n",
    "- 101-dimension features with proper `key_to_dim` mapping\n",
    "- 4-fold CV structure (fold0-fold3)\n",
    "\n",
    "## Target: R2 = 0.397 (Paper SOTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone PercePiano and install dependencies\nimport os\nimport sys\nfrom pathlib import Path\nfrom types import ModuleType\n\n# Clone PercePiano repository\nPERCEPIANO_ROOT = Path('/tmp/PercePiano')\nif not PERCEPIANO_ROOT.exists():\n    print(\"Cloning PercePiano repository...\")\n    !git clone https://github.com/JonghoKimSNU/PercePiano.git /tmp/PercePiano\nelse:\n    print(f\"PercePiano already present at {PERCEPIANO_ROOT}\")\n\nPERCEPIANO_PATH = PERCEPIANO_ROOT / 'virtuoso' / 'virtuoso'\n\n# Install dependencies (keep numpy 2.0, we'll patch compatibility)\n!pip install omegaconf tqdm --quiet\n\n# Patch numpy 2.0 compatibility for PercePiano\n# PercePiano imports 'from numpy.lib.arraysetops import isin' which was removed in numpy 2.0\nimport numpy as np\nif not hasattr(np.lib, 'arraysetops'):\n    arraysetops = ModuleType('numpy.lib.arraysetops')\n    arraysetops.isin = np.isin\n    sys.modules['numpy.lib.arraysetops'] = arraysetops\n    np.lib.arraysetops = arraysetops\n    print(\"Patched numpy.lib.arraysetops for numpy 2.0 compatibility\")\n\n# Add to Python path (virtuoso first, then pyScoreParser)\nsys.path.insert(0, str(PERCEPIANO_PATH / 'pyScoreParser'))\nsys.path.insert(0, str(PERCEPIANO_PATH))\n\nprint(f\"\\nnumpy version: {np.__version__}\")\nprint(f\"PercePiano path: {PERCEPIANO_PATH}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths - using original preprocessed data\n",
    "DATA_ROOT = Path('/tmp/percepiano_original')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_original')\n",
    "LABEL_ROOT = Path('/tmp/percepiano_labels')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_original'\n",
    "GDRIVE_LABEL_PATH = 'gdrive:crescendai_data/percepiano_labels'\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LABEL_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "if 'gdrive:' not in result.stdout:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "print(\"rclone 'gdrive' remote: CONFIGURED\")\n",
    "\n",
    "# Download preprocessed data\n",
    "print(\"\\nDownloading original PercePiano preprocessed data...\")\n",
    "subprocess.run(\n",
    "    ['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'],\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "# Download label files\n",
    "print(\"\\nDownloading label files...\")\n",
    "subprocess.run(\n",
    "    ['rclone', 'copy', GDRIVE_LABEL_PATH, str(LABEL_ROOT), '--progress'],\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "for fold in range(4):\n",
    "    fold_path = DATA_ROOT / f'fold{fold}'\n",
    "    if fold_path.exists():\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            split_path = fold_path / split\n",
    "            if split_path.exists():\n",
    "                count = len([f for f in split_path.glob('*.pkl') if f.name != 'stat.pkl'])\n",
    "                print(f\"  fold{fold}/{split}: {count} samples\")\n",
    "\n",
    "# Verify labels\n",
    "label_file = LABEL_ROOT / 'label_2round_mean_reg_19_with0_rm_highstd0.json'\n",
    "if label_file.exists():\n",
    "    print(f\"\\nLabel file: {label_file.name} [OK]\")\n",
    "else:\n",
    "    raise RuntimeError(f\"Label file not found: {label_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Restore checkpoints from Google Drive (run this to resume training on a new machine)\nGDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_data/checkpoints/percepiano_original'\n\nprint(\"Checking for existing checkpoints on Google Drive...\")\nresult = subprocess.run(\n    ['rclone', 'lsf', GDRIVE_CHECKPOINT_PATH],\n    capture_output=True, text=True\n)\n\nif result.returncode == 0 and result.stdout.strip():\n    remote_files = result.stdout.strip().split('\\n')\n    print(f\"Found {len(remote_files)} checkpoint(s) on Google Drive:\")\n    for f in remote_files:\n        print(f\"  {f}\")\n    \n    print(f\"\\nRestoring to {CHECKPOINT_ROOT}...\")\n    subprocess.run(\n        ['rclone', 'copy', GDRIVE_CHECKPOINT_PATH, str(CHECKPOINT_ROOT), '--progress'],\n        capture_output=False\n    )\n    print(\"Restore complete!\")\nelse:\n    print(\"No existing checkpoints found on Google Drive.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pickle\n\n# We'll iterate through all 4 folds\nN_FOLDS = 4\n\n# Load stats from fold0 to get model configuration\nstat_path = DATA_ROOT / 'fold0' / 'train' / 'stat.pkl'\nwith open(stat_path, 'rb') as f:\n    data_stats = pickle.load(f)\n\nprint(f\"Loaded stats from fold0 (for model config)\")\nprint(f\"Keys: {list(data_stats.keys())}\")\nprint(f\"Input keys: {len(data_stats.get('input_keys', []))} features\")\nprint(f\"key_to_dim['input']: {len(data_stats.get('key_to_dim', {}).get('input', {}))} entries\")\n\n# Get input dimension from key_to_dim\ninput_key_to_dim = data_stats.get('key_to_dim', {}).get('input', {})\nif input_key_to_dim:\n    max_dim = max(v[1] for v in input_key_to_dim.values())\n    print(f\"\\nInput dimension: {max_dim}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Import Original PercePiano Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import original PercePiano components\n",
    "from model_m2pf import VirtuosoNetMultiLevel, VirtuosoNetSingle\n",
    "from omegaconf import OmegaConf\n",
    "import yaml\n",
    "\n",
    "print(\"Successfully imported original PercePiano models!\")\n",
    "print(f\"  VirtuosoNetMultiLevel: {VirtuosoNetMultiLevel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SOTA config\n",
    "CONFIG_PATH = PERCEPIANO_PATH.parent / 'ymls' / 'shared' / 'label19' / 'han_measnote_nomask_bigger256.yml'\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "net_param = OmegaConf.create(config['nn_params'])\n",
    "\n",
    "# Override input_size to match our data\n",
    "net_param.input_size = max_dim\n",
    "net_param.graph_keys = []\n",
    "\n",
    "print(\"SOTA Configuration:\")\n",
    "print(f\"  input_size: {net_param.input_size}\")\n",
    "print(f\"  hidden_size: {net_param.encoder.size}\")\n",
    "print(f\"  layers: note={net_param.note.layer}, voice={net_param.voice.layer}, beat={net_param.beat.layer}, measure={net_param.measure.layer}\")\n",
    "print(f\"  attention_heads: {net_param.num_attention_head}\")\n",
    "print(f\"  dropout: {net_param.drop_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pack_sequence, pad_sequence\nimport pickle\nimport json\nimport re\nfrom pathlib import Path\n\n# Load perceptual labels from JSON\nlabel_file = LABEL_ROOT / 'label_2round_mean_reg_19_with0_rm_highstd0.json'\nwith open(label_file) as f:\n    PERCEPTUAL_LABELS = json.load(f)\nprint(f\"Loaded {len(PERCEPTUAL_LABELS)} perceptual labels\")\n\n\ndef extract_label_key(filename):\n    \"\"\"Extract label key from pkl filename.\n    \n    Example: all_2rounds_Beethoven_WoO80_thema_8bars_11_1.mid.pkl\n          -> Beethoven_WoO80_thema_8bars_11_1\n    \"\"\"\n    # Remove prefix and suffix\n    name = filename.replace('.pkl', '').replace('.mid', '')\n    # Remove 'all_2rounds_' prefix if present\n    if name.startswith('all_2rounds_'):\n        name = name[len('all_2rounds_'):]\n    return name\n\n\nclass PercePianoDataset(Dataset):\n    \"\"\"Load original PercePiano preprocessed data with perceptual labels.\"\"\"\n    \n    def __init__(self, data_dir, split='train', max_notes=5000):\n        self.data_dir = Path(data_dir) / split\n        self.max_notes = max_notes\n        \n        # Load all pkl files that have matching labels\n        all_files = sorted([f for f in self.data_dir.glob('*.pkl') if f.name != 'stat.pkl'])\n        \n        self.files = []\n        self.labels_cache = {}\n        missing = 0\n        \n        for f in all_files:\n            key = extract_label_key(f.name)\n            if key in PERCEPTUAL_LABELS:\n                self.files.append(f)\n                # Labels: first 19 values (20th is pianist ID)\n                self.labels_cache[f.name] = PERCEPTUAL_LABELS[key][:19]\n            else:\n                missing += 1\n        \n        print(f\"Loaded {len(self.files)} samples from {split} ({missing} missing labels)\")\n    \n    def __len__(self):\n        return len(self.files)\n    \n    def __getitem__(self, idx):\n        with open(self.files[idx], 'rb') as f:\n            data = pickle.load(f)\n        \n        # Get input features\n        x = torch.tensor(data['input'], dtype=torch.float32)\n        \n        # Truncate if needed\n        if len(x) > self.max_notes:\n            x = x[:self.max_notes]\n        \n        # Get note locations\n        note_locations = {\n            'beat': torch.tensor(data['note_location']['beat'][:len(x)], dtype=torch.long),\n            'measure': torch.tensor(data['note_location']['measure'][:len(x)], dtype=torch.long),\n            'voice': torch.tensor(data['note_location']['voice'][:len(x)], dtype=torch.long),\n            'section': torch.tensor(data['note_location']['section'][:len(x)], dtype=torch.long),\n        }\n        \n        # Get perceptual labels (19 dimensions, normalized 0-1)\n        labels = torch.tensor(self.labels_cache[self.files[idx].name], dtype=torch.float32)\n        \n        return x, note_locations, labels\n\n\ndef collate_fn(batch):\n    \"\"\"Collate batch for PercePiano model.\"\"\"\n    xs, note_locs, labels = zip(*batch)\n    \n    # Sort by length (descending) for packing\n    lengths = [len(x) for x in xs]\n    sorted_idx = sorted(range(len(lengths)), key=lambda i: lengths[i], reverse=True)\n    \n    xs_sorted = [xs[i] for i in sorted_idx]\n    batch_x = pack_sequence(xs_sorted, enforce_sorted=True)\n    \n    # Pad note locations\n    note_locations = {\n        'beat': pad_sequence([note_locs[i]['beat'] for i in sorted_idx], batch_first=True),\n        'measure': pad_sequence([note_locs[i]['measure'] for i in sorted_idx], batch_first=True),\n        'voice': pad_sequence([note_locs[i]['voice'] for i in sorted_idx], batch_first=True),\n        'section': pad_sequence([note_locs[i]['section'] for i in sorted_idx], batch_first=True),\n    }\n    \n    labels_batch = torch.stack([labels[i] for i in sorted_idx])\n    \n    return batch_x, note_locations, labels_batch\n\n\nprint(\"Dataset and collate_fn defined. Will create datasets per-fold during training.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Verify input size using a sample from fold0\nsample_fold_path = DATA_ROOT / 'fold0'\nsample_ds = PercePianoDataset(sample_fold_path, 'train')\nsample_x, _, _ = sample_ds[0]\nactual_input_size = sample_x.shape[1]\nprint(f\"Data input size: {actual_input_size}\")\nprint(f\"Config input size: {net_param.input_size}\")\n\nif actual_input_size != net_param.input_size:\n    print(f\"Updating config input_size to {actual_input_size}\")\n    net_param.input_size = actual_input_size\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\nDevice: {device}\")\nprint(f\"Model will be initialized per-fold during training\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\n\ndef r2_score(y_true, y_pred):\n    \"\"\"Calculate R2 score manually (avoids scikit-learn numpy 2.0 dependency).\"\"\"\n    ss_res = np.sum((y_true - y_pred) ** 2)\n    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n    if ss_tot == 0:\n        return 0.0\n    return 1 - (ss_res / ss_tot)\n\ndef r2_score_multioutput(y_true, y_pred):\n    \"\"\"Calculate R2 score for multi-output (average across dimensions).\"\"\"\n    n_outputs = y_true.shape[1] if y_true.ndim > 1 else 1\n    if n_outputs == 1:\n        return r2_score(y_true.ravel(), y_pred.ravel())\n    r2s = []\n    for i in range(n_outputs):\n        r2s.append(r2_score(y_true[:, i], y_pred[:, i]))\n    return np.mean(r2s)\n\n# Hyperparameters (matching paper)\nBATCH_SIZE = 8\nLR = 2.5e-5\nWEIGHT_DECAY = 1e-5\nMAX_EPOCHS = 200\nPATIENCE = 20\nGRAD_CLIP = 2.0\n\nprint(f\"Training config:\")\nprint(f\"  Batch size: {BATCH_SIZE}\")\nprint(f\"  LR: {LR}\")\nprint(f\"  Patience: {PATIENCE}\")\nprint(f\"  Folds: {N_FOLDS}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_x, note_locations, labels in loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        note_locations = {k: v.to(device) for k, v in note_locations.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch_x, None, None, note_locations)\n",
    "        logits = outputs[-1]\n",
    "        preds = sigmoid(logits)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, note_locations, labels in loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            note_locations = {k: v.to(device) for k, v in note_locations.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_x, None, None, note_locations)\n",
    "            preds = sigmoid(outputs[-1])\n",
    "            \n",
    "            loss = criterion(preds, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    r2 = r2_score_multioutput(all_labels, all_preds)\n",
    "    \n",
    "    return total_loss / len(loader), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 4-Fold Cross-Validation Training Loop with Checkpoint Resuming\nprint(\"=\"*70)\nprint(\"4-FOLD CROSS-VALIDATION WITH ORIGINAL PERCEPIANO\")\nprint(\"=\"*70)\nprint(f\"Target: R2 = 0.397 (Paper SOTA)\")\nprint(\"=\"*70 + \"\\n\")\n\n# Migrate old checkpoint naming (best.pt -> fold0_best.pt)\nold_checkpoint = CHECKPOINT_ROOT / 'best.pt'\nnew_fold0_checkpoint = CHECKPOINT_ROOT / 'fold0_best.pt'\nif old_checkpoint.exists() and not new_fold0_checkpoint.exists():\n    print(\"Migrating old checkpoint: best.pt -> fold0_best.pt\")\n    checkpoint = torch.load(old_checkpoint, map_location=device, weights_only=False)\n    # Add fold info if missing\n    if 'fold' not in checkpoint:\n        checkpoint['fold'] = 0\n    torch.save(checkpoint, new_fold0_checkpoint)\n    print(f\"  R2: {checkpoint['r2']:+.4f} (epoch {checkpoint['epoch']})\\n\")\n\nfold_results = {}\n\nfor fold in range(N_FOLDS):\n    fold_checkpoint = CHECKPOINT_ROOT / f'fold{fold}_best.pt'\n    \n    # Check if fold already completed\n    if fold_checkpoint.exists():\n        checkpoint = torch.load(fold_checkpoint, map_location=device, weights_only=False)\n        fold_r2 = checkpoint['r2']\n        fold_epoch = checkpoint['epoch']\n        fold_results[fold] = fold_r2\n        print(f\"Fold {fold}: SKIPPED (checkpoint exists) - R2: {fold_r2:+.4f} (epoch {fold_epoch})\")\n        print(\"-\"*70 + \"\\n\")\n        continue\n    \n    print(f\"Fold {fold}: Training...\")\n    print(\"-\"*70)\n    \n    # Load fold-specific data\n    fold_path = DATA_ROOT / f'fold{fold}'\n    \n    # Load fold-specific stats\n    with open(fold_path / 'train' / 'stat.pkl', 'rb') as f:\n        fold_stats = pickle.load(f)\n    \n    # Create datasets for this fold\n    train_ds = PercePianoDataset(fold_path, 'train')\n    val_ds = PercePianoDataset(fold_path, 'valid')\n    \n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, \n                              collate_fn=collate_fn, num_workers=0)\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n                            collate_fn=collate_fn, num_workers=0)\n    \n    # Initialize fresh model for this fold\n    model = VirtuosoNetMultiLevel(net_param, fold_stats, multi_level=\"total_note_cat\")\n    model = model.to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3000, gamma=0.98)\n    criterion = torch.nn.MSELoss()\n    sigmoid = torch.nn.Sigmoid()\n    \n    best_r2 = -float('inf')\n    best_epoch = 0\n    patience_counter = 0\n    \n    for epoch in range(MAX_EPOCHS):\n        start = time.time()\n        \n        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n        val_loss, val_r2 = validate(model, val_loader, criterion, device)\n        \n        elapsed = time.time() - start\n        \n        is_best = val_r2 > best_r2\n        if is_best:\n            best_r2 = val_r2\n            best_epoch = epoch\n            patience_counter = 0\n            torch.save({\n                'epoch': epoch,\n                'state_dict': model.state_dict(),\n                'r2': val_r2,\n                'fold': fold,\n            }, fold_checkpoint)\n        else:\n            patience_counter += 1\n        \n        marker = \" *best*\" if is_best else \"\"\n        print(f\"Epoch {epoch:3d} | train: {train_loss:.4f} | val: {val_loss:.4f} | r2: {val_r2:+.4f} | {elapsed:.1f}s{marker}\")\n        \n        if patience_counter >= PATIENCE:\n            print(f\"\\nEarly stopping at epoch {epoch}\")\n            break\n    \n    fold_results[fold] = best_r2\n    print(f\"\\nFold {fold} Best R2: {best_r2:+.4f} (epoch {best_epoch})\")\n    print(\"-\"*70 + \"\\n\")\n\n# Summary\nprint(\"=\"*70)\nprint(\"4-FOLD CROSS-VALIDATION RESULTS\")\nprint(\"=\"*70)\nfor fold, r2 in sorted(fold_results.items()):\n    print(f\"  Fold {fold}: R2 = {r2:+.4f}\")\navg_r2 = np.mean(list(fold_results.values()))\nstd_r2 = np.std(list(fold_results.values()))\nprint(\"-\"*70)\nprint(f\"  Average R2: {avg_r2:+.4f} +/- {std_r2:.4f}\")\nprint(f\"  Target R2:  +0.3970 (Paper SOTA)\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "source": "# Sync checkpoints to Google Drive\nGDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_data/checkpoints/percepiano_original'\n\nprint(\"Syncing checkpoints to Google Drive...\")\nprint(f\"  Local:  {CHECKPOINT_ROOT}\")\nprint(f\"  Remote: {GDRIVE_CHECKPOINT_PATH}\")\n\n# List local checkpoints\nlocal_checkpoints = list(CHECKPOINT_ROOT.glob('fold*_best.pt'))\nprint(f\"\\nLocal checkpoints: {len(local_checkpoints)}\")\nfor ckpt in sorted(local_checkpoints):\n    checkpoint = torch.load(ckpt, map_location='cpu', weights_only=False)\n    print(f\"  {ckpt.name}: R2={checkpoint['r2']:+.4f} (epoch {checkpoint['epoch']})\")\n\n# Sync to gdrive\nresult = subprocess.run(\n    ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n    capture_output=False\n)\n\nprint(\"\\nSync complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Per-dimension R2 Analysis (averaged across folds)\nDIMENSIONS = [\n    'timing', 'articulation_length', 'articulation_touch',\n    'pedal_amount', 'pedal_clarity', 'timbre_variety', 'timbre_depth',\n    'timbre_brightness', 'timbre_loudness', 'sophistication',\n    'dynamic_range', 'tempo', 'space', 'balance', 'drama',\n    'mood_valence', 'mood_energy', 'mood_imagination', 'interpretation'\n]\n\nsigmoid = torch.nn.Sigmoid()\n\n# Collect predictions from all folds\nall_fold_preds = []\nall_fold_labels = []\n\nfor fold in range(N_FOLDS):\n    fold_checkpoint = CHECKPOINT_ROOT / f'fold{fold}_best.pt'\n    if not fold_checkpoint.exists():\n        print(f\"Warning: Fold {fold} checkpoint not found, skipping\")\n        continue\n    \n    # Load fold data\n    fold_path = DATA_ROOT / f'fold{fold}'\n    with open(fold_path / 'train' / 'stat.pkl', 'rb') as f:\n        fold_stats = pickle.load(f)\n    \n    val_ds = PercePianoDataset(fold_path, 'valid')\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n                            collate_fn=collate_fn, num_workers=0)\n    \n    # Load model\n    model = VirtuosoNetMultiLevel(net_param, fold_stats, multi_level=\"total_note_cat\")\n    checkpoint = torch.load(fold_checkpoint, map_location=device, weights_only=False)\n    model.load_state_dict(checkpoint['state_dict'])\n    model = model.to(device)\n    model.eval()\n    \n    fold_preds, fold_labels = [], []\n    with torch.no_grad():\n        for batch_x, note_locations, labels in val_loader:\n            batch_x = batch_x.to(device)\n            note_locations = {k: v.to(device) for k, v in note_locations.items()}\n            \n            outputs = model(batch_x, None, None, note_locations)\n            preds = sigmoid(outputs[-1])\n            \n            fold_preds.append(preds.cpu().numpy())\n            fold_labels.append(labels.numpy())\n    \n    all_fold_preds.append(np.vstack(fold_preds))\n    all_fold_labels.append(np.vstack(fold_labels))\n    print(f\"Fold {fold}: {len(val_ds)} samples\")\n\n# Concatenate all folds\nall_preds = np.vstack(all_fold_preds)\nall_labels = np.vstack(all_fold_labels)\n\nprint(f\"\\nTotal samples across {len(all_fold_preds)} folds: {len(all_preds)}\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"PER-DIMENSION R2 (Aggregated Across Folds)\")\nprint(\"=\"*50)\ndim_r2s = []\nfor i, dim in enumerate(DIMENSIONS):\n    if i < all_preds.shape[1]:\n        r2 = r2_score(all_labels[:, i], all_preds[:, i])\n        dim_r2s.append((dim, r2))\n\ndim_r2s.sort(key=lambda x: x[1], reverse=True)\nfor dim, r2 in dim_r2s:\n    status = \"[OK]\" if r2 >= 0.2 else \"[LOW]\" if r2 >= 0 else \"[NEG]\"\n    print(f\"{dim:<25} {r2:>+.4f} {status}\")\n\noverall_r2 = r2_score_multioutput(all_labels, all_preds)\nprint(f\"\\nOverall R2: {overall_r2:+.4f}\")\nprint(f\"Positive R2: {sum(1 for _, r2 in dim_r2s if r2 > 0)}/{len(dim_r2s)}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}