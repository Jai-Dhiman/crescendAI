{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Definitive Experiments\n",
    "\n",
    "## Parts\n",
    "1. **M1a-M1d**: MuQ Layer Ablation (find optimal layers)\n",
    "2. **F8-F11**: MuQ + Symbolic Fusion\n",
    "3. **D9a-D9c**: MERT + MuQ Audio Fusion\n",
    "4. **X2-X3**: Cross-Dataset Validation (ASAP, PSyllabus)\n",
    "5. **S3-S4**: Statistical Rigor (Bootstrap, Bonferroni)\n",
    "6. **A3-A7**: Analysis (Error correlation, dimensions, calibration)\n",
    "7. **Export**: Save all results to GDrive\n",
    "\n",
    "## Requirements\n",
    "- Compute: A100 (80GB VRAM)\n",
    "- rclone configured with `gdrive:` remote\n",
    "- External datasets: ASAP, PSyllabus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: CUDA setup (must be before any CUDA operations)\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    raise RuntimeError(\"GPU required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Install dependencies and clone repo\n",
    "!pip install transformers librosa soundfile pytorch_lightning nnAudio scipy scikit-learn muq requests tqdm --quiet\n",
    "\n",
    "import os\n",
    "REPO_DIR = '/tmp/crescendai'\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull origin main\n",
    "else:\n",
    "    !git clone https://github.com/jai-dhiman/crescendai.git {REPO_DIR}\n",
    "\n",
    "print(f\"Repo: {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Imports\n",
    "import sys\n",
    "sys.path.insert(0, f'{REPO_DIR}/model/src')\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from audio_experiments import PERCEPIANO_DIMENSIONS, DIMENSION_CATEGORIES, BASE_CONFIG, SEED\n",
    "from audio_experiments.extractors import (\n",
    "    extract_mert_for_layer_range,\n",
    "    extract_muq_embeddings,\n",
    ")\n",
    "from audio_experiments.models import (\n",
    "    MuQStatsModel,\n",
    "    MuQBaseModel,\n",
    "    MERTMuQEnsemble,\n",
    "    MERTMuQConcatModel,\n",
    "    AsymmetricGatedFusion,\n",
    ")\n",
    "from audio_experiments.training import (\n",
    "    run_4fold_mert_experiment,\n",
    "    run_4fold_dual_experiment,\n",
    "    restore_all_from_gdrive,\n",
    "    should_run_experiment,\n",
    "    sync_experiment_to_gdrive,\n",
    "    get_completed_experiments,\n",
    "    print_experiment_status,\n",
    "    # Fusion runners\n",
    "    run_simple_fusion_experiment,\n",
    "    run_weighted_fusion_experiment,\n",
    "    run_ridge_fusion_experiment,\n",
    "    run_confidence_fusion_experiment,\n",
    "    run_error_correlation_experiment,\n",
    "    save_fusion_experiment,\n",
    "    # Statistics\n",
    "    bootstrap_r2_extended,\n",
    "    bootstrap_r2_comparison,\n",
    "    paired_ttest_per_sample,\n",
    "    wilcoxon_test,\n",
    "    cohens_d,\n",
    "    bonferroni_correction,\n",
    "    fdr_correction,\n",
    "    # Fusion strategies\n",
    "    simple_average_fusion,\n",
    "    weighted_fusion_grid_search,\n",
    "    compute_error_correlation,\n",
    "    compute_per_dimension_comparison,\n",
    ")\n",
    "from audio_experiments.training.sync import numpy_serializer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Imports: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Path configuration\n",
    "DATA_ROOT = Path('/tmp/definitive_experiments')\n",
    "AUDIO_DIR = DATA_ROOT / 'audio'\n",
    "LABEL_DIR = DATA_ROOT / 'labels'\n",
    "MUQ_CACHE_ROOT = DATA_ROOT / 'muq_cache'\n",
    "MERT_CACHE_ROOT = DATA_ROOT / 'mert_cache'\n",
    "CHECKPOINT_ROOT = DATA_ROOT / 'checkpoints'\n",
    "RESULTS_DIR = DATA_ROOT / 'results'\n",
    "LOG_DIR = DATA_ROOT / 'logs'\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "\n",
    "# Cross-dataset directories\n",
    "ASAP_DIR = DATA_ROOT / 'asap'\n",
    "PSYLLABUS_DIR = DATA_ROOT / 'psyllabus'\n",
    "\n",
    "# GDrive paths\n",
    "GDRIVE_AUDIO = 'gdrive:crescendai_data/audio_baseline/percepiano_rendered'\n",
    "GDRIVE_LABELS = 'gdrive:crescendai_data/percepiano_labels'\n",
    "GDRIVE_FOLDS = 'gdrive:crescendai_data/percepiano_fold_assignments.json'\n",
    "GDRIVE_MERT_CACHE = 'gdrive:crescendai_data/audio_baseline/mert_embeddings/L7-12'\n",
    "GDRIVE_MUQ_CACHE = 'gdrive:crescendai_data/audio_baseline/muq_embeddings'\n",
    "GDRIVE_RESULTS = 'gdrive:crescendai_data/checkpoints/definitive_experiments'\n",
    "GDRIVE_SYMBOLIC = 'gdrive:crescendai_data/checkpoints/aligned_fusion/symbolic_predictions.json'\n",
    "\n",
    "for d in [AUDIO_DIR, LABEL_DIR, MUQ_CACHE_ROOT, MERT_CACHE_ROOT, CHECKPOINT_ROOT,\n",
    "          RESULTS_DIR, LOG_DIR, FIGURES_DIR, ASAP_DIR, PSYLLABUS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_rclone(cmd, desc=\"\"):\n",
    "    if desc:\n",
    "        print(f\"{desc}...\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"rclone failed: {desc}\\nCommand: {' '.join(cmd)}\\nStderr: {result.stderr}\")\n",
    "    return result\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "if 'gdrive:' not in result.stdout:\n",
    "    raise RuntimeError(\"rclone 'gdrive' not configured\")\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"GDrive results: {GDRIVE_RESULTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Download data\n",
    "run_rclone(['rclone', 'copy', GDRIVE_AUDIO, str(AUDIO_DIR), '--progress'], \"Downloading audio\")\n",
    "run_rclone(['rclone', 'copy', GDRIVE_LABELS, str(LABEL_DIR)], \"Downloading labels\")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'folds.json'\n",
    "run_rclone(['rclone', 'copyto', GDRIVE_FOLDS, str(FOLD_FILE)], \"Downloading folds\")\n",
    "\n",
    "# Load labels and folds\n",
    "LABEL_FILE = LABEL_DIR / 'label_2round_mean_reg_19_with0_rm_highstd0.json'\n",
    "with open(LABEL_FILE) as f:\n",
    "    LABELS = json.load(f)\n",
    "with open(FOLD_FILE) as f:\n",
    "    FOLD_ASSIGNMENTS = json.load(f)\n",
    "\n",
    "# Create key->fold_id mapping\n",
    "FOLD_BY_KEY = {}\n",
    "for fold_id in range(4):\n",
    "    for key in FOLD_ASSIGNMENTS.get(f\"fold_{fold_id}\", []):\n",
    "        FOLD_BY_KEY[key] = fold_id\n",
    "\n",
    "ALL_KEYS = sorted(FOLD_BY_KEY.keys())\n",
    "print(f\"Samples per fold: {[len(FOLD_ASSIGNMENTS.get(f'fold_{i}', [])) for i in range(4)]}\")\n",
    "print(f\"Total samples: {len(ALL_KEYS)}\")\n",
    "print(f\"Audio files: {len(list(AUDIO_DIR.glob('*.wav')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Initialize results tracking\n",
    "ALL_RESULTS = {}\n",
    "\n",
    "# Get completed experiments from GDrive\n",
    "print(\"Checking GDrive for completed experiments...\")\n",
    "COMPLETED_CACHE = get_completed_experiments(GDRIVE_RESULTS)\n",
    "print(f\"Found {len(COMPLETED_CACHE)} completed experiments\")\n",
    "\n",
    "# Define experiment IDs\n",
    "EXPERIMENT_IDS = [\n",
    "    # Part 1: MuQ Layer Ablation (MuQ has 12 transformer layers, indices 0-12)\n",
    "    'M1a_muq_L1-4',\n",
    "    'M1b_muq_L5-8',\n",
    "    'M1c_muq_L9-12',\n",
    "    'M1d_muq_L1-12',\n",
    "    'M2_muq_last_hidden',  # Test last_hidden_state (replicates D8 from phase 2)\n",
    "    # Part 2: MuQ + Symbolic Fusion\n",
    "    'F8_muq_symbolic_simple',\n",
    "    'F9_muq_symbolic_weighted',\n",
    "    'F10_muq_symbolic_ridge',\n",
    "    'F11_muq_symbolic_confidence',\n",
    "    # Part 3: MERT + MuQ Fusion\n",
    "    'D9a_mert_muq_ensemble',\n",
    "    'D9b_mert_muq_concat',\n",
    "    'D9c_mert_muq_gated',\n",
    "    # Part 4: Cross-Dataset Validation\n",
    "    'X2_asap_multiperformer',\n",
    "    'X3_psyllabus_difficulty',\n",
    "    # Part 5: Statistics\n",
    "    'S3_bootstrap_all',\n",
    "    'S4_significance_tests',\n",
    "    # Part 6: Analysis\n",
    "    'A3_error_correlation',\n",
    "    'A4_dimension_breakdown',\n",
    "    'A5_failure_cases',\n",
    "    'A6_calibration',\n",
    "    'A7_gate_visualization',\n",
    "]\n",
    "\n",
    "print_experiment_status(EXPERIMENT_IDS, COMPLETED_CACHE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: MuQ Layer Ablation (M1a-M1d)\n",
    "\n",
    "Find optimal MuQ layer range. MuQ has 12 transformer layers (hidden_states indices 0-12, where 0 is initial embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: MuQ Layer Configurations\n",
    "# MuQ has 13 hidden states (indices 0-12): index 0 is initial embedding, 1-12 are transformer layers\n",
    "MUQ_LAYER_CONFIGS = {\n",
    "    'M1a_muq_L1-4': {'layer_start': 1, 'layer_end': 5, 'desc': 'MuQ layers 1-4 (early acoustic)'},\n",
    "    'M1b_muq_L5-8': {'layer_start': 5, 'layer_end': 9, 'desc': 'MuQ layers 5-8 (mid perceptual)'},\n",
    "    'M1c_muq_L9-12': {'layer_start': 9, 'layer_end': 13, 'desc': 'MuQ layers 9-12 (late semantic)'},\n",
    "    'M1d_muq_L1-12': {'layer_start': 1, 'layer_end': 13, 'desc': 'MuQ all layers 1-12'},\n",
    "    'M2_muq_last_hidden': {'layer_start': None, 'layer_end': None, 'desc': 'MuQ last hidden state only (like D8)'},\n",
    "}\n",
    "\n",
    "# MuQ Stats pooling config (proven best in prior experiments)\n",
    "MUQ_CONFIG = {\n",
    "    **BASE_CONFIG,\n",
    "    'input_dim': 1024,\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'pooling_stats': 'mean_std',  # 2x input dim\n",
    "}\n",
    "\n",
    "def make_muq_stats_model(cfg):\n",
    "    return MuQStatsModel(\n",
    "        input_dim=cfg['input_dim'],\n",
    "        hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling_stats=cfg['pooling_stats'],\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "print(\"MuQ layer ablation configs ready\")\n",
    "for exp_id, cfg in MUQ_LAYER_CONFIGS.items():\n",
    "    if cfg['layer_start'] is None:\n",
    "        print(f\"  {exp_id}: last hidden state\")\n",
    "    else:\n",
    "        print(f\"  {exp_id}: layers {cfg['layer_start']}-{cfg['layer_end']-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: M1a - MuQ Layers 1-4\n",
    "exp_id = 'M1a_muq_L1-4'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Create layer-specific cache\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Extract embeddings\n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: M1b - MuQ Layers 5-8\n",
    "exp_id = 'M1b_muq_L5-8'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: M1c - MuQ Layers 9-12\n",
    "exp_id = 'M1c_muq_L9-12'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: M1d - MuQ All Layers\n",
    "exp_id = 'M1d_muq_L1-12'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MUQ_CACHE_ROOT / f\"L{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    extract_muq_embeddings(\n",
    "        AUDIO_DIR, cache_dir, ALL_KEYS,\n",
    "        layer_start=cfg['layer_start'],\n",
    "        layer_end=cfg['layer_end']\n",
    "    )\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-m2-muq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: M2 - MuQ Last Hidden State (replicates D8 from phase 2)\n",
    "# D8_muq_stats achieved R2=0.560 using last_hidden_state - let's verify this result\n",
    "exp_id = 'M2_muq_last_hidden'\n",
    "cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Create cache for last_hidden_state embeddings\n",
    "    cache_dir = MUQ_CACHE_ROOT / 'last_hidden'\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Try to download from GDrive first (D8 used this cache)\n",
    "    try:\n",
    "        run_rclone(['rclone', 'copy', GDRIVE_MUQ_CACHE, str(cache_dir)], \"Downloading MuQ cache (last_hidden)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"No existing cache on GDrive, will extract fresh: {e}\")\n",
    "    # Extract any missing (no layer range = last_hidden_state)\n",
    "    extract_muq_embeddings(AUDIO_DIR, cache_dir, ALL_KEYS)\n",
    "    \n",
    "    # Train with stats pooling (same as D8)\n",
    "    ALL_RESULTS[exp_id] = run_4fold_mert_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description=cfg['desc'],\n",
    "        model_factory=make_muq_stats_model,\n",
    "        mert_cache_dir=cache_dir,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=MUQ_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: MuQ Layer Ablation Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MuQ LAYER ABLATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Experiment':<25} {'Layers':<12} {'R2':>10} {'Std':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "best_muq_exp = None\n",
    "best_muq_r2 = 0\n",
    "\n",
    "for exp_id in ['M1a_muq_L1-4', 'M1b_muq_L5-8', 'M1c_muq_L9-12', 'M1d_muq_L1-12', 'M2_muq_last_hidden']:\n",
    "    # Load from disk if not in memory\n",
    "    if exp_id not in ALL_RESULTS:\n",
    "        result_file = RESULTS_DIR / f\"{exp_id}.json\"\n",
    "        if result_file.exists():\n",
    "            with open(result_file) as f:\n",
    "                ALL_RESULTS[exp_id] = json.load(f)\n",
    "    \n",
    "    if exp_id in ALL_RESULTS:\n",
    "        r = ALL_RESULTS[exp_id]\n",
    "        r2 = r['summary']['avg_r2']\n",
    "        std = r['summary']['std_r2']\n",
    "        cfg = MUQ_LAYER_CONFIGS[exp_id]\n",
    "        layers = 'last_hidden' if cfg['layer_start'] is None else f\"{cfg['layer_start']}-{cfg['layer_end']-1}\"\n",
    "        print(f\"{exp_id:<25} {layers:<12} {r2:>10.4f} {std:>10.4f}\")\n",
    "        \n",
    "        if r2 > best_muq_r2:\n",
    "            best_muq_r2 = r2\n",
    "            best_muq_exp = exp_id\n",
    "\n",
    "print(\"-\"*70)\n",
    "if best_muq_exp:\n",
    "    print(f\"BEST: {best_muq_exp} (R2={best_muq_r2:.4f})\")\n",
    "    BEST_MUQ_CONFIG = MUQ_LAYER_CONFIGS[best_muq_exp]\n",
    "    if BEST_MUQ_CONFIG['layer_start'] is None:\n",
    "        BEST_MUQ_CACHE = MUQ_CACHE_ROOT / 'last_hidden'\n",
    "    else:\n",
    "        BEST_MUQ_CACHE = MUQ_CACHE_ROOT / f\"L{BEST_MUQ_CONFIG['layer_start']}-{BEST_MUQ_CONFIG['layer_end']-1}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: MuQ + Symbolic Fusion (F8-F11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Load Symbolic Predictions\n",
    "SYMBOLIC_PRED_FILE = DATA_ROOT / 'symbolic_predictions.json'\n",
    "run_rclone(['rclone', 'copyto', GDRIVE_SYMBOLIC, str(SYMBOLIC_PRED_FILE)], \"Downloading symbolic predictions\")\n",
    "\n",
    "with open(SYMBOLIC_PRED_FILE) as f:\n",
    "    SYMBOLIC_PREDICTIONS = json.load(f)\n",
    "\n",
    "print(f\"Loaded symbolic predictions for {len(SYMBOLIC_PREDICTIONS)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Generate MuQ Predictions\n",
    "def generate_muq_predictions(checkpoint_dir: Path, cache_dir: Path, fold_assignments: Dict, labels: Dict) -> Dict[str, List[float]]:\n",
    "    \"\"\"Generate CV predictions from trained MuQ models.\"\"\"\n",
    "    from audio_experiments.data import MERTDataset, mert_collate_fn\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    predictions = {}\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    for fold in range(4):\n",
    "        ckpt_path = checkpoint_dir / f\"fold{fold}_best.ckpt\"\n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"Warning: checkpoint not found: {ckpt_path}\")\n",
    "            continue\n",
    "        \n",
    "        model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "        model = model.to(device).eval()\n",
    "        \n",
    "        # Get validation keys for this fold\n",
    "        val_keys = fold_assignments.get(f\"fold_{fold}\", [])\n",
    "        val_ds = MERTDataset(cache_dir, labels, fold_assignments, fold, \"val\", max_frames=1000)\n",
    "        val_dl = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=mert_collate_fn)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                pred = model(batch['embeddings'].to(device), batch['attention_mask'].to(device))\n",
    "                for key, p in zip(batch['keys'], pred.cpu().numpy()):\n",
    "                    predictions[key] = p.tolist()\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Generate predictions from best MuQ model\n",
    "if best_muq_exp:\n",
    "    print(f\"Generating MuQ predictions from {best_muq_exp}...\")\n",
    "    MUQ_PREDICTIONS = generate_muq_predictions(\n",
    "        CHECKPOINT_ROOT / best_muq_exp,\n",
    "        BEST_MUQ_CACHE,\n",
    "        FOLD_ASSIGNMENTS,\n",
    "        LABELS\n",
    "    )\n",
    "    print(f\"Generated predictions for {len(MUQ_PREDICTIONS)} samples\")\n",
    "else:\n",
    "    print(\"WARNING: No MuQ model trained yet\")\n",
    "    MUQ_PREDICTIONS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Align predictions\n",
    "# Find common keys\n",
    "FUSION_KEYS = sorted(\n",
    "    set(MUQ_PREDICTIONS.keys()) &\n",
    "    set(SYMBOLIC_PREDICTIONS.keys()) &\n",
    "    set(LABELS.keys())\n",
    ")\n",
    "print(f\"Aligned samples: {len(FUSION_KEYS)}\")\n",
    "\n",
    "# Create aligned arrays\n",
    "MUQ_ARR = np.array([MUQ_PREDICTIONS[k] for k in FUSION_KEYS])\n",
    "SYMBOLIC_ARR = np.array([SYMBOLIC_PREDICTIONS[k] for k in FUSION_KEYS])\n",
    "LABELS_ARR = np.array([LABELS[k][:19] for k in FUSION_KEYS])\n",
    "\n",
    "print(f\"MuQ shape: {MUQ_ARR.shape}\")\n",
    "print(f\"Symbolic shape: {SYMBOLIC_ARR.shape}\")\n",
    "print(f\"Labels shape: {LABELS_ARR.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: F8 - Simple Average Fusion\n",
    "exp_id = 'F8_muq_symbolic_simple'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_simple_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: F9 - Weighted Fusion\n",
    "exp_id = 'F9_muq_symbolic_weighted'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_weighted_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, FOLD_BY_KEY, FUSION_KEYS, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: F10 - Ridge Stacking\n",
    "exp_id = 'F10_muq_symbolic_ridge'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_ridge_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, FOLD_BY_KEY, FUSION_KEYS, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: F11 - Confidence Weighted\n",
    "exp_id = 'F11_muq_symbolic_confidence'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_confidence_fusion_experiment(\n",
    "        exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR, n_bootstrap=10000\n",
    "    )\n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: MERT + MuQ Audio Fusion (D9a-D9c)\n",
    "\n",
    "Test if two audio encoders provide complementary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Extract MERT embeddings (layers 7-12, best from prior ablation)\n",
    "MERT_CACHE = MERT_CACHE_ROOT / 'L7-12'\n",
    "MERT_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Try to download from GDrive first\n",
    "try:                                                                                                                     \n",
    "    run_rclone(['rclone', 'copy', GDRIVE_MERT_CACHE, str(MERT_CACHE)], \"Downloading MERT cache\")                         \n",
    "except RuntimeError as e:                                                                                                \n",
    "    print(f\"No existing cache on GDrive, will extract fresh: {e}\")\n",
    "\n",
    "# Extract any missing\n",
    "extract_mert_for_layer_range(7, 13, AUDIO_DIR, MERT_CACHE, ALL_KEYS)\n",
    "print(f\"MERT embeddings ready: {len(list(MERT_CACHE.glob('*.pt')))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Ensure MuQ embeddings for D9 fusion experiments\n",
    "# Use the best MuQ config - either from layer ablation or last_hidden_state (D8 approach)\n",
    "if best_muq_exp:   \n",
    "    if BEST_MUQ_CONFIG['layer_start'] is None:\n",
    "        # Best is last_hidden_state\n",
    "        MUQ_CACHE = MUQ_CACHE_ROOT / 'last_hidden'\n",
    "        MUQ_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "        try:       \n",
    "            run_rclone(['rclone', 'copy', GDRIVE_MUQ_CACHE, str(MUQ_CACHE)], \"Downloading MuQ cache\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"No cache on GDrive (may already be extracted locally): {e}\")\n",
    "        extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE, ALL_KEYS)\n",
    "    else:\n",
    "        # Best is a specific layer range\n",
    "        MUQ_CACHE = BEST_MUQ_CACHE\n",
    "        MUQ_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "        extract_muq_embeddings(\n",
    "            AUDIO_DIR, MUQ_CACHE, ALL_KEYS,\n",
    "            layer_start=BEST_MUQ_CONFIG['layer_start'],\n",
    "            layer_end=BEST_MUQ_CONFIG['layer_end']\n",
    "        )\n",
    "else:   \n",
    "    # No ablation results yet - use last_hidden_state as default (D8's approach)\n",
    "    MUQ_CACHE = MUQ_CACHE_ROOT / 'last_hidden'\n",
    "    MUQ_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        run_rclone(['rclone', 'copy', GDRIVE_MUQ_CACHE, str(MUQ_CACHE)], \"Downloading MuQ cache (last_hidden)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"No cache on GDrive, will extract fresh: {e}\")\n",
    "    extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE, ALL_KEYS)\n",
    "\n",
    "print(f\"MuQ cache: {MUQ_CACHE}\")\n",
    "print(f\"MuQ embeddings: {len(list(MUQ_CACHE.glob('*.pt')))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: D9a - MERT+MuQ Ensemble (Late Fusion)\n",
    "exp_id = 'D9a_mert_muq_ensemble'\n",
    "\n",
    "DUAL_CONFIG = {\n",
    "    **BASE_CONFIG,\n",
    "    'input_dim': 1024,\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'fusion_weight': 0.5,\n",
    "}\n",
    "\n",
    "def make_ensemble_model(cfg):\n",
    "    return MERTMuQEnsemble(\n",
    "        input_dim=cfg['input_dim'],\n",
    "        hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling='attention',\n",
    "        fusion_weight=cfg['fusion_weight'],\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_4fold_dual_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description='MERT+MuQ late fusion ensemble',\n",
    "        model_factory=make_ensemble_model,\n",
    "        mert_cache_dir=MERT_CACHE,\n",
    "        muq_cache_dir=MUQ_CACHE,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=DUAL_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 27: D9b - MERT+MuQ Concat (Early Fusion)\n",
    "exp_id = 'D9b_mert_muq_concat'\n",
    "\n",
    "def make_concat_model(cfg):\n",
    "    return MERTMuQConcatModel(\n",
    "        mert_dim=cfg['input_dim'],\n",
    "        muq_dim=cfg['input_dim'],\n",
    "        hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling='attention',\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_4fold_dual_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description='MERT+MuQ early fusion concat',\n",
    "        model_factory=make_concat_model,\n",
    "        mert_cache_dir=MERT_CACHE,\n",
    "        muq_cache_dir=MUQ_CACHE,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=DUAL_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: D9c - MERT+MuQ Gated Fusion\n",
    "exp_id = 'D9c_mert_muq_gated'\n",
    "\n",
    "def make_gated_model(cfg):\n",
    "    return AsymmetricGatedFusion(\n",
    "        mert_dim=cfg['input_dim'],\n",
    "        muq_dim=cfg['input_dim'],\n",
    "        mert_hidden=cfg['hidden_dim'],\n",
    "        shared_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling='attention',\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    ALL_RESULTS[exp_id] = run_4fold_dual_experiment(\n",
    "        exp_id=exp_id,\n",
    "        description='MERT+MuQ asymmetric gated fusion',\n",
    "        model_factory=make_gated_model,\n",
    "        mert_cache_dir=MERT_CACHE,\n",
    "        muq_cache_dir=MUQ_CACHE,\n",
    "        labels=LABELS,\n",
    "        fold_assignments=FOLD_ASSIGNMENTS,\n",
    "        config=DUAL_CONFIG,\n",
    "        checkpoint_root=CHECKPOINT_ROOT,\n",
    "        results_dir=RESULTS_DIR,\n",
    "        log_dir=LOG_DIR,\n",
    "    )\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Extract gate weights from D9c\n",
    "exp_id = 'D9c_mert_muq_gated'\n",
    "ckpt_path = CHECKPOINT_ROOT / exp_id / 'fold0_best.ckpt'\n",
    "\n",
    "if ckpt_path.exists():\n",
    "    from audio_experiments.data import DualEmbeddingDataset, dual_collate_fn\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    model = AsymmetricGatedFusion.load_from_checkpoint(ckpt_path)\n",
    "    model = model.to('cuda').eval()\n",
    "    \n",
    "    # Get sample batch for gate extraction\n",
    "    val_keys = FOLD_ASSIGNMENTS.get('fold_0', [])[:32]\n",
    "    ds = DualEmbeddingDataset(MERT_CACHE, MUQ_CACHE, LABELS, val_keys, max_frames=1000)\n",
    "    dl = DataLoader(ds, batch_size=32, collate_fn=dual_collate_fn)\n",
    "    batch = next(iter(dl))\n",
    "    \n",
    "    gate_info = model.get_learned_gates(\n",
    "        batch['mert_embeddings'].cuda(),\n",
    "        batch['muq_embeddings'].cuda(),\n",
    "        batch['mert_mask'].cuda(),\n",
    "        batch['muq_mask'].cuda(),\n",
    "    )\n",
    "    \n",
    "    # Store gate weights per dimension\n",
    "    GATE_WEIGHTS = {\n",
    "        dim: float(gate_info['mert_weight_per_dim'][i])\n",
    "        for i, dim in enumerate(PERCEPIANO_DIMENSIONS)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nLearned Gate Weights (higher = more MERT):\")\n",
    "    for dim, weight in sorted(GATE_WEIGHTS.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {dim:<25}: {weight:.3f}\")\n",
    "    \n",
    "    # Save to results\n",
    "    if exp_id in ALL_RESULTS:\n",
    "        ALL_RESULTS[exp_id]['gate_weights'] = GATE_WEIGHTS\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    GATE_WEIGHTS = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Cross-Dataset Validation (X2-X3)\n",
    "\n",
    "Validate model generalization on external datasets:\n",
    "- **X2**: ASAP Multi-Performer Analysis (variance across performers of same piece)\n",
    "- **X3**: PSyllabus Difficulty Correlation (correlation with difficulty levels 1-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t65bjx4nlbr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 32a: ASAP Dataset Setup\n",
    "# Downloads ASAP metadata and links audio from MAESTRO v2.0.0\n",
    "# This cell can take 1-2 hours due to MAESTRO download (~115GB)\n",
    "\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "ASAP_REPO = ASAP_DIR / 'asap-dataset'\n",
    "MAESTRO_DIR = ASAP_DIR / 'maestro-v2.0.0'\n",
    "MAESTRO_ZIP = ASAP_DIR / 'maestro-v2.0.0.zip'\n",
    "MAESTRO_URL = 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0.zip'\n",
    "\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "def download_with_progress(url: str, output_path: Path, desc: str):\n",
    "    \"\"\"Download file with progress bar.\"\"\"\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc=desc) as t:\n",
    "        urllib.request.urlretrieve(url, output_path, reporthook=t.update_to)\n",
    "\n",
    "# Step 1: Clone ASAP repository\n",
    "if not ASAP_REPO.exists():\n",
    "    print(\"Cloning ASAP repository...\")\n",
    "    result = subprocess.run(\n",
    "        ['git', 'clone', 'https://github.com/fosfrancesco/asap-dataset.git', str(ASAP_REPO)],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Failed to clone ASAP: {result.stderr}\")\n",
    "    print(f\"Cloned to: {ASAP_REPO}\")\n",
    "else:\n",
    "    print(f\"ASAP repo exists: {ASAP_REPO}\")\n",
    "\n",
    "# Step 2: Download MAESTRO v2.0.0 if not exists\n",
    "if not MAESTRO_DIR.exists():\n",
    "    if not MAESTRO_ZIP.exists():\n",
    "        print(f\"\\nDownloading MAESTRO v2.0.0 (~115GB)...\")\n",
    "        print(\"This will take a while. Go get some coffee.\")\n",
    "        download_with_progress(MAESTRO_URL, MAESTRO_ZIP, \"MAESTRO v2.0.0\")\n",
    "    \n",
    "    # Extract MAESTRO\n",
    "    print(f\"\\nExtracting MAESTRO archive...\")\n",
    "    with zipfile.ZipFile(MAESTRO_ZIP, 'r') as zf:\n",
    "        # Get total size for progress\n",
    "        total_size = sum(f.file_size for f in zf.infolist())\n",
    "        extracted_size = 0\n",
    "        \n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Extracting\") as pbar:\n",
    "            for member in zf.infolist():\n",
    "                zf.extract(member, ASAP_DIR)\n",
    "                extracted_size += member.file_size\n",
    "                pbar.update(member.file_size)\n",
    "    \n",
    "    print(f\"Extracted to: {MAESTRO_DIR}\")\n",
    "    \n",
    "    # Clean up zip to save space\n",
    "    print(\"Removing zip file to save space...\")\n",
    "    MAESTRO_ZIP.unlink()\n",
    "else:\n",
    "    print(f\"MAESTRO exists: {MAESTRO_DIR}\")\n",
    "\n",
    "# Step 3: Run ASAP initialize_dataset.py to link audio\n",
    "asap_metadata_csv = ASAP_REPO / 'metadata.csv'\n",
    "asap_init_script = ASAP_REPO / 'initialize_dataset.py'\n",
    "\n",
    "# Check if audio already linked by looking for wav files\n",
    "existing_wavs = list(ASAP_REPO.rglob('*.wav'))\n",
    "if len(existing_wavs) < 100:  # Expect ~500+ wav files if properly initialized\n",
    "    print(f\"\\nLinking MAESTRO audio to ASAP ({len(existing_wavs)} wav files found)...\")\n",
    "    result = subprocess.run(\n",
    "        ['python', str(asap_init_script), '-m', str(MAESTRO_DIR)],\n",
    "        cwd=ASAP_REPO,\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Warning: initialize_dataset.py returned error: {result.stderr}\")\n",
    "    \n",
    "    # Recount wav files\n",
    "    existing_wavs = list(ASAP_REPO.rglob('*.wav'))\n",
    "    print(f\"After initialization: {len(existing_wavs)} wav files\")\n",
    "else:\n",
    "    print(f\"ASAP audio already linked: {len(existing_wavs)} wav files\")\n",
    "\n",
    "# Step 4: Load and parse ASAP metadata\n",
    "import pandas as pd\n",
    "\n",
    "if asap_metadata_csv.exists():\n",
    "    asap_df = pd.read_csv(asap_metadata_csv)\n",
    "    print(f\"\\nASAP metadata loaded: {len(asap_df)} performances\")\n",
    "    \n",
    "    # Filter to performances with audio\n",
    "    asap_with_audio = asap_df[asap_df['audio_performance'].notna()]\n",
    "    print(f\"Performances with audio: {len(asap_with_audio)}\")\n",
    "    \n",
    "    # Group by piece (using 'title' column) to find multi-performer pieces\n",
    "    piece_counts = asap_with_audio.groupby('title').size()\n",
    "    multi_performer_pieces = piece_counts[piece_counts >= 5]\n",
    "    print(f\"Pieces with 5+ performers: {len(multi_performer_pieces)}\")\n",
    "    \n",
    "    # Store for use in X2 experiment\n",
    "    ASAP_METADATA = asap_df\n",
    "    ASAP_WITH_AUDIO = asap_with_audio\n",
    "    ASAP_MULTI_PERFORMER = multi_performer_pieces\n",
    "else:\n",
    "    raise FileNotFoundError(f\"ASAP metadata not found: {asap_metadata_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 32: X2 - ASAP Multi-Performer Analysis\n",
    "# Analyzes variance in predictions across different performers playing the same piece\n",
    "# If the model captures performance quality (not just piece characteristics),\n",
    "# we expect meaningful variance across performers of the same piece.\n",
    "\n",
    "exp_id = 'X2_asap_multiperformer'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"X2: ASAP MULTI-PERFORMER ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Verify ASAP data is available\n",
    "    if 'ASAP_WITH_AUDIO' not in dir() or 'ASAP_MULTI_PERFORMER' not in dir():\n",
    "        raise RuntimeError(\"Run ASAP setup cell first (Cell 32a)\")\n",
    "    \n",
    "    if len(ASAP_MULTI_PERFORMER) == 0:\n",
    "        raise RuntimeError(\"No multi-performer pieces found in ASAP dataset\")\n",
    "    \n",
    "    # Get best MuQ configuration from layer ablation\n",
    "    if best_muq_exp is None:\n",
    "        print(\"Warning: No best MuQ experiment found. Using default layers 1-12.\")\n",
    "        muq_layer_start, muq_layer_end = 1, 13\n",
    "    else:\n",
    "        muq_layer_start = BEST_MUQ_CONFIG['layer_start']\n",
    "        muq_layer_end = BEST_MUQ_CONFIG['layer_end']\n",
    "    \n",
    "    print(f\"Using MuQ layers {muq_layer_start}-{muq_layer_end-1}\")\n",
    "    \n",
    "    # Setup cache directory for ASAP embeddings\n",
    "    asap_muq_cache = ASAP_DIR / 'muq_cache' / f\"L{muq_layer_start}-{muq_layer_end-1}\"\n",
    "    asap_muq_cache.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load trained MuQ model (use fold 0 for inference)\n",
    "    ckpt_path = CHECKPOINT_ROOT / best_muq_exp / 'fold0_best.ckpt' if best_muq_exp else None\n",
    "    if ckpt_path is None or not ckpt_path.exists():\n",
    "        # Try to find any available checkpoint\n",
    "        for exp in ['M1d_muq_L1-12', 'M1c_muq_L9-12', 'M1b_muq_L5-8', 'M1a_muq_L1-4']:\n",
    "            fallback_path = CHECKPOINT_ROOT / exp / 'fold0_best.ckpt'\n",
    "            if fallback_path.exists():\n",
    "                ckpt_path = fallback_path\n",
    "                print(f\"Using fallback checkpoint: {exp}\")\n",
    "                break\n",
    "    \n",
    "    if ckpt_path is None or not ckpt_path.exists():\n",
    "        raise FileNotFoundError(\"No trained MuQ checkpoint found. Run MuQ experiments first.\")\n",
    "    \n",
    "    model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "    model = model.to('cuda').eval()\n",
    "    \n",
    "    # Process each multi-performer piece\n",
    "    piece_results = {}\n",
    "    all_performances_processed = 0\n",
    "    \n",
    "    for piece_title in tqdm(ASAP_MULTI_PERFORMER.index, desc=\"Processing pieces\"):\n",
    "        # Get all performances of this piece with audio\n",
    "        piece_perfs = ASAP_WITH_AUDIO[ASAP_WITH_AUDIO['title'] == piece_title]\n",
    "        \n",
    "        if len(piece_perfs) < 5:\n",
    "            continue\n",
    "        \n",
    "        piece_predictions = []\n",
    "        piece_keys = []\n",
    "        \n",
    "        for _, perf_row in piece_perfs.iterrows():\n",
    "            # Construct audio path\n",
    "            # ASAP stores audio_performance as relative path from repo root\n",
    "            audio_rel_path = perf_row['audio_performance']\n",
    "            if pd.isna(audio_rel_path):\n",
    "                continue\n",
    "            \n",
    "            audio_path = ASAP_REPO / audio_rel_path\n",
    "            if not audio_path.exists():\n",
    "                # Try alternate path construction\n",
    "                audio_path = ASAP_REPO / perf_row['folder'] / Path(audio_rel_path).name\n",
    "            \n",
    "            if not audio_path.exists():\n",
    "                continue\n",
    "            \n",
    "            key = audio_path.stem\n",
    "            emb_path = asap_muq_cache / f\"{key}.pt\"\n",
    "            \n",
    "            # Extract embedding if not cached\n",
    "            if not emb_path.exists():\n",
    "                try:\n",
    "                    extract_muq_embeddings(\n",
    "                        audio_path.parent, asap_muq_cache, [key],\n",
    "                        layer_start=muq_layer_start, layer_end=muq_layer_end\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"  Warning: Failed to extract {key}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Load embedding and predict\n",
    "            if emb_path.exists():\n",
    "                try:\n",
    "                    with torch.no_grad():\n",
    "                        emb = torch.load(emb_path).unsqueeze(0).cuda()\n",
    "                        mask = torch.ones(1, emb.shape[1], dtype=torch.bool).cuda()\n",
    "                        pred = model(emb, mask).cpu().numpy()[0]\n",
    "                        piece_predictions.append(pred)\n",
    "                        piece_keys.append(key)\n",
    "                except Exception as e:\n",
    "                    print(f\"  Warning: Failed to predict {key}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Compute statistics for this piece\n",
    "        if len(piece_predictions) >= 2:\n",
    "            piece_predictions = np.array(piece_predictions)\n",
    "            \n",
    "            # Mean prediction across all performers\n",
    "            mean_pred = piece_predictions.mean(axis=0)  # [19]\n",
    "            \n",
    "            # Standard deviation across performers for each dimension\n",
    "            std_per_dim = piece_predictions.std(axis=0)  # [19]\n",
    "            \n",
    "            # Overall mean prediction (single scalar)\n",
    "            mean_overall = float(mean_pred.mean())\n",
    "            \n",
    "            # Overall std (std of mean predictions across performers)\n",
    "            std_overall = float(piece_predictions.mean(axis=1).std())\n",
    "            \n",
    "            piece_results[piece_title] = {\n",
    "                'n_performances': len(piece_predictions),\n",
    "                'performer_keys': piece_keys,\n",
    "                'mean_pred_overall': mean_overall,\n",
    "                'std_pred_overall': std_overall,\n",
    "                'mean_pred_per_dim': mean_pred.tolist(),\n",
    "                'std_pred_per_dim': std_per_dim.tolist(),\n",
    "                'per_dim_analysis': {\n",
    "                    dim: {\n",
    "                        'mean': float(mean_pred[i]),\n",
    "                        'std': float(std_per_dim[i]),\n",
    "                    }\n",
    "                    for i, dim in enumerate(PERCEPIANO_DIMENSIONS)\n",
    "                },\n",
    "            }\n",
    "            \n",
    "            all_performances_processed += len(piece_predictions)\n",
    "    \n",
    "    # Compute aggregate statistics\n",
    "    all_stds = [v['std_pred_overall'] for v in piece_results.values()]\n",
    "    mean_intra_piece_std = np.mean(all_stds) if all_stds else 0\n",
    "    median_intra_piece_std = np.median(all_stds) if all_stds else 0\n",
    "    \n",
    "    # Per-dimension analysis: which dimensions show most/least variance across performers?\n",
    "    dim_variances = {dim: [] for dim in PERCEPIANO_DIMENSIONS}\n",
    "    for piece_data in piece_results.values():\n",
    "        for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n",
    "            dim_variances[dim].append(piece_data['std_pred_per_dim'][i])\n",
    "    \n",
    "    dim_mean_variance = {\n",
    "        dim: float(np.mean(variances)) if variances else 0\n",
    "        for dim, variances in dim_variances.items()\n",
    "    }\n",
    "    \n",
    "    # Sort dimensions by variance (high to low)\n",
    "    sorted_dims = sorted(dim_mean_variance.items(), key=lambda x: -x[1])\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = {\n",
    "        'exp_id': exp_id,\n",
    "        'n_pieces': len(piece_results),\n",
    "        'n_performances_total': all_performances_processed,\n",
    "        'mean_intra_piece_std': float(mean_intra_piece_std),\n",
    "        'median_intra_piece_std': float(median_intra_piece_std),\n",
    "        'meaningful_variation': mean_intra_piece_std > 0.05,\n",
    "        'high_variance_dimensions': [d for d, v in sorted_dims[:5]],\n",
    "        'low_variance_dimensions': [d for d, v in sorted_dims[-5:]],\n",
    "        'dimension_variance': dim_mean_variance,\n",
    "        'piece_details': piece_results,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nASAP Multi-Performer Results:\")\n",
    "    print(f\"  Pieces analyzed: {len(piece_results)}\")\n",
    "    print(f\"  Total performances: {all_performances_processed}\")\n",
    "    print(f\"  Mean intra-piece std: {mean_intra_piece_std:.4f}\")\n",
    "    print(f\"  Median intra-piece std: {median_intra_piece_std:.4f}\")\n",
    "    print(f\"  Meaningful variation (std > 0.05): {ALL_RESULTS[exp_id]['meaningful_variation']}\")\n",
    "    print(f\"\\n  Highest variance dimensions:\")\n",
    "    for dim, var in sorted_dims[:5]:\n",
    "        print(f\"    {dim}: {var:.4f}\")\n",
    "    print(f\"\\n  Lowest variance dimensions:\")\n",
    "    for dim, var in sorted_dims[-5:]:\n",
    "        print(f\"    {dim}: {var:.4f}\")\n",
    "    \n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(f\"SKIP {exp_id}: already completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bx07ohvsas9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 33a: PSyllabus Dataset Setup\n",
    "# Downloads metadata from Zenodo and audio from YouTube via yt-dlp\n",
    "# This cell can take several hours due to YouTube rate limiting\n",
    "# Target: ~50 samples per difficulty level (1-11) = ~550 total\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Install yt-dlp if not available\n",
    "try:\n",
    "    import yt_dlp\n",
    "except ImportError:\n",
    "    print(\"Installing yt-dlp...\")\n",
    "    subprocess.run(['pip', 'install', '-q', 'yt-dlp'], check=True)\n",
    "    import yt_dlp\n",
    "\n",
    "PSYLLABUS_METADATA_URL = 'https://zenodo.org/records/14794592/files/new_clean_data.json?download=1'\n",
    "PSYLLABUS_METADATA_FILE = PSYLLABUS_DIR / 'new_clean_data.json'\n",
    "PSYLLABUS_AUDIO_DIR = PSYLLABUS_DIR / 'audio'\n",
    "PSYLLABUS_CHECKPOINT_FILE = PSYLLABUS_DIR / 'download_checkpoint.json'\n",
    "\n",
    "PSYLLABUS_AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Step 1: Download metadata from Zenodo\n",
    "if not PSYLLABUS_METADATA_FILE.exists():\n",
    "    print(\"Downloading PSyllabus metadata from Zenodo...\")\n",
    "    download_with_progress(PSYLLABUS_METADATA_URL, PSYLLABUS_METADATA_FILE, \"PSyllabus metadata\")\n",
    "else:\n",
    "    print(f\"PSyllabus metadata exists: {PSYLLABUS_METADATA_FILE}\")\n",
    "\n",
    "# Step 2: Load and parse metadata\n",
    "with open(PSYLLABUS_METADATA_FILE) as f:\n",
    "    psyllabus_raw = json.load(f)\n",
    "\n",
    "# Parse entries - structure may vary, handle different formats\n",
    "psyllabus_entries = []\n",
    "if isinstance(psyllabus_raw, list):\n",
    "    psyllabus_entries = psyllabus_raw\n",
    "elif isinstance(psyllabus_raw, dict):\n",
    "    # Could be keyed by ID or have a 'data' field\n",
    "    if 'data' in psyllabus_raw:\n",
    "        psyllabus_entries = psyllabus_raw['data']\n",
    "    else:\n",
    "        # Assume keys are IDs\n",
    "        psyllabus_entries = [{'id': k, **v} for k, v in psyllabus_raw.items()]\n",
    "\n",
    "print(f\"PSyllabus entries loaded: {len(psyllabus_entries)}\")\n",
    "\n",
    "# Step 3: Extract YouTube URLs and difficulty levels\n",
    "def extract_youtube_id(entry):\n",
    "    \"\"\"Extract YouTube video ID from various possible fields.\"\"\"\n",
    "    for field in ['youtube_id', 'video_id', 'url', 'youtube_url', 'link']:\n",
    "        if field in entry:\n",
    "            val = entry[field]\n",
    "            if val:\n",
    "                # Extract ID from URL if needed\n",
    "                if 'youtube.com' in str(val) or 'youtu.be' in str(val):\n",
    "                    if 'v=' in val:\n",
    "                        return val.split('v=')[1].split('&')[0]\n",
    "                    elif 'youtu.be/' in val:\n",
    "                        return val.split('youtu.be/')[1].split('?')[0]\n",
    "                else:\n",
    "                    return str(val)\n",
    "    return None\n",
    "\n",
    "def extract_difficulty(entry):\n",
    "    \"\"\"Extract difficulty level from various possible fields.\"\"\"\n",
    "    for field in ['difficulty', 'level', 'grade', 'difficulty_level']:\n",
    "        if field in entry:\n",
    "            val = entry[field]\n",
    "            if val is not None:\n",
    "                try:\n",
    "                    diff = int(val)\n",
    "                    if 1 <= diff <= 11:\n",
    "                        return diff\n",
    "                except (ValueError, TypeError):\n",
    "                    pass\n",
    "    return None\n",
    "\n",
    "# Parse entries\n",
    "parsed_entries = []\n",
    "for entry in psyllabus_entries:\n",
    "    yt_id = extract_youtube_id(entry)\n",
    "    difficulty = extract_difficulty(entry)\n",
    "    \n",
    "    if yt_id and difficulty:\n",
    "        parsed_entries.append({\n",
    "            'youtube_id': yt_id,\n",
    "            'difficulty': difficulty,\n",
    "            'composer': entry.get('composer', ''),\n",
    "            'title': entry.get('title', entry.get('name', '')),\n",
    "        })\n",
    "\n",
    "print(f\"Parsed entries with YouTube ID and difficulty: {len(parsed_entries)}\")\n",
    "\n",
    "# Group by difficulty level\n",
    "by_difficulty = {i: [] for i in range(1, 12)}\n",
    "for entry in parsed_entries:\n",
    "    by_difficulty[entry['difficulty']].append(entry)\n",
    "\n",
    "print(\"Distribution by difficulty level:\")\n",
    "for diff, entries in sorted(by_difficulty.items()):\n",
    "    print(f\"  Level {diff:2d}: {len(entries):4d} entries\")\n",
    "\n",
    "# Step 4: Stratified sampling - select ~50 per level\n",
    "TARGET_PER_LEVEL = 50\n",
    "sampled_entries = []\n",
    "\n",
    "random.seed(42)  # Reproducible sampling\n",
    "for diff in range(1, 12):\n",
    "    available = by_difficulty[diff]\n",
    "    if len(available) <= TARGET_PER_LEVEL:\n",
    "        sampled_entries.extend(available)\n",
    "    else:\n",
    "        sampled_entries.extend(random.sample(available, TARGET_PER_LEVEL))\n",
    "\n",
    "print(f\"\\nSampled {len(sampled_entries)} entries for download\")\n",
    "\n",
    "# Step 5: Download audio from YouTube\n",
    "# Load checkpoint if exists (for resumability)\n",
    "download_checkpoint = {'completed': [], 'failed': []}\n",
    "if PSYLLABUS_CHECKPOINT_FILE.exists():\n",
    "    with open(PSYLLABUS_CHECKPOINT_FILE) as f:\n",
    "        download_checkpoint = json.load(f)\n",
    "    print(f\"Loaded checkpoint: {len(download_checkpoint['completed'])} completed, {len(download_checkpoint['failed'])} failed\")\n",
    "\n",
    "completed_ids = set(download_checkpoint['completed'])\n",
    "failed_ids = set(download_checkpoint['failed'])\n",
    "\n",
    "# Filter to entries not yet attempted\n",
    "to_download = [e for e in sampled_entries if e['youtube_id'] not in completed_ids and e['youtube_id'] not in failed_ids]\n",
    "print(f\"Entries to download: {len(to_download)}\")\n",
    "\n",
    "def download_youtube_audio(youtube_id: str, output_dir: Path, max_retries: int = 3) -> bool:\n",
    "    \"\"\"Download audio from YouTube using yt-dlp.\"\"\"\n",
    "    output_template = str(output_dir / f\"{youtube_id}.%(ext)s\")\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'extractaudio': True,\n",
    "        'audioformat': 'wav',\n",
    "        'outtmpl': output_template,\n",
    "        'quiet': True,\n",
    "        'no_warnings': True,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                ydl.download([f'https://www.youtube.com/watch?v={youtube_id}'])\n",
    "            \n",
    "            # Verify file exists\n",
    "            wav_path = output_dir / f\"{youtube_id}.wav\"\n",
    "            if wav_path.exists() and wav_path.stat().st_size > 1000:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            continue\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Download with rate limiting\n",
    "newly_completed = 0\n",
    "newly_failed = 0\n",
    "\n",
    "for i, entry in enumerate(tqdm(to_download, desc=\"Downloading YouTube audio\")):\n",
    "    yt_id = entry['youtube_id']\n",
    "    \n",
    "    # Check if already downloaded\n",
    "    wav_path = PSYLLABUS_AUDIO_DIR / f\"{yt_id}.wav\"\n",
    "    if wav_path.exists() and wav_path.stat().st_size > 1000:\n",
    "        download_checkpoint['completed'].append(yt_id)\n",
    "        newly_completed += 1\n",
    "        continue\n",
    "    \n",
    "    # Download\n",
    "    success = download_youtube_audio(yt_id, PSYLLABUS_AUDIO_DIR)\n",
    "    \n",
    "    if success:\n",
    "        download_checkpoint['completed'].append(yt_id)\n",
    "        newly_completed += 1\n",
    "    else:\n",
    "        download_checkpoint['failed'].append(yt_id)\n",
    "        newly_failed += 1\n",
    "    \n",
    "    # Save checkpoint every 10 downloads\n",
    "    if (i + 1) % 10 == 0:\n",
    "        with open(PSYLLABUS_CHECKPOINT_FILE, 'w') as f:\n",
    "            json.dump(download_checkpoint, f)\n",
    "    \n",
    "    # Rate limiting: random delay between downloads\n",
    "    time.sleep(random.uniform(2.0, 4.0))\n",
    "\n",
    "# Final checkpoint save\n",
    "with open(PSYLLABUS_CHECKPOINT_FILE, 'w') as f:\n",
    "    json.dump(download_checkpoint, f)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nDownload Summary:\")\n",
    "print(f\"  Newly completed: {newly_completed}\")\n",
    "print(f\"  Newly failed: {newly_failed}\")\n",
    "print(f\"  Total completed: {len(download_checkpoint['completed'])}\")\n",
    "print(f\"  Total failed: {len(download_checkpoint['failed'])}\")\n",
    "\n",
    "# Count successful downloads by difficulty\n",
    "successful_by_diff = {i: 0 for i in range(1, 12)}\n",
    "for entry in sampled_entries:\n",
    "    wav_path = PSYLLABUS_AUDIO_DIR / f\"{entry['youtube_id']}.wav\"\n",
    "    if wav_path.exists() and wav_path.stat().st_size > 1000:\n",
    "        successful_by_diff[entry['difficulty']] += 1\n",
    "\n",
    "print(\"\\nSuccessful downloads by difficulty:\")\n",
    "for diff, count in sorted(successful_by_diff.items()):\n",
    "    print(f\"  Level {diff:2d}: {count:3d}\")\n",
    "\n",
    "# Store for use in X3 experiment\n",
    "PSYLLABUS_SAMPLED = sampled_entries\n",
    "PSYLLABUS_SUCCESS_BY_DIFF = successful_by_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 33: X3 - PSyllabus Difficulty Correlation\n",
    "# Correlates model predictions with ground-truth difficulty levels (1-11)\n",
    "# Difficulty is a proxy for required skill level, so we expect weak-to-moderate\n",
    "# positive correlation (rho > 0.2) if the model captures performance quality.\n",
    "\n",
    "exp_id = 'X3_psyllabus_difficulty'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    print(\"=\"*70)\n",
    "    print(\"X3: PSYLLABUS DIFFICULTY CORRELATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Verify PSyllabus data is available\n",
    "    if 'PSYLLABUS_SAMPLED' not in dir():\n",
    "        raise RuntimeError(\"Run PSyllabus setup cell first (Cell 33a)\")\n",
    "    \n",
    "    # Get best MuQ configuration\n",
    "    if best_muq_exp is None:\n",
    "        print(\"Warning: No best MuQ experiment found. Using default layers 1-12.\")\n",
    "        muq_layer_start, muq_layer_end = 1, 13\n",
    "    else:\n",
    "        muq_layer_start = BEST_MUQ_CONFIG['layer_start']\n",
    "        muq_layer_end = BEST_MUQ_CONFIG['layer_end']\n",
    "    \n",
    "    print(f\"Using MuQ layers {muq_layer_start}-{muq_layer_end-1}\")\n",
    "    \n",
    "    # Setup cache directory\n",
    "    psyllabus_muq_cache = PSYLLABUS_DIR / 'muq_cache' / f\"L{muq_layer_start}-{muq_layer_end-1}\"\n",
    "    psyllabus_muq_cache.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load trained MuQ model\n",
    "    ckpt_path = CHECKPOINT_ROOT / best_muq_exp / 'fold0_best.ckpt' if best_muq_exp else None\n",
    "    if ckpt_path is None or not ckpt_path.exists():\n",
    "        for exp in ['M1d_muq_L1-12', 'M1c_muq_L9-12', 'M1b_muq_L5-8', 'M1a_muq_L1-4']:\n",
    "            fallback_path = CHECKPOINT_ROOT / exp / 'fold0_best.ckpt'\n",
    "            if fallback_path.exists():\n",
    "                ckpt_path = fallback_path\n",
    "                print(f\"Using fallback checkpoint: {exp}\")\n",
    "                break\n",
    "    \n",
    "    if ckpt_path is None or not ckpt_path.exists():\n",
    "        raise FileNotFoundError(\"No trained MuQ checkpoint found. Run MuQ experiments first.\")\n",
    "    \n",
    "    model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "    model = model.to('cuda').eval()\n",
    "    \n",
    "    # Process each downloaded audio file\n",
    "    difficulties = []\n",
    "    predictions = []\n",
    "    prediction_details = []\n",
    "    \n",
    "    for entry in tqdm(PSYLLABUS_SAMPLED, desc=\"Processing PSyllabus audio\"):\n",
    "        yt_id = entry['youtube_id']\n",
    "        difficulty = entry['difficulty']\n",
    "        \n",
    "        # Check if audio exists\n",
    "        wav_path = PSYLLABUS_AUDIO_DIR / f\"{yt_id}.wav\"\n",
    "        if not wav_path.exists() or wav_path.stat().st_size < 1000:\n",
    "            continue\n",
    "        \n",
    "        key = yt_id\n",
    "        emb_path = psyllabus_muq_cache / f\"{key}.pt\"\n",
    "        \n",
    "        # Extract embedding if not cached\n",
    "        if not emb_path.exists():\n",
    "            try:\n",
    "                extract_muq_embeddings(\n",
    "                    PSYLLABUS_AUDIO_DIR, psyllabus_muq_cache, [key],\n",
    "                    layer_start=muq_layer_start, layer_end=muq_layer_end\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Failed to extract {key}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Load embedding and predict\n",
    "        if emb_path.exists():\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    emb = torch.load(emb_path).unsqueeze(0).cuda()\n",
    "                    mask = torch.ones(1, emb.shape[1], dtype=torch.bool).cuda()\n",
    "                    pred = model(emb, mask).cpu().numpy()[0]\n",
    "                    \n",
    "                    # Store results\n",
    "                    mean_pred = float(pred.mean())\n",
    "                    predictions.append(mean_pred)\n",
    "                    difficulties.append(difficulty)\n",
    "                    \n",
    "                    prediction_details.append({\n",
    "                        'youtube_id': yt_id,\n",
    "                        'difficulty': difficulty,\n",
    "                        'mean_prediction': mean_pred,\n",
    "                        'per_dim_prediction': pred.tolist(),\n",
    "                        'composer': entry.get('composer', ''),\n",
    "                        'title': entry.get('title', ''),\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Failed to predict {key}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nProcessed {len(predictions)} samples\")\n",
    "    \n",
    "    if len(predictions) < 10:\n",
    "        print(\"ERROR: Insufficient data for correlation analysis (need at least 10 samples)\")\n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'error': 'Insufficient data',\n",
    "            'n_samples': len(predictions),\n",
    "        }\n",
    "    else:\n",
    "        # Compute Spearman correlation\n",
    "        rho, p_value = stats.spearmanr(difficulties, predictions)\n",
    "        \n",
    "        # Compute correlation by difficulty range (low/mid/high)\n",
    "        low_mask = np.array(difficulties) <= 4\n",
    "        mid_mask = (np.array(difficulties) >= 5) & (np.array(difficulties) <= 7)\n",
    "        high_mask = np.array(difficulties) >= 8\n",
    "        \n",
    "        range_analysis = {}\n",
    "        for name, mask in [('low_1-4', low_mask), ('mid_5-7', mid_mask), ('high_8-11', high_mask)]:\n",
    "            if mask.sum() >= 5:\n",
    "                range_preds = np.array(predictions)[mask]\n",
    "                range_diffs = np.array(difficulties)[mask]\n",
    "                if len(set(range_diffs)) > 1:  # Need variance for correlation\n",
    "                    r, p = stats.spearmanr(range_diffs, range_preds)\n",
    "                    range_analysis[name] = {\n",
    "                        'n': int(mask.sum()),\n",
    "                        'rho': float(r),\n",
    "                        'p_value': float(p),\n",
    "                        'mean_prediction': float(range_preds.mean()),\n",
    "                    }\n",
    "                else:\n",
    "                    range_analysis[name] = {\n",
    "                        'n': int(mask.sum()),\n",
    "                        'mean_prediction': float(range_preds.mean()),\n",
    "                    }\n",
    "        \n",
    "        # Per-dimension correlation analysis\n",
    "        all_preds = np.array([d['per_dim_prediction'] for d in prediction_details])\n",
    "        all_diffs = np.array(difficulties)\n",
    "        \n",
    "        per_dim_correlation = {}\n",
    "        for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n",
    "            dim_preds = all_preds[:, i]\n",
    "            r, p = stats.spearmanr(all_diffs, dim_preds)\n",
    "            per_dim_correlation[dim] = {\n",
    "                'rho': float(r),\n",
    "                'p_value': float(p),\n",
    "                'significant': p < 0.05,\n",
    "            }\n",
    "        \n",
    "        # Sort dimensions by correlation strength\n",
    "        sorted_dims = sorted(per_dim_correlation.items(), key=lambda x: -abs(x[1]['rho']))\n",
    "        \n",
    "        # Mean prediction by difficulty level\n",
    "        mean_by_difficulty = {}\n",
    "        for diff in range(1, 12):\n",
    "            diff_mask = np.array(difficulties) == diff\n",
    "            if diff_mask.sum() > 0:\n",
    "                mean_by_difficulty[diff] = float(np.array(predictions)[diff_mask].mean())\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'n_samples': len(predictions),\n",
    "            'spearman_rho': float(rho),\n",
    "            'p_value': float(p_value),\n",
    "            'significant': p_value < 0.05,\n",
    "            'weak_positive': rho > 0.2,\n",
    "            'moderate_positive': rho > 0.4,\n",
    "            'difficulty_range': [int(min(difficulties)), int(max(difficulties))],\n",
    "            'mean_by_difficulty': mean_by_difficulty,\n",
    "            'range_analysis': range_analysis,\n",
    "            'per_dimension_correlation': per_dim_correlation,\n",
    "            'strongest_correlating_dims': [d for d, v in sorted_dims[:5]],\n",
    "            'sample_details': prediction_details[:20],  # Store first 20 for inspection\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nPSyllabus Difficulty Correlation Results:\")\n",
    "        print(f\"  Samples: {len(predictions)}\")\n",
    "        print(f\"  Difficulty range: {min(difficulties)}-{max(difficulties)}\")\n",
    "        print(f\"  Spearman rho: {rho:.4f}\")\n",
    "        print(f\"  p-value: {p_value:.2e}\")\n",
    "        print(f\"  Significant (p < 0.05): {p_value < 0.05}\")\n",
    "        print(f\"  Weak positive (rho > 0.2): {rho > 0.2}\")\n",
    "        print(f\"  Moderate positive (rho > 0.4): {rho > 0.4}\")\n",
    "        \n",
    "        print(f\"\\n  Mean prediction by difficulty level:\")\n",
    "        for diff in sorted(mean_by_difficulty.keys()):\n",
    "            print(f\"    Level {diff:2d}: {mean_by_difficulty[diff]:.4f}\")\n",
    "        \n",
    "        print(f\"\\n  Strongest correlating dimensions:\")\n",
    "        for dim, corr in sorted_dims[:5]:\n",
    "            print(f\"    {dim}: rho={corr['rho']:.4f}, p={corr['p_value']:.2e}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(f\"SKIP {exp_id}: already completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Statistical Rigor (S3-S4)\n",
    "\n",
    "Bootstrap CIs and significance tests for all comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 35: S3 - Bootstrap CIs for all comparisons\n",
    "exp_id = 'S3_bootstrap_all'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    bootstrap_results = {}\n",
    "    \n",
    "    # MuQ vs Symbolic\n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        print(\"Computing MuQ vs Symbolic bootstrap...\")\n",
    "        bootstrap_results['muq_vs_symbolic'] = bootstrap_r2_comparison(\n",
    "            LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR, n_bootstrap=10000\n",
    "        )\n",
    "        print(f\"  MuQ: {bootstrap_results['muq_vs_symbolic']['r2_a']:.4f}\")\n",
    "        print(f\"  Symbolic: {bootstrap_results['muq_vs_symbolic']['r2_b']:.4f}\")\n",
    "        print(f\"  Diff: {bootstrap_results['muq_vs_symbolic']['difference']:.4f}\")\n",
    "        print(f\"  MuQ significantly better: {bootstrap_results['muq_vs_symbolic']['a_significantly_better']}\")\n",
    "    \n",
    "    # MuQ CIs\n",
    "    if len(MUQ_ARR) > 0:\n",
    "        print(\"\\nComputing MuQ bootstrap CIs...\")\n",
    "        bootstrap_results['muq_ci'] = bootstrap_r2_extended(LABELS_ARR, MUQ_ARR, n_bootstrap=10000)\n",
    "        print(f\"  R2: {bootstrap_results['muq_ci']['overall']['r2']:.4f}\")\n",
    "        print(f\"  95% CI: [{bootstrap_results['muq_ci']['overall']['ci_lower']:.4f}, {bootstrap_results['muq_ci']['overall']['ci_upper']:.4f}]\")\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = {\n",
    "        'exp_id': exp_id,\n",
    "        'n_bootstrap': 10000,\n",
    "        'comparisons': bootstrap_results,\n",
    "    }\n",
    "    \n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 36: S4 - Significance Tests\n",
    "exp_id = 'S4_significance_tests'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    significance_results = {}\n",
    "    \n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        # Paired t-test\n",
    "        ttest = paired_ttest_per_sample(LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR)\n",
    "        significance_results['paired_ttest'] = ttest\n",
    "        print(f\"Paired t-test: t={ttest['t_stat']:.4f}, p={ttest['p_value']:.2e}\")\n",
    "        \n",
    "        # Wilcoxon\n",
    "        wilcox = wilcoxon_test(LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR)\n",
    "        significance_results['wilcoxon'] = wilcox\n",
    "        print(f\"Wilcoxon: stat={wilcox['stat']:.4f}, p={wilcox['p_value']:.2e}\")\n",
    "        \n",
    "        # Cohen's d\n",
    "        d = cohens_d(LABELS_ARR, MUQ_ARR, SYMBOLIC_ARR)\n",
    "        significance_results['cohens_d'] = d\n",
    "        print(f\"Cohen's d: {d:.4f}\")\n",
    "        \n",
    "        # Per-dimension tests with Bonferroni\n",
    "        per_dim_p = []\n",
    "        for i in range(19):\n",
    "            t = paired_ttest_per_sample(\n",
    "                LABELS_ARR[:, i:i+1],\n",
    "                MUQ_ARR[:, i:i+1],\n",
    "                SYMBOLIC_ARR[:, i:i+1]\n",
    "            )\n",
    "            per_dim_p.append(t['p_value'])\n",
    "        \n",
    "        bonf_corrected, bonf_sig = bonferroni_correction(np.array(per_dim_p))\n",
    "        significance_results['per_dimension'] = {\n",
    "            dim: {\n",
    "                'raw_p': per_dim_p[i],\n",
    "                'corrected_p': float(bonf_corrected[i]),\n",
    "                'significant': bool(bonf_sig[i]),\n",
    "            }\n",
    "            for i, dim in enumerate(PERCEPIANO_DIMENSIONS)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nBonferroni correction: {sum(bonf_sig)}/19 dimensions significant\")\n",
    "    \n",
    "    ALL_RESULTS[exp_id] = {\n",
    "        'exp_id': exp_id,\n",
    "        'tests': significance_results,\n",
    "    }\n",
    "    \n",
    "    save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "    sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Analysis (A3-A7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 38: A3 - Error Correlation Analysis\n",
    "exp_id = 'A3_error_correlation'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        ALL_RESULTS[exp_id] = run_error_correlation_experiment(\n",
    "            exp_id, MUQ_ARR, SYMBOLIC_ARR, LABELS_ARR\n",
    "        )\n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 39: A4 - Per-Dimension Breakdown\n",
    "exp_id = 'A4_dimension_breakdown'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0 and len(SYMBOLIC_ARR) > 0:\n",
    "        fused = simple_average_fusion(MUQ_ARR, SYMBOLIC_ARR)\n",
    "        \n",
    "        dim_comparison = {}\n",
    "        for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n",
    "            muq_r2 = r2_score(LABELS_ARR[:, i], MUQ_ARR[:, i])\n",
    "            symbolic_r2 = r2_score(LABELS_ARR[:, i], SYMBOLIC_ARR[:, i])\n",
    "            fusion_r2 = r2_score(LABELS_ARR[:, i], fused[:, i])\n",
    "            \n",
    "            # Determine category\n",
    "            category = None\n",
    "            for cat, dims in DIMENSION_CATEGORIES.items():\n",
    "                if dim in dims:\n",
    "                    category = cat\n",
    "                    break\n",
    "            \n",
    "            dim_comparison[dim] = {\n",
    "                'muq_r2': float(muq_r2),\n",
    "                'symbolic_r2': float(symbolic_r2),\n",
    "                'fusion_r2': float(fusion_r2),\n",
    "                'winner': 'muq' if muq_r2 > symbolic_r2 else 'symbolic',\n",
    "                'muq_advantage': float(muq_r2 - symbolic_r2),\n",
    "                'category': category,\n",
    "            }\n",
    "        \n",
    "        # Count winners by category\n",
    "        category_summary = {}\n",
    "        for cat in DIMENSION_CATEGORIES:\n",
    "            cat_dims = [d for d, v in dim_comparison.items() if v['category'] == cat]\n",
    "            muq_wins = sum(1 for d in cat_dims if dim_comparison[d]['winner'] == 'muq')\n",
    "            category_summary[cat] = {\n",
    "                'total': len(cat_dims),\n",
    "                'muq_wins': muq_wins,\n",
    "                'symbolic_wins': len(cat_dims) - muq_wins,\n",
    "            }\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'per_dimension': dim_comparison,\n",
    "            'category_summary': category_summary,\n",
    "            'muq_total_wins': sum(1 for v in dim_comparison.values() if v['winner'] == 'muq'),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nDimension Breakdown:\")\n",
    "        print(f\"  MuQ wins: {ALL_RESULTS[exp_id]['muq_total_wins']}/19 dimensions\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 40: A5 - Failure Cases\n",
    "exp_id = 'A5_failure_cases'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0:\n",
    "        # Compute per-sample MSE\n",
    "        mse_per_sample = ((LABELS_ARR - MUQ_ARR) ** 2).mean(axis=1)\n",
    "        \n",
    "        # Find worst predictions\n",
    "        worst_indices = np.argsort(mse_per_sample)[-10:]\n",
    "        \n",
    "        failure_cases = []\n",
    "        for idx in worst_indices:\n",
    "            key = FUSION_KEYS[idx]\n",
    "            sample_mse = mse_per_sample[idx]\n",
    "            \n",
    "            # Find worst dimensions for this sample\n",
    "            dim_errors = np.abs(LABELS_ARR[idx] - MUQ_ARR[idx])\n",
    "            worst_dims = np.argsort(dim_errors)[-3:]\n",
    "            \n",
    "            failure_cases.append({\n",
    "                'key': key,\n",
    "                'mse': float(sample_mse),\n",
    "                'worst_dimensions': [PERCEPIANO_DIMENSIONS[i] for i in worst_dims],\n",
    "                'predicted': MUQ_ARR[idx].tolist(),\n",
    "                'actual': LABELS_ARR[idx].tolist(),\n",
    "            })\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'n_samples': len(mse_per_sample),\n",
    "            'mean_mse': float(mse_per_sample.mean()),\n",
    "            'max_mse': float(mse_per_sample.max()),\n",
    "            'failure_cases': failure_cases,\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nFailure Case Analysis:\")\n",
    "        print(f\"  Mean MSE: {ALL_RESULTS[exp_id]['mean_mse']:.4f}\")\n",
    "        print(f\"  Max MSE: {ALL_RESULTS[exp_id]['max_mse']:.4f}\")\n",
    "        print(f\"  Worst samples: {[f['key'] for f in failure_cases[:3]]}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 41: A6 - Calibration\n",
    "exp_id = 'A6_calibration'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if len(MUQ_ARR) > 0:\n",
    "        # Compute calibration by decile\n",
    "        n_bins = 10\n",
    "        calibration = []\n",
    "        \n",
    "        # Flatten for overall calibration\n",
    "        preds_flat = MUQ_ARR.flatten()\n",
    "        labels_flat = LABELS_ARR.flatten()\n",
    "        \n",
    "        # Bin by predicted values\n",
    "        bins = np.linspace(0, 1, n_bins + 1)\n",
    "        for i in range(n_bins):\n",
    "            mask = (preds_flat >= bins[i]) & (preds_flat < bins[i+1])\n",
    "            if mask.sum() > 0:\n",
    "                calibration.append({\n",
    "                    'bin': i,\n",
    "                    'bin_range': [float(bins[i]), float(bins[i+1])],\n",
    "                    'count': int(mask.sum()),\n",
    "                    'mean_predicted': float(preds_flat[mask].mean()),\n",
    "                    'mean_actual': float(labels_flat[mask].mean()),\n",
    "                    'error': float(preds_flat[mask].mean() - labels_flat[mask].mean()),\n",
    "                })\n",
    "        \n",
    "        # Dispersion ratio\n",
    "        pred_std = MUQ_ARR.std()\n",
    "        label_std = LABELS_ARR.std()\n",
    "        dispersion_ratio = pred_std / label_std if label_std > 0 else 0\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'calibration_bins': calibration,\n",
    "            'dispersion_ratio': float(dispersion_ratio),\n",
    "            'pred_std': float(pred_std),\n",
    "            'label_std': float(label_std),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nCalibration Analysis:\")\n",
    "        print(f\"  Dispersion ratio: {dispersion_ratio:.4f}\")\n",
    "        print(f\"  Prediction std: {pred_std:.4f}\")\n",
    "        print(f\"  Label std: {label_std:.4f}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 42: A7 - Gate Weight Visualization\n",
    "exp_id = 'A7_gate_visualization'\n",
    "\n",
    "if should_run_experiment(exp_id, CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    if GATE_WEIGHTS:\n",
    "        # Sort by MERT preference\n",
    "        sorted_dims = sorted(GATE_WEIGHTS.items(), key=lambda x: -x[1])\n",
    "        \n",
    "        # Group by category\n",
    "        category_gates = {}\n",
    "        for cat, dims in DIMENSION_CATEGORIES.items():\n",
    "            cat_weights = [GATE_WEIGHTS.get(d, 0.5) for d in dims]\n",
    "            category_gates[cat] = {\n",
    "                'mean_mert_weight': float(np.mean(cat_weights)),\n",
    "                'dimensions': {d: GATE_WEIGHTS.get(d, 0.5) for d in dims},\n",
    "            }\n",
    "        \n",
    "        ALL_RESULTS[exp_id] = {\n",
    "            'exp_id': exp_id,\n",
    "            'gate_weights': GATE_WEIGHTS,\n",
    "            'mert_preferred_dims': [d for d, w in sorted_dims[:5]],\n",
    "            'muq_preferred_dims': [d for d, w in sorted_dims[-5:]],\n",
    "            'category_summary': category_gates,\n",
    "            'mean_gate': float(np.mean(list(GATE_WEIGHTS.values()))),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nGate Weight Analysis:\")\n",
    "        print(f\"  Mean gate (0.5=balanced): {ALL_RESULTS[exp_id]['mean_gate']:.3f}\")\n",
    "        print(f\"  MERT-preferred: {ALL_RESULTS[exp_id]['mert_preferred_dims']}\")\n",
    "        print(f\"  MuQ-preferred: {ALL_RESULTS[exp_id]['muq_preferred_dims']}\")\n",
    "        \n",
    "        save_fusion_experiment(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, ALL_RESULTS)\n",
    "        sync_experiment_to_gdrive(exp_id, ALL_RESULTS[exp_id], RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS)\n",
    "    else:\n",
    "        print(\"No gate weights available (D9c not trained)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Results Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 44: Export all results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load any missing results from disk\n",
    "for exp_id in EXPERIMENT_IDS:\n",
    "    if exp_id not in ALL_RESULTS:\n",
    "        result_file = RESULTS_DIR / f\"{exp_id}.json\"\n",
    "        if result_file.exists():\n",
    "            with open(result_file) as f:\n",
    "                ALL_RESULTS[exp_id] = json.load(f)\n",
    "\n",
    "# Save aggregate results\n",
    "aggregate_file = RESULTS_DIR / 'definitive_all_results.json'\n",
    "with open(aggregate_file, 'w') as f:\n",
    "    json.dump(ALL_RESULTS, f, indent=2, default=numpy_serializer)\n",
    "print(f\"Saved: {aggregate_file}\")\n",
    "\n",
    "# Sync to GDrive\n",
    "run_rclone(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS], \"Syncing results to GDrive\")\n",
    "print(f\"Synced to: {GDRIVE_RESULTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 45: Final Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEFINITIVE EXPERIMENTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Part 1: MuQ Layer Ablation\n",
    "print(\"\\nPart 1: MuQ Layer Ablation\")\n",
    "print(\"-\"*40)\n",
    "for exp_id in ['M1a_muq_L1-4', 'M1b_muq_L5-8', 'M1c_muq_L9-12', 'M1d_muq_L1-12', 'M2_muq_last_hidden']:\n",
    "    if exp_id in ALL_RESULTS and 'summary' in ALL_RESULTS[exp_id]:\n",
    "        r2 = ALL_RESULTS[exp_id]['summary']['avg_r2']\n",
    "        print(f\"  {exp_id}: R2={r2:.4f}\")\n",
    "\n",
    "# Part 2: MuQ + Symbolic Fusion\n",
    "print(\"\\nPart 2: MuQ + Symbolic Fusion\")\n",
    "print(\"-\"*40)\n",
    "for exp_id in ['F8_muq_symbolic_simple', 'F9_muq_symbolic_weighted', 'F10_muq_symbolic_ridge', 'F11_muq_symbolic_confidence']:\n",
    "    if exp_id in ALL_RESULTS and 'overall_r2' in ALL_RESULTS[exp_id]:\n",
    "        r2 = ALL_RESULTS[exp_id]['overall_r2']\n",
    "        print(f\"  {exp_id}: R2={r2:.4f}\")\n",
    "\n",
    "# Part 3: MERT + MuQ Fusion\n",
    "print(\"\\nPart 3: MERT + MuQ Audio Fusion\")\n",
    "print(\"-\"*40)\n",
    "for exp_id in ['D9a_mert_muq_ensemble', 'D9b_mert_muq_concat', 'D9c_mert_muq_gated']:\n",
    "    if exp_id in ALL_RESULTS and 'summary' in ALL_RESULTS[exp_id]:\n",
    "        r2 = ALL_RESULTS[exp_id]['summary']['avg_r2']\n",
    "        print(f\"  {exp_id}: R2={r2:.4f}\")\n",
    "\n",
    "# Part 4: Cross-Dataset Validation\n",
    "print(\"\\nPart 4: Cross-Dataset Validation\")\n",
    "print(\"-\"*40)\n",
    "if 'X2_asap_multiperformer' in ALL_RESULTS:\n",
    "    r = ALL_RESULTS['X2_asap_multiperformer']\n",
    "    print(f\"  ASAP Multi-Performer:\")\n",
    "    print(f\"    Pieces analyzed: {r.get('n_pieces', 0)}\")\n",
    "    print(f\"    Intra-piece std: {r.get('mean_intra_piece_std', 0):.4f}\")\n",
    "    print(f\"    Meaningful variation: {r.get('meaningful_variation', False)}\")\n",
    "if 'X3_psyllabus_difficulty' in ALL_RESULTS:\n",
    "    r = ALL_RESULTS['X3_psyllabus_difficulty']\n",
    "    print(f\"  PSyllabus Difficulty:\")\n",
    "    print(f\"    Samples: {r.get('n_samples', 0)}\")\n",
    "    print(f\"    Spearman rho: {r.get('spearman_rho', 0):.4f}\")\n",
    "    print(f\"    Significant: {r.get('significant', False)}\")\n",
    "\n",
    "# Completion stats\n",
    "completed = sum(1 for e in EXPERIMENT_IDS if e in ALL_RESULTS)\n",
    "print(f\"\\nCompleted: {completed}/{len(EXPERIMENT_IDS)} experiments\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
