{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Audio Baseline Experiments\n",
    "\n",
    "Comprehensive experiments for the ISMIR paper.\n",
    "\n",
    "## Experiments\n",
    "- **B0**: Baseline re-run (MERT+MLP, L13-24, mean pool)\n",
    "- **A1-A3**: Baselines (linear probe, Mel-CNN, raw statistics)\n",
    "- **B1a-B1d**: Layer ablation (1-6, 7-12, 13-24, 1-24)\n",
    "- **B2a-B2c**: Pooling ablation (max, attention, LSTM)\n",
    "- **C1a-C1b**: Loss ablation (hybrid MSE+CCC, pure CCC)\n",
    "\n",
    "## Requirements\n",
    "- Compute: A100 (80GB VRAM)\n",
    "- rclone configured with `gdrive:` remote"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA deterministic mode (must be before any CUDA operations)\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    raise RuntimeError(\"GPU required\")"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies and clone repo\n",
    "# Note: torch is pre-installed on Thunder Compute (don't reinstall)\n",
    "!pip install transformers librosa soundfile pytorch_lightning nnAudio scipy scikit-learn muq --quiet\n",
    "\n",
    "# Clone the repo\n",
    "import os\n",
    "REPO_DIR = '/tmp/crescendai'\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull origin main\n",
    "else:\n",
    "    !git clone https://github.com/jai-dhiman/crescendai.git {REPO_DIR}\n",
    "\n",
    "print(f\"Repo: {REPO_DIR}\")"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Setup imports\n",
    "import sys\n",
    "sys.path.insert(0, f'{REPO_DIR}/model/src')\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Import from our package\n",
    "from audio_experiments import PERCEPIANO_DIMENSIONS, BASE_CONFIG, SEED\n",
    "from audio_experiments.extractors import (\n",
    "    extract_mert_for_layer_range,\n",
    "    extract_mel_spectrograms,\n",
    "    extract_statistics_for_all,\n",
    ")\n",
    "from audio_experiments.models import BaseMERTModel, LinearProbeModel, MelCNNModel, StatsMLPModel\n",
    "from audio_experiments.training import (\n",
    "    run_4fold_mert_experiment,\n",
    "    run_4fold_mel_experiment,\n",
    "    run_4fold_stats_experiment,\n",
    "    restore_all_from_gdrive,\n",
    "    should_run_experiment,\n",
    "    sync_experiment_to_gdrive,\n",
    "    get_completed_experiments,\n",
    "    print_experiment_status,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Imports: OK\")"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Setup paths and download data\n",
    "DATA_ROOT = Path('/tmp/phase2')\n",
    "AUDIO_DIR = DATA_ROOT / 'audio'\n",
    "LABEL_DIR = DATA_ROOT / 'labels'\n",
    "MERT_CACHE_ROOT = DATA_ROOT / 'mert_cache'\n",
    "MEL_CACHE_DIR = DATA_ROOT / 'mel_cache'\n",
    "STATS_CACHE_DIR = DATA_ROOT / 'stats_cache'\n",
    "CHECKPOINT_ROOT = DATA_ROOT / 'checkpoints'\n",
    "RESULTS_DIR = DATA_ROOT / 'results'\n",
    "LOG_DIR = DATA_ROOT / 'logs'\n",
    "\n",
    "GDRIVE_AUDIO = 'gdrive:crescendai_data/audio_baseline/percepiano_rendered'\n",
    "GDRIVE_LABELS = 'gdrive:crescendai_data/percepiano_labels'\n",
    "GDRIVE_FOLDS = 'gdrive:crescendai_data/percepiano_fold_assignments.json'  # PercePiano original splits\n",
    "GDRIVE_MERT_CACHE = 'gdrive:crescendai_data/audio_baseline/mert_embeddings'\n",
    "GDRIVE_RESULTS = 'gdrive:crescendai_data/checkpoints/audio_phase2'\n",
    "\n",
    "for d in [AUDIO_DIR, LABEL_DIR, MERT_CACHE_ROOT, MEL_CACHE_DIR, STATS_CACHE_DIR,\n",
    "          CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_rclone(cmd, desc):\n",
    "    print(f\"{desc}...\")\n",
    "    subprocess.run(cmd, capture_output=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "if 'gdrive:' not in result.stdout:\n",
    "    raise RuntimeError(\"rclone 'gdrive' not configured\")\n",
    "\n",
    "# Download data\n",
    "run_rclone(['rclone', 'copy', GDRIVE_AUDIO, str(AUDIO_DIR), '--progress'], \"Downloading audio\")\n",
    "run_rclone(['rclone', 'copy', GDRIVE_LABELS, str(LABEL_DIR)], \"Downloading labels\")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'folds.json'\n",
    "run_rclone(['rclone', 'copyto', GDRIVE_FOLDS, str(FOLD_FILE)], \"Downloading folds\")\n",
    "\n",
    "# Load labels and folds\n",
    "LABEL_FILE = LABEL_DIR / 'label_2round_mean_reg_19_with0_rm_highstd0.json'\n",
    "with open(LABEL_FILE) as f:\n",
    "    LABELS = json.load(f)\n",
    "with open(FOLD_FILE) as f:\n",
    "    FOLD_ASSIGNMENTS = json.load(f)\n",
    "\n",
    "# FOLD_ASSIGNMENTS format: {\"fold_0\": [keys], \"fold_1\": [keys], ...}\n",
    "# Used by MERTDataset and run_4fold_mert_experiment\n",
    "\n",
    "# Create key->fold_id mapping for experiments that need it (D9, D9b)\n",
    "FOLD_BY_KEY = {}\n",
    "for fold_id in range(4):\n",
    "    for key in FOLD_ASSIGNMENTS.get(f\"fold_{fold_id}\", []):\n",
    "        FOLD_BY_KEY[key] = fold_id\n",
    "\n",
    "print(f\"Fold format: {list(FOLD_ASSIGNMENTS.keys())}\")\n",
    "print(f\"Samples per fold: {[len(FOLD_ASSIGNMENTS.get(f'fold_{i}', [])) for i in range(4)]}\")\n",
    "print(f\"Total samples: {len(FOLD_BY_KEY)}\")\n",
    "\n",
    "ALL_KEYS = list(LABELS.keys())\n",
    "print(f\"Audio: {len(list(AUDIO_DIR.glob('*.wav')))} files\")\n",
    "print(f\"Labels: {len(LABELS)} segments\")"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Restore MERT cache and completed experiments from GDrive\n",
    "DEFAULT_MERT_DIR = MERT_CACHE_ROOT / 'L13-24'\n",
    "DEFAULT_MERT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "result = subprocess.run(['rclone', 'lsf', GDRIVE_MERT_CACHE], capture_output=True, text=True)\n",
    "if result.returncode == 0 and '.pt' in result.stdout:\n",
    "    print(\"Restoring MERT cache...\")\n",
    "    run_rclone(['rclone', 'copy', GDRIVE_MERT_CACHE, str(DEFAULT_MERT_DIR)], \"Restoring cache\")\n",
    "    print(f\"Restored: {len(list(DEFAULT_MERT_DIR.glob('*.pt')))} embeddings\")\n",
    "\n",
    "ALL_RESULTS = {}\n",
    "\n",
    "ALL_EXPERIMENT_IDS = [\n",
    "    'B0_baseline', 'A1_linear_probe', 'A2_mel_cnn', 'A3_raw_stats',\n",
    "    'B1a_layers_1-6', 'B1b_layers_7-12', 'B1c_layers_13-24', 'B1d_layers_1-24',\n",
    "    'B2a_max_pool', 'B2b_attention_pool', 'B2c_lstm_pool',\n",
    "    'C1a_hybrid_loss', 'C1b_pure_ccc',\n",
    "]\n",
    "\n",
    "print(\"\\nChecking GDrive for completed experiments...\")\n",
    "restored = restore_all_from_gdrive(\n",
    "    GDRIVE_RESULTS,\n",
    "    RESULTS_DIR,\n",
    "    CHECKPOINT_ROOT,\n",
    "    ALL_RESULTS,\n",
    ")\n",
    "\n",
    "# Cache completed experiments to avoid repeated GDrive calls\n",
    "COMPLETED_CACHE = get_completed_experiments(GDRIVE_RESULTS)\n",
    "\n",
    "print_experiment_status(ALL_EXPERIMENT_IDS, COMPLETED_CACHE)"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiments"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B0: Baseline\n",
    "if should_run_experiment('B0_baseline', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "    def make_mert_model(cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg.get('pooling', 'mean'),\n",
    "            loss_type=cfg.get('loss_type', 'mse'), max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B0_baseline'] = run_4fold_mert_experiment(\n",
    "        'B0_baseline', 'MERT+MLP, L13-24, mean pooling',\n",
    "        make_mert_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B0_baseline', ALL_RESULTS['B0_baseline'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1: Linear Probe\n",
    "if should_run_experiment('A1_linear_probe', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Ensure embeddings exist (reuses B0's extraction if already done)\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "    def make_linear_probe(cfg):\n",
    "        return LinearProbeModel(\n",
    "            input_dim=cfg['input_dim'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['A1_linear_probe'] = run_4fold_mert_experiment(\n",
    "        'A1_linear_probe', 'Linear probe on MERT',\n",
    "        make_linear_probe, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'A1_linear_probe', ALL_RESULTS['A1_linear_probe'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2: Mel-CNN\n",
    "if should_run_experiment('A2_mel_cnn', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    extract_mel_spectrograms(AUDIO_DIR, MEL_CACHE_DIR, ALL_KEYS)\n",
    "\n",
    "    ALL_RESULTS['A2_mel_cnn'] = run_4fold_mel_experiment(\n",
    "        'A2_mel_cnn', '4-layer CNN on mel spectrograms',\n",
    "        MEL_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'A2_mel_cnn', ALL_RESULTS['A2_mel_cnn'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3: Raw Statistics\n",
    "if should_run_experiment('A3_raw_stats', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    extract_statistics_for_all(AUDIO_DIR, STATS_CACHE_DIR, ALL_KEYS)\n",
    "\n",
    "    ALL_RESULTS['A3_raw_stats'] = run_4fold_stats_experiment(\n",
    "        'A3_raw_stats', 'MLP on audio statistics (49-dim)',\n",
    "        STATS_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'A3_raw_stats', ALL_RESULTS['A3_raw_stats'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1a: Layer Ablation - Early Layers (1-6)\n",
    "if should_run_experiment('B1a_layers_1-6', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MERT_CACHE_ROOT / 'L1-6'\n",
    "    extract_mert_for_layer_range(1, 7, AUDIO_DIR, cache_dir, ALL_KEYS)\n",
    "\n",
    "    def make_mert_model(cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg.get('pooling', 'mean'),\n",
    "            loss_type=cfg.get('loss_type', 'mse'), max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B1a_layers_1-6'] = run_4fold_mert_experiment(\n",
    "        'B1a_layers_1-6', 'MERT layers 1-6 (early)',\n",
    "        make_mert_model, cache_dir, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B1a_layers_1-6', ALL_RESULTS['B1a_layers_1-6'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1b: Layer Ablation - Mid Layers (7-12)\n",
    "if should_run_experiment('B1b_layers_7-12', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MERT_CACHE_ROOT / 'L7-12'\n",
    "    extract_mert_for_layer_range(7, 13, AUDIO_DIR, cache_dir, ALL_KEYS)\n",
    "\n",
    "    def make_mert_model(cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg.get('pooling', 'mean'),\n",
    "            loss_type=cfg.get('loss_type', 'mse'), max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B1b_layers_7-12'] = run_4fold_mert_experiment(\n",
    "        'B1b_layers_7-12', 'MERT layers 7-12 (mid)',\n",
    "        make_mert_model, cache_dir, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B1b_layers_7-12', ALL_RESULTS['B1b_layers_7-12'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1c: Layer Ablation - Late Layers (13-24)\n",
    "if should_run_experiment('B1c_layers_13-24', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MERT_CACHE_ROOT / 'L13-24'\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, cache_dir, ALL_KEYS)\n",
    "\n",
    "    def make_mert_model(cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg.get('pooling', 'mean'),\n",
    "            loss_type=cfg.get('loss_type', 'mse'), max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B1c_layers_13-24'] = run_4fold_mert_experiment(\n",
    "        'B1c_layers_13-24', 'MERT layers 13-24 (late)',\n",
    "        make_mert_model, cache_dir, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B1c_layers_13-24', ALL_RESULTS['B1c_layers_13-24'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B1d: Layer Ablation - All Layers (1-24)\n",
    "if should_run_experiment('B1d_layers_1-24', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    cache_dir = MERT_CACHE_ROOT / 'L1-24'\n",
    "    extract_mert_for_layer_range(1, 25, AUDIO_DIR, cache_dir, ALL_KEYS)\n",
    "\n",
    "    def make_mert_model(cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg.get('pooling', 'mean'),\n",
    "            loss_type=cfg.get('loss_type', 'mse'), max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B1d_layers_1-24'] = run_4fold_mert_experiment(\n",
    "        'B1d_layers_1-24', 'MERT all layers 1-24',\n",
    "        make_mert_model, cache_dir, LABELS, FOLD_ASSIGNMENTS,\n",
    "        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B1d_layers_1-24', ALL_RESULTS['B1d_layers_1-24'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2a: Pooling Ablation - Max Pooling\n",
    "if should_run_experiment('B2a_max_pool', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Ensure L13-24 embeddings exist\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "    cfg = BASE_CONFIG.copy()\n",
    "    cfg['pooling'] = 'max'\n",
    "\n",
    "    def make_max_pool_model(cfg=cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg['pooling'],\n",
    "            loss_type='mse', max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B2a_max_pool'] = run_4fold_mert_experiment(\n",
    "        'B2a_max_pool', 'MERT + max pooling',\n",
    "        make_max_pool_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        cfg, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B2a_max_pool', ALL_RESULTS['B2a_max_pool'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2b: Pooling Ablation - Attention Pooling\n",
    "if should_run_experiment('B2b_attention_pool', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Ensure L13-24 embeddings exist\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "    cfg = BASE_CONFIG.copy()\n",
    "    cfg['pooling'] = 'attention'\n",
    "\n",
    "    def make_attention_pool_model(cfg=cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg['pooling'],\n",
    "            loss_type='mse', max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B2b_attention_pool'] = run_4fold_mert_experiment(\n",
    "        'B2b_attention_pool', 'MERT + attention pooling',\n",
    "        make_attention_pool_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        cfg, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B2b_attention_pool', ALL_RESULTS['B2b_attention_pool'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B2c: Pooling Ablation - Bi-LSTM Pooling\n",
    "if should_run_experiment('B2c_lstm_pool', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Ensure L13-24 embeddings exist\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "    cfg = BASE_CONFIG.copy()\n",
    "    cfg['pooling'] = 'lstm'\n",
    "\n",
    "    def make_lstm_pool_model(cfg=cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling=cfg['pooling'],\n",
    "            loss_type='mse', max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['B2c_lstm_pool'] = run_4fold_mert_experiment(\n",
    "        'B2c_lstm_pool', 'MERT + Bi-LSTM pooling',\n",
    "        make_lstm_pool_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        cfg, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'B2c_lstm_pool', ALL_RESULTS['B2c_lstm_pool'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1a: Loss Ablation - Hybrid MSE + CCC Loss\n",
    "if should_run_experiment('C1a_hybrid_loss', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Ensure L13-24 embeddings exist\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "    cfg = BASE_CONFIG.copy()\n",
    "    cfg['loss_type'] = 'hybrid'\n",
    "\n",
    "    def make_hybrid_loss_model(cfg=cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling='mean',\n",
    "            loss_type=cfg['loss_type'], max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['C1a_hybrid_loss'] = run_4fold_mert_experiment(\n",
    "        'C1a_hybrid_loss', 'MERT + MSE + 0.5*CCC loss',\n",
    "        make_hybrid_loss_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        cfg, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'C1a_hybrid_loss', ALL_RESULTS['C1a_hybrid_loss'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1b: Loss Ablation - Pure CCC Loss\n",
    "if should_run_experiment('C1b_pure_ccc', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, COMPLETED_CACHE):\n",
    "    # Ensure L13-24 embeddings exist\n",
    "    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "    cfg = BASE_CONFIG.copy()\n",
    "    cfg['loss_type'] = 'ccc'\n",
    "\n",
    "    def make_ccc_loss_model(cfg=cfg):\n",
    "        return BaseMERTModel(\n",
    "            input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "            dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "            weight_decay=cfg['weight_decay'], pooling='mean',\n",
    "            loss_type=cfg['loss_type'], max_epochs=cfg['max_epochs'],\n",
    "        )\n",
    "\n",
    "    ALL_RESULTS['C1b_pure_ccc'] = run_4fold_mert_experiment(\n",
    "        'C1b_pure_ccc', 'MERT + pure CCC loss',\n",
    "        make_ccc_loss_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n",
    "        cfg, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n",
    "    )\n",
    "    sync_experiment_to_gdrive(\n",
    "        'C1b_pure_ccc', ALL_RESULTS['C1b_pure_ccc'],\n",
    "        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n",
    "    )"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results Summary"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results table\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2 RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_r2 = ALL_RESULTS.get('B0_baseline', {}).get('summary', {}).get('avg_r2', 0)\n",
    "\n",
    "print(f\"{'Experiment':<25} {'Avg R2':>10} {'95% CI':>20} {'vs B0':>10} {'Disp':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "exp_order = [\n",
    "    'B0_baseline', None,\n",
    "    'A1_linear_probe', 'A2_mel_cnn', 'A3_raw_stats', None,\n",
    "    'B1a_layers_1-6', 'B1b_layers_7-12', 'B1c_layers_13-24', 'B1d_layers_1-24', None,\n",
    "    'B2a_max_pool', 'B2b_attention_pool', 'B2c_lstm_pool', None,\n",
    "    'C1a_hybrid_loss', 'C1b_pure_ccc',\n",
    "]\n",
    "\n",
    "for exp_id in exp_order:\n",
    "    if exp_id is None:\n",
    "        print(\"-\"*80)\n",
    "        continue\n",
    "    if exp_id not in ALL_RESULTS:\n",
    "        continue\n",
    "\n",
    "    r = ALL_RESULTS[exp_id]\n",
    "    s = r['summary']\n",
    "    ci = s.get('r2_ci_95', [0, 0])\n",
    "    diff = s['avg_r2'] - baseline_r2 if exp_id != 'B0_baseline' else 0\n",
    "    diff_str = f\"{diff:+.3f}\" if exp_id != 'B0_baseline' else '---'\n",
    "\n",
    "    print(f\"{exp_id:<25} {s['avg_r2']:>10.4f} [{ci[0]:.3f}, {ci[1]:.3f}] {diff_str:>10} {s.get('dispersion_ratio', 0):>8.2f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety sync\n",
    "with open(RESULTS_DIR / 'phase2_all_results.json', 'w') as f:\n",
    "    json.dump(ALL_RESULTS, f, indent=2)\n",
    "\n",
    "print(\"Final sync to Google Drive...\")\n",
    "run_rclone(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS], \"Syncing results\")\n",
    "run_rclone(['rclone', 'copy', str(CHECKPOINT_ROOT), f\"{GDRIVE_RESULTS}/checkpoints\"], \"Syncing checkpoints\")\n",
    "\n",
    "print_experiment_status(ALL_EXPERIMENT_IDS, {k: v['summary']['avg_r2'] for k, v in ALL_RESULTS.items()})\n",
    "print(\"Done! Results at:\", GDRIVE_RESULTS)"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Phase 3: Advanced Architecture Experiments\n\nBased on research recommendations for improving audio-only R2 toward 0.50+:\n- **D1a/D1b**: Statistical pooling (mean+std, mean+std+min+max)\n- **D2a/D2b**: Uncertainty-weighted loss (mean pool, attention pool)\n- **D3**: Dimension-specific heads (BiLSTM for timing, MLP for rest)\n- **D4**: Multi-layer MERT concat ([6,9,12])\n- **D5**: Transformer pooling (2-layer encoder before attention pool)\n- **D6**: Multi-scale temporal pooling\n\nExpected gains: +0.02-0.05 R2 cumulative from best configurations.",
   "metadata": {},
   "id": "cell-24"
  },
  {
   "cell_type": "code",
   "source": "# Phase 3 model imports\nfrom audio_experiments.models import (\n    StatsPoolingModel,\n    UncertaintyWeightedModel,\n    DimensionSpecificModel,\n    TransformerPoolingModel,\n    MultiScalePoolingModel,\n    MultiLayerMERTModel,\n)\nfrom audio_experiments.extractors import extract_mert_multilayer_concat\n\n# Phase 3 experiment IDs\nPHASE3_EXPERIMENT_IDS = [\n    'D1a_stats_mean_std', 'D1b_stats_full',\n    'D2a_uncertainty_mean', 'D2b_uncertainty_attn',\n    'D3_dimension_heads',\n    'D4_multilayer_6_9_12',\n    'D5_transformer_pool',\n    'D6_multiscale_pool',\n]\n\n# Extend ALL_EXPERIMENT_IDS\nALL_EXPERIMENT_IDS.extend(PHASE3_EXPERIMENT_IDS)\n\n# Check for completed experiments\nPHASE3_COMPLETED = get_completed_experiments(GDRIVE_RESULTS)\nprint_experiment_status(PHASE3_EXPERIMENT_IDS, PHASE3_COMPLETED)",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-25"
  },
  {
   "cell_type": "code",
   "source": "# D1a: Statistical Pooling (mean + std)\nif should_run_experiment('D1a_stats_mean_std', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_stats_model(cfg):\n        return StatsPoolingModel(\n            input_dim=1024,\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling_stats='mean_std',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D1a_stats_mean_std'] = run_4fold_mert_experiment(\n        'D1a_stats_mean_std', 'MERT + stats pooling (mean+std)',\n        make_stats_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D1a_stats_mean_std', ALL_RESULTS['D1a_stats_mean_std'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-26"
  },
  {
   "cell_type": "code",
   "source": "# D1b: Statistical Pooling (mean + std + min + max)\nif should_run_experiment('D1b_stats_full', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_stats_full_model(cfg):\n        return StatsPoolingModel(\n            input_dim=1024,\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling_stats='mean_std_min_max',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D1b_stats_full'] = run_4fold_mert_experiment(\n        'D1b_stats_full', 'MERT + stats pooling (mean+std+min+max)',\n        make_stats_full_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D1b_stats_full', ALL_RESULTS['D1b_stats_full'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-27"
  },
  {
   "cell_type": "code",
   "source": "# D2a: Uncertainty-Weighted Loss (mean pooling)\nif should_run_experiment('D2a_uncertainty_mean', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_uncertainty_model(cfg):\n        return UncertaintyWeightedModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling='mean',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D2a_uncertainty_mean'] = run_4fold_mert_experiment(\n        'D2a_uncertainty_mean', 'MERT + uncertainty-weighted loss (mean pool)',\n        make_uncertainty_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D2a_uncertainty_mean', ALL_RESULTS['D2a_uncertainty_mean'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-28"
  },
  {
   "cell_type": "code",
   "source": "# D2b: Uncertainty-Weighted Loss (attention pooling)\nif should_run_experiment('D2b_uncertainty_attn', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_uncertainty_attn_model(cfg):\n        return UncertaintyWeightedModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling='attention',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D2b_uncertainty_attn'] = run_4fold_mert_experiment(\n        'D2b_uncertainty_attn', 'MERT + uncertainty-weighted loss (attention pool)',\n        make_uncertainty_attn_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D2b_uncertainty_attn', ALL_RESULTS['D2b_uncertainty_attn'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-29"
  },
  {
   "cell_type": "code",
   "source": "# D3: Dimension-Specific Heads (BiLSTM for timing, MLP for rest)\nif should_run_experiment('D3_dimension_heads', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_dimension_heads_model(cfg):\n        return DimensionSpecificModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            lstm_hidden=256,\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D3_dimension_heads'] = run_4fold_mert_experiment(\n        'D3_dimension_heads', 'MERT + dimension-specific heads (BiLSTM timing, MLP rest)',\n        make_dimension_heads_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D3_dimension_heads', ALL_RESULTS['D3_dimension_heads'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-30"
  },
  {
   "cell_type": "code",
   "source": "# D4: Multi-Layer MERT Concat [6, 9, 12]\nif should_run_experiment('D4_multilayer_6_9_12', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    multilayer_cache = MERT_CACHE_ROOT / 'L6-9-12-concat'\n    extract_mert_multilayer_concat([6, 9, 12], AUDIO_DIR, multilayer_cache, ALL_KEYS)\n\n    cfg = BASE_CONFIG.copy()\n    cfg['input_dim'] = 1024 * 3  # 3 layers concatenated = 3072\n\n    def make_multilayer_model(cfg=cfg):\n        return MultiLayerMERTModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling='attention',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D4_multilayer_6_9_12'] = run_4fold_mert_experiment(\n        'D4_multilayer_6_9_12', 'MERT concat layers [6,9,12] + attention pool',\n        make_multilayer_model, multilayer_cache, LABELS, FOLD_ASSIGNMENTS,\n        cfg, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D4_multilayer_6_9_12', ALL_RESULTS['D4_multilayer_6_9_12'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-31"
  },
  {
   "cell_type": "code",
   "source": "# D5: Transformer Pooling (2-layer encoder before attention pool)\nif should_run_experiment('D5_transformer_pool', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_transformer_model(cfg):\n        return TransformerPoolingModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            num_heads=8,\n            num_layers=2,\n            pooling='attention',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D5_transformer_pool'] = run_4fold_mert_experiment(\n        'D5_transformer_pool', 'MERT + 2-layer transformer + attention pool',\n        make_transformer_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D5_transformer_pool', ALL_RESULTS['D5_transformer_pool'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-32"
  },
  {
   "cell_type": "code",
   "source": "# D6: Multi-Scale Temporal Pooling\nif should_run_experiment('D6_multiscale_pool', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE3_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_multiscale_model(cfg):\n        return MultiScalePoolingModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            scales=(4, 8, 16, 32),\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D6_multiscale_pool'] = run_4fold_mert_experiment(\n        'D6_multiscale_pool', 'MERT + multi-scale pooling (4,8,16,32 frames)',\n        make_multiscale_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D6_multiscale_pool', ALL_RESULTS['D6_multiscale_pool'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-33"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Phase 3 Results Summary",
   "metadata": {},
   "id": "cell-34"
  },
  {
   "cell_type": "code",
   "source": "# Phase 3 Results Summary\nprint(\"=\"*80)\nprint(\"PHASE 3 RESULTS SUMMARY\")\nprint(\"=\"*80)\n\n# Get Phase 2 baseline for comparison\nbaseline_r2 = ALL_RESULTS.get('B0_baseline', {}).get('summary', {}).get('avg_r2', 0)\nbest_phase2 = max(\n    ALL_RESULTS.get('B1b_layers_7-12', {}).get('summary', {}).get('avg_r2', 0),\n    ALL_RESULTS.get('B2b_attention_pool', {}).get('summary', {}).get('avg_r2', 0),\n    baseline_r2\n)\n\nprint(f\"\\nPhase 2 Baseline (B0): {baseline_r2:.4f}\")\nprint(f\"Best Phase 2: {best_phase2:.4f}\")\nprint()\n\nprint(f\"{'Experiment':<25} {'Avg R2':>10} {'95% CI':>20} {'vs Best P2':>12}\")\nprint(\"-\"*75)\n\nfor exp_id in PHASE3_EXPERIMENT_IDS:\n    if exp_id not in ALL_RESULTS:\n        result_file = RESULTS_DIR / f'{exp_id}.json'\n        if result_file.exists():\n            with open(result_file) as f:\n                ALL_RESULTS[exp_id] = json.load(f)\n        else:\n            continue\n\n    r = ALL_RESULTS[exp_id]\n    s = r['summary']\n    ci = s.get('r2_ci_95', [0, 0])\n    diff = s['avg_r2'] - best_phase2\n    print(f\"{exp_id:<25} {s['avg_r2']:>10.4f} [{ci[0]:.3f}, {ci[1]:.3f}] {diff:>+12.4f}\")\n\nprint(\"=\"*75)\n\n# Find best Phase 3 experiment\nphase3_results = [(ALL_RESULTS.get(exp_id, {}).get('summary', {}).get('avg_r2', 0), exp_id)\n                  for exp_id in PHASE3_EXPERIMENT_IDS if exp_id in ALL_RESULTS]\nif phase3_results:\n    best_p3 = max(phase3_results)\n    print(f\"\\nBest Phase 3: {best_p3[1]} (R2={best_p3[0]:.4f})\")\n    print(f\"Improvement over Phase 2: {best_p3[0] - best_phase2:+.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-35"
  },
  {
   "cell_type": "code",
   "source": "# Per-Dimension Analysis for Best Phase 3 Model\nfrom audio_experiments import DIMENSION_CATEGORIES\n\nphase3_results = [(ALL_RESULTS.get(exp_id, {}).get('summary', {}).get('avg_r2', 0), exp_id)\n                  for exp_id in PHASE3_EXPERIMENT_IDS if exp_id in ALL_RESULTS]\n\nif phase3_results:\n    best_p3 = max(phase3_results)\n    best_exp = ALL_RESULTS[best_p3[1]]\n    per_dim = best_exp.get('per_dimension', {})\n\n    print(f\"\\nPer-Dimension R2 for {best_p3[1]}\")\n    print(\"-\"*50)\n\n    for category, dims in DIMENSION_CATEGORIES.items():\n        cat_r2s = [per_dim.get(d, {}).get('r2', 0) for d in dims]\n        cat_avg = np.mean(cat_r2s) if cat_r2s else 0\n        print(f\"\\n{category.upper()} (avg: {cat_avg:.3f})\")\n        for dim in dims:\n            r2 = per_dim.get(dim, {}).get('r2', 0)\n            print(f\"  {dim:<25} {r2:.4f}\")\n\n    print(\"\\n\" + \"=\"*50)\n    print(\"TIMING DIMENSIONS (key target for improvement)\")\n    print(\"=\"*50)\n    timing_r2 = per_dim.get('timing', {}).get('r2', 0)\n    tempo_r2 = per_dim.get('tempo', {}).get('r2', 0)\n    print(f\"timing: {timing_r2:.4f}\")\n    print(f\"tempo:  {tempo_r2:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-36"
  },
  {
   "cell_type": "code",
   "source": "# Final sync all results (Phase 2 + Phase 3)\nall_results_combined = {}\nfor exp_id in ALL_EXPERIMENT_IDS:\n    if exp_id in ALL_RESULTS:\n        all_results_combined[exp_id] = ALL_RESULTS[exp_id]\n\nwith open(RESULTS_DIR / 'all_results_combined.json', 'w') as f:\n    json.dump(all_results_combined, f, indent=2)\n\nprint(\"Final sync to Google Drive...\")\nrun_rclone(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS], \"Syncing results\")\nrun_rclone(['rclone', 'copy', str(CHECKPOINT_ROOT), f\"{GDRIVE_RESULTS}/checkpoints\"], \"Syncing checkpoints\")\n\nprint_experiment_status(ALL_EXPERIMENT_IDS, {k: v['summary']['avg_r2'] for k, v in ALL_RESULTS.items() if 'summary' in v})\nprint(\"\\nDone! Results at:\", GDRIVE_RESULTS)",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-37"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Phase 3.5: MuQ Experiments\n\nMuQ (Music Understanding Quantized) is an alternative music representation model from ByteDance/OpenMuQ.\nSimilar to MERT but trained with different objectives, potentially capturing complementary features.\n\n- **D7**: MuQ baseline (mean pooling)\n- **D8**: MuQ with stats pooling (mean+std)\n- **D9**: MERT+MuQ ensemble (average predictions)\n- **D9b**: MERT+MuQ early fusion (concatenate embeddings)\n\nExpected gains: R2 += 0.03-0.05 from ensemble/fusion.",
   "metadata": {},
   "id": "cell-38"
  },
  {
   "cell_type": "code",
   "source": "# MuQ imports and setup\nfrom audio_experiments.extractors import MuQExtractor, extract_muq_embeddings\nfrom audio_experiments.models import MuQBaseModel, MuQStatsModel, MERTMuQEnsemble, MERTMuQConcatModel, AsymmetricGatedFusion\n\n# MuQ cache directory\nMUQ_CACHE_DIR = DATA_ROOT / 'muq_cache'\nMUQ_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n\n# Phase 3.5 experiment IDs\nPHASE35_EXPERIMENT_IDS = [\n    'D7_muq_baseline',\n    'D8_muq_stats',\n    'D9_mert_muq_ensemble',\n    'D9b_mert_muq_concat',\n    'D9c_asymmetric_gated_fusion',\n]\n\nALL_EXPERIMENT_IDS.extend(PHASE35_EXPERIMENT_IDS)\nPHASE35_COMPLETED = get_completed_experiments(GDRIVE_RESULTS)\nprint_experiment_status(PHASE35_EXPERIMENT_IDS, PHASE35_COMPLETED)",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-39"
  },
  {
   "cell_type": "code",
   "source": "# D7: MuQ Baseline (mean pooling)\nif should_run_experiment('D7_muq_baseline', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE35_COMPLETED):\n    # Extract MuQ embeddings (using last hidden state)\n    extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE_DIR, ALL_KEYS)\n\n    def make_muq_baseline(cfg):\n        return MuQBaseModel(\n            input_dim=1024,  # MuQ hidden size\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling='mean',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D7_muq_baseline'] = run_4fold_mert_experiment(\n        'D7_muq_baseline', 'MuQ baseline with mean pooling',\n        make_muq_baseline, MUQ_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D7_muq_baseline', ALL_RESULTS['D7_muq_baseline'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-40"
  },
  {
   "cell_type": "code",
   "source": "# D8: MuQ with Stats Pooling (mean + std)\nif should_run_experiment('D8_muq_stats', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE35_COMPLETED):\n    # Ensure MuQ embeddings exist\n    extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE_DIR, ALL_KEYS)\n\n    def make_muq_stats(cfg):\n        return MuQStatsModel(\n            input_dim=1024,\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling_stats='mean_std',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D8_muq_stats'] = run_4fold_mert_experiment(\n        'D8_muq_stats', 'MuQ with stats pooling (mean+std)',\n        make_muq_stats, MUQ_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D8_muq_stats', ALL_RESULTS['D8_muq_stats'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-41"
  },
  {
   "cell_type": "code",
   "source": "# D9: MERT+MuQ Ensemble (late fusion - average predictions)\n# Note: This requires a custom training loop since we need both MERT and MuQ embeddings\n\nif should_run_experiment('D9_mert_muq_ensemble', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE35_COMPLETED):\n    from audio_experiments.data import DualEmbeddingDataset, dual_collate_fn\n    from torch.utils.data import DataLoader\n    \n    # Ensure both embeddings exist\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n    extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE_DIR, ALL_KEYS)\n    \n    def run_ensemble_experiment():\n        from sklearn.metrics import r2_score\n        import numpy as np\n        \n        all_preds, all_labels = [], []\n        fold_metrics = []\n        \n        for fold in range(4):\n            print(f\"\\nFold {fold + 1}/4\")\n            val_keys = [k for k, f in FOLD_BY_KEY.items() if f == fold]\n            train_keys = [k for k, f in FOLD_BY_KEY.items() if f != fold]\n            \n            # Create dual-embedding datasets\n            train_ds = DualEmbeddingDataset(\n                DEFAULT_MERT_DIR, MUQ_CACHE_DIR, LABELS, train_keys,\n                max_frames=BASE_CONFIG['max_frames']\n            )\n            val_ds = DualEmbeddingDataset(\n                DEFAULT_MERT_DIR, MUQ_CACHE_DIR, LABELS, val_keys,\n                max_frames=BASE_CONFIG['max_frames']\n            )\n            \n            train_dl = DataLoader(\n                train_ds, batch_size=BASE_CONFIG['batch_size'],\n                shuffle=True, num_workers=2, collate_fn=dual_collate_fn\n            )\n            val_dl = DataLoader(\n                val_ds, batch_size=BASE_CONFIG['batch_size'],\n                shuffle=False, num_workers=2, collate_fn=dual_collate_fn\n            )\n            \n            # Create model\n            model = MERTMuQEnsemble(\n                input_dim=1024,\n                hidden_dim=BASE_CONFIG['hidden_dim'],\n                dropout=BASE_CONFIG['dropout'],\n                learning_rate=BASE_CONFIG['learning_rate'],\n                weight_decay=BASE_CONFIG['weight_decay'],\n                pooling='attention',\n                fusion_weight=0.5,\n                max_epochs=BASE_CONFIG['max_epochs'],\n            )\n            \n            # Setup trainer\n            ckpt_dir = CHECKPOINT_ROOT / 'D9_mert_muq_ensemble' / f'fold{fold}'\n            ckpt_dir.mkdir(parents=True, exist_ok=True)\n            \n            trainer = pl.Trainer(\n                max_epochs=BASE_CONFIG['max_epochs'],\n                callbacks=[\n                    pl.callbacks.ModelCheckpoint(\n                        dirpath=ckpt_dir, filename='best',\n                        monitor='val_r2', mode='max', save_top_k=1\n                    ),\n                    pl.callbacks.EarlyStopping(\n                        monitor='val_r2', mode='max',\n                        patience=BASE_CONFIG['patience']\n                    ),\n                ],\n                logger=pl.loggers.CSVLogger(LOG_DIR, name='D9_mert_muq_ensemble', version=f'fold{fold}'),\n                accelerator='auto', devices=1,\n                gradient_clip_val=BASE_CONFIG['gradient_clip_val'],\n                enable_progress_bar=True, deterministic=True,\n            )\n            \n            trainer.fit(model, train_dl, val_dl)\n            \n            # Load best and evaluate\n            best_path = list(ckpt_dir.glob('best*.ckpt'))[0]\n            model = MERTMuQEnsemble.load_from_checkpoint(best_path)\n            model.eval()\n            \n            preds, labels = [], []\n            for batch in val_dl:\n                batch = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n                with torch.no_grad():\n                    pred = model(\n                        batch['mert_embeddings'], batch['muq_embeddings'],\n                        batch.get('mert_mask'), batch.get('muq_mask')\n                    )\n                preds.append(pred.cpu())\n                labels.append(batch['labels'].cpu())\n            \n            preds = torch.cat(preds).numpy()\n            labels = torch.cat(labels).numpy()\n            fold_r2 = r2_score(labels, preds)\n            \n            print(f\"Fold {fold + 1} R2: {fold_r2:.4f}\")\n            fold_metrics.append({'fold': fold, 'r2': fold_r2})\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n        \n        all_preds = np.array(all_preds)\n        all_labels = np.array(all_labels)\n        avg_r2 = r2_score(all_labels, all_preds)\n        \n        return {\n            'summary': {\n                'avg_r2': avg_r2,\n                'fold_r2s': [m['r2'] for m in fold_metrics],\n            },\n            'description': 'MERT+MuQ late fusion ensemble',\n        }\n    \n    ALL_RESULTS['D9_mert_muq_ensemble'] = run_ensemble_experiment()\n    # Save results to disk before sync\n    with open(RESULTS_DIR / 'D9_mert_muq_ensemble.json', 'w') as f:\n        json.dump(ALL_RESULTS['D9_mert_muq_ensemble'], f, indent=2)\n    sync_experiment_to_gdrive(\n        'D9_mert_muq_ensemble', ALL_RESULTS['D9_mert_muq_ensemble'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-42"
  },
  {
   "cell_type": "code",
   "source": "# D9b: MERT+MuQ Early Fusion (concatenate embeddings before prediction)\n# Uses best MERT layers (7-12) concatenated with MuQ embeddings\nif should_run_experiment('D9b_mert_muq_concat', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE35_COMPLETED):\n    from audio_experiments.data import DualEmbeddingDataset, dual_collate_fn\n    from torch.utils.data import DataLoader\n    \n    # Use L7-12 MERT cache (best performing layers)\n    MERT_L7_12_CACHE = MERT_CACHE_ROOT / 'L7-12'\n    MERT_L7_12_CACHE.mkdir(parents=True, exist_ok=True)\n    \n    # Ensure both embeddings exist\n    extract_mert_for_layer_range(7, 13, AUDIO_DIR, MERT_L7_12_CACHE, ALL_KEYS)\n    extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE_DIR, ALL_KEYS)\n    \n    def run_concat_experiment():\n        from sklearn.metrics import r2_score\n        import numpy as np\n        \n        all_preds, all_labels = [], []\n        fold_metrics = []\n        \n        for fold in range(4):\n            print(f\"\\nFold {fold + 1}/4\")\n            val_keys = [k for k, f in FOLD_BY_KEY.items() if f == fold]\n            train_keys = [k for k, f in FOLD_BY_KEY.items() if f != fold]\n            \n            train_ds = DualEmbeddingDataset(\n                MERT_L7_12_CACHE, MUQ_CACHE_DIR, LABELS, train_keys,\n                max_frames=BASE_CONFIG['max_frames']\n            )\n            val_ds = DualEmbeddingDataset(\n                MERT_L7_12_CACHE, MUQ_CACHE_DIR, LABELS, val_keys,\n                max_frames=BASE_CONFIG['max_frames']\n            )\n            \n            train_dl = DataLoader(train_ds, batch_size=BASE_CONFIG['batch_size'],\n                                  shuffle=True, num_workers=2, collate_fn=dual_collate_fn)\n            val_dl = DataLoader(val_ds, batch_size=BASE_CONFIG['batch_size'],\n                                shuffle=False, num_workers=2, collate_fn=dual_collate_fn)\n            \n            # Early fusion: concatenate MERT L7-12 (6144-dim) + MuQ (1024-dim)\n            model = MERTMuQConcatModel(\n                mert_dim=1024,  # Layers are averaged, not concatenated\n                muq_dim=1024,\n                hidden_dim=BASE_CONFIG['hidden_dim'],\n                dropout=BASE_CONFIG['dropout'],\n                learning_rate=BASE_CONFIG['learning_rate'],\n                weight_decay=BASE_CONFIG['weight_decay'],\n                pooling='attention',\n                max_epochs=BASE_CONFIG['max_epochs'],\n            )\n            \n            ckpt_dir = CHECKPOINT_ROOT / 'D9b_mert_muq_concat' / f'fold{fold}'\n            ckpt_dir.mkdir(parents=True, exist_ok=True)\n            \n            trainer = pl.Trainer(\n                max_epochs=BASE_CONFIG['max_epochs'],\n                callbacks=[\n                    pl.callbacks.ModelCheckpoint(dirpath=ckpt_dir, filename='best',\n                                                 monitor='val_r2', mode='max', save_top_k=1),\n                    pl.callbacks.EarlyStopping(monitor='val_r2', mode='max',\n                                               patience=BASE_CONFIG['patience']),\n                ],\n                logger=pl.loggers.CSVLogger(LOG_DIR, name='D9b_mert_muq_concat', version=f'fold{fold}'),\n                accelerator='auto', devices=1,\n                gradient_clip_val=BASE_CONFIG['gradient_clip_val'],\n                enable_progress_bar=True, deterministic=True,\n            )\n            \n            trainer.fit(model, train_dl, val_dl)\n            \n            best_path = list(ckpt_dir.glob('best*.ckpt'))[0]\n            model = MERTMuQConcatModel.load_from_checkpoint(best_path)\n            model.eval()\n            \n            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n            model = model.to(device)\n            \n            preds, labels_list = [], []\n            for batch in val_dl:\n                batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n                with torch.no_grad():\n                    pred = model(batch['mert_embeddings'], batch['muq_embeddings'],\n                                 batch.get('mert_mask'), batch.get('muq_mask'))\n                preds.append(pred.cpu())\n                labels_list.append(batch['labels'].cpu())\n            \n            preds = torch.cat(preds).numpy()\n            labels_arr = torch.cat(labels_list).numpy()\n            fold_r2 = r2_score(labels_arr, preds)\n            \n            print(f\"Fold {fold + 1} R2: {fold_r2:.4f}\")\n            fold_metrics.append({'fold': fold, 'r2': fold_r2})\n            all_preds.extend(preds)\n            all_labels.extend(labels_arr)\n        \n        all_preds = np.array(all_preds)\n        all_labels = np.array(all_labels)\n        avg_r2 = r2_score(all_labels, all_preds)\n        \n        return {\n            'summary': {'avg_r2': float(avg_r2), 'fold_r2s': [m['r2'] for m in fold_metrics]},\n            'description': 'MERT L7-12 + MuQ early fusion (concat embeddings)',\n        }\n    \n    ALL_RESULTS['D9b_mert_muq_concat'] = run_concat_experiment()\n    # Save results to disk before sync\n    with open(RESULTS_DIR / 'D9b_mert_muq_concat.json', 'w') as f:\n        json.dump(ALL_RESULTS['D9b_mert_muq_concat'], f, indent=2)\n    sync_experiment_to_gdrive(\n        'D9b_mert_muq_concat', ALL_RESULTS['D9b_mert_muq_concat'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-43"
  },
  {
   "cell_type": "code",
   "source": "# D9c: Asymmetric Gated Fusion (per-dimension gating with asymmetric projections)\n# Uses 2-stage MERT projection (1024->512->512) with per-dim gating and learns per-dimension gates\n\nif should_run_experiment('D9c_asymmetric_gated_fusion', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE35_COMPLETED):\n    from audio_experiments.data import DualEmbeddingDataset, dual_collate_fn\n    from torch.utils.data import DataLoader\n    \n    # Use L7-12 MERT cache (best performing layers)\n    MERT_L7_12_CACHE = MERT_CACHE_ROOT / 'L7-12'\n    MERT_L7_12_CACHE.mkdir(parents=True, exist_ok=True)\n    \n    # Ensure both embeddings exist\n    extract_mert_for_layer_range(7, 13, AUDIO_DIR, MERT_L7_12_CACHE, ALL_KEYS)\n    extract_muq_embeddings(AUDIO_DIR, MUQ_CACHE_DIR, ALL_KEYS)\n    \n    def run_asymmetric_gated_experiment():\n        from sklearn.metrics import r2_score\n        import numpy as np\n        \n        all_preds, all_labels = [], []\n        fold_metrics = []\n        learned_gates = []\n        \n        for fold in range(4):\n            print(f\"\\nFold {fold + 1}/4\")\n            val_keys = [k for k, f in FOLD_BY_KEY.items() if f == fold]\n            train_keys = [k for k, f in FOLD_BY_KEY.items() if f != fold]\n            \n            train_ds = DualEmbeddingDataset(\n                MERT_L7_12_CACHE, MUQ_CACHE_DIR, LABELS, train_keys,\n                max_frames=BASE_CONFIG['max_frames']\n            )\n            val_ds = DualEmbeddingDataset(\n                MERT_L7_12_CACHE, MUQ_CACHE_DIR, LABELS, val_keys,\n                max_frames=BASE_CONFIG['max_frames']\n            )\n            \n            train_dl = DataLoader(train_ds, batch_size=BASE_CONFIG['batch_size'],\n                                  shuffle=True, num_workers=2, collate_fn=dual_collate_fn)\n            val_dl = DataLoader(val_ds, batch_size=BASE_CONFIG['batch_size'],\n                                shuffle=False, num_workers=2, collate_fn=dual_collate_fn)\n            \n            # Asymmetric gated fusion with per-dimension routing\n            model = AsymmetricGatedFusion(\n                mert_dim=1024,  # Layers are averaged, not concatenated\n                muq_dim=1024,\n                mert_hidden=512,    # Intermediate projection for MERT\n                shared_dim=512,     # Final shared dimension\n                num_labels=19,\n                dropout=BASE_CONFIG['dropout'],\n                learning_rate=BASE_CONFIG['learning_rate'],\n                weight_decay=BASE_CONFIG['weight_decay'],\n                pooling='attention',\n                max_epochs=BASE_CONFIG['max_epochs'],\n            )\n            \n            ckpt_dir = CHECKPOINT_ROOT / 'D9c_asymmetric_gated_fusion' / f'fold{fold}'\n            ckpt_dir.mkdir(parents=True, exist_ok=True)\n            \n            trainer = pl.Trainer(\n                max_epochs=BASE_CONFIG['max_epochs'],\n                callbacks=[\n                    pl.callbacks.ModelCheckpoint(dirpath=ckpt_dir, filename='best',\n                                                 monitor='val_r2', mode='max', save_top_k=1),\n                    pl.callbacks.EarlyStopping(monitor='val_r2', mode='max',\n                                               patience=BASE_CONFIG['patience']),\n                ],\n                logger=pl.loggers.CSVLogger(LOG_DIR, name='D9c_asymmetric_gated_fusion', version=f'fold{fold}'),\n                accelerator='auto', devices=1,\n                gradient_clip_val=BASE_CONFIG['gradient_clip_val'],\n                enable_progress_bar=True, deterministic=True,\n            )\n            \n            trainer.fit(model, train_dl, val_dl)\n            \n            best_path = list(ckpt_dir.glob('best*.ckpt'))[0]\n            model = AsymmetricGatedFusion.load_from_checkpoint(best_path)\n            model.eval()\n            \n            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n            model = model.to(device)\n            \n            preds, labels_list = [], []\n            for batch in val_dl:\n                batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n                with torch.no_grad():\n                    pred = model(batch['mert_embeddings'], batch['muq_embeddings'],\n                                 batch.get('mert_mask'), batch.get('muq_mask'))\n                preds.append(pred.cpu())\n                labels_list.append(batch['labels'].cpu())\n            \n            preds = torch.cat(preds).numpy()\n            labels_arr = torch.cat(labels_list).numpy()\n            fold_r2 = r2_score(labels_arr, preds)\n            \n            # Collect learned gate values for interpretability\n            sample_batch = next(iter(val_dl))\n            sample_batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in sample_batch.items()}\n            gate_info = model.get_learned_gates(\n                sample_batch['mert_embeddings'], sample_batch['muq_embeddings'],\n                sample_batch.get('mert_mask'), sample_batch.get('muq_mask')\n            )\n            learned_gates.append(gate_info['mert_weight_per_dim'])\n            \n            print(f\"Fold {fold + 1} R2: {fold_r2:.4f}\")\n            fold_metrics.append({'fold': fold, 'r2': fold_r2})\n            all_preds.extend(preds)\n            all_labels.extend(labels_arr)\n        \n        all_preds = np.array(all_preds)\n        all_labels = np.array(all_labels)\n        avg_r2 = r2_score(all_labels, all_preds)\n        \n        # Average gate weights across folds\n        avg_gates = np.mean(learned_gates, axis=0)\n        \n        return {\n            'summary': {'avg_r2': float(avg_r2), 'fold_r2s': [m['r2'] for m in fold_metrics]},\n            'description': 'Asymmetric gated fusion (MERT 6144->768->512, MuQ 1024->512, per-dim gates)',\n            'gate_weights': {\n                'mert_weight_per_dim': avg_gates.tolist(),\n                'interpretation': 'Higher values = more MERT influence for that dimension'\n            }\n        }\n    \n    ALL_RESULTS['D9c_asymmetric_gated_fusion'] = run_asymmetric_gated_experiment()\n    # Save results to disk before sync\n    with open(RESULTS_DIR / 'D9c_asymmetric_gated_fusion.json', 'w') as f:\n        json.dump(ALL_RESULTS['D9c_asymmetric_gated_fusion'], f, indent=2)\n    sync_experiment_to_gdrive(\n        'D9c_asymmetric_gated_fusion', ALL_RESULTS['D9c_asymmetric_gated_fusion'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-43b"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Phase 3.6: Contrastive Auxiliary Loss Experiments\n\nAdds a contrastive learning objective as auxiliary loss during training. \nThe idea is to learn representations where performances with similar ratings are closer together in embedding space.\n\n- **D10a**: Contrastive with lambda=0.05 (light regularization)\n- **D10b**: Contrastive with lambda=0.1 (moderate regularization)\n- **D10c**: Contrastive with lambda=0.2 (strong regularization)\n- **D10d**: Contrastive warmup (lambda decays from 0.5 to 0.05)\n\nExpected gains: R2 += 0.02-0.04 from improved representation structure.",
   "metadata": {},
   "id": "cell-44"
  },
  {
   "cell_type": "code",
   "source": "# Contrastive model imports and setup\nfrom audio_experiments.models import ContrastiveAuxiliaryModel, ContrastiveWarmupModel\n\n# Phase 3.6 experiment IDs\nPHASE36_EXPERIMENT_IDS = [\n    'D10a_contrastive_0.05',\n    'D10b_contrastive_0.1',\n    'D10c_contrastive_0.2',\n    'D10d_contrastive_warmup',\n]\n\nALL_EXPERIMENT_IDS.extend(PHASE36_EXPERIMENT_IDS)\nPHASE36_COMPLETED = get_completed_experiments(GDRIVE_RESULTS)\nprint_experiment_status(PHASE36_EXPERIMENT_IDS, PHASE36_COMPLETED)",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-45"
  },
  {
   "cell_type": "code",
   "source": "# D10a: Contrastive Auxiliary Loss (lambda=0.05)\nif should_run_experiment('D10a_contrastive_0.05', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE36_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_contrastive_model_005(cfg):\n        return ContrastiveAuxiliaryModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            contrastive_lambda=0.05,\n            temperature=0.07,\n            pooling='attention',\n            contrastive_type='supervised',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D10a_contrastive_0.05'] = run_4fold_mert_experiment(\n        'D10a_contrastive_0.05', 'MERT + contrastive auxiliary loss (lambda=0.05)',\n        make_contrastive_model_005, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D10a_contrastive_0.05', ALL_RESULTS['D10a_contrastive_0.05'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-46"
  },
  {
   "cell_type": "code",
   "source": "# D10b: Contrastive Auxiliary Loss (lambda=0.1)\nif should_run_experiment('D10b_contrastive_0.1', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE36_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_contrastive_model_01(cfg):\n        return ContrastiveAuxiliaryModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            contrastive_lambda=0.1,\n            temperature=0.07,\n            pooling='attention',\n            contrastive_type='supervised',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D10b_contrastive_0.1'] = run_4fold_mert_experiment(\n        'D10b_contrastive_0.1', 'MERT + contrastive auxiliary loss (lambda=0.1)',\n        make_contrastive_model_01, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D10b_contrastive_0.1', ALL_RESULTS['D10b_contrastive_0.1'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-47"
  },
  {
   "cell_type": "code",
   "source": "# D10c: Contrastive Auxiliary Loss (lambda=0.2)\nif should_run_experiment('D10c_contrastive_0.2', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE36_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_contrastive_model_02(cfg):\n        return ContrastiveAuxiliaryModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            contrastive_lambda=0.2,\n            temperature=0.07,\n            pooling='attention',\n            contrastive_type='supervised',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D10c_contrastive_0.2'] = run_4fold_mert_experiment(\n        'D10c_contrastive_0.2', 'MERT + contrastive auxiliary loss (lambda=0.2)',\n        make_contrastive_model_02, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D10c_contrastive_0.2', ALL_RESULTS['D10c_contrastive_0.2'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-48"
  },
  {
   "cell_type": "code",
   "source": "# D10d: Contrastive Warmup (lambda decays from 0.5 to 0.05)\nif should_run_experiment('D10d_contrastive_warmup', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE36_COMPLETED):\n    extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n\n    def make_contrastive_warmup_model(cfg):\n        return ContrastiveWarmupModel(\n            input_dim=cfg['input_dim'],\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            contrastive_lambda_start=0.5,\n            contrastive_lambda_end=0.05,\n            temperature=0.07,\n            pooling='attention',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['D10d_contrastive_warmup'] = run_4fold_mert_experiment(\n        'D10d_contrastive_warmup', 'MERT + contrastive warmup (0.5 -> 0.05)',\n        make_contrastive_warmup_model, DEFAULT_MERT_DIR, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'D10d_contrastive_warmup', ALL_RESULTS['D10d_contrastive_warmup'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-49"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Phase 3.5 + 3.6 Results Summary",
   "metadata": {},
   "id": "cell-50"
  },
  {
   "cell_type": "code",
   "source": "# Comprehensive Results Summary\nprint(\"=\"*80)\nprint(\"COMPREHENSIVE AUDIO MODEL RESULTS\")\nprint(\"=\"*80)\n\n# Collect all results\nall_exp_results = []\nfor exp_id in ALL_EXPERIMENT_IDS:\n    if exp_id in ALL_RESULTS and 'summary' in ALL_RESULTS[exp_id]:\n        r2 = ALL_RESULTS[exp_id]['summary'].get('avg_r2', 0)\n        all_exp_results.append((r2, exp_id))\n\n# Sort by R2\nall_exp_results.sort(reverse=True)\n\n# Get PercePiano baseline for comparison\nPERCEPIANO_R2 = 0.397  # Original paper SOTA\n\nprint(f\"\\n{'Rank':<6} {'Experiment':<30} {'R2':>10} {'vs PercePiano':>15}\")\nprint(\"-\"*65)\n\nfor i, (r2, exp_id) in enumerate(all_exp_results[:15], 1):\n    diff = r2 - PERCEPIANO_R2\n    marker = \" ***\" if r2 > 0.50 else (\" **\" if r2 > 0.48 else (\" *\" if r2 > PERCEPIANO_R2 else \"\"))\n    print(f\"{i:<6} {exp_id:<30} {r2:>10.4f} {diff:>+15.4f}{marker}\")\n\nprint(\"-\"*65)\nprint(\"Legend: *** = R2 > 0.50, ** = R2 > 0.48, * = beats PercePiano SOTA\")\n\n# Best model summary\nif all_exp_results:\n    best_r2, best_exp = all_exp_results[0]\n    print(f\"\\n{'='*65}\")\n    print(\"BEST MODEL\")\n    print(f\"{'='*65}\")\n    print(f\"Experiment: {best_exp}\")\n    print(f\"R2: {best_r2:.4f}\")\n    print(f\"Improvement over PercePiano SOTA: +{best_r2 - PERCEPIANO_R2:.4f} ({(best_r2 - PERCEPIANO_R2) / PERCEPIANO_R2 * 100:.1f}%)\")\n\n# Layer efficiency analysis\nprint(f\"\\n{'='*65}\")\nprint(\"LAYER EFFICIENCY ANALYSIS\")\nprint(f\"{'='*65}\")\nlayer_exps = [\n    ('B1a_layers_1-6', 'L1-6', 6),\n    ('B1b_layers_7-12', 'L7-12', 6),\n    ('B1c_layers_13-24', 'L13-24', 12),\n    ('B1d_layers_1-24', 'L1-24', 24),\n    ('E1a_layer_9_only', 'L9 only', 1),\n    ('E1b_layer_12_only', 'L12 only', 1),\n    ('E1c_layers_10-12', 'L10-12', 3),\n]\n\nprint(f\"\\n{'Config':<15} {'Layers':>8} {'R2':>10} {'R2/Layer':>12}\")\nprint(\"-\"*50)\nfor exp_id, name, n_layers in layer_exps:\n    if exp_id in ALL_RESULTS and 'summary' in ALL_RESULTS[exp_id]:\n        r2 = ALL_RESULTS[exp_id]['summary']['avg_r2']\n        efficiency = r2 / n_layers\n        print(f\"{name:<15} {n_layers:>8} {r2:>10.4f} {efficiency:>12.4f}\")\n\n# Recommendations\nprint(f\"\\n{'='*65}\")\nprint(\"RECOMMENDATIONS\")\nprint(f\"{'='*65}\")\nprint(\"\"\"\nFOR THE PAPER:\n1. Lead with audio SOTA: MERT L7-12 achieves R2=0.487, beating\n   PercePiano's symbolic SOTA (0.397) by 23%\n2. Audio wins on 18/19 dimensions after multiple correction\n3. Fusion adds only +2.5% due to high error correlation (r=0.76)\n\nFOR THE PRODUCT:\n1. Use MERT L7-12 or best single layer for production\n2. Single layer (E1a/E1b) may offer 80%+ of performance at 6x speed\n3. Real-time factor should be < 0.1x for responsive feedback\n\"\"\")\n\n# Final sync\nwith open(RESULTS_DIR / 'comprehensive_results.json', 'w') as f:\n    json.dump({\n        'all_experiments': {exp_id: ALL_RESULTS.get(exp_id, {}).get('summary', {}) \n                           for exp_id in ALL_EXPERIMENT_IDS if exp_id in ALL_RESULTS},\n        'best_model': {'exp_id': best_exp, 'r2': best_r2} if all_exp_results else None,\n        'percepiano_baseline': PERCEPIANO_R2,\n    }, f, indent=2)\n\nprint(\"\\nSyncing final results to Google Drive...\")\nrun_rclone(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS], \"Syncing results\")\nprint(f\"Done! Results at: {GDRIVE_RESULTS}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-51"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Phase 4: Product-Focused Experiments\n\nExperiments focused on optimizing for production deployment:\n- **E1**: Single best layer test (can we use fewer layers for similar performance?)\n- **E2**: Inference latency benchmark (measure real-world speed)\n- **E3**: Per-dimension audio advantage analysis (which dimensions does audio excel at?)\n\nThese experiments inform product decisions around model size, latency, and feature prioritization.",
   "metadata": {},
   "id": "cell-52"
  },
  {
   "cell_type": "code",
   "source": "# Phase 4 experiment IDs\nPHASE4_EXPERIMENT_IDS = [\n    'E1a_layer_9_only',\n    'E1b_layer_12_only', \n    'E1c_layers_10-12',\n]\n\nALL_EXPERIMENT_IDS.extend(PHASE4_EXPERIMENT_IDS)\nPHASE4_COMPLETED = get_completed_experiments(GDRIVE_RESULTS)\nprint_experiment_status(PHASE4_EXPERIMENT_IDS, PHASE4_COMPLETED)",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-53"
  },
  {
   "cell_type": "code",
   "source": "# E1a: Single Layer 9 (middle of best range)\n# If this matches L7-12 performance, we can 6x reduce extraction time\nif should_run_experiment('E1a_layer_9_only', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE4_COMPLETED):\n    cache_dir = MERT_CACHE_ROOT / 'L9-only'\n    extract_mert_for_layer_range(9, 10, AUDIO_DIR, cache_dir, ALL_KEYS)\n\n    def make_single_layer_model(cfg):\n        return BaseMERTModel(\n            input_dim=1024,  # Single layer = 1024\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling='attention',\n            loss_type='mse',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['E1a_layer_9_only'] = run_4fold_mert_experiment(\n        'E1a_layer_9_only', 'MERT layer 9 only (single layer)',\n        make_single_layer_model, cache_dir, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'E1a_layer_9_only', ALL_RESULTS['E1a_layer_9_only'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-54"
  },
  {
   "cell_type": "code",
   "source": "# E1b: Single Layer 12 (last of best range)\nif should_run_experiment('E1b_layer_12_only', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE4_COMPLETED):\n    cache_dir = MERT_CACHE_ROOT / 'L12-only'\n    extract_mert_for_layer_range(12, 13, AUDIO_DIR, cache_dir, ALL_KEYS)\n\n    def make_single_layer_model(cfg):\n        return BaseMERTModel(\n            input_dim=1024,\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling='attention',\n            loss_type='mse',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    ALL_RESULTS['E1b_layer_12_only'] = run_4fold_mert_experiment(\n        'E1b_layer_12_only', 'MERT layer 12 only (single layer)',\n        make_single_layer_model, cache_dir, LABELS, FOLD_ASSIGNMENTS,\n        BASE_CONFIG, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'E1b_layer_12_only', ALL_RESULTS['E1b_layer_12_only'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-55"
  },
  {
   "cell_type": "code",
   "source": "# E1c: Layers 10-12 (compact version of L7-12)\n# Tests if we can use half the layers for similar performance\nif should_run_experiment('E1c_layers_10-12', CHECKPOINT_ROOT, RESULTS_DIR, GDRIVE_RESULTS, PHASE4_COMPLETED):\n    cache_dir = MERT_CACHE_ROOT / 'L10-12'\n    extract_mert_for_layer_range(10, 13, AUDIO_DIR, cache_dir, ALL_KEYS)\n\n    def make_compact_model(cfg):\n        return BaseMERTModel(\n            input_dim=1024 * 3,  # 3 layers concatenated\n            hidden_dim=cfg['hidden_dim'],\n            dropout=cfg['dropout'],\n            learning_rate=cfg['learning_rate'],\n            weight_decay=cfg['weight_decay'],\n            pooling='attention',\n            loss_type='mse',\n            max_epochs=cfg['max_epochs'],\n        )\n\n    cfg = BASE_CONFIG.copy()\n    cfg['input_dim'] = 1024 * 3\n\n    ALL_RESULTS['E1c_layers_10-12'] = run_4fold_mert_experiment(\n        'E1c_layers_10-12', 'MERT layers 10-12 (compact)',\n        make_compact_model, cache_dir, LABELS, FOLD_ASSIGNMENTS,\n        cfg, CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR\n    )\n    sync_experiment_to_gdrive(\n        'E1c_layers_10-12', ALL_RESULTS['E1c_layers_10-12'],\n        RESULTS_DIR, CHECKPOINT_ROOT, GDRIVE_RESULTS, ALL_RESULTS\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-56"
  },
  {
   "cell_type": "code",
   "source": [
    "# E2: Inference Latency Benchmark\n",
    "# Measures real-world inference speed for different audio lengths\n",
    "import time\n",
    "\n",
    "def benchmark_inference_latency():\n",
    "    \"\"\"Benchmark MERT extraction + model inference for different audio lengths.\"\"\"\n",
    "    from transformers import Wav2Vec2FeatureExtractor, AutoModel\n",
    "    import librosa\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"E2: INFERENCE LATENCY BENCHMARK\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load MERT model\n",
    "    print(\"\\nLoading MERT model...\")\n",
    "    processor = Wav2Vec2FeatureExtractor.from_pretrained(\"m-a-p/MERT-v1-330M\", trust_remote_code=True)\n",
    "    mert_model = AutoModel.from_pretrained(\"m-a-p/MERT-v1-330M\", trust_remote_code=True)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mert_model = mert_model.to(device).eval()\n",
    "    \n",
    "    # Load a trained prediction head\n",
    "    best_ckpt = None\n",
    "    for exp_id in ['B1b_layers_7-12', 'B0_baseline']:\n",
    "        ckpt_dir = CHECKPOINT_ROOT / exp_id\n",
    "        if ckpt_dir.exists():\n",
    "            ckpts = list(ckpt_dir.glob('fold0*.ckpt'))\n",
    "            if ckpts:\n",
    "                best_ckpt = ckpts[0]\n",
    "                break\n",
    "    \n",
    "    if best_ckpt:\n",
    "        pred_model = BaseMERTModel.load_from_checkpoint(best_ckpt).to(device).eval()\n",
    "        print(f\"Loaded prediction head from {best_ckpt.parent.name}\")\n",
    "    else:\n",
    "        print(\"Warning: No trained model found, benchmarking MERT only\")\n",
    "        pred_model = None\n",
    "    \n",
    "    # Test different audio lengths\n",
    "    test_durations = [10, 30, 60, 120]  # seconds\n",
    "    results = []\n",
    "    \n",
    "    # Get a sample audio file\n",
    "    sample_files = list(AUDIO_DIR.glob('*.wav'))[:1]\n",
    "    if not sample_files:\n",
    "        print(\"No audio files found for benchmarking\")\n",
    "        return {}\n",
    "    \n",
    "    sample_audio, sr = librosa.load(sample_files[0], sr=24000, duration=max(test_durations))\n",
    "    \n",
    "    for duration in test_durations:\n",
    "        n_samples = int(duration * sr)\n",
    "        audio_segment = sample_audio[:min(n_samples, len(sample_audio))]\n",
    "        actual_duration = len(audio_segment) / sr\n",
    "        \n",
    "        # Warmup\n",
    "        with torch.no_grad():\n",
    "            inputs = processor(audio_segment, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            _ = mert_model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # Benchmark MERT extraction\n",
    "        n_runs = 5\n",
    "        mert_times = []\n",
    "        for _ in range(n_runs):\n",
    "            torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "            start = time.perf_counter()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                inputs = processor(audio_segment, sampling_rate=sr, return_tensors=\"pt\")\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                outputs = mert_model(**inputs, output_hidden_states=True)\n",
    "                embeddings = torch.stack(outputs.hidden_states[7:13]).mean(dim=0)\n",
    "            \n",
    "            torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "            mert_times.append(time.perf_counter() - start)\n",
    "        \n",
    "        avg_mert_time = np.mean(mert_times)\n",
    "        \n",
    "        # Benchmark prediction head\n",
    "        pred_time = 0\n",
    "        if pred_model:\n",
    "            pred_times = []\n",
    "            for _ in range(n_runs):\n",
    "                torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "                start = time.perf_counter()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    mask = torch.ones(1, embeddings.shape[1], dtype=torch.bool, device=device)\n",
    "                    _ = pred_model(embeddings, mask)\n",
    "                \n",
    "                torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "                pred_times.append(time.perf_counter() - start)\n",
    "            pred_time = np.mean(pred_times)\n",
    "        \n",
    "        total_time = avg_mert_time + pred_time\n",
    "        rtf = total_time / actual_duration  # Real-time factor\n",
    "        \n",
    "        results.append({\n",
    "            'duration_sec': float(actual_duration),\n",
    "            'mert_extraction_sec': float(avg_mert_time),\n",
    "            'prediction_sec': float(pred_time),\n",
    "            'total_sec': float(total_time),\n",
    "            'real_time_factor': float(rtf),\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{actual_duration:.0f}s audio:\")\n",
    "        print(f\"  MERT extraction: {avg_mert_time*1000:.1f}ms\")\n",
    "        print(f\"  Prediction head: {pred_time*1000:.1f}ms\")\n",
    "        print(f\"  Total: {total_time*1000:.1f}ms (RTF: {rtf:.3f}x)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LATENCY SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Duration':<12} {'MERT':<12} {'Pred':<12} {'Total':<12} {'RTF':<8}\")\n",
    "    print(\"-\"*60)\n",
    "    for r in results:\n",
    "        print(f\"{r['duration_sec']:.0f}s{'':<9} {r['mert_extraction_sec']*1000:.0f}ms{'':<7} \"\n",
    "              f\"{r['prediction_sec']*1000:.0f}ms{'':<8} {r['total_sec']*1000:.0f}ms{'':<7} {r['real_time_factor']:.3f}x\")\n",
    "    \n",
    "    return {'latency_results': results, 'device': str(device)}\n",
    "\n",
    "ALL_RESULTS['E2_latency_benchmark'] = benchmark_inference_latency()\n",
    "\n",
    "# Save and sync E2 results\n",
    "with open(RESULTS_DIR / 'E2_latency_benchmark.json', 'w') as f:\n",
    "    json.dump(ALL_RESULTS.get('E2_latency_benchmark', {}), f, indent=2)\n",
    "run_rclone(['rclone', 'copy', str(RESULTS_DIR / 'E2_latency_benchmark.json'), GDRIVE_RESULTS], \"Syncing E2 results\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-57"
  },
  {
   "cell_type": "code",
   "source": [
    "# E3: Per-Dimension Audio Advantage Analysis\n",
    "# Compare audio model performance against symbolic (PercePiano) per dimension\n",
    "# This forms the core paper narrative\n",
    "\n",
    "def analyze_per_dimension_advantage():\n",
    "    \"\"\"Analyze which dimensions audio excels at vs symbolic.\"\"\"\n",
    "    from scipy import stats\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"E3: PER-DIMENSION AUDIO ADVANTAGE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Try to load aligned fusion results from GDrive\n",
    "    fusion_results_dir = DATA_ROOT / 'aligned_fusion_results'\n",
    "    fusion_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fusion_results_file = fusion_results_dir / 'S0_bootstrap.json'\n",
    "    \n",
    "    if not fusion_results_file.exists():\n",
    "        print(\"Downloading fusion results from GDrive...\")\n",
    "        subprocess.run(['rclone', 'copy', \n",
    "                       'gdrive:crescendai_data/checkpoints/aligned_fusion/S0_bootstrap.json',\n",
    "                       str(fusion_results_dir)], capture_output=True)\n",
    "    \n",
    "    if not fusion_results_file.exists():\n",
    "        print(\"Fusion results not found. Run aligned_fusion notebook first.\")\n",
    "        return {}\n",
    "    \n",
    "    with open(fusion_results_file) as f:\n",
    "        bootstrap_results = json.load(f)\n",
    "    \n",
    "    audio_dims = bootstrap_results['audio']['per_dimension']\n",
    "    symbolic_dims = bootstrap_results['symbolic']['per_dimension']\n",
    "    \n",
    "    # Analyze by category\n",
    "    DIMENSION_CATEGORIES = {\n",
    "        'Timing': ['timing', 'tempo'],\n",
    "        'Articulation': ['articulation_length', 'articulation_touch'],\n",
    "        'Pedal': ['pedal_amount', 'pedal_clarity'],\n",
    "        'Timbre': ['timbre_variety', 'timbre_depth', 'timbre_brightness', 'timbre_loudness'],\n",
    "        'Dynamics': ['dynamic_range'],\n",
    "        'Musical': ['space', 'balance', 'drama'],\n",
    "        'Mood': ['mood_valence', 'mood_energy', 'mood_imagination'],\n",
    "        'Overall': ['sophistication', 'interpretation'],\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'Dimension':<25} {'Audio R2':>10} {'Symbolic R2':>12} {'Advantage':>12} {'Winner':>10}\")\n",
    "    print(\"-\"*75)\n",
    "    \n",
    "    results = []\n",
    "    for dim in PERCEPIANO_DIMENSIONS:\n",
    "        audio_r2 = audio_dims.get(dim, {}).get('r2', 0)\n",
    "        symbolic_r2 = symbolic_dims.get(dim, {}).get('r2', 0)\n",
    "        advantage = audio_r2 - symbolic_r2\n",
    "        winner = 'AUDIO' if advantage > 0.02 else ('SYMBOLIC' if advantage < -0.02 else 'TIE')\n",
    "        \n",
    "        results.append({\n",
    "            'dimension': dim,\n",
    "            'audio_r2': audio_r2,\n",
    "            'symbolic_r2': symbolic_r2,\n",
    "            'advantage': advantage,\n",
    "            'winner': winner,\n",
    "        })\n",
    "        \n",
    "        print(f\"{dim:<25} {audio_r2:>10.4f} {symbolic_r2:>12.4f} {advantage:>+12.4f} {winner:>10}\")\n",
    "    \n",
    "    # Category summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CATEGORY SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n{'Category':<20} {'Audio Avg':>12} {'Symbolic Avg':>14} {'Advantage':>12}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    category_results = []\n",
    "    for category, dims in DIMENSION_CATEGORIES.items():\n",
    "        audio_avg = np.mean([audio_dims.get(d, {}).get('r2', 0) for d in dims])\n",
    "        symbolic_avg = np.mean([symbolic_dims.get(d, {}).get('r2', 0) for d in dims])\n",
    "        advantage = audio_avg - symbolic_avg\n",
    "        \n",
    "        category_results.append({\n",
    "            'category': category,\n",
    "            'audio_avg': float(audio_avg),\n",
    "            'symbolic_avg': float(symbolic_avg),\n",
    "            'advantage': float(advantage),\n",
    "        })\n",
    "        \n",
    "        print(f\"{category:<20} {audio_avg:>12.4f} {symbolic_avg:>14.4f} {advantage:>+12.4f}\")\n",
    "    \n",
    "    # Key findings\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"KEY FINDINGS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    audio_wins = sum(1 for r in results if r['winner'] == 'AUDIO')\n",
    "    symbolic_wins = sum(1 for r in results if r['winner'] == 'SYMBOLIC')\n",
    "    ties = sum(1 for r in results if r['winner'] == 'TIE')\n",
    "    \n",
    "    print(f\"\\nDimension wins: Audio={audio_wins}, Symbolic={symbolic_wins}, Ties={ties}\")\n",
    "    \n",
    "    # Best/worst dimensions for audio\n",
    "    sorted_by_advantage = sorted(results, key=lambda x: x['advantage'], reverse=True)\n",
    "    \n",
    "    print(\"\\nAudio's strongest dimensions:\")\n",
    "    for r in sorted_by_advantage[:5]:\n",
    "        print(f\"  {r['dimension']}: +{r['advantage']:.4f}\")\n",
    "    \n",
    "    print(\"\\nAudio's weakest dimensions:\")\n",
    "    for r in sorted_by_advantage[-3:]:\n",
    "        print(f\"  {r['dimension']}: {r['advantage']:+.4f}\")\n",
    "    \n",
    "    # Best category\n",
    "    best_category = max(category_results, key=lambda x: x['advantage'])\n",
    "    print(f\"\\nBest category for audio: {best_category['category']} (+{best_category['advantage']:.4f})\")\n",
    "    \n",
    "    return {\n",
    "        'per_dimension': results,\n",
    "        'per_category': category_results,\n",
    "        'audio_wins': audio_wins,\n",
    "        'symbolic_wins': symbolic_wins,\n",
    "    }\n",
    "\n",
    "ALL_RESULTS['E3_dimension_analysis'] = analyze_per_dimension_advantage()\n",
    "\n",
    "# Save and sync E3 results\n",
    "with open(RESULTS_DIR / 'E3_dimension_analysis.json', 'w') as f:\n",
    "    json.dump(ALL_RESULTS.get('E3_dimension_analysis', {}), f, indent=2)\n",
    "run_rclone(['rclone', 'copy', str(RESULTS_DIR / 'E3_dimension_analysis.json'), GDRIVE_RESULTS], \"Syncing E3 results\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-58"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Comprehensive Results Summary\n\nFinal summary of all experiments across all phases, with recommendations for paper and product.",
   "metadata": {},
   "id": "cell-59"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Comprehensive Results Summary\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE AUDIO EXPERIMENTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect all results\n",
    "all_exp_ids = (\n",
    "    ALL_EXPERIMENT_IDS +  # Phase 2\n",
    "    PHASE3_EXPERIMENT_IDS +  # Phase 3\n",
    "    PHASE35_EXPERIMENT_IDS +  # MuQ\n",
    "    PHASE36_EXPERIMENT_IDS +  # Contrastive\n",
    "    PHASE4_EXPERIMENT_IDS  # E1a-c\n",
    ")\n",
    "\n",
    "# Load any missing results from disk\n",
    "for exp_id in all_exp_ids:\n",
    "    if exp_id not in ALL_RESULTS:\n",
    "        result_file = RESULTS_DIR / f'{exp_id}.json'\n",
    "        if result_file.exists():\n",
    "            with open(result_file) as f:\n",
    "                ALL_RESULTS[exp_id] = json.load(f)\n",
    "\n",
    "# Print results table\n",
    "print(f\"\\n{'Experiment':<35} {'Avg R2':>10} {'Description'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "results_list = []\n",
    "for exp_id in all_exp_ids:\n",
    "    if exp_id in ALL_RESULTS:\n",
    "        r = ALL_RESULTS[exp_id]\n",
    "        avg_r2 = r.get('summary', {}).get('avg_r2', 0)\n",
    "        desc = r.get('description', '')[:30]\n",
    "        results_list.append((avg_r2, exp_id, desc))\n",
    "        print(f\"{exp_id:<35} {avg_r2:>10.4f} {desc}\")\n",
    "\n",
    "# Find best result\n",
    "if results_list:\n",
    "    best = max(results_list, key=lambda x: x[0])\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"BEST RESULT: {best[1]}\")\n",
    "    print(f\"  R2 = {best[0]:.4f}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Summary by phase\n",
    "print(\"\\n--- SUMMARY BY PHASE ---\")\n",
    "phases = [\n",
    "    (\"Phase 2 (Baselines)\", ALL_EXPERIMENT_IDS),\n",
    "    (\"Phase 3 (Advanced)\", PHASE3_EXPERIMENT_IDS),\n",
    "    (\"Phase 3.5 (MuQ)\", PHASE35_EXPERIMENT_IDS),\n",
    "    (\"Phase 3.6 (Contrastive)\", PHASE36_EXPERIMENT_IDS),\n",
    "    (\"Phase 4 (Product)\", PHASE4_EXPERIMENT_IDS),\n",
    "]\n",
    "\n",
    "for phase_name, phase_ids in phases:\n",
    "    phase_results = [ALL_RESULTS.get(e, {}).get('summary', {}).get('avg_r2', 0) \n",
    "                     for e in phase_ids if e in ALL_RESULTS]\n",
    "    if phase_results:\n",
    "        best_r2 = max(phase_results)\n",
    "        print(f\"{phase_name:<25} Best R2: {best_r2:.4f}\")\n",
    "\n",
    "# Final sync\n",
    "print(\"\\n--- SYNCING ALL RESULTS ---\")\n",
    "with open(RESULTS_DIR / 'all_experiments_summary.json', 'w') as f:\n",
    "    json.dump(ALL_RESULTS, f, indent=2, default=str)\n",
    "\n",
    "run_rclone(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS], \"Final sync\")\n",
    "print(f\"\\nResults synced to: {GDRIVE_RESULTS}\")\n",
    "print(\"\\nDONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}