{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Symbolic Predictions for Fusion\n",
    "\n",
    "Run this on Thunder Compute after training the PercePiano symbolic model.\n",
    "Generates predictions aligned with audio validation samples for fusion testing.\n",
    "\n",
    "**Output:** `gdrive:crescendai_data/predictions/symbolic_predictions.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup PercePiano with numpy 2.0 compatibility\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from types import ModuleType\n",
    "import subprocess\n",
    "\n",
    "PERCEPIANO_ROOT = Path('/tmp/PercePiano')\n",
    "if not PERCEPIANO_ROOT.exists():\n",
    "    print(\"Cloning PercePiano repository...\")\n",
    "    !git clone https://github.com/JonghoKimSNU/PercePiano.git /tmp/PercePiano\n",
    "else:\n",
    "    print(f\"PercePiano already present at {PERCEPIANO_ROOT}\")\n",
    "\n",
    "PERCEPIANO_PATH = PERCEPIANO_ROOT / 'virtuoso' / 'virtuoso'\n",
    "\n",
    "# Install dependencies\n",
    "!pip install omegaconf tqdm --quiet\n",
    "\n",
    "# Patch numpy 2.0 compatibility\n",
    "import numpy as np\n",
    "if not hasattr(np.lib, 'arraysetops'):\n",
    "    arraysetops = ModuleType('numpy.lib.arraysetops')\n",
    "    arraysetops.isin = np.isin\n",
    "    sys.modules['numpy.lib.arraysetops'] = arraysetops\n",
    "    np.lib.arraysetops = arraysetops\n",
    "    print(\"Patched numpy.lib.arraysetops for numpy 2.0 compatibility\")\n",
    "\n",
    "sys.path.insert(0, str(PERCEPIANO_PATH / 'pyScoreParser'))\n",
    "sys.path.insert(0, str(PERCEPIANO_PATH))\n",
    "\n",
    "print(f\"\\nnumpy version: {np.__version__}\")\n",
    "print(f\"PercePiano path: {PERCEPIANO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from GDrive\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path('/tmp/percepiano_original')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_original')\n",
    "FOLD_ASSIGNMENTS_FILE = Path('/tmp/audio_fold_assignments.json')\n",
    "\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "if 'gdrive:' not in result.stdout:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "print(\"rclone configured\")\n",
    "\n",
    "print(\"\\nDownloading data...\")\n",
    "!rclone copy gdrive:crescendai_data/percepiano_original $DATA_ROOT --progress\n",
    "!rclone copy gdrive:crescendai_data/checkpoints/percepiano_original $CHECKPOINT_ROOT --progress\n",
    "!rclone copyto gdrive:crescendai_data/audio_baseline/audio_fold_assignments.json $FOLD_ASSIGNMENTS_FILE\n",
    "\n",
    "print(\"\\nVerifying...\")\n",
    "print(f\"Data folds: {len(list(DATA_ROOT.glob('fold*')))}\")\n",
    "print(f\"Checkpoints: {len(list(CHECKPOINT_ROOT.glob('*.pt')))}\")\n",
    "print(f\"Fold assignments: {FOLD_ASSIGNMENTS_FILE.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fold assignments\n",
    "import json\n",
    "\n",
    "with open(FOLD_ASSIGNMENTS_FILE) as f:\n",
    "    fold_assignments = json.load(f)\n",
    "\n",
    "# Get all keys we need predictions for\n",
    "all_keys = set()\n",
    "for fold_id in range(4):\n",
    "    all_keys.update(fold_assignments.get(f'fold_{fold_id}', []))\n",
    "all_keys.update(fold_assignments.get('test', []))\n",
    "\n",
    "print(f\"Total keys to predict: {len(all_keys)}\")\n",
    "print(f\"  Validation: {sum(len(fold_assignments.get(f'fold_{i}', [])) for i in range(4))}\")\n",
    "print(f\"  Test: {len(fold_assignments.get('test', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PercePiano model\n",
    "from model_m2pf import VirtuosoNetMultiLevel\n",
    "from omegaconf import OmegaConf\n",
    "import yaml\n",
    "import pickle\n",
    "\n",
    "# Load config\n",
    "CONFIG_PATH = PERCEPIANO_PATH.parent / 'ymls' / 'shared' / 'label19' / 'han_measnote_nomask_bigger256.yml'\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "net_param = OmegaConf.create(config['nn_params'])\n",
    "net_param.graph_keys = []\n",
    "\n",
    "print(f\"Config loaded: {CONFIG_PATH.name}\")\n",
    "print(f\"Hidden size: {net_param.encoder.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "\n",
    "def extract_label_key(filename):\n",
    "    \"\"\"Extract label key from pkl filename.\"\"\"\n",
    "    name = filename.replace('.pkl', '').replace('.mid', '')\n",
    "    if name.startswith('all_2rounds_'):\n",
    "        name = name[len('all_2rounds_'):]\n",
    "    return name\n",
    "\n",
    "def load_sample(pkl_path, max_notes=5000):\n",
    "    \"\"\"Load a single sample from pkl file.\"\"\"\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    x = torch.tensor(data['input'], dtype=torch.float32)\n",
    "    if len(x) > max_notes:\n",
    "        x = x[:max_notes]\n",
    "    \n",
    "    note_locations = {\n",
    "        'beat': torch.tensor(data['note_location']['beat'][:len(x)], dtype=torch.long),\n",
    "        'measure': torch.tensor(data['note_location']['measure'][:len(x)], dtype=torch.long),\n",
    "        'voice': torch.tensor(data['note_location']['voice'][:len(x)], dtype=torch.long),\n",
    "        'section': torch.tensor(data['note_location']['section'][:len(x)], dtype=torch.long),\n",
    "    }\n",
    "    return x, note_locations\n",
    "\n",
    "def predict_single(model, x, note_locations, device, sigmoid):\n",
    "    \"\"\"Generate prediction for a single sample.\"\"\"\n",
    "    batch_x = pack_sequence([x], enforce_sorted=True).to(device)\n",
    "    note_locs = {k: v.unsqueeze(0).to(device) for k, v in note_locations.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_x, None, None, note_locs)\n",
    "        pred = sigmoid(outputs[-1]).squeeze(0).cpu().numpy()\n",
    "    return pred\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build key -> pkl file mapping\n",
    "key_to_pkl = {}\n",
    "\n",
    "for fold_id in range(4):\n",
    "    fold_path = DATA_ROOT / f'fold{fold_id}'\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        split_path = fold_path / split\n",
    "        if split_path.exists():\n",
    "            for pkl_file in split_path.glob('*.pkl'):\n",
    "                if pkl_file.name != 'stat.pkl':\n",
    "                    key = extract_label_key(pkl_file.name)\n",
    "                    if key not in key_to_pkl:  # Keep first occurrence\n",
    "                        key_to_pkl[key] = pkl_file\n",
    "\n",
    "print(f\"Mapped {len(key_to_pkl)} unique keys to pkl files\")\n",
    "\n",
    "# Check coverage\n",
    "missing = all_keys - set(key_to_pkl.keys())\n",
    "if missing:\n",
    "    print(f\"Warning: {len(missing)} keys not found in data\")\n",
    "else:\n",
    "    print(\"All keys found in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for each fold\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "predictions = {}\n",
    "\n",
    "for fold_id in range(4):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold_id}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint_path = CHECKPOINT_ROOT / f'fold{fold_id}_best.pt'\n",
    "    if not checkpoint_path.exists():\n",
    "        print(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Load fold stats\n",
    "    fold_path = DATA_ROOT / f'fold{fold_id}'\n",
    "    with open(fold_path / 'train' / 'stat.pkl', 'rb') as f:\n",
    "        fold_stats = pickle.load(f)\n",
    "    \n",
    "    # Update input size\n",
    "    net_param.input_size = max(v[1] for v in fold_stats['key_to_dim']['input'].values())\n",
    "    \n",
    "    # Load model\n",
    "    model = VirtuosoNetMultiLevel(net_param, fold_stats, multi_level=\"total_note_cat\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Loaded model (R2={checkpoint['r2']:.4f}, epoch {checkpoint['epoch']})\")\n",
    "    \n",
    "    # Get fold validation keys\n",
    "    fold_keys = set(fold_assignments.get(f'fold_{fold_id}', []))\n",
    "    print(f\"Generating predictions for {len(fold_keys)} validation samples...\")\n",
    "    \n",
    "    count = 0\n",
    "    for key in fold_keys:\n",
    "        if key not in key_to_pkl:\n",
    "            continue\n",
    "        \n",
    "        x, note_locations = load_sample(key_to_pkl[key])\n",
    "        pred = predict_single(model, x, note_locations, device, sigmoid)\n",
    "        predictions[key] = pred.tolist()\n",
    "        count += 1\n",
    "    \n",
    "    print(f\"Generated {count} predictions for fold {fold_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set predictions using fold 0 model\n",
    "test_keys = set(fold_assignments.get('test', []))\n",
    "print(f\"\\nGenerating predictions for {len(test_keys)} test samples...\")\n",
    "\n",
    "# Reload fold 0 model\n",
    "fold_path = DATA_ROOT / 'fold0'\n",
    "with open(fold_path / 'train' / 'stat.pkl', 'rb') as f:\n",
    "    fold_stats = pickle.load(f)\n",
    "\n",
    "net_param.input_size = max(v[1] for v in fold_stats['key_to_dim']['input'].values())\n",
    "model = VirtuosoNetMultiLevel(net_param, fold_stats, multi_level=\"total_note_cat\")\n",
    "checkpoint = torch.load(CHECKPOINT_ROOT / 'fold0_best.pt', map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "count = 0\n",
    "for key in test_keys:\n",
    "    if key in predictions:  # Skip if already predicted\n",
    "        continue\n",
    "    if key not in key_to_pkl:\n",
    "        continue\n",
    "    \n",
    "    x, note_locations = load_sample(key_to_pkl[key])\n",
    "    pred = predict_single(model, x, note_locations, device, sigmoid)\n",
    "    predictions[key] = pred.tolist()\n",
    "    count += 1\n",
    "\n",
    "print(f\"Generated {count} test predictions\")\n",
    "print(f\"\\nTotal predictions: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions locally\n",
    "output_path = Path('/tmp/symbolic_predictions.json')\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(predictions, f)\n",
    "\n",
    "print(f\"Saved {len(predictions)} predictions to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to GDrive\n",
    "!rclone mkdir gdrive:crescendai_data/predictions\n",
    "!rclone copyto /tmp/symbolic_predictions.json gdrive:crescendai_data/predictions/symbolic_predictions.json\n",
    "\n",
    "print(\"\\nUploaded to gdrive:crescendai_data/predictions/symbolic_predictions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"PREDICTION GENERATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "val_count = sum(1 for k in predictions if k not in test_keys)\n",
    "test_count = sum(1 for k in predictions if k in test_keys)\n",
    "\n",
    "print(f\"\\nTotal predictions: {len(predictions)}\")\n",
    "print(f\"  Validation: {val_count}\")\n",
    "print(f\"  Test: {test_count}\")\n",
    "print(f\"\\nOutput: gdrive:crescendai_data/predictions/symbolic_predictions.json\")\n",
    "print(\"\\nNext: Run 'uv run python scripts/analyze_models.py' locally\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
