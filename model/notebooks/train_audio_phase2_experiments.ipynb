{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Audio Baseline Experiments\n",
    "\n",
    "Comprehensive experiments for the ISMIR paper. Run all cells sequentially.\n",
    "\n",
    "## Experiments\n",
    "- **B0**: Baseline re-run (MERT+MLP, L13-24, mean pool)\n",
    "- **A1-A3**: Baselines (linear probe, Mel-CNN, raw statistics)\n",
    "- **B1a-B1d**: Layer ablation (1-6, 7-12, 13-24, 1-24)\n",
    "- **B2a-B2c**: Pooling ablation (max, attention, LSTM)\n",
    "- **C1a-C1b**: Loss ablation (hybrid MSE+CCC, pure CCC)\n",
    "\n",
    "## Requirements\n",
    "- Thunder Compute A100 (80GB VRAM)\n",
    "- rclone configured with `gdrive:` remote\n",
    "- ~14-15 hours runtime\n",
    "- ~16GB storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: GPU Check\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    raise RuntimeError(\"GPU required for Phase 2 experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install dependencies\n",
    "!pip install transformers librosa soundfile pytorch_lightning nnAudio --quiet\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Imports and reproducibility\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nnAudio.features import MelSpectrogram\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "SEED = 42\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")\n",
    "print(f\"Seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Paths and data download\n",
    "DATA_ROOT = Path('/tmp/phase2')\n",
    "AUDIO_DIR = DATA_ROOT / 'audio'\n",
    "LABEL_DIR = DATA_ROOT / 'labels'\n",
    "MERT_CACHE_ROOT = DATA_ROOT / 'mert_cache'\n",
    "MEL_CACHE_DIR = DATA_ROOT / 'mel_cache'\n",
    "STATS_CACHE_DIR = DATA_ROOT / 'stats_cache'\n",
    "CHECKPOINT_ROOT = DATA_ROOT / 'checkpoints'\n",
    "RESULTS_DIR = DATA_ROOT / 'results'\n",
    "LOG_DIR = DATA_ROOT / 'logs'\n",
    "\n",
    "# Google Drive paths\n",
    "GDRIVE_AUDIO = 'gdrive:crescendai_data/audio_baseline/percepiano_rendered'\n",
    "GDRIVE_LABELS = 'gdrive:crescendai_data/percepiano_labels'\n",
    "GDRIVE_FOLDS = 'gdrive:crescendai_data/audio_baseline/audio_fold_assignments.json'\n",
    "GDRIVE_MERT_CACHE = 'gdrive:crescendai_data/audio_baseline/mert_embeddings'\n",
    "GDRIVE_RESULTS = 'gdrive:crescendai_data/checkpoints/audio_phase2'\n",
    "\n",
    "# Create directories\n",
    "for d in [AUDIO_DIR, LABEL_DIR, MERT_CACHE_ROOT, MEL_CACHE_DIR, STATS_CACHE_DIR, \n",
    "          CHECKPOINT_ROOT, RESULTS_DIR, LOG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_rclone(cmd, description):\n",
    "    \"\"\"Run rclone command with error checking.\"\"\"\n",
    "    print(f\"{description}...\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Warning: {result.stderr}\")\n",
    "    return result\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "if 'gdrive:' not in result.stdout:\n",
    "    raise RuntimeError(\"rclone 'gdrive' remote not configured\")\n",
    "print(\"rclone: OK\")\n",
    "\n",
    "# Download audio\n",
    "run_rclone(['rclone', 'copy', GDRIVE_AUDIO, str(AUDIO_DIR), '--progress'], \"Downloading audio\")\n",
    "print(f\"Audio files: {len(list(AUDIO_DIR.glob('*.wav')))}\")\n",
    "\n",
    "# Download labels\n",
    "run_rclone(['rclone', 'copy', GDRIVE_LABELS, str(LABEL_DIR)], \"Downloading labels\")\n",
    "\n",
    "# Download fold assignments\n",
    "FOLD_FILE = DATA_ROOT / 'folds.json'\n",
    "run_rclone(['rclone', 'copyto', GDRIVE_FOLDS, str(FOLD_FILE)], \"Downloading folds\")\n",
    "\n",
    "# Load labels and folds\n",
    "LABEL_FILE = LABEL_DIR / 'label_2round_mean_reg_19_with0_rm_highstd0.json'\n",
    "with open(LABEL_FILE) as f:\n",
    "    LABELS = json.load(f)\n",
    "with open(FOLD_FILE) as f:\n",
    "    FOLD_ASSIGNMENTS = json.load(f)\n",
    "\n",
    "print(f\"Labels: {len(LABELS)} segments\")\n",
    "print(f\"Folds: {list(FOLD_ASSIGNMENTS.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Restore existing MERT cache (L13-24)\n",
    "DEFAULT_MERT_DIR = MERT_CACHE_ROOT / 'L13-24'\n",
    "DEFAULT_MERT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Checking for existing MERT cache (L13-24)...\")\n",
    "result = subprocess.run(['rclone', 'lsf', GDRIVE_MERT_CACHE], capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    remote_files = [f for f in result.stdout.strip().split('\\n') if f.endswith('.pt')]\n",
    "    if remote_files:\n",
    "        print(f\"Found {len(remote_files)} cached embeddings. Restoring...\")\n",
    "        run_rclone(['rclone', 'copy', GDRIVE_MERT_CACHE, str(DEFAULT_MERT_DIR)], \"Restoring MERT cache\")\n",
    "        print(f\"Restored: {len(list(DEFAULT_MERT_DIR.glob('*.pt')))} embeddings\")\n",
    "else:\n",
    "    print(\"No existing cache found. Will extract fresh.\")\n",
    "\n",
    "print(f\"\\nSetup complete. Data root: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Shared Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Constants and configuration\n",
    "PERCEPIANO_DIMENSIONS = [\n",
    "    \"timing\", \"articulation_length\", \"articulation_touch\",\n",
    "    \"pedal_amount\", \"pedal_clarity\",\n",
    "    \"timbre_variety\", \"timbre_depth\", \"timbre_brightness\", \"timbre_loudness\",\n",
    "    \"dynamic_range\", \"tempo\", \"space\", \"balance\", \"drama\",\n",
    "    \"mood_valence\", \"mood_energy\", \"mood_imagination\",\n",
    "    \"sophistication\", \"interpretation\",\n",
    "]\n",
    "\n",
    "DIMENSION_CATEGORIES = {\n",
    "    \"timing\": [\"timing\"],\n",
    "    \"articulation\": [\"articulation_length\", \"articulation_touch\"],\n",
    "    \"pedal\": [\"pedal_amount\", \"pedal_clarity\"],\n",
    "    \"timbre\": [\"timbre_variety\", \"timbre_depth\", \"timbre_brightness\", \"timbre_loudness\"],\n",
    "    \"dynamics\": [\"dynamic_range\"],\n",
    "    \"tempo_space\": [\"tempo\", \"space\", \"balance\", \"drama\"],\n",
    "    \"emotion\": [\"mood_valence\", \"mood_energy\", \"mood_imagination\"],\n",
    "    \"interpretation\": [\"sophistication\", \"interpretation\"],\n",
    "}\n",
    "\n",
    "# Base configuration (modified per experiment)\n",
    "BASE_CONFIG = {\n",
    "    'input_dim': 1024,\n",
    "    'hidden_dim': 512,\n",
    "    'num_labels': 19,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'gradient_clip_val': 1.0,\n",
    "    'batch_size': 64,\n",
    "    'max_epochs': 200,\n",
    "    'patience': 15,\n",
    "    'max_frames': 1000,\n",
    "    'n_folds': 4,\n",
    "    'num_workers': 2,\n",
    "    'seed': SEED,\n",
    "}\n",
    "\n",
    "# Track all results\n",
    "ALL_RESULTS = {}\n",
    "\n",
    "print(f\"Dimensions: {len(PERCEPIANO_DIMENSIONS)}\")\n",
    "print(f\"Base config: batch_size={BASE_CONFIG['batch_size']}, max_epochs={BASE_CONFIG['max_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: MERT Extractor (configurable layers)\n",
    "class MERTLayerExtractor:\n",
    "    \"\"\"MERT-330M extractor with configurable layer range.\"\"\"\n",
    "    \n",
    "    def __init__(self, layer_start: int = 13, layer_end: int = 25, cache_dir: Optional[Path] = None):\n",
    "        self.layer_start = layer_start\n",
    "        self.layer_end = layer_end\n",
    "        self.target_sr = 24000\n",
    "        self.cache_dir = Path(cache_dir) if cache_dir else None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        print(f\"Loading MERT-v1-330M (layers {layer_start}-{layer_end-1}) on {self.device}...\")\n",
    "        self.processor = AutoProcessor.from_pretrained(\"m-a-p/MERT-v1-330M\", trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            \"m-a-p/MERT-v1-330M\",\n",
    "            output_hidden_states=True,\n",
    "            trust_remote_code=True,\n",
    "        ).to(self.device)\n",
    "        self.model.eval()\n",
    "        print(f\"Model loaded. Hidden size: {self.model.config.hidden_size}\")\n",
    "    \n",
    "    def get_cache_path(self, key: str) -> Path:\n",
    "        return self.cache_dir / f\"{key}.pt\"\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_from_file(self, audio_path: Path, use_cache: bool = True) -> torch.Tensor:\n",
    "        audio_path = Path(audio_path)\n",
    "        key = audio_path.stem\n",
    "        \n",
    "        if use_cache and self.cache_dir:\n",
    "            cache_path = self.get_cache_path(key)\n",
    "            if cache_path.exists():\n",
    "                return torch.load(cache_path, weights_only=True)\n",
    "        \n",
    "        audio, _ = librosa.load(audio_path, sr=self.target_sr, mono=True)\n",
    "        inputs = self.processor(audio, sampling_rate=self.target_sr, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        hidden_states = outputs.hidden_states[self.layer_start:self.layer_end]\n",
    "        embeddings = torch.stack(hidden_states, dim=0).mean(dim=0).squeeze(0).cpu()\n",
    "        \n",
    "        if use_cache and self.cache_dir:\n",
    "            self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(embeddings, self.get_cache_path(key))\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def extract_mert_for_layer_range(layer_start: int, layer_end: int, audio_dir: Path, \n",
    "                                  cache_dir: Path, keys: List[str]) -> int:\n",
    "    \"\"\"Extract MERT embeddings for a specific layer range. Returns count extracted.\"\"\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cached = {p.stem for p in cache_dir.glob('*.pt')}\n",
    "    to_extract = [k for k in keys if k not in cached]\n",
    "    \n",
    "    if not to_extract:\n",
    "        print(f\"All {len(keys)} embeddings already cached.\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"Extracting {len(to_extract)} embeddings (layers {layer_start}-{layer_end-1})...\")\n",
    "    extractor = MERTLayerExtractor(layer_start, layer_end, cache_dir)\n",
    "    \n",
    "    for key in tqdm(to_extract, desc=f\"MERT L{layer_start}-{layer_end-1}\"):\n",
    "        audio_path = audio_dir / f\"{key}.wav\"\n",
    "        if audio_path.exists():\n",
    "            extractor.extract_from_file(audio_path)\n",
    "    \n",
    "    del extractor\n",
    "    torch.cuda.empty_cache()\n",
    "    return len(to_extract)\n",
    "\n",
    "\n",
    "print(\"MERT extractor defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Mel spectrogram extractor (nnAudio)\n",
    "class MelExtractor:\n",
    "    \"\"\"GPU-accelerated mel spectrogram extraction using nnAudio.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Optional[Path] = None, sr: int = 24000):\n",
    "        self.sr = sr\n",
    "        self.cache_dir = Path(cache_dir) if cache_dir else None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.mel_spec = MelSpectrogram(\n",
    "            sr=sr, n_fft=2048, hop_length=512, n_mels=128,\n",
    "            fmin=20, fmax=8000, trainable_mel=False, trainable_STFT=False\n",
    "        ).to(self.device)\n",
    "    \n",
    "    def extract_from_file(self, audio_path: Path, use_cache: bool = True) -> torch.Tensor:\n",
    "        audio_path = Path(audio_path)\n",
    "        key = audio_path.stem\n",
    "        \n",
    "        if use_cache and self.cache_dir:\n",
    "            cache_path = self.cache_dir / f\"{key}.pt\"\n",
    "            if cache_path.exists():\n",
    "                return torch.load(cache_path, weights_only=True)\n",
    "        \n",
    "        audio, _ = librosa.load(audio_path, sr=self.sr, mono=True)\n",
    "        audio_tensor = torch.from_numpy(audio).float().unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mel = self.mel_spec(audio_tensor)  # [1, n_mels, time]\n",
    "            mel = mel.squeeze(0).cpu()  # [n_mels, time]\n",
    "        \n",
    "        if use_cache and self.cache_dir:\n",
    "            self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(mel, self.cache_dir / f\"{key}.pt\")\n",
    "        \n",
    "        return mel\n",
    "\n",
    "\n",
    "def extract_mel_spectrograms(audio_dir: Path, cache_dir: Path, keys: List[str]) -> int:\n",
    "    \"\"\"Extract mel spectrograms for all keys. Returns count extracted.\"\"\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cached = {p.stem for p in cache_dir.glob('*.pt')}\n",
    "    to_extract = [k for k in keys if k not in cached]\n",
    "    \n",
    "    if not to_extract:\n",
    "        print(f\"All {len(keys)} mel spectrograms already cached.\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"Extracting {len(to_extract)} mel spectrograms...\")\n",
    "    extractor = MelExtractor(cache_dir)\n",
    "    \n",
    "    for key in tqdm(to_extract, desc=\"Mel extraction\"):\n",
    "        audio_path = audio_dir / f\"{key}.wav\"\n",
    "        if audio_path.exists():\n",
    "            extractor.extract_from_file(audio_path)\n",
    "    \n",
    "    return len(to_extract)\n",
    "\n",
    "\n",
    "print(\"Mel extractor defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Audio statistics extractor\n",
    "def extract_audio_statistics(audio: np.ndarray, sr: int = 24000) -> np.ndarray:\n",
    "    \"\"\"Extract 49-dim hand-crafted audio features.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Energy features (3)\n",
    "    rms = librosa.feature.rms(y=audio)[0]\n",
    "    features.extend([rms.mean(), rms.std(), rms.max()])\n",
    "    \n",
    "    # Spectral features (8)\n",
    "    cent = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n",
    "    bw = librosa.feature.spectral_bandwidth(y=audio, sr=sr)[0]\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio)[0]\n",
    "    features.extend([cent.mean(), cent.std(), bw.mean(), bw.std(),\n",
    "                     rolloff.mean(), rolloff.std(), zcr.mean(), zcr.std()])\n",
    "    \n",
    "    # MFCCs (26 = 13 coeffs x mean/std)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    features.extend(mfcc.mean(axis=1).tolist())\n",
    "    features.extend(mfcc.std(axis=1).tolist())\n",
    "    \n",
    "    # Chroma (12 = 12 bins x mean)\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    features.extend(chroma.mean(axis=1).tolist())\n",
    "    \n",
    "    return np.array(features, dtype=np.float32)  # Shape: (49,)\n",
    "\n",
    "\n",
    "def extract_statistics_for_all(audio_dir: Path, cache_dir: Path, keys: List[str]) -> int:\n",
    "    \"\"\"Extract audio statistics for all keys. Returns count extracted.\"\"\"\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cached = {p.stem for p in cache_dir.glob('*.pt')}\n",
    "    to_extract = [k for k in keys if k not in cached]\n",
    "    \n",
    "    if not to_extract:\n",
    "        print(f\"All {len(keys)} statistics already cached.\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"Extracting {len(to_extract)} audio statistics...\")\n",
    "    \n",
    "    for key in tqdm(to_extract, desc=\"Stats extraction\"):\n",
    "        audio_path = audio_dir / f\"{key}.wav\"\n",
    "        if audio_path.exists():\n",
    "            audio, sr = librosa.load(audio_path, sr=24000, mono=True)\n",
    "            stats_arr = extract_audio_statistics(audio, sr)\n",
    "            torch.save(torch.from_numpy(stats_arr), cache_dir / f\"{key}.pt\")\n",
    "    \n",
    "    return len(to_extract)\n",
    "\n",
    "\n",
    "print(\"Statistics extractor defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Dataset classes\n",
    "class MERTDataset(Dataset):\n",
    "    \"\"\"Dataset for MERT embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Path, labels: dict, fold_assignments: dict,\n",
    "                 fold_id: int, mode: str, max_frames: int = 1000):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.max_frames = max_frames\n",
    "        \n",
    "        available = {p.stem for p in self.cache_dir.glob('*.pt')}\n",
    "        \n",
    "        if mode == \"test\":\n",
    "            valid_keys = set(fold_assignments.get(\"test\", []))\n",
    "        elif mode == \"val\":\n",
    "            valid_keys = set(fold_assignments.get(f\"fold_{fold_id}\", []))\n",
    "        else:  # train\n",
    "            valid_keys = set()\n",
    "            for i in range(4):\n",
    "                if i != fold_id:\n",
    "                    valid_keys.update(fold_assignments.get(f\"fold_{i}\", []))\n",
    "        \n",
    "        self.samples = [(k, torch.tensor(labels[k][:19], dtype=torch.float32))\n",
    "                        for k in valid_keys if k in available and k in labels]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key, label = self.samples[idx]\n",
    "        emb = torch.load(self.cache_dir / f\"{key}.pt\", weights_only=True)\n",
    "        if emb.shape[0] > self.max_frames:\n",
    "            emb = emb[:self.max_frames]\n",
    "        return {\"embeddings\": emb, \"labels\": label, \"key\": key, \"length\": emb.shape[0]}\n",
    "\n",
    "\n",
    "class MelDataset(Dataset):\n",
    "    \"\"\"Dataset for mel spectrograms.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Path, labels: dict, fold_assignments: dict,\n",
    "                 fold_id: int, mode: str, max_frames: int = 2000):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.max_frames = max_frames\n",
    "        \n",
    "        available = {p.stem for p in self.cache_dir.glob('*.pt')}\n",
    "        \n",
    "        if mode == \"test\":\n",
    "            valid_keys = set(fold_assignments.get(\"test\", []))\n",
    "        elif mode == \"val\":\n",
    "            valid_keys = set(fold_assignments.get(f\"fold_{fold_id}\", []))\n",
    "        else:\n",
    "            valid_keys = set()\n",
    "            for i in range(4):\n",
    "                if i != fold_id:\n",
    "                    valid_keys.update(fold_assignments.get(f\"fold_{i}\", []))\n",
    "        \n",
    "        self.samples = [(k, torch.tensor(labels[k][:19], dtype=torch.float32))\n",
    "                        for k in valid_keys if k in available and k in labels]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key, label = self.samples[idx]\n",
    "        mel = torch.load(self.cache_dir / f\"{key}.pt\", weights_only=True)  # [128, T]\n",
    "        if mel.shape[1] > self.max_frames:\n",
    "            mel = mel[:, :self.max_frames]\n",
    "        return {\"mel\": mel, \"labels\": label, \"key\": key, \"length\": mel.shape[1]}\n",
    "\n",
    "\n",
    "class StatsDataset(Dataset):\n",
    "    \"\"\"Dataset for audio statistics.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: Path, labels: dict, fold_assignments: dict,\n",
    "                 fold_id: int, mode: str):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        \n",
    "        available = {p.stem for p in self.cache_dir.glob('*.pt')}\n",
    "        \n",
    "        if mode == \"test\":\n",
    "            valid_keys = set(fold_assignments.get(\"test\", []))\n",
    "        elif mode == \"val\":\n",
    "            valid_keys = set(fold_assignments.get(f\"fold_{fold_id}\", []))\n",
    "        else:\n",
    "            valid_keys = set()\n",
    "            for i in range(4):\n",
    "                if i != fold_id:\n",
    "                    valid_keys.update(fold_assignments.get(f\"fold_{i}\", []))\n",
    "        \n",
    "        self.samples = [(k, torch.tensor(labels[k][:19], dtype=torch.float32))\n",
    "                        for k in valid_keys if k in available and k in labels]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        key, label = self.samples[idx]\n",
    "        stats = torch.load(self.cache_dir / f\"{key}.pt\", weights_only=True)\n",
    "        return {\"features\": stats, \"labels\": label, \"key\": key}\n",
    "\n",
    "\n",
    "def mert_collate_fn(batch):\n",
    "    embs = [b[\"embeddings\"] for b in batch]\n",
    "    labels = torch.stack([b[\"labels\"] for b in batch])\n",
    "    lengths = torch.tensor([b[\"length\"] for b in batch])\n",
    "    padded = pad_sequence(embs, batch_first=True)\n",
    "    mask = torch.arange(padded.shape[1]).unsqueeze(0) < lengths.unsqueeze(1)\n",
    "    return {\"embeddings\": padded, \"attention_mask\": mask, \"labels\": labels, \n",
    "            \"keys\": [b[\"key\"] for b in batch], \"lengths\": lengths}\n",
    "\n",
    "\n",
    "def mel_collate_fn(batch):\n",
    "    mels = [b[\"mel\"] for b in batch]  # Each is [128, T]\n",
    "    labels = torch.stack([b[\"labels\"] for b in batch])\n",
    "    lengths = torch.tensor([b[\"length\"] for b in batch])\n",
    "    max_len = max(m.shape[1] for m in mels)\n",
    "    padded = torch.zeros(len(mels), 128, max_len)\n",
    "    for i, m in enumerate(mels):\n",
    "        padded[i, :, :m.shape[1]] = m\n",
    "    return {\"mel\": padded, \"labels\": labels, \"keys\": [b[\"key\"] for b in batch], \"lengths\": lengths}\n",
    "\n",
    "\n",
    "def stats_collate_fn(batch):\n",
    "    features = torch.stack([b[\"features\"] for b in batch])\n",
    "    labels = torch.stack([b[\"labels\"] for b in batch])\n",
    "    return {\"features\": features, \"labels\": labels, \"keys\": [b[\"key\"] for b in batch]}\n",
    "\n",
    "\n",
    "print(\"Dataset classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Model classes\n",
    "\n",
    "# Loss functions\n",
    "def ccc_loss(pred: torch.Tensor, target: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"Concordance Correlation Coefficient loss.\"\"\"\n",
    "    pred_mean = pred.mean(dim=0)\n",
    "    target_mean = target.mean(dim=0)\n",
    "    pred_var = pred.var(dim=0, unbiased=False)\n",
    "    target_var = target.var(dim=0, unbiased=False)\n",
    "    covar = ((pred - pred_mean) * (target - target_mean)).mean(dim=0)\n",
    "    ccc = (2 * covar) / (pred_var + target_var + (pred_mean - target_mean)**2 + eps)\n",
    "    return (1 - ccc).mean()\n",
    "\n",
    "\n",
    "class BaseMERTModel(pl.LightningModule):\n",
    "    \"\"\"Base class for MERT-based models.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=1024, hidden_dim=512, num_labels=19, dropout=0.2,\n",
    "                 learning_rate=1e-4, weight_decay=1e-5, pooling=\"mean\", \n",
    "                 loss_type=\"mse\", max_epochs=200):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = learning_rate\n",
    "        self.wd = weight_decay\n",
    "        self.pooling = pooling\n",
    "        self.loss_type = loss_type\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        # Attention pooling\n",
    "        if pooling == \"attention\":\n",
    "            self.attn = nn.Sequential(\n",
    "                nn.Linear(input_dim, 256), nn.Tanh(), nn.Linear(256, 1)\n",
    "            )\n",
    "        \n",
    "        # LSTM pooling\n",
    "        if pooling == \"lstm\":\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_dim // 2, batch_first=True, \n",
    "                               bidirectional=True, num_layers=1)\n",
    "            self.lstm_attn = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, 128), nn.Tanh(), nn.Linear(128, 1)\n",
    "            )\n",
    "            input_dim = hidden_dim  # LSTM output dim\n",
    "        \n",
    "        # MLP head\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_labels), nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.val_outputs = []\n",
    "    \n",
    "    def pool(self, x, mask=None, lengths=None):\n",
    "        if self.pooling == \"mean\":\n",
    "            if mask is not None:\n",
    "                m = mask.unsqueeze(-1).float()\n",
    "                return (x * m).sum(1) / m.sum(1).clamp(min=1)\n",
    "            return x.mean(1)\n",
    "        elif self.pooling == \"max\":\n",
    "            if mask is not None:\n",
    "                x = x.masked_fill(~mask.unsqueeze(-1), float('-inf'))\n",
    "            return x.max(1)[0]\n",
    "        elif self.pooling == \"attention\":\n",
    "            scores = self.attn(x).squeeze(-1)\n",
    "            if mask is not None:\n",
    "                scores = scores.masked_fill(~mask, float('-inf'))\n",
    "            w = torch.softmax(scores, dim=-1).unsqueeze(-1)\n",
    "            return (x * w).sum(1)\n",
    "        elif self.pooling == \"lstm\":\n",
    "            if lengths is not None:\n",
    "                packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "                lstm_out, _ = self.lstm(packed)\n",
    "                x, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "            else:\n",
    "                x, _ = self.lstm(x)\n",
    "            # Attention over LSTM outputs\n",
    "            scores = self.lstm_attn(x).squeeze(-1)\n",
    "            if mask is not None:\n",
    "                # Adjust mask size if needed\n",
    "                if mask.shape[1] > x.shape[1]:\n",
    "                    mask = mask[:, :x.shape[1]]\n",
    "                scores = scores.masked_fill(~mask, float('-inf'))\n",
    "            w = torch.softmax(scores, dim=-1).unsqueeze(-1)\n",
    "            return (x * w).sum(1)\n",
    "        return x.mean(1)\n",
    "    \n",
    "    def forward(self, x, mask=None, lengths=None):\n",
    "        pooled = self.pool(x, mask, lengths)\n",
    "        return self.clf(pooled)\n",
    "    \n",
    "    def compute_loss(self, pred, target):\n",
    "        if self.loss_type == \"mse\":\n",
    "            return self.mse_loss(pred, target)\n",
    "        elif self.loss_type == \"ccc\":\n",
    "            return ccc_loss(pred, target)\n",
    "        elif self.loss_type == \"hybrid\":\n",
    "            return self.mse_loss(pred, target) + 0.5 * ccc_loss(pred, target)\n",
    "        return self.mse_loss(pred, target)\n",
    "    \n",
    "    def training_step(self, batch, idx):\n",
    "        pred = self(batch[\"embeddings\"], batch.get(\"attention_mask\"), batch.get(\"lengths\"))\n",
    "        loss = self.compute_loss(pred, batch[\"labels\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, idx):\n",
    "        pred = self(batch[\"embeddings\"], batch.get(\"attention_mask\"), batch.get(\"lengths\"))\n",
    "        self.log(\"val_loss\", self.mse_loss(pred, batch[\"labels\"]), prog_bar=True)\n",
    "        self.val_outputs.append({\"p\": pred.cpu(), \"l\": batch[\"labels\"].cpu()})\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.val_outputs:\n",
    "            p = torch.cat([x[\"p\"] for x in self.val_outputs]).numpy()\n",
    "            l = torch.cat([x[\"l\"] for x in self.val_outputs]).numpy()\n",
    "            self.log(\"val_r2\", r2_score(l, p), prog_bar=True)\n",
    "            self.val_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=self.max_epochs, eta_min=1e-6)\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": sch, \"interval\": \"epoch\"}}\n",
    "\n",
    "\n",
    "class LinearProbeModel(pl.LightningModule):\n",
    "    \"\"\"Simple linear probe on MERT embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=1024, num_labels=19, learning_rate=1e-4, \n",
    "                 weight_decay=1e-5, max_epochs=200):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = learning_rate\n",
    "        self.wd = weight_decay\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, num_labels)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.val_outputs = []\n",
    "    \n",
    "    def forward(self, x, mask=None, lengths=None):\n",
    "        # Mean pooling\n",
    "        if mask is not None:\n",
    "            m = mask.unsqueeze(-1).float()\n",
    "            pooled = (x * m).sum(1) / m.sum(1).clamp(min=1)\n",
    "        else:\n",
    "            pooled = x.mean(1)\n",
    "        return torch.sigmoid(self.linear(pooled))\n",
    "    \n",
    "    def training_step(self, batch, idx):\n",
    "        pred = self(batch[\"embeddings\"], batch.get(\"attention_mask\"))\n",
    "        loss = self.loss_fn(pred, batch[\"labels\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, idx):\n",
    "        pred = self(batch[\"embeddings\"], batch.get(\"attention_mask\"))\n",
    "        self.log(\"val_loss\", self.loss_fn(pred, batch[\"labels\"]), prog_bar=True)\n",
    "        self.val_outputs.append({\"p\": pred.cpu(), \"l\": batch[\"labels\"].cpu()})\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.val_outputs:\n",
    "            p = torch.cat([x[\"p\"] for x in self.val_outputs]).numpy()\n",
    "            l = torch.cat([x[\"l\"] for x in self.val_outputs]).numpy()\n",
    "            self.log(\"val_r2\", r2_score(l, p), prog_bar=True)\n",
    "            self.val_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=self.max_epochs, eta_min=1e-6)\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": sch, \"interval\": \"epoch\"}}\n",
    "\n",
    "\n",
    "class MelCNNModel(pl.LightningModule):\n",
    "    \"\"\"4-layer CNN on mel spectrograms.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=512, num_labels=19, dropout=0.2,\n",
    "                 learning_rate=1e-4, weight_decay=1e-5, max_epochs=200):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = learning_rate\n",
    "        self.wd = weight_decay\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_labels), nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.val_outputs = []\n",
    "    \n",
    "    def forward(self, mel):\n",
    "        # mel: [B, 128, T]\n",
    "        x = mel.unsqueeze(1)  # [B, 1, 128, T]\n",
    "        x = self.conv(x)  # [B, 256, 1, 1]\n",
    "        x = x.flatten(1)  # [B, 256]\n",
    "        return self.head(x)\n",
    "    \n",
    "    def training_step(self, batch, idx):\n",
    "        pred = self(batch[\"mel\"])\n",
    "        loss = self.loss_fn(pred, batch[\"labels\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, idx):\n",
    "        pred = self(batch[\"mel\"])\n",
    "        self.log(\"val_loss\", self.loss_fn(pred, batch[\"labels\"]), prog_bar=True)\n",
    "        self.val_outputs.append({\"p\": pred.cpu(), \"l\": batch[\"labels\"].cpu()})\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.val_outputs:\n",
    "            p = torch.cat([x[\"p\"] for x in self.val_outputs]).numpy()\n",
    "            l = torch.cat([x[\"l\"] for x in self.val_outputs]).numpy()\n",
    "            self.log(\"val_r2\", r2_score(l, p), prog_bar=True)\n",
    "            self.val_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=self.max_epochs, eta_min=1e-6)\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": sch, \"interval\": \"epoch\"}}\n",
    "\n",
    "\n",
    "class StatsMLPModel(pl.LightningModule):\n",
    "    \"\"\"MLP on hand-crafted audio statistics.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=49, hidden_dim=256, num_labels=19, dropout=0.2,\n",
    "                 learning_rate=1e-4, weight_decay=1e-5, max_epochs=200):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = learning_rate\n",
    "        self.wd = weight_decay\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_labels), nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.val_outputs = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "    def training_step(self, batch, idx):\n",
    "        pred = self(batch[\"features\"])\n",
    "        loss = self.loss_fn(pred, batch[\"labels\"])\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, idx):\n",
    "        pred = self(batch[\"features\"])\n",
    "        self.log(\"val_loss\", self.loss_fn(pred, batch[\"labels\"]), prog_bar=True)\n",
    "        self.val_outputs.append({\"p\": pred.cpu(), \"l\": batch[\"labels\"].cpu()})\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        if self.val_outputs:\n",
    "            p = torch.cat([x[\"p\"] for x in self.val_outputs]).numpy()\n",
    "            l = torch.cat([x[\"l\"] for x in self.val_outputs]).numpy()\n",
    "            self.log(\"val_r2\", r2_score(l, p), prog_bar=True)\n",
    "            self.val_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=self.max_epochs, eta_min=1e-6)\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": sch, \"interval\": \"epoch\"}}\n",
    "\n",
    "\n",
    "print(\"Model classes defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Training and evaluation functions\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "\n",
    "def bootstrap_r2(y_true: np.ndarray, y_pred: np.ndarray, n_bootstrap: int = 1000) -> Tuple[float, float, float]:\n",
    "    \"\"\"Compute bootstrap 95% CI for R2.\"\"\"\n",
    "    np.random.seed(SEED)\n",
    "    n_samples = len(y_true)\n",
    "    r2_scores = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        r2_scores.append(r2_score(y_true[idx], y_pred[idx]))\n",
    "    return np.percentile(r2_scores, [2.5, 50, 97.5])\n",
    "\n",
    "\n",
    "def compute_comprehensive_metrics(all_preds: np.ndarray, all_labels: np.ndarray) -> dict:\n",
    "    \"\"\"Compute all metrics for experiment results.\"\"\"\n",
    "    overall_r2 = r2_score(all_labels, all_preds)\n",
    "    overall_mae = mean_absolute_error(all_labels, all_preds)\n",
    "    overall_rmse = np.sqrt(mean_squared_error(all_labels, all_preds))\n",
    "    \n",
    "    # Bootstrap CI\n",
    "    ci = bootstrap_r2(all_labels, all_preds)\n",
    "    \n",
    "    # Per-dimension metrics\n",
    "    per_dim = {}\n",
    "    for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n",
    "        y_true, y_pred = all_labels[:, i], all_preds[:, i]\n",
    "        pearson, p_val = stats.pearsonr(y_true, y_pred)\n",
    "        per_dim[dim] = {\n",
    "            \"r2\": float(r2_score(y_true, y_pred)),\n",
    "            \"mae\": float(mean_absolute_error(y_true, y_pred)),\n",
    "            \"pearson\": float(pearson),\n",
    "            \"p_value\": float(p_val),\n",
    "            \"label_mean\": float(y_true.mean()),\n",
    "            \"label_std\": float(y_true.std()),\n",
    "            \"pred_mean\": float(y_pred.mean()),\n",
    "            \"pred_std\": float(y_pred.std()),\n",
    "        }\n",
    "    \n",
    "    # Dispersion ratio\n",
    "    avg_label_std = np.mean([all_labels[:, i].std() for i in range(19)])\n",
    "    avg_pred_std = np.mean([all_preds[:, i].std() for i in range(19)])\n",
    "    dispersion_ratio = avg_pred_std / avg_label_std if avg_label_std > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"overall_r2\": float(overall_r2),\n",
    "        \"r2_ci_95\": [float(ci[0]), float(ci[2])],\n",
    "        \"overall_mae\": float(overall_mae),\n",
    "        \"overall_rmse\": float(overall_rmse),\n",
    "        \"dispersion_ratio\": float(dispersion_ratio),\n",
    "        \"per_dimension\": per_dim,\n",
    "    }\n",
    "\n",
    "\n",
    "def experiment_completed(exp_id: str, checkpoint_dir: Path) -> bool:\n",
    "    \"\"\"Check if experiment has all fold checkpoints.\"\"\"\n",
    "    exp_dir = checkpoint_dir / exp_id\n",
    "    if not exp_dir.exists():\n",
    "        return False\n",
    "    return all((exp_dir / f\"fold{i}_best.ckpt\").exists() for i in range(4))\n",
    "\n",
    "\n",
    "def load_existing_results(exp_id: str, results_dir: Path) -> Optional[dict]:\n",
    "    \"\"\"Load results from JSON if exists.\"\"\"\n",
    "    results_file = results_dir / f\"{exp_id}.json\"\n",
    "    if results_file.exists():\n",
    "        with open(results_file) as f:\n",
    "            return json.load(f)\n",
    "    return None\n",
    "\n",
    "\n",
    "def run_4fold_mert_experiment(\n",
    "    exp_id: str,\n",
    "    description: str,\n",
    "    model_factory: Callable,\n",
    "    mert_cache_dir: Path,\n",
    "    config: dict,\n",
    ") -> dict:\n",
    "    \"\"\"Run 4-fold CV for MERT-based experiment.\"\"\"\n",
    "    exp_checkpoint_dir = CHECKPOINT_ROOT / exp_id\n",
    "    exp_checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if already done\n",
    "    existing = load_existing_results(exp_id, RESULTS_DIR)\n",
    "    if existing and experiment_completed(exp_id, CHECKPOINT_ROOT):\n",
    "        print(f\"SKIP {exp_id}: already completed (R2={existing['summary']['avg_r2']:.4f})\")\n",
    "        return existing\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EXPERIMENT: {exp_id}\")\n",
    "    print(f\"Description: {description}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    fold_results = {}\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for fold in range(config['n_folds']):\n",
    "        ckpt_path = exp_checkpoint_dir / f\"fold{fold}_best.ckpt\"\n",
    "        \n",
    "        # Create datasets\n",
    "        train_ds = MERTDataset(mert_cache_dir, LABELS, FOLD_ASSIGNMENTS, fold, \"train\", config['max_frames'])\n",
    "        val_ds = MERTDataset(mert_cache_dir, LABELS, FOLD_ASSIGNMENTS, fold, \"val\", config['max_frames'])\n",
    "        \n",
    "        if len(train_ds) == 0 or len(val_ds) == 0:\n",
    "            print(f\"Fold {fold}: No data available, skipping\")\n",
    "            continue\n",
    "        \n",
    "        train_dl = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True,\n",
    "                              collate_fn=mert_collate_fn, num_workers=config['num_workers'], pin_memory=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=False,\n",
    "                            collate_fn=mert_collate_fn, num_workers=config['num_workers'], pin_memory=True)\n",
    "        \n",
    "        if ckpt_path.exists():\n",
    "            print(f\"Fold {fold}: Loading existing checkpoint\")\n",
    "            model = model_factory(config)\n",
    "            model = model.__class__.load_from_checkpoint(ckpt_path)\n",
    "        else:\n",
    "            print(f\"Fold {fold}: Training ({len(train_ds)} train, {len(val_ds)} val)\")\n",
    "            model = model_factory(config)\n",
    "            \n",
    "            callbacks = [\n",
    "                ModelCheckpoint(dirpath=exp_checkpoint_dir, filename=f'fold{fold}_best',\n",
    "                                monitor='val_r2', mode='max', save_top_k=1),\n",
    "                EarlyStopping(monitor='val_r2', mode='max', patience=config['patience'], verbose=True),\n",
    "            ]\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config['max_epochs'],\n",
    "                callbacks=callbacks,\n",
    "                logger=CSVLogger(save_dir=LOG_DIR, name=exp_id, version=f'fold{fold}'),\n",
    "                accelerator='auto', devices=1,\n",
    "                gradient_clip_val=config['gradient_clip_val'],\n",
    "                enable_progress_bar=True,\n",
    "                deterministic=True,\n",
    "                log_every_n_steps=10,\n",
    "            )\n",
    "            \n",
    "            trainer.fit(model, train_dl, val_dl)\n",
    "            fold_results[fold] = float(callbacks[0].best_model_score or 0)\n",
    "            \n",
    "            # Reload best\n",
    "            model = model.__class__.load_from_checkpoint(ckpt_path)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval().to('cuda')\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                pred = model(batch[\"embeddings\"].cuda(), batch[\"attention_mask\"].cuda(), batch.get(\"lengths\"))\n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "                all_labels.append(batch[\"labels\"].numpy())\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Aggregate results\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    metrics = compute_comprehensive_metrics(all_preds, all_labels)\n",
    "    \n",
    "    # If fold_results is empty (loaded from checkpoints), compute from metrics\n",
    "    if not fold_results:\n",
    "        fold_results = {i: metrics['overall_r2'] for i in range(4)}  # Approximate\n",
    "    \n",
    "    avg_r2 = np.mean(list(fold_results.values()))\n",
    "    std_r2 = np.std(list(fold_results.values()))\n",
    "    \n",
    "    results = {\n",
    "        \"experiment_id\": exp_id,\n",
    "        \"description\": description,\n",
    "        \"config\": config,\n",
    "        \"summary\": {\n",
    "            \"avg_r2\": float(avg_r2),\n",
    "            \"std_r2\": float(std_r2),\n",
    "            \"r2_ci_95\": metrics['r2_ci_95'],\n",
    "            \"overall_r2\": metrics['overall_r2'],\n",
    "            \"overall_mae\": metrics['overall_mae'],\n",
    "            \"dispersion_ratio\": metrics['dispersion_ratio'],\n",
    "        },\n",
    "        \"fold_results\": {str(k): float(v) for k, v in fold_results.items()},\n",
    "        \"per_dimension\": metrics['per_dimension'],\n",
    "        \"training_time_seconds\": time.time() - start_time,\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    with open(RESULTS_DIR / f\"{exp_id}.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{exp_id} COMPLETE: R2={avg_r2:.4f} +/- {std_r2:.4f}, CI=[{metrics['r2_ci_95'][0]:.4f}, {metrics['r2_ci_95'][1]:.4f}]\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_4fold_mel_experiment(exp_id: str, description: str, config: dict) -> dict:\n",
    "    \"\"\"Run 4-fold CV for Mel-CNN experiment.\"\"\"\n",
    "    exp_checkpoint_dir = CHECKPOINT_ROOT / exp_id\n",
    "    exp_checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    existing = load_existing_results(exp_id, RESULTS_DIR)\n",
    "    if existing and experiment_completed(exp_id, CHECKPOINT_ROOT):\n",
    "        print(f\"SKIP {exp_id}: already completed (R2={existing['summary']['avg_r2']:.4f})\")\n",
    "        return existing\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EXPERIMENT: {exp_id}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    fold_results = {}\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for fold in range(config['n_folds']):\n",
    "        ckpt_path = exp_checkpoint_dir / f\"fold{fold}_best.ckpt\"\n",
    "        \n",
    "        train_ds = MelDataset(MEL_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"train\")\n",
    "        val_ds = MelDataset(MEL_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"val\")\n",
    "        \n",
    "        train_dl = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True,\n",
    "                              collate_fn=mel_collate_fn, num_workers=config['num_workers'], pin_memory=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=False,\n",
    "                            collate_fn=mel_collate_fn, num_workers=config['num_workers'], pin_memory=True)\n",
    "        \n",
    "        if ckpt_path.exists():\n",
    "            model = MelCNNModel.load_from_checkpoint(ckpt_path)\n",
    "        else:\n",
    "            print(f\"Fold {fold}: Training\")\n",
    "            model = MelCNNModel(\n",
    "                hidden_dim=config['hidden_dim'],\n",
    "                learning_rate=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                max_epochs=config['max_epochs'],\n",
    "            )\n",
    "            \n",
    "            callbacks = [\n",
    "                ModelCheckpoint(dirpath=exp_checkpoint_dir, filename=f'fold{fold}_best',\n",
    "                                monitor='val_r2', mode='max', save_top_k=1),\n",
    "                EarlyStopping(monitor='val_r2', mode='max', patience=config['patience'], verbose=True),\n",
    "            ]\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config['max_epochs'],\n",
    "                callbacks=callbacks,\n",
    "                logger=CSVLogger(save_dir=LOG_DIR, name=exp_id, version=f'fold{fold}'),\n",
    "                accelerator='auto', devices=1,\n",
    "                gradient_clip_val=config['gradient_clip_val'],\n",
    "                enable_progress_bar=True,\n",
    "                deterministic=True,\n",
    "            )\n",
    "            \n",
    "            trainer.fit(model, train_dl, val_dl)\n",
    "            fold_results[fold] = float(callbacks[0].best_model_score or 0)\n",
    "            model = MelCNNModel.load_from_checkpoint(ckpt_path)\n",
    "        \n",
    "        model.eval().to('cuda')\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                pred = model(batch[\"mel\"].cuda())\n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "                all_labels.append(batch[\"labels\"].numpy())\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    metrics = compute_comprehensive_metrics(all_preds, all_labels)\n",
    "    \n",
    "    if not fold_results:\n",
    "        fold_results = {i: metrics['overall_r2'] for i in range(4)}\n",
    "    \n",
    "    avg_r2 = np.mean(list(fold_results.values()))\n",
    "    std_r2 = np.std(list(fold_results.values()))\n",
    "    \n",
    "    results = {\n",
    "        \"experiment_id\": exp_id,\n",
    "        \"description\": description,\n",
    "        \"summary\": {\n",
    "            \"avg_r2\": float(avg_r2),\n",
    "            \"std_r2\": float(std_r2),\n",
    "            \"r2_ci_95\": metrics['r2_ci_95'],\n",
    "            \"overall_r2\": metrics['overall_r2'],\n",
    "            \"overall_mae\": metrics['overall_mae'],\n",
    "            \"dispersion_ratio\": metrics['dispersion_ratio'],\n",
    "        },\n",
    "        \"fold_results\": {str(k): float(v) for k, v in fold_results.items()},\n",
    "        \"per_dimension\": metrics['per_dimension'],\n",
    "        \"training_time_seconds\": time.time() - start_time,\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / f\"{exp_id}.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{exp_id} COMPLETE: R2={avg_r2:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_4fold_stats_experiment(exp_id: str, description: str, config: dict) -> dict:\n",
    "    \"\"\"Run 4-fold CV for statistics MLP experiment.\"\"\"\n",
    "    exp_checkpoint_dir = CHECKPOINT_ROOT / exp_id\n",
    "    exp_checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    existing = load_existing_results(exp_id, RESULTS_DIR)\n",
    "    if existing and experiment_completed(exp_id, CHECKPOINT_ROOT):\n",
    "        print(f\"SKIP {exp_id}: already completed (R2={existing['summary']['avg_r2']:.4f})\")\n",
    "        return existing\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EXPERIMENT: {exp_id}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    fold_results = {}\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for fold in range(config['n_folds']):\n",
    "        ckpt_path = exp_checkpoint_dir / f\"fold{fold}_best.ckpt\"\n",
    "        \n",
    "        train_ds = StatsDataset(STATS_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"train\")\n",
    "        val_ds = StatsDataset(STATS_CACHE_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"val\")\n",
    "        \n",
    "        train_dl = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True,\n",
    "                              collate_fn=stats_collate_fn, num_workers=config['num_workers'], pin_memory=True)\n",
    "        val_dl = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=False,\n",
    "                            collate_fn=stats_collate_fn, num_workers=config['num_workers'], pin_memory=True)\n",
    "        \n",
    "        if ckpt_path.exists():\n",
    "            model = StatsMLPModel.load_from_checkpoint(ckpt_path)\n",
    "        else:\n",
    "            print(f\"Fold {fold}: Training\")\n",
    "            model = StatsMLPModel(\n",
    "                input_dim=49,\n",
    "                hidden_dim=256,\n",
    "                learning_rate=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                max_epochs=config['max_epochs'],\n",
    "            )\n",
    "            \n",
    "            callbacks = [\n",
    "                ModelCheckpoint(dirpath=exp_checkpoint_dir, filename=f'fold{fold}_best',\n",
    "                                monitor='val_r2', mode='max', save_top_k=1),\n",
    "                EarlyStopping(monitor='val_r2', mode='max', patience=config['patience'], verbose=True),\n",
    "            ]\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=config['max_epochs'],\n",
    "                callbacks=callbacks,\n",
    "                logger=CSVLogger(save_dir=LOG_DIR, name=exp_id, version=f'fold{fold}'),\n",
    "                accelerator='auto', devices=1,\n",
    "                gradient_clip_val=config['gradient_clip_val'],\n",
    "                enable_progress_bar=True,\n",
    "                deterministic=True,\n",
    "            )\n",
    "            \n",
    "            trainer.fit(model, train_dl, val_dl)\n",
    "            fold_results[fold] = float(callbacks[0].best_model_score or 0)\n",
    "            model = StatsMLPModel.load_from_checkpoint(ckpt_path)\n",
    "        \n",
    "        model.eval().to('cuda')\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                pred = model(batch[\"features\"].cuda())\n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "                all_labels.append(batch[\"labels\"].numpy())\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    metrics = compute_comprehensive_metrics(all_preds, all_labels)\n",
    "    \n",
    "    if not fold_results:\n",
    "        fold_results = {i: metrics['overall_r2'] for i in range(4)}\n",
    "    \n",
    "    avg_r2 = np.mean(list(fold_results.values()))\n",
    "    std_r2 = np.std(list(fold_results.values()))\n",
    "    \n",
    "    results = {\n",
    "        \"experiment_id\": exp_id,\n",
    "        \"description\": description,\n",
    "        \"summary\": {\n",
    "            \"avg_r2\": float(avg_r2),\n",
    "            \"std_r2\": float(std_r2),\n",
    "            \"r2_ci_95\": metrics['r2_ci_95'],\n",
    "            \"overall_r2\": metrics['overall_r2'],\n",
    "            \"overall_mae\": metrics['overall_mae'],\n",
    "            \"dispersion_ratio\": metrics['dispersion_ratio'],\n",
    "        },\n",
    "        \"fold_results\": {str(k): float(v) for k, v in fold_results.items()},\n",
    "        \"per_dimension\": metrics['per_dimension'],\n",
    "        \"training_time_seconds\": time.time() - start_time,\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / f\"{exp_id}.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{exp_id} COMPLETE: R2={avg_r2:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Training functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: B0 - Baseline Re-run\n",
    "# Get all valid keys\n",
    "ALL_KEYS = list(LABELS.keys())\n",
    "\n",
    "# Ensure default MERT cache exists\n",
    "extract_mert_for_layer_range(13, 25, AUDIO_DIR, DEFAULT_MERT_DIR, ALL_KEYS)\n",
    "\n",
    "# Run baseline\n",
    "config_b0 = BASE_CONFIG.copy()\n",
    "config_b0['pooling'] = 'mean'\n",
    "config_b0['loss_type'] = 'mse'\n",
    "\n",
    "def model_factory_b0(cfg):\n",
    "    return BaseMERTModel(\n",
    "        input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'], pooling=cfg['pooling'],\n",
    "        loss_type=cfg['loss_type'], max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "ALL_RESULTS['B0_baseline'] = run_4fold_mert_experiment(\n",
    "    'B0_baseline', 'MERT+MLP, L13-24, mean pooling (baseline)',\n",
    "    model_factory_b0, DEFAULT_MERT_DIR, config_b0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: A1 - Linear Probe\n",
    "config_a1 = BASE_CONFIG.copy()\n",
    "\n",
    "def model_factory_a1(cfg):\n",
    "    return LinearProbeModel(\n",
    "        input_dim=cfg['input_dim'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "ALL_RESULTS['A1_linear_probe'] = run_4fold_mert_experiment(\n",
    "    'A1_linear_probe', 'Linear probe on MERT (L13-24)',\n",
    "    model_factory_a1, DEFAULT_MERT_DIR, config_a1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: A2 - Mel-CNN (extraction)\n",
    "print(\"Extracting mel spectrograms...\")\n",
    "extract_mel_spectrograms(AUDIO_DIR, MEL_CACHE_DIR, ALL_KEYS)\n",
    "print(f\"Mel cache: {len(list(MEL_CACHE_DIR.glob('*.pt')))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: A2 - Mel-CNN (training)\n",
    "config_a2 = BASE_CONFIG.copy()\n",
    "\n",
    "ALL_RESULTS['A2_mel_cnn'] = run_4fold_mel_experiment(\n",
    "    'A2_mel_cnn', '4-layer CNN on mel spectrograms',\n",
    "    config_a2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: A3 - Raw Statistics (extraction)\n",
    "print(\"Extracting audio statistics...\")\n",
    "extract_statistics_for_all(AUDIO_DIR, STATS_CACHE_DIR, ALL_KEYS)\n",
    "print(f\"Stats cache: {len(list(STATS_CACHE_DIR.glob('*.pt')))} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: A3 - Raw Statistics (training)\n",
    "config_a3 = BASE_CONFIG.copy()\n",
    "\n",
    "ALL_RESULTS['A3_raw_stats'] = run_4fold_stats_experiment(\n",
    "    'A3_raw_stats', 'MLP on hand-crafted audio statistics (49-dim)',\n",
    "    config_a3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: B1a - Layers 1-6\n",
    "L1_6_DIR = MERT_CACHE_ROOT / 'L1-6'\n",
    "extract_mert_for_layer_range(1, 7, AUDIO_DIR, L1_6_DIR, ALL_KEYS)\n",
    "\n",
    "config_b1a = BASE_CONFIG.copy()\n",
    "config_b1a['pooling'] = 'mean'\n",
    "config_b1a['loss_type'] = 'mse'\n",
    "\n",
    "ALL_RESULTS['B1a_layers_1-6'] = run_4fold_mert_experiment(\n",
    "    'B1a_layers_1-6', 'MERT layers 1-6 (early/acoustic)',\n",
    "    model_factory_b0, L1_6_DIR, config_b1a\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: B1b - Layers 7-12\n",
    "L7_12_DIR = MERT_CACHE_ROOT / 'L7-12'\n",
    "extract_mert_for_layer_range(7, 13, AUDIO_DIR, L7_12_DIR, ALL_KEYS)\n",
    "\n",
    "config_b1b = BASE_CONFIG.copy()\n",
    "config_b1b['pooling'] = 'mean'\n",
    "config_b1b['loss_type'] = 'mse'\n",
    "\n",
    "ALL_RESULTS['B1b_layers_7-12'] = run_4fold_mert_experiment(\n",
    "    'B1b_layers_7-12', 'MERT layers 7-12 (mid)',\n",
    "    model_factory_b0, L7_12_DIR, config_b1b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: B1c - Layers 13-24 (sanity check, should match B0)\n",
    "# Uses same cache as B0, just verifying\n",
    "config_b1c = BASE_CONFIG.copy()\n",
    "config_b1c['pooling'] = 'mean'\n",
    "config_b1c['loss_type'] = 'mse'\n",
    "\n",
    "ALL_RESULTS['B1c_layers_13-24'] = run_4fold_mert_experiment(\n",
    "    'B1c_layers_13-24', 'MERT layers 13-24 (late/semantic)',\n",
    "    model_factory_b0, DEFAULT_MERT_DIR, config_b1c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: B1d - All Layers 1-24\n",
    "L1_24_DIR = MERT_CACHE_ROOT / 'L1-24'\n",
    "extract_mert_for_layer_range(1, 25, AUDIO_DIR, L1_24_DIR, ALL_KEYS)\n",
    "\n",
    "config_b1d = BASE_CONFIG.copy()\n",
    "config_b1d['pooling'] = 'mean'\n",
    "config_b1d['loss_type'] = 'mse'\n",
    "\n",
    "ALL_RESULTS['B1d_layers_1-24'] = run_4fold_mert_experiment(\n",
    "    'B1d_layers_1-24', 'MERT all layers 1-24',\n",
    "    model_factory_b0, L1_24_DIR, config_b1d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: B2a - Max Pooling\n",
    "config_b2a = BASE_CONFIG.copy()\n",
    "config_b2a['pooling'] = 'max'\n",
    "config_b2a['loss_type'] = 'mse'\n",
    "\n",
    "def model_factory_max(cfg):\n",
    "    return BaseMERTModel(\n",
    "        input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'], pooling='max',\n",
    "        loss_type=cfg['loss_type'], max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "ALL_RESULTS['B2a_max_pool'] = run_4fold_mert_experiment(\n",
    "    'B2a_max_pool', 'MERT + max pooling',\n",
    "    model_factory_max, DEFAULT_MERT_DIR, config_b2a\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: B2b - Attention Pooling\n",
    "config_b2b = BASE_CONFIG.copy()\n",
    "config_b2b['pooling'] = 'attention'\n",
    "config_b2b['loss_type'] = 'mse'\n",
    "\n",
    "def model_factory_attn(cfg):\n",
    "    return BaseMERTModel(\n",
    "        input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'], pooling='attention',\n",
    "        loss_type=cfg['loss_type'], max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "ALL_RESULTS['B2b_attention_pool'] = run_4fold_mert_experiment(\n",
    "    'B2b_attention_pool', 'MERT + attention pooling',\n",
    "    model_factory_attn, DEFAULT_MERT_DIR, config_b2b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: B2c - LSTM Pooling\n",
    "config_b2c = BASE_CONFIG.copy()\n",
    "config_b2c['pooling'] = 'lstm'\n",
    "config_b2c['loss_type'] = 'mse'\n",
    "\n",
    "def model_factory_lstm(cfg):\n",
    "    return BaseMERTModel(\n",
    "        input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'], pooling='lstm',\n",
    "        loss_type=cfg['loss_type'], max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "ALL_RESULTS['B2c_lstm_pool'] = run_4fold_mert_experiment(\n",
    "    'B2c_lstm_pool', 'MERT + Bi-LSTM + attention pooling',\n",
    "    model_factory_lstm, DEFAULT_MERT_DIR, config_b2c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: C1a - Hybrid Loss (MSE + CCC)\n",
    "config_c1a = BASE_CONFIG.copy()\n",
    "config_c1a['pooling'] = 'mean'\n",
    "config_c1a['loss_type'] = 'hybrid'\n",
    "\n",
    "def model_factory_hybrid(cfg):\n",
    "    return BaseMERTModel(\n",
    "        input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'], pooling='mean',\n",
    "        loss_type='hybrid', max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "ALL_RESULTS['C1a_hybrid_loss'] = run_4fold_mert_experiment(\n",
    "    'C1a_hybrid_loss', 'MERT + MSE + 0.5*CCC loss',\n",
    "    model_factory_hybrid, DEFAULT_MERT_DIR, config_c1a\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 27: C1b - Pure CCC Loss\n",
    "config_c1b = BASE_CONFIG.copy()\n",
    "config_c1b['pooling'] = 'mean'\n",
    "config_c1b['loss_type'] = 'ccc'\n",
    "\n",
    "def model_factory_ccc(cfg):\n",
    "    return BaseMERTModel(\n",
    "        input_dim=cfg['input_dim'], hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'], learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'], pooling='mean',\n",
    "        loss_type='ccc', max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "ALL_RESULTS['C1b_pure_ccc'] = run_4fold_mert_experiment(\n",
    "    'C1b_pure_ccc', 'MERT + pure CCC loss',\n",
    "    model_factory_ccc, DEFAULT_MERT_DIR, config_c1b\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: Aggregate and display results\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2 RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get baseline R2 for comparison\n",
    "baseline_r2 = ALL_RESULTS.get('B0_baseline', {}).get('summary', {}).get('avg_r2', 0)\n",
    "\n",
    "print(f\"{'Experiment':<25} {'Avg R2':>10} {'95% CI':>20} {'vs B0':>10} {'Disp':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Order of experiments\n",
    "exp_order = [\n",
    "    ('B0_baseline', 'B0: Baseline'),\n",
    "    (None, '-' * 60),\n",
    "    ('A1_linear_probe', 'A1: Linear Probe'),\n",
    "    ('A2_mel_cnn', 'A2: Mel-CNN'),\n",
    "    ('A3_raw_stats', 'A3: Raw Statistics'),\n",
    "    (None, '-' * 60),\n",
    "    ('B1a_layers_1-6', 'B1a: Layers 1-6'),\n",
    "    ('B1b_layers_7-12', 'B1b: Layers 7-12'),\n",
    "    ('B1c_layers_13-24', 'B1c: Layers 13-24'),\n",
    "    ('B1d_layers_1-24', 'B1d: Layers 1-24'),\n",
    "    (None, '-' * 60),\n",
    "    ('B2a_max_pool', 'B2a: Max Pooling'),\n",
    "    ('B2b_attention_pool', 'B2b: Attention Pool'),\n",
    "    ('B2c_lstm_pool', 'B2c: LSTM Pool'),\n",
    "    (None, '-' * 60),\n",
    "    ('C1a_hybrid_loss', 'C1a: Hybrid Loss'),\n",
    "    ('C1b_pure_ccc', 'C1b: Pure CCC'),\n",
    "]\n",
    "\n",
    "for exp_id, label in exp_order:\n",
    "    if exp_id is None:\n",
    "        print(label)\n",
    "        continue\n",
    "    \n",
    "    if exp_id not in ALL_RESULTS:\n",
    "        print(f\"{label:<25} {'N/A':>10}\")\n",
    "        continue\n",
    "    \n",
    "    r = ALL_RESULTS[exp_id]\n",
    "    s = r['summary']\n",
    "    avg_r2 = s['avg_r2']\n",
    "    ci = s.get('r2_ci_95', [0, 0])\n",
    "    disp = s.get('dispersion_ratio', 0)\n",
    "    diff = avg_r2 - baseline_r2 if exp_id != 'B0_baseline' else 0\n",
    "    diff_str = f\"{diff:+.3f}\" if exp_id != 'B0_baseline' else '---'\n",
    "    \n",
    "    print(f\"{label:<25} {avg_r2:>10.4f} [{ci[0]:.3f}, {ci[1]:.3f}] {diff_str:>10} {disp:>8.2f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Key findings\n",
    "print(\"\\nKEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# MLP necessary?\n",
    "if 'A1_linear_probe' in ALL_RESULTS and 'B0_baseline' in ALL_RESULTS:\n",
    "    linear_r2 = ALL_RESULTS['A1_linear_probe']['summary']['avg_r2']\n",
    "    mlp_r2 = ALL_RESULTS['B0_baseline']['summary']['avg_r2']\n",
    "    print(f\"MLP necessary: Linear R2={linear_r2:.4f} vs MLP R2={mlp_r2:.4f} (diff={mlp_r2-linear_r2:+.4f})\")\n",
    "\n",
    "# MERT necessary?\n",
    "if 'A2_mel_cnn' in ALL_RESULTS and 'B0_baseline' in ALL_RESULTS:\n",
    "    mel_r2 = ALL_RESULTS['A2_mel_cnn']['summary']['avg_r2']\n",
    "    mert_r2 = ALL_RESULTS['B0_baseline']['summary']['avg_r2']\n",
    "    print(f\"MERT necessary: Mel-CNN R2={mel_r2:.4f} vs MERT R2={mert_r2:.4f} (diff={mert_r2-mel_r2:+.4f})\")\n",
    "\n",
    "# Best layers\n",
    "layer_exps = ['B1a_layers_1-6', 'B1b_layers_7-12', 'B1c_layers_13-24', 'B1d_layers_1-24']\n",
    "layer_results = [(e, ALL_RESULTS[e]['summary']['avg_r2']) for e in layer_exps if e in ALL_RESULTS]\n",
    "if layer_results:\n",
    "    best_layer = max(layer_results, key=lambda x: x[1])\n",
    "    print(f\"Best layers: {best_layer[0]} (R2={best_layer[1]:.4f})\")\n",
    "\n",
    "# Best pooling\n",
    "pool_exps = ['B0_baseline', 'B2a_max_pool', 'B2b_attention_pool', 'B2c_lstm_pool']\n",
    "pool_results = [(e, ALL_RESULTS[e]['summary']['avg_r2']) for e in pool_exps if e in ALL_RESULTS]\n",
    "if pool_results:\n",
    "    best_pool = max(pool_results, key=lambda x: x[1])\n",
    "    print(f\"Best pooling: {best_pool[0]} (R2={best_pool[1]:.4f})\")\n",
    "\n",
    "# Best loss (dispersion improvement)\n",
    "loss_exps = ['B0_baseline', 'C1a_hybrid_loss', 'C1b_pure_ccc']\n",
    "loss_results = [(e, ALL_RESULTS[e]['summary'].get('dispersion_ratio', 0)) for e in loss_exps if e in ALL_RESULTS]\n",
    "if loss_results:\n",
    "    best_loss = max(loss_results, key=lambda x: x[1])\n",
    "    baseline_disp = ALL_RESULTS.get('B0_baseline', {}).get('summary', {}).get('dispersion_ratio', 0)\n",
    "    print(f\"Best loss for dispersion: {best_loss[0]} (disp={best_loss[1]:.2f} vs baseline {baseline_disp:.2f})\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 30: Save and sync results\n",
    "# Save aggregated results\n",
    "all_results_file = RESULTS_DIR / 'phase2_all_results.json'\n",
    "with open(all_results_file, 'w') as f:\n",
    "    json.dump(ALL_RESULTS, f, indent=2)\n",
    "print(f\"Saved: {all_results_file}\")\n",
    "\n",
    "# Sync to Google Drive\n",
    "print(\"\\nSyncing results to Google Drive...\")\n",
    "run_rclone(['rclone', 'copy', str(RESULTS_DIR), GDRIVE_RESULTS, '-v'], \"Syncing results\")\n",
    "run_rclone(['rclone', 'copy', str(CHECKPOINT_ROOT), f\"{GDRIVE_RESULTS}/checkpoints\", '-v'], \"Syncing checkpoints\")\n",
    "run_rclone(['rclone', 'copy', str(LOG_DIR), f\"{GDRIVE_RESULTS}/logs\", '-v'], \"Syncing logs\")\n",
    "\n",
    "# Also sync MERT caches for reproducibility\n",
    "for layer_dir in MERT_CACHE_ROOT.iterdir():\n",
    "    if layer_dir.is_dir():\n",
    "        run_rclone(['rclone', 'copy', str(layer_dir), f\"{GDRIVE_RESULTS}/mert_cache/{layer_dir.name}\", '-v'],\n",
    "                   f\"Syncing MERT cache {layer_dir.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2 EXPERIMENTS COMPLETE\")\n",
    "print(f\"Results: {GDRIVE_RESULTS}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
