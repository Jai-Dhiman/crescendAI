{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piano Performance Evaluation - Full Model Training\n",
    "\n",
    "Trains the complete multi-modal performance evaluation model on MAESTRO synthetic labels.\n",
    "\n",
    "**Current Dimensions**: 6 technical dimensions (note_accuracy, rhythmic_precision, dynamics_control, articulation, pedaling, tone_quality)\n",
    "\n",
    "**Future Expansion**: 4 interpretive dimensions will be added after expert labeling (phrasing, expressiveness, musicality, overall_quality)\n",
    "\n",
    "**Requirements:**\n",
    "- Colab Pro (T4/V100 GPU recommended)\n",
    "- Google Drive with segments and labels uploaded\n",
    "- HuggingFace account for MERT model access\n",
    "- crescendai repository on GitHub\n",
    "\n",
    "**Expected Training Time**: ~8-12 GPU hours on T4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Expected Google Drive Structure\n\nData and checkpoints are stored in **MyDrive**:\n\n```\nMyDrive/\n  crescendai_data/\n    all_segments/                        # Audio segments (~65GB)\n      *.wav                              # MAESTRO segments\n      midi_segments/                     # MIDI segments\n        *.mid\n    annotations/                         # Annotation files (FILTERED)\n      synthetic_train_filtered.jsonl     # ~92k training samples (cleaned)\n      synthetic_val_filtered.jsonl       # ~17k validation samples (cleaned)\n      synthetic_test_filtered.jsonl      # ~6k test samples (cleaned)\n\n  crescendai_checkpoints/                # Checkpoints saved DIRECTLY here (persistent)\n    *.ckpt\n```\n\n**Important Notes:**\n- Checkpoints are saved **directly to Google Drive** (persistent across sessions)\n- Training will automatically **resume from the latest checkpoint** if one exists\n- Filtered annotation files must exist before training (run filtering script once)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace Login\n",
    "import os\n",
    "os.environ.pop(\"HF_TOKEN\", None)\n",
    "os.environ.pop(\"HUGGINGFACEHUB_API_TOKEN\", None)\n",
    "\n",
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "try:\n",
    "    import getpass as gp\n",
    "    raw = gp.getpass(\"Paste your Hugging Face token (input hidden): \")\n",
    "    token = raw.decode() if isinstance(raw, (bytes, bytearray)) else raw\n",
    "    if not isinstance(token, str):\n",
    "        raise TypeError(f\"Unexpected token type: {type(token).__name__}\")\n",
    "    token = token.strip()\n",
    "    if not token:\n",
    "        raise ValueError(\"Empty token provided\")\n",
    "    login(token=token, add_to_git_credential=False)\n",
    "    who = HfApi().whoami(token=token)\n",
    "    print(f\"✓ Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
    "except Exception as e:\n",
    "    print(f\"[HF Login] getpass flow failed: {e}\")\n",
    "    print(\"Falling back to interactive login widget...\")\n",
    "    login()\n",
    "    try:\n",
    "        who = HfApi().whoami()\n",
    "        print(f\"✓ Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"[HF Login] Verification skipped: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Load data from MyDrive\nimport os\nfrom pathlib import Path\n\nprint(\"Loading data from Google Drive MyDrive...\\n\")\n\n# Data location (all in MyDrive for reliable access)\nGDRIVE_ROOT = '/content/drive/MyDrive/crescendai_data'\nDATA_ROOT = f'{GDRIVE_ROOT}/all_segments'\nANNOTATIONS_ROOT = f'{GDRIVE_ROOT}/annotations'\n\n# PRODUCTION FIX: Save checkpoints DIRECTLY to Google Drive (persistent across sessions)\nCHECKPOINT_ROOT = '/content/drive/MyDrive/crescendai_checkpoints'\nLOGS_ROOT = '/content/logs'\n\nprint(f\"Data paths:\")\nprint(f\"  Audio segments: {DATA_ROOT}\")\nprint(f\"  Annotations: {ANNOTATIONS_ROOT}\")\nprint(f\"  Checkpoints: {CHECKPOINT_ROOT} (Google Drive - PERSISTENT)\")\nprint(f\"  Logs: {LOGS_ROOT}\\n\")\n\n# Verify structure\nrequired_paths = [\n    (DATA_ROOT, \"Audio segments directory\"),\n    (ANNOTATIONS_ROOT, \"Annotations directory\"),\n    (f\"{ANNOTATIONS_ROOT}/synthetic_train_filtered.jsonl\", \"Training annotations (filtered)\"),\n    (f\"{ANNOTATIONS_ROOT}/synthetic_val_filtered.jsonl\", \"Validation annotations (filtered)\"),\n    (f\"{ANNOTATIONS_ROOT}/synthetic_test_filtered.jsonl\", \"Test annotations (filtered)\"),\n]\n\nprint(\"Verifying structure...\\n\")\nall_good = True\nfor path, desc in required_paths:\n    if os.path.exists(path):\n        print(f\"✓ {desc}: {path}\")\n    else:\n        print(f\"✗ {desc} NOT FOUND: {path}\")\n        all_good = False\n\n# Create checkpoint and logs directories\nos.makedirs(CHECKPOINT_ROOT, exist_ok=True)\nos.makedirs(LOGS_ROOT, exist_ok=True)\n\n# Check for existing checkpoints (for resume)\nexisting_checkpoints = list(Path(CHECKPOINT_ROOT).glob('*.ckpt'))\nif existing_checkpoints:\n    print(f\"\\n✓ Found {len(existing_checkpoints)} existing checkpoint(s) - training can resume\")\n    for ckpt in existing_checkpoints[:3]:  # Show first 3\n        print(f\"  - {ckpt.name}\")\nelse:\n    print(f\"\\n✓ No existing checkpoints - will start fresh training\")\n\nif not all_good:\n    print(\"\\n\" + \"=\"*70)\n    print(\"ERROR: Google Drive structure incomplete\")\n    print(\"=\"*70)\n    print(\"\\nExpected location: MyDrive/crescendai_data/\")\n    print(\"  all_segments/\")\n    print(\"  annotations/synthetic_train_filtered.jsonl\")\n    print(\"  annotations/synthetic_val_filtered.jsonl\")\n    print(\"  annotations/synthetic_test_filtered.jsonl\")\n    print(\"\\nPlease make sure you have run the filtering script to create\")\n    print(\"the filtered annotation files and uploaded them to Google Drive.\")\n    print(\"=\"*70)\n    raise RuntimeError(\"Google Drive structure incomplete. Please check sync.\")\nelse:\n    print(\"\\n✓ All required files present. Ready to proceed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "REPO_URL = \"https://github.com/Jai-Dhiman/crescendai.git\"\n",
    "BRANCH = \"main\"\n",
    "\n",
    "# Remove old clone if exists\n",
    "!rm -rf /content/crescendai\n",
    "\n",
    "# Clone fresh\n",
    "!git clone --branch {BRANCH} {REPO_URL} /content/crescendai\n",
    "\n",
    "# Navigate to model directory\n",
    "%cd /content/crescendai/model\n",
    "\n",
    "# Show git status\n",
    "print(\"\\nRepository status:\")\n",
    "!git log -1 --oneline\n",
    "!git status --short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Add to PATH for this session\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "print(\"\\n✓ uv installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\nprint(\"Installing dependencies (this may take 2-3 minutes)...\\n\")\n!uv pip install --system -e .\n\n# Verify installation\nimport os\nos.environ['MPLBACKEND'] = 'Agg'  # Non-interactive backend for matplotlib\n\nimport torch\nimport pytorch_lightning as pl\nimport warnings\n\n# Suppress MIDI divide-by-zero warnings (harmless - empty MIDI files)\nwarnings.filterwarnings('ignore', message='divide by zero encountered in scalar divide')\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"✓ Dependencies installed successfully\")\nprint(\"=\"*70)\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"Lightning: {pl.__version__}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify GPU and Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"\\n✓ GPU READY FOR TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"⚠️  CRITICAL: NO GPU DETECTED!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nTraining on CPU will be EXTREMELY SLOW (200x slower than GPU).\")\n",
    "    print(\"\\nTO ENABLE GPU:\")\n",
    "    print(\"1. Go to: Runtime → Change runtime type\")\n",
    "    print(\"2. Set 'Hardware accelerator' to: T4 GPU\")\n",
    "    print(\"3. Click 'Save'\")\n",
    "    print(\"4. Re-run all cells from the beginning\")\n",
    "    print(\"\\nDO NOT proceed with training until GPU is enabled!\")\n",
    "    print(\"=\"*70)\n",
    "    raise RuntimeError(\"GPU required for training. Please enable GPU and restart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MERT model (one-time, will be cached)\n",
    "from transformers import AutoModel\n",
    "\n",
    "print(\"Downloading MERT-95M model (one-time, ~380MB)...\")\n",
    "print(\"This will be cached for future use.\\n\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"m-a-p/MERT-v1-95M\", trust_remote_code=True)\n",
    "num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "\n",
    "print(f\"✓ MERT-95M downloaded and cached\")\n",
    "print(f\"  Parameters: {num_params:.1f}M\")\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Training Configuration\n",
    "\n",
    "This creates a config file with paths pointing to your Google Drive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import yaml\n\n# Training configuration\nconfig = {\n    'data': {\n        # Paths to FILTERED annotation files on Google Drive\n        'train_path': f'{ANNOTATIONS_ROOT}/synthetic_train_filtered.jsonl',\n        'val_path': f'{ANNOTATIONS_ROOT}/synthetic_val_filtered.jsonl',\n        'test_path': f'{ANNOTATIONS_ROOT}/synthetic_test_filtered.jsonl',\n        \n        # Current dimensions (6 technical)\n        'dimensions': [\n            'note_accuracy',\n            'rhythmic_precision',\n            'dynamics_control',\n            'articulation',\n            'pedaling',\n            'tone_quality'\n        ],\n        \n        # Audio settings (MERT requirements)\n        'audio_sample_rate': 24000,\n        'max_audio_length': 240000,  # 10 seconds at 24kHz\n        'max_midi_events': 512,\n        \n        # DataLoader settings\n        'batch_size': 8,\n        'num_workers': 0,  # MUST be 0 for Google Drive (prevents concurrent access errors)\n        'pin_memory': True,\n        \n        # Augmentation (training robustness)\n        'augmentation': {\n            'enabled': True,\n            'pitch_shift': {\n                'enabled': True,\n                'probability': 0.3,\n                'min_semitones': -2,\n                'max_semitones': 2\n            },\n            'time_stretch': {\n                'enabled': True,\n                'probability': 0.3,\n                'min_rate': 0.85,\n                'max_rate': 1.15\n            },\n            'add_noise': {\n                'enabled': True,\n                'probability': 0.2,\n                'min_snr_db': 25,\n                'max_snr_db': 40\n            },\n            'room_acoustics': {\n                'enabled': True,\n                'probability': 0.2,\n                'num_room_types': 5\n            },\n            'compress_audio': {\n                'enabled': True,\n                'probability': 0.15,\n                'bitrates': [128, 192, 256, 320]\n            },\n            'gain_variation': {\n                'enabled': True,\n                'probability': 0.3,\n                'min_db': -6,\n                'max_db': 6\n            },\n            'max_transforms': 3\n        }\n    },\n    \n    'model': {\n        # Architecture dimensions\n        'audio_dim': 768,\n        'midi_dim': 256,\n        'fusion_dim': 1024,\n        'aggregator_dim': 512,\n        'num_dimensions': 6,\n        \n        # Encoder settings\n        'mert_model_name': 'm-a-p/MERT-v1-95M',\n        'freeze_audio_encoder': False,\n        'gradient_checkpointing': True,\n        \n        # MIDI encoder\n        'midi_hidden_size': 256,\n        'midi_num_layers': 6,\n        'midi_num_heads': 4,\n        \n        # Fusion\n        'fusion_num_heads': 8,\n        'fusion_dropout': 0.1,\n        \n        # Aggregator\n        'lstm_hidden': 256,\n        'lstm_layers': 2,\n        'attention_heads': 4,\n        'aggregator_dropout': 0.2,\n        \n        # Task heads\n        'shared_hidden': 256,\n        'task_hidden': 128,\n        'mtl_dropout': 0.1\n    },\n    \n    'training': {\n        # Training duration\n        'max_epochs': 18,\n        'precision': 16,  # Mixed precision (FP16) for speed\n        \n        # Optimization\n        'optimizer': 'AdamW',\n        'learning_rate': 1e-5,\n        'backbone_lr': 1e-5,  # Lower LR for pre-trained MERT\n        'heads_lr': 1e-4,     # Higher LR for task heads\n        'weight_decay': 0.01,\n        \n        # Learning rate schedule\n        'scheduler': 'cosine',\n        'warmup_steps': 500,\n        'min_lr': 1e-6,\n        \n        # Gradient settings\n        'gradient_clip_val': 1.0,\n        'accumulate_grad_batches': 4,  # Effective batch size = 8 * 4 = 32\n        \n        # Validation\n        'val_check_interval': 1.0,  # Check every epoch\n        'limit_val_batches': 1.0,   # Use full val set\n        'track_correlations': True\n    },\n    \n    'callbacks': {\n        # Model checkpointing\n        'checkpoint': {\n            'monitor': 'val_loss',\n            'mode': 'min',\n            'save_top_k': 3,\n            'save_last': True,\n            'dirpath': CHECKPOINT_ROOT,\n            'filename': 'model-{epoch:02d}-{val_loss:.4f}'\n        },\n        \n        # Early stopping\n        'early_stopping': {\n            'monitor': 'val_loss',\n            'mode': 'min',\n            'patience': 5,\n            'min_delta': 0.001\n        },\n        \n        # Learning rate monitoring\n        'lr_monitor': {\n            'logging_interval': 'step'\n        }\n    },\n    \n    'logging': {\n        # Logging frequency\n        'log_every_n_steps': 50,\n        \n        # WandB (optional)\n        'use_wandb': False,\n        'wandb_project': 'piano-eval',\n        'wandb_entity': None,\n        'wandb_run_name': 'full-model',\n        \n        # TensorBoard\n        'use_tensorboard': True,\n        'tensorboard_logdir': LOGS_ROOT\n    },\n    \n    'seed': 42\n}\n\n# Save config\nCONFIG_PATH = '/tmp/training_config.yaml'\nwith open(CONFIG_PATH, 'w') as f:\n    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n\nprint(\"=\"*70)\nprint(\"✓ Training configuration created\")\nprint(\"=\"*70)\nprint(f\"Config saved to: {CONFIG_PATH}\")\nprint(f\"\\nTraining Summary:\")\nprint(f\"  Dimensions: {len(config['data']['dimensions'])}\")\nprint(f\"  Batch size: {config['data']['batch_size']}\")\nprint(f\"  Num workers: {config['data']['num_workers']} (0 = sequential loading for Google Drive)\")\nprint(f\"  Gradient accumulation: {config['training']['accumulate_grad_batches']}\")\nprint(f\"  Effective batch size: {config['data']['batch_size'] * config['training']['accumulate_grad_batches']}\")\nprint(f\"  Max epochs: {config['training']['max_epochs']}\")\nprint(f\"  Precision: FP{config['training']['precision']}\")\nprint(f\"\\nCheckpoints: {config['callbacks']['checkpoint']['dirpath']} (Google Drive)\")\nprint(f\"TensorBoard: {config['logging']['tensorboard_logdir']}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre-flight Check (Optional but Recommended)\n",
    "\n",
    "Verifies everything is set up correctly before starting training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pre-flight check\n",
    "print(\"Running pre-flight check...\\n\")\n",
    "!python preflight_check.py --config {CONFIG_PATH} --skip-model --skip-dataloader\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"If all checks passed, proceed to training below.\")\n",
    "print(\"If any issues found, fix them before training.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training\n",
    "\n",
    "**Expected duration**: ~8-12 hours on T4 GPU for 20 epochs\n",
    "\n",
    "Training will automatically:\n",
    "- Save checkpoints to Google Drive (persistent)\n",
    "- Log metrics to TensorBoard\n",
    "- Stop early if validation loss plateaus\n",
    "- Resume from checkpoint if interrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Start training\nfrom pathlib import Path\n\nprint(\"=\"*70)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*70)\nprint(\"\\nThis will take ~8-12 hours on T4 GPU.\")\nprint(\"Checkpoints saved directly to Google Drive (persistent).\")\nprint(\"Safe to close browser - training continues in background.\")\nprint(\"\\nPress Ctrl+C to stop (will save checkpoint).\\n\")\n\n# Check for existing checkpoint to resume from\nexisting_checkpoints = sorted(Path(CHECKPOINT_ROOT).glob('*.ckpt'))\nresume_arg = \"\"\nif existing_checkpoints:\n    latest_ckpt = existing_checkpoints[-1]  # Get most recent\n    print(f\"✓ Found checkpoint: {latest_ckpt.name}\")\n    print(f\"  Training will RESUME from this checkpoint\\n\")\n    resume_arg = f\"--checkpoint {latest_ckpt}\"\nelse:\n    print(\"✓ No checkpoint found - starting fresh training\\n\")\n\nprint(\"=\"*70 + \"\\n\")\n\n!python train.py --config {CONFIG_PATH} {resume_arg}\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"✓ TRAINING COMPLETE\")\nprint(\"=\"*70)\nprint(f\"Checkpoints saved to: {config['callbacks']['checkpoint']['dirpath']}\")\nprint(f\"Logs saved to: {config['logging']['tensorboard_logdir']}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Load TensorBoard\n%load_ext tensorboard\n%tensorboard --logdir {LOGS_ROOT}\n\nprint(\"\\nTensorBoard is now running above.\")\nprint(\"Monitor:\")\nprint(\"  - Training/validation loss\")\nprint(\"  - Per-dimension MAE and correlations\")\nprint(\"  - Learning rate schedule\")\nprint(\"  - Gradient norms\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOGS_ROOT}/full_model\n",
    "\n",
    "print(\"\\nTensorBoard is now running above.\")\n",
    "print(\"Monitor:\")\n",
    "print(\"  - Training/validation loss\")\n",
    "print(\"  - Per-dimension MAE and correlations\")\n",
    "print(\"  - Learning rate schedule\")\n",
    "print(\"  - Gradient norms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Find best checkpoint\nimport os\nfrom pathlib import Path\n\ncheckpoint_dir = Path(CHECKPOINT_ROOT)\ncheckpoints = sorted(checkpoint_dir.glob(\"model-*.ckpt\"))\n\nif not checkpoints:\n    print(\"No checkpoints found. Make sure training completed successfully.\")\nelse:\n    # Get best checkpoint (lowest val_loss)\n    best_ckpt = checkpoints[0]\n    print(f\"Best checkpoint: {best_ckpt.name}\")\n    print(f\"Full path: {best_ckpt}\")\n    \n    # Load model\n    from src.models.lightning_module import PerformanceEvaluationModel\n    \n    print(\"\\nLoading model...\")\n    model = PerformanceEvaluationModel.load_from_checkpoint(str(best_ckpt))\n    model.eval()\n    model = model.cuda()\n    \n    num_params = sum(p.numel() for p in model.parameters()) / 1e6\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n    \n    print(f\"\\n✓ Model loaded successfully\")\n    print(f\"  Total parameters: {num_params:.1f}M\")\n    print(f\"  Trainable parameters: {trainable_params:.1f}M\")\n    print(f\"  Dimensions: {model.dimension_names}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best checkpoint\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(f\"{CHECKPOINT_ROOT}/full_model\")\n",
    "checkpoints = sorted(checkpoint_dir.glob(\"model-*.ckpt\"))\n",
    "\n",
    "if not checkpoints:\n",
    "    print(\"No checkpoints found. Make sure training completed successfully.\")\n",
    "else:\n",
    "    # Get best checkpoint (lowest val_loss)\n",
    "    best_ckpt = checkpoints[0]\n",
    "    print(f\"Best checkpoint: {best_ckpt.name}\")\n",
    "    print(f\"Full path: {best_ckpt}\")\n",
    "    \n",
    "    # Load model\n",
    "    from src.models.lightning_module import PerformanceEvaluationModel\n",
    "    \n",
    "    print(\"\\nLoading model...\")\n",
    "    model = PerformanceEvaluationModel.load_from_checkpoint(str(best_ckpt))\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "    \n",
    "    print(f\"\\n✓ Model loaded successfully\")\n",
    "    print(f\"  Total parameters: {num_params:.1f}M\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:.1f}M\")\n",
    "    print(f\"  Dimensions: {model.dimension_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test evaluation\n",
    "import pytorch_lightning as pl\n",
    "from src.data.dataset import create_dataloaders\n",
    "\n",
    "print(\"Creating test dataloader...\")\n",
    "_, _, test_loader = create_dataloaders(\n",
    "    train_annotation_path=config['data']['train_path'],\n",
    "    val_annotation_path=config['data']['val_path'],\n",
    "    test_annotation_path=config['data']['test_path'],\n",
    "    dimension_names=config['data']['dimensions'],\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    num_workers=0,  # Single worker for test\n",
    "    augmentation_config=None,  # No augmentation for test\n",
    "    audio_sample_rate=config['data']['audio_sample_rate'],\n",
    "    max_audio_length=config['data']['max_audio_length'],\n",
    "    max_midi_events=config['data']['max_midi_events'],\n",
    ")\n",
    "\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "print(\"\\nRunning test evaluation...\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    precision=16,\n",
    ")\n",
    "\n",
    "test_results = trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPer-dimension metrics:\")\n",
    "for dim in model.dimension_names:\n",
    "    mae = test_results[0].get(f'test_mae_{dim}', 'N/A')\n",
    "    pearson = test_results[0].get(f'test_pearson_{dim}', 'N/A')\n",
    "    spearman = test_results[0].get(f'test_spearman_{dim}', 'N/A')\n",
    "    print(f\"  {dim}:\")\n",
    "    print(f\"    MAE: {mae:.3f}\" if mae != 'N/A' else f\"    MAE: {mae}\")\n",
    "    print(f\"    Pearson r: {pearson:.3f}\" if pearson != 'N/A' else f\"    Pearson r: {pearson}\")\n",
    "    print(f\"    Spearman ρ: {spearman:.3f}\" if spearman != 'N/A' else f\"    Spearman ρ: {spearman}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nEvaluation complete!\")\n",
    "print(f\"Full results saved to TensorBoard: {config['logging']['tensorboard_logdir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Best Checkpoint (Optional)\n",
    "\n",
    "Download the best model checkpoint to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download best checkpoint\n",
    "from google.colab import files\n",
    "\n",
    "if 'best_ckpt' in locals():\n",
    "    print(f\"Downloading: {best_ckpt.name}\")\n",
    "    print(f\"Size: {best_ckpt.stat().st_size / 1e6:.1f} MB\")\n",
    "    print(\"\\nThis may take a few minutes...\")\n",
    "    files.download(str(best_ckpt))\n",
    "    print(\"\\n✓ Download complete!\")\n",
    "else:\n",
    "    print(\"No checkpoint found to download. Make sure training completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Troubleshooting\n\n### Session Disconnected\n- **Don't worry!** Checkpoints are saved directly to Google Drive (persistent)\n- Re-run cells 1-7 (setup environment, mount Drive, install dependencies)\n- Re-run the training cell - will **automatically resume** from latest checkpoint\n- Check Google Drive → MyDrive → crescendai_checkpoints for saved checkpoints\n\n### Out of Memory (OOM)\n- Reduce batch size: `config['data']['batch_size'] = 4`\n- Increase gradient accumulation: `config['training']['accumulate_grad_batches'] = 8`\n- This keeps effective batch size = 4 × 8 = 32\n\n### I/O Errors During Training\n- **Already fixed!** `num_workers=0` prevents Google Drive concurrent access issues\n- If you still see errors, check Google Drive sync status\n- Try remounting Drive: `drive.flush_and_unmount()` then remount\n\n### Slow Training\n- Verify you have T4 or better GPU (not K80)\n- Check `num_workers=0` in config (required for Google Drive)\n- Sequential loading is normal and expected with Google Drive\n\n### MIDI Divide-by-Zero Warnings\n- **Harmless** - occurs when MIDI files have 0 duration\n- Already suppressed in the notebook\n- Does not affect training\n\n### How to Start Fresh (Delete Checkpoints)\nIf you want to restart training from scratch:\n```python\nimport shutil\nshutil.rmtree('/content/drive/MyDrive/crescendai_checkpoints')\nprint(\"✓ All checkpoints deleted - will start fresh\")\n```\n\n### Target Performance (MVP Goals)\n**Technical dimensions** (current):\n- Pearson r: 0.50-0.65\n- MAE: 10-15 points (0-100 scale)\n\n**Interpretive dimensions** (after expert labels):\n- Pearson r: 0.35-0.50\n- MAE: 12-18 points\n\nIf you achieve these targets, the architecture is validated!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}