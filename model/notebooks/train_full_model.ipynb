{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piano Performance Evaluation - Full Model Training\n",
    "\n",
    "Trains the complete multi-modal performance evaluation model on MAESTRO synthetic labels.\n",
    "\n",
    "**Current Dimensions**: 6 technical dimensions (note_accuracy, rhythmic_precision, dynamics_control, articulation, pedaling, tone_quality)\n",
    "\n",
    "**Future Expansion**: 4 interpretive dimensions will be added after expert labeling (phrasing, expressiveness, musicality, overall_quality)\n",
    "\n",
    "**Requirements:**\n",
    "- Colab Pro (T4/V100 GPU recommended)\n",
    "- Google Drive with segments and labels uploaded\n",
    "- HuggingFace account for MERT model access\n",
    "- crescendai repository on GitHub\n",
    "\n",
    "**Expected Training Time**: ~8-12 GPU hours on T4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Expected Google Drive Structure\n\nData and checkpoints are stored in **MyDrive**:\n\n```\nMyDrive/\n  crescendai_data/\n    all_segments/                  # Audio segments (~65GB)\n      *.wav                        # MAESTRO segments\n      youtube_*.wav                # YouTube test segments\n      midi_segments/               # MIDI segments\n        *.mid\n    annotations/                   # Annotation files\n      synthetic_train_colab.jsonl  # ~114k training samples\n      synthetic_val_colab.jsonl    # ~21k validation samples\n      synthetic_test_colab.jsonl   # ~7k test samples\n\n  crescendai_model/\n    checkpoints/                   # Checkpoints saved here\n      (will be created automatically)\n    logs/                          # TensorBoard logs\n      (will be created automatically)\n```\n\nAll data is in MyDrive for reliable Colab access."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace Login\n",
    "import os\n",
    "os.environ.pop(\"HF_TOKEN\", None)\n",
    "os.environ.pop(\"HUGGINGFACEHUB_API_TOKEN\", None)\n",
    "\n",
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "try:\n",
    "    import getpass as gp\n",
    "    raw = gp.getpass(\"Paste your Hugging Face token (input hidden): \")\n",
    "    token = raw.decode() if isinstance(raw, (bytes, bytearray)) else raw\n",
    "    if not isinstance(token, str):\n",
    "        raise TypeError(f\"Unexpected token type: {type(token).__name__}\")\n",
    "    token = token.strip()\n",
    "    if not token:\n",
    "        raise ValueError(\"Empty token provided\")\n",
    "    login(token=token, add_to_git_credential=False)\n",
    "    who = HfApi().whoami(token=token)\n",
    "    print(f\"✓ Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
    "except Exception as e:\n",
    "    print(f\"[HF Login] getpass flow failed: {e}\")\n",
    "    print(\"Falling back to interactive login widget...\")\n",
    "    login()\n",
    "    try:\n",
    "        who = HfApi().whoami()\n",
    "        print(f\"✓ Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"[HF Login] Verification skipped: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Load data from MyDrive\nimport os\nfrom pathlib import Path\n\nprint(\"Loading data from Google Drive MyDrive...\\n\")\n\n# Data location (all in MyDrive for reliable access)\nGDRIVE_ROOT = '/content/drive/MyDrive/crescendai_data'\nDATA_ROOT = f'{GDRIVE_ROOT}/all_segments'\nANNOTATIONS_ROOT = f'{GDRIVE_ROOT}/annotations'\n\n# Checkpoint and logs location (MyDrive for persistence)\nCHECKPOINT_ROOT = '/content/drive/MyDrive/crescendai_model/checkpoints'\nLOGS_ROOT = '/content/drive/MyDrive/crescendai_model/logs'\n\nprint(f\"Data paths:\")\nprint(f\"  Audio segments: {DATA_ROOT}\")\nprint(f\"  Annotations: {ANNOTATIONS_ROOT}\")\nprint(f\"  Checkpoints: {CHECKPOINT_ROOT}\")\nprint(f\"  Logs: {LOGS_ROOT}\\n\")\n\n# Verify structure\nrequired_paths = [\n    (DATA_ROOT, \"Audio segments directory\"),\n    (ANNOTATIONS_ROOT, \"Annotations directory\"),\n    (f\"{ANNOTATIONS_ROOT}/synthetic_train_colab.jsonl\", \"Training annotations\"),\n    (f\"{ANNOTATIONS_ROOT}/synthetic_val_colab.jsonl\", \"Validation annotations\"),\n    (f\"{ANNOTATIONS_ROOT}/synthetic_test_colab.jsonl\", \"Test annotations\"),\n]\n\nprint(\"Verifying structure...\\n\")\nall_good = True\nfor path, desc in required_paths:\n    if os.path.exists(path):\n        print(f\"✓ {desc}: {path}\")\n    else:\n        print(f\"✗ {desc} NOT FOUND: {path}\")\n        all_good = False\n\n# Create checkpoint and logs directories\nos.makedirs(CHECKPOINT_ROOT, exist_ok=True)\nos.makedirs(LOGS_ROOT, exist_ok=True)\n\nif not all_good:\n    print(\"\\n\" + \"=\"*70)\n    print(\"ERROR: Google Drive structure incomplete\")\n    print(\"=\"*70)\n    print(\"\\nExpected location: MyDrive/crescendai_data/\")\n    print(\"  all_segments/\")\n    print(\"  annotations/\")\n    print(\"\\nPlease verify files are uploaded to MyDrive.\")\n    print(\"=\"*70)\n    raise RuntimeError(\"Google Drive structure incomplete. Please check sync.\")\nelse:\n    print(\"\\n✓ All required files present. Ready to proceed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "REPO_URL = \"https://github.com/Jai-Dhiman/crescendai.git\"\n",
    "BRANCH = \"main\"\n",
    "\n",
    "# Remove old clone if exists\n",
    "!rm -rf /content/crescendai\n",
    "\n",
    "# Clone fresh\n",
    "!git clone --branch {BRANCH} {REPO_URL} /content/crescendai\n",
    "\n",
    "# Navigate to model directory\n",
    "%cd /content/crescendai/model\n",
    "\n",
    "# Show git status\n",
    "print(\"\\nRepository status:\")\n",
    "!git log -1 --oneline\n",
    "!git status --short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Add to PATH for this session\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "print(\"\\n✓ uv installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"Installing dependencies (this may take 2-3 minutes)...\\n\")\n",
    "!uv pip install --system -e .\n",
    "\n",
    "# Verify installation\n",
    "import os\n",
    "os.environ['MPLBACKEND'] = 'Agg'  # Non-interactive backend for matplotlib\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Dependencies installed successfully\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify GPU and Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(\"\\n✓ GPU READY FOR TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"⚠️  CRITICAL: NO GPU DETECTED!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nTraining on CPU will be EXTREMELY SLOW (200x slower than GPU).\")\n",
    "    print(\"\\nTO ENABLE GPU:\")\n",
    "    print(\"1. Go to: Runtime → Change runtime type\")\n",
    "    print(\"2. Set 'Hardware accelerator' to: T4 GPU\")\n",
    "    print(\"3. Click 'Save'\")\n",
    "    print(\"4. Re-run all cells from the beginning\")\n",
    "    print(\"\\nDO NOT proceed with training until GPU is enabled!\")\n",
    "    print(\"=\"*70)\n",
    "    raise RuntimeError(\"GPU required for training. Please enable GPU and restart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MERT model (one-time, will be cached)\n",
    "from transformers import AutoModel\n",
    "\n",
    "print(\"Downloading MERT-95M model (one-time, ~380MB)...\")\n",
    "print(\"This will be cached for future use.\\n\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"m-a-p/MERT-v1-95M\", trust_remote_code=True)\n",
    "num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "\n",
    "print(f\"✓ MERT-95M downloaded and cached\")\n",
    "print(f\"  Parameters: {num_params:.1f}M\")\n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Training Configuration\n",
    "\n",
    "This creates a config file with paths pointing to your Google Drive data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import yaml\n\n# Training configuration\nconfig = {\n    'data': {\n        # Paths to annotation files on Google Drive (UPDATED: using _colab.jsonl files)\n        'train_path': f'{ANNOTATIONS_ROOT}/synthetic_train_colab.jsonl',\n        'val_path': f'{ANNOTATIONS_ROOT}/synthetic_val_colab.jsonl',\n        'test_path': f'{ANNOTATIONS_ROOT}/synthetic_test_colab.jsonl',\n        \n        # Current dimensions (6 technical)\n        # TODO: Add 4 interpretive dimensions when expert labels available:\n        #   - phrasing\n        #   - expressiveness  \n        #   - musicality\n        #   - overall_quality\n        'dimensions': [\n            'note_accuracy',\n            'rhythmic_precision',\n            'dynamics_control',\n            'articulation',\n            'pedaling',\n            'tone_quality'\n        ],\n        \n        # Audio settings (MERT requirements)\n        'audio_sample_rate': 24000,\n        'max_audio_length': 240000,  # 10 seconds at 24kHz\n        'max_midi_events': 512,\n        \n        # DataLoader settings\n        'batch_size': 8,\n        'num_workers': 2,  # Colab: 2 workers works well\n        'pin_memory': True,\n        \n        # Augmentation (training robustness)\n        'augmentation': {\n            'enabled': True,\n            'pitch_shift': {\n                'enabled': True,\n                'probability': 0.3,\n                'min_semitones': -2,\n                'max_semitones': 2\n            },\n            'time_stretch': {\n                'enabled': True,\n                'probability': 0.3,\n                'min_rate': 0.85,\n                'max_rate': 1.15\n            },\n            'add_noise': {\n                'enabled': True,\n                'probability': 0.2,\n                'min_snr_db': 25,\n                'max_snr_db': 40\n            },\n            'room_acoustics': {\n                'enabled': True,\n                'probability': 0.2,\n                'num_room_types': 5\n            },\n            'compress_audio': {\n                'enabled': True,\n                'probability': 0.15,\n                'bitrates': [128, 192, 256, 320]\n            },\n            'gain_variation': {\n                'enabled': True,\n                'probability': 0.3,\n                'min_db': -6,\n                'max_db': 6\n            },\n            'max_transforms': 3\n        }\n    },\n    \n    'model': {\n        # Architecture dimensions\n        'audio_dim': 768,\n        'midi_dim': 256,  # Set to 0 for audio-only mode\n        'fusion_dim': 1024,\n        'aggregator_dim': 512,\n        'num_dimensions': 6,  # Update to 10 when adding interpretive dimensions\n        \n        # Encoder settings\n        'mert_model_name': 'm-a-p/MERT-v1-95M',\n        'freeze_audio_encoder': False,\n        'gradient_checkpointing': True,  # Saves memory\n    },\n    \n    'training': {\n        # Training duration\n        'max_epochs': 20,\n        'precision': 16,  # Mixed precision (FP16) for speed\n        \n        # Optimization\n        'optimizer': 'AdamW',\n        'learning_rate': 1e-5,\n        'backbone_lr': 1e-5,  # Lower LR for pre-trained MERT\n        'heads_lr': 1e-4,     # Higher LR for task heads\n        'weight_decay': 0.01,\n        \n        # Learning rate schedule\n        'scheduler': 'cosine',\n        'warmup_steps': 500,\n        'min_lr': 1e-6,\n        \n        # Gradient settings\n        'gradient_clip_val': 1.0,\n        'accumulate_grad_batches': 4,  # Effective batch size = 8 * 4 = 32\n        \n        # Validation\n        'val_check_interval': 1.0,  # Check every epoch\n        'limit_val_batches': 1.0,   # Use full val set\n    },\n    \n    'callbacks': {\n        # Model checkpointing\n        'checkpoint': {\n            'monitor': 'val_loss',\n            'mode': 'min',\n            'save_top_k': 3,\n            'save_last': True,\n            'dirpath': f'{CHECKPOINT_ROOT}/full_model',\n            'filename': 'model-{epoch:02d}-{val_loss:.4f}'\n        },\n        \n        # Early stopping\n        'early_stopping': {\n            'monitor': 'val_loss',\n            'mode': 'min',\n            'patience': 5,\n            'min_delta': 0.001\n        },\n        \n        # Learning rate monitoring\n        'lr_monitor': {\n            'logging_interval': 'step'\n        }\n    },\n    \n    'logging': {\n        # Logging frequency\n        'log_every_n_steps': 50,\n        \n        # WandB (optional - set to True if you have account)\n        'use_wandb': False,\n        'wandb_project': 'piano-eval',\n        'wandb_entity': None,\n        'wandb_run_name': 'full-model',\n        \n        # TensorBoard\n        'use_tensorboard': True,\n        'tensorboard_logdir': f'{LOGS_ROOT}/full_model'\n    },\n    \n    'seed': 42\n}\n\n# Save config\nCONFIG_PATH = '/tmp/training_config.yaml'\nwith open(CONFIG_PATH, 'w') as f:\n    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n\nprint(\"=\"*70)\nprint(\"✓ Training configuration created\")\nprint(\"=\"*70)\nprint(f\"Config saved to: {CONFIG_PATH}\")\nprint(f\"\\nTraining Summary:\")\nprint(f\"  Dimensions: {len(config['data']['dimensions'])}\")\nprint(f\"  Batch size: {config['data']['batch_size']}\")\nprint(f\"  Gradient accumulation: {config['training']['accumulate_grad_batches']}\")\nprint(f\"  Effective batch size: {config['data']['batch_size'] * config['training']['accumulate_grad_batches']}\")\nprint(f\"  Max epochs: {config['training']['max_epochs']}\")\nprint(f\"  Precision: FP{config['training']['precision']}\")\nprint(f\"\\nCheckpoints: {config['callbacks']['checkpoint']['dirpath']}\")\nprint(f\"TensorBoard: {config['logging']['tensorboard_logdir']}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre-flight Check (Optional but Recommended)\n",
    "\n",
    "Verifies everything is set up correctly before starting training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pre-flight check\n",
    "print(\"Running pre-flight check...\\n\")\n",
    "!python preflight_check.py --config {CONFIG_PATH} --skip-model --skip-dataloader\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"If all checks passed, proceed to training below.\")\n",
    "print(\"If any issues found, fix them before training.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training\n",
    "\n",
    "**Expected duration**: ~8-12 hours on T4 GPU for 20 epochs\n",
    "\n",
    "Training will automatically:\n",
    "- Save checkpoints to Google Drive (persistent)\n",
    "- Log metrics to TensorBoard\n",
    "- Stop early if validation loss plateaus\n",
    "- Resume from checkpoint if interrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"=\"*70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThis will take ~8-12 hours on T4 GPU.\")\n",
    "print(\"Checkpoints saved to Google Drive (persistent).\")\n",
    "print(\"Safe to close browser - training continues in background.\")\n",
    "print(\"\\nPress Ctrl+C to stop (will save checkpoint).\\n\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "!python train.py --config {CONFIG_PATH}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Checkpoints saved to: {config['callbacks']['checkpoint']['dirpath']}\")\n",
    "print(f\"Logs saved to: {config['logging']['tensorboard_logdir']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitor Training (Optional)\n",
    "\n",
    "Launch TensorBoard to monitor training progress in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOGS_ROOT}/full_model\n",
    "\n",
    "print(\"\\nTensorBoard is now running above.\")\n",
    "print(\"Monitor:\")\n",
    "print(\"  - Training/validation loss\")\n",
    "print(\"  - Per-dimension MAE and correlations\")\n",
    "print(\"  - Learning rate schedule\")\n",
    "print(\"  - Gradient norms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Best Model\n",
    "\n",
    "After training completes, evaluate the best checkpoint on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best checkpoint\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(f\"{CHECKPOINT_ROOT}/full_model\")\n",
    "checkpoints = sorted(checkpoint_dir.glob(\"model-*.ckpt\"))\n",
    "\n",
    "if not checkpoints:\n",
    "    print(\"No checkpoints found. Make sure training completed successfully.\")\n",
    "else:\n",
    "    # Get best checkpoint (lowest val_loss)\n",
    "    best_ckpt = checkpoints[0]\n",
    "    print(f\"Best checkpoint: {best_ckpt.name}\")\n",
    "    print(f\"Full path: {best_ckpt}\")\n",
    "    \n",
    "    # Load model\n",
    "    from src.models.lightning_module import PerformanceEvaluationModel\n",
    "    \n",
    "    print(\"\\nLoading model...\")\n",
    "    model = PerformanceEvaluationModel.load_from_checkpoint(str(best_ckpt))\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    \n",
    "    num_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "    \n",
    "    print(f\"\\n✓ Model loaded successfully\")\n",
    "    print(f\"  Total parameters: {num_params:.1f}M\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:.1f}M\")\n",
    "    print(f\"  Dimensions: {model.dimension_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test evaluation\n",
    "import pytorch_lightning as pl\n",
    "from src.data.dataset import create_dataloaders\n",
    "\n",
    "print(\"Creating test dataloader...\")\n",
    "_, _, test_loader = create_dataloaders(\n",
    "    train_annotation_path=config['data']['train_path'],\n",
    "    val_annotation_path=config['data']['val_path'],\n",
    "    test_annotation_path=config['data']['test_path'],\n",
    "    dimension_names=config['data']['dimensions'],\n",
    "    batch_size=config['data']['batch_size'],\n",
    "    num_workers=0,  # Single worker for test\n",
    "    augmentation_config=None,  # No augmentation for test\n",
    "    audio_sample_rate=config['data']['audio_sample_rate'],\n",
    "    max_audio_length=config['data']['max_audio_length'],\n",
    "    max_midi_events=config['data']['max_midi_events'],\n",
    ")\n",
    "\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "print(\"\\nRunning test evaluation...\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    precision=16,\n",
    ")\n",
    "\n",
    "test_results = trainer.test(model, dataloaders=test_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nPer-dimension metrics:\")\n",
    "for dim in model.dimension_names:\n",
    "    mae = test_results[0].get(f'test_mae_{dim}', 'N/A')\n",
    "    pearson = test_results[0].get(f'test_pearson_{dim}', 'N/A')\n",
    "    spearman = test_results[0].get(f'test_spearman_{dim}', 'N/A')\n",
    "    print(f\"  {dim}:\")\n",
    "    print(f\"    MAE: {mae:.3f}\" if mae != 'N/A' else f\"    MAE: {mae}\")\n",
    "    print(f\"    Pearson r: {pearson:.3f}\" if pearson != 'N/A' else f\"    Pearson r: {pearson}\")\n",
    "    print(f\"    Spearman ρ: {spearman:.3f}\" if spearman != 'N/A' else f\"    Spearman ρ: {spearman}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nEvaluation complete!\")\n",
    "print(f\"Full results saved to TensorBoard: {config['logging']['tensorboard_logdir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Best Checkpoint (Optional)\n",
    "\n",
    "Download the best model checkpoint to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download best checkpoint\n",
    "from google.colab import files\n",
    "\n",
    "if 'best_ckpt' in locals():\n",
    "    print(f\"Downloading: {best_ckpt.name}\")\n",
    "    print(f\"Size: {best_ckpt.stat().st_size / 1e6:.1f} MB\")\n",
    "    print(\"\\nThis may take a few minutes...\")\n",
    "    files.download(str(best_ckpt))\n",
    "    print(\"\\n✓ Download complete!\")\n",
    "else:\n",
    "    print(\"No checkpoint found to download. Make sure training completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Session Disconnected\n",
    "- Re-run cells 1-2 (Drive mount, repo clone)\n",
    "- Re-run training cell - will automatically resume from last checkpoint\n",
    "- All checkpoints are in Google Drive (persistent)\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "- Reduce batch size: `config['data']['batch_size'] = 4`\n",
    "- Increase gradient accumulation: `config['training']['accumulate_grad_batches'] = 8`\n",
    "- This keeps effective batch size = 4 × 8 = 32\n",
    "\n",
    "### Slow Training\n",
    "- Verify you have T4 or better GPU (not K80)\n",
    "- Check data is in Google Drive (not Colab Files)\n",
    "- Try reducing `num_workers` if I/O bottleneck\n",
    "\n",
    "### MIDI Loading Warnings\n",
    "- Expected: ~2-5% of MIDI files may fail to load\n",
    "- System handles gracefully with audio-only fallback\n",
    "- Training continues normally\n",
    "\n",
    "### Target Performance (MVP Goals)\n",
    "**Technical dimensions**:\n",
    "- Pearson r: 0.50-0.65\n",
    "- MAE: 10-15 points (0-100 scale)\n",
    "\n",
    "**Interpretive dimensions** (after expert labels):\n",
    "- Pearson r: 0.35-0.50\n",
    "- MAE: 12-18 points\n",
    "\n",
    "If you achieve these targets, the architecture is validated!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}