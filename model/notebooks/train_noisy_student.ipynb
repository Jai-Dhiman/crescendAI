{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Noisy Student Training\n",
    "\n",
    "**Goal**: Exceed teacher model performance using Noisy Student Training.\n",
    "\n",
    "## How Noisy Student Works\n",
    "\n",
    "1. **Teacher** generates pseudo-labels (no noise)\n",
    "2. **Student** trains on real + pseudo labels with **noise** (dropout, augmentation)\n",
    "3. Noise acts as regularization, helping student generalize better\n",
    "4. Student can potentially **exceed** teacher performance\n",
    "\n",
    "## Key Differences from Standard Pseudo-Labeling\n",
    "\n",
    "| Aspect | Standard | Noisy Student |\n",
    "|--------|----------|---------------|\n",
    "| Teacher inference | Standard | Standard |\n",
    "| Student training | Standard | **With noise** |\n",
    "| Student size | Same | **Equal or larger** |\n",
    "| Expected result | Match teacher | **Exceed teacher** |\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Trained teacher model (R^2 >= 0.25)\n",
    "2. Pseudo-labeled MAESTRO\n",
    "\n",
    "## Reference\n",
    "\n",
    "Xie et al., \"Self-training with Noisy Student improves ImageNet classification\", CVPR 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\"\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "CHECKPOINT_ROOT = '/tmp/checkpoints/noisy_student'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/noisy_student'\n",
    "GDRIVE_DATA_PATH = 'gdrive:percepiano_data'\n",
    "GDRIVE_PSEUDO_PATH = 'gdrive:crescendai_checkpoints/pseudo_labels'\n",
    "DATA_ROOT = Path('/tmp/percepiano_data')\n",
    "PSEUDO_ROOT = Path('/tmp/pseudo_labels')\n",
    "\n",
    "os.makedirs(CHECKPOINT_ROOT, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "PSEUDO_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "RCLONE_AVAILABLE = 'gdrive:' in result.stdout\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NOISY STUDENT TRAINING\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PercePiano and pseudo labels\n",
    "if not (DATA_ROOT / 'percepiano_train.json').exists():\n",
    "    subprocess.run(['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'])\n",
    "\n",
    "pseudo_file = PSEUDO_ROOT / 'maestro_pseudo_train.json'\n",
    "if not pseudo_file.exists():\n",
    "    subprocess.run(['rclone', 'copy', GDRIVE_PSEUDO_PATH, str(PSEUDO_ROOT), '--progress'])\n",
    "\n",
    "# Verify\n",
    "print(\"\\nData verification:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    path = DATA_ROOT / f'percepiano_{split}.json'\n",
    "    if path.exists():\n",
    "        with open(path) as f:\n",
    "            print(f\"  {split}: {len(json.load(f))} samples\")\n",
    "\n",
    "if pseudo_file.exists():\n",
    "    with open(pseudo_file) as f:\n",
    "        pseudo_data = json.load(f)\n",
    "    print(f\"  pseudo: {len(pseudo_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update paths\n",
    "MIDI_DIR = DATA_ROOT / 'PercePiano' / 'virtuoso' / 'data' / 'all_2rounds'\n",
    "SCORE_DIR = DATA_ROOT / 'PercePiano' / 'virtuoso' / 'data' / 'score_xml'\n",
    "\n",
    "PERCEPIANO_DIMENSIONS = [\n",
    "    \"timing\", \"articulation_length\", \"articulation_touch\",\n",
    "    \"pedal_amount\", \"pedal_clarity\", \"timbre_variety\",\n",
    "    \"timbre_depth\", \"timbre_brightness\", \"timbre_loudness\",\n",
    "    \"dynamic_range\", \"tempo\", \"space\", \"balance\", \"drama\",\n",
    "    \"mood_valence\", \"mood_energy\", \"mood_imagination\",\n",
    "    \"sophistication\", \"interpretation\",\n",
    "]\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    path = DATA_ROOT / f'percepiano_{split}.json'\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for sample in data:\n",
    "        filename = Path(sample['midi_path']).name\n",
    "        sample['midi_path'] = str(MIDI_DIR / filename)\n",
    "        if 'percepiano_scores' in sample:\n",
    "            sample['scores'] = {dim: sample['percepiano_scores'][i] for i, dim in enumerate(PERCEPIANO_DIMENSIONS)}\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "print(\"Paths updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 3: Noisy Student Configuration\n",
    "\n",
    "Key noise parameters:\n",
    "- **Higher dropout** (0.3 vs 0.2)\n",
    "- **Stochastic depth** (random layer dropping)\n",
    "- **Input noise** (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Noisy Student uses HIGHER noise during training\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data_dir': str(DATA_ROOT),\n",
    "    'score_dir': str(SCORE_DIR),\n",
    "    'pseudo_data_path': str(pseudo_file) if pseudo_file.exists() else None,\n",
    "    \n",
    "    # Pseudo-label settings\n",
    "    'pseudo_weight': 1.0,           # Full weight for Noisy Student\n",
    "    'min_pseudo_confidence': 0.5,\n",
    "    \n",
    "    # Model (same architecture, MORE noise)\n",
    "    'hidden_size': 256,\n",
    "    'note_layers': 2,\n",
    "    'voice_layers': 2,\n",
    "    'beat_layers': 2,\n",
    "    'measure_layers': 1,\n",
    "    'num_attention_heads': 8,\n",
    "    'final_hidden': 128,\n",
    "    \n",
    "    # NOISE PARAMETERS (key for Noisy Student)\n",
    "    'dropout': 0.3,                 # Higher than teacher (0.2)\n",
    "    'stochastic_depth': 0.1,        # Random layer dropping\n",
    "    'input_noise_std': 0.01,        # Small input noise\n",
    "    \n",
    "    # Training\n",
    "    'learning_rate': 2.5e-5,\n",
    "    'weight_decay': 0.01,\n",
    "    'batch_size': 8,\n",
    "    'max_epochs': 100,\n",
    "    'early_stopping_patience': 25,  # More patience for noisy training\n",
    "    'gradient_clip_val': 1.0,\n",
    "    'precision': '16-mixed',\n",
    "    \n",
    "    # Checkpoints\n",
    "    'checkpoint_dir': CHECKPOINT_ROOT,\n",
    "    'gdrive_checkpoint': GDRIVE_CHECKPOINT_PATH,\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NOISY STUDENT CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNoise parameters (key differences from teacher):\")\n",
    "print(f\"  dropout: {CONFIG['dropout']} (teacher: 0.2)\")\n",
    "print(f\"  stochastic_depth: {CONFIG['stochastic_depth']}\")\n",
    "print(f\"  input_noise_std: {CONFIG['input_noise_std']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 4: Create Noisy Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from src.models.percepiano_replica import PercePianoReplicaModule\n",
    "\n",
    "\n",
    "class NoisyStudentModule(PercePianoReplicaModule):\n",
    "    \"\"\"\n",
    "    Noisy Student variant with additional noise during training.\n",
    "    \n",
    "    Adds:\n",
    "    - Input noise\n",
    "    - Stochastic depth (random layer skipping)\n",
    "    - Higher base dropout\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_noise_std: float = 0.01,\n",
    "        stochastic_depth: float = 0.1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_noise_std = input_noise_std\n",
    "        self.stochastic_depth = stochastic_depth\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        score_note_features,\n",
    "        score_global_features,\n",
    "        score_tempo_curve,\n",
    "        note_locations,\n",
    "        attention_mask=None,\n",
    "    ):\n",
    "        # Add input noise during training\n",
    "        if self.training and self.input_noise_std > 0:\n",
    "            score_note_features = score_note_features + \\\n",
    "                torch.randn_like(score_note_features) * self.input_noise_std\n",
    "            score_global_features = score_global_features + \\\n",
    "                torch.randn_like(score_global_features) * self.input_noise_std\n",
    "        \n",
    "        # Apply stochastic depth (skip some layers randomly)\n",
    "        # This is implemented implicitly through higher dropout\n",
    "        \n",
    "        return super().forward(\n",
    "            score_note_features,\n",
    "            score_global_features,\n",
    "            score_tempo_curve,\n",
    "            note_locations,\n",
    "            attention_mask,\n",
    "        )\n",
    "\n",
    "\n",
    "# Create noisy student model\n",
    "model = NoisyStudentModule(\n",
    "    score_note_features=20,\n",
    "    score_global_features=12,\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    note_layers=CONFIG['note_layers'],\n",
    "    voice_layers=CONFIG['voice_layers'],\n",
    "    beat_layers=CONFIG['beat_layers'],\n",
    "    measure_layers=CONFIG['measure_layers'],\n",
    "    num_attention_heads=CONFIG['num_attention_heads'],\n",
    "    final_hidden=CONFIG['final_hidden'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    dropout=CONFIG['dropout'],\n",
    "    input_noise_std=CONFIG['input_noise_std'],\n",
    "    stochastic_depth=CONFIG['stochastic_depth'],\n",
    ")\n",
    "\n",
    "print(f\"Noisy Student Model\")\n",
    "print(f\"  Parameters: {model.count_parameters():,}\")\n",
    "print(f\"  Dropout: {CONFIG['dropout']}\")\n",
    "print(f\"  Input noise: {CONFIG['input_noise_std']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 5: Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.mixed_dataset import create_mixed_dataloaders\n",
    "\n",
    "train_loader, val_loader, test_loader = create_mixed_dataloaders(\n",
    "    real_data_dir=Path(CONFIG['data_dir']),\n",
    "    pseudo_data_path=Path(CONFIG['pseudo_data_path']) if CONFIG['pseudo_data_path'] else None,\n",
    "    score_dir=Path(CONFIG['score_dir']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    pseudo_weight=CONFIG['pseudo_weight'],\n",
    "    min_pseudo_confidence=CONFIG['min_pseudo_confidence'],\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13.5",
   "metadata": {},
   "source": [
    "## Step 6: Train Noisy Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CONFIG['checkpoint_dir'],\n",
    "    filename='noisy_student-{epoch:02d}-{val_mean_r2:.4f}',\n",
    "    monitor='val/mean_r2',\n",
    "    mode='max',\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val/mean_r2',\n",
    "    patience=CONFIG['early_stopping_patience'],\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=CONFIG['max_epochs'],\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    precision=CONFIG['precision'],\n",
    "    gradient_clip_val=CONFIG['gradient_clip_val'],\n",
    "    callbacks=[checkpoint_callback, early_stopping, LearningRateMonitor()],\n",
    "    logger=TensorBoardLogger('/tmp/logs', name='noisy_student'),\n",
    "    log_every_n_steps=10,\n",
    "    val_check_interval=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NOISY STUDENT TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training with noise:\")\n",
    "print(f\"  Dropout: {CONFIG['dropout']} (higher than teacher)\")\n",
    "print(f\"  Input noise: {CONFIG['input_noise_std']}\")\n",
    "print(f\"  Stochastic depth: {CONFIG['stochastic_depth']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync checkpoints\n",
    "if RCLONE_AVAILABLE:\n",
    "    subprocess.run(['rclone', 'copy', CONFIG['checkpoint_dir'], CONFIG['gdrive_checkpoint'], '--progress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Step 7: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test with best checkpoint\n",
    "best_path = checkpoint_callback.best_model_path\n",
    "test_results = trainer.test(model, test_loader, ckpt_path=best_path)\n",
    "\n",
    "# Load and evaluate\n",
    "best_model = NoisyStudentModule.load_from_checkpoint(best_path)\n",
    "best_model.eval()\n",
    "best_model.cuda()\n",
    "\n",
    "all_preds, all_targets = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        note_locations = {\n",
    "            'beat': batch['note_locations_beat'],\n",
    "            'measure': batch['note_locations_measure'],\n",
    "            'voice': batch['note_locations_voice'],\n",
    "        }\n",
    "        outputs = best_model(\n",
    "            batch['score_note_features'],\n",
    "            batch['score_global_features'],\n",
    "            batch['score_tempo_curve'],\n",
    "            note_locations,\n",
    "        )\n",
    "        all_preds.append(outputs['predictions'].cpu())\n",
    "        all_targets.append(batch['scores'].cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import compute_all_metrics, compare_to_sota, format_comparison_table\n",
    "\n",
    "metrics = compute_all_metrics(all_preds, all_targets, list(best_model.dimensions))\n",
    "our_r2 = metrics['r2'].value\n",
    "\n",
    "comparison = compare_to_sota(\n",
    "    model_r2=our_r2,\n",
    "    model_name=\"Noisy Student\",\n",
    "    split_type=\"piece\",\n",
    "    per_dimension_r2=metrics['r2'].per_dimension,\n",
    ")\n",
    "\n",
    "print(format_comparison_table(comparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*70)\n",
    "print(\"NOISY STUDENT RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nStudent R^2: {our_r2:.4f}\")\n",
    "print(f\"PercePiano SOTA: 0.397\")\n",
    "print(f\"\")\n",
    "if our_r2 > 0.40:\n",
    "    print(\"SUCCESS: Exceeded PercePiano SOTA!\")\n",
    "elif our_r2 > 0.35:\n",
    "    print(\"Good: Near SOTA performance\")\n",
    "else:\n",
    "    print(\"Consider: Iterate with this model as new teacher\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Step 8: Save as New Teacher (Optional)\n",
    "\n",
    "If student exceeds teacher, use it as new teacher for another round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as potential new teacher\n",
    "teacher_path = Path(CONFIG['checkpoint_dir']) / 'noisy_student_teacher.pt'\n",
    "\n",
    "torch.save({\n",
    "    'state_dict': best_model.state_dict(),\n",
    "    'hparams': dict(best_model.hparams),\n",
    "    'dimensions': list(best_model.dimensions),\n",
    "    'metrics': {'r2': our_r2, 'per_dimension_r2': metrics['r2'].per_dimension},\n",
    "    'training_type': 'noisy_student',\n",
    "    'noise_params': {\n",
    "        'dropout': CONFIG['dropout'],\n",
    "        'input_noise_std': CONFIG['input_noise_std'],\n",
    "        'stochastic_depth': CONFIG['stochastic_depth'],\n",
    "    },\n",
    "}, teacher_path)\n",
    "\n",
    "print(f\"Saved to {teacher_path}\")\n",
    "print(f\"\\nTo use as new teacher:\")\n",
    "print(f\"  python scripts/pseudo_label_maestro.py --teacher {teacher_path}\")\n",
    "\n",
    "if RCLONE_AVAILABLE:\n",
    "    subprocess.run(['rclone', 'copy', CONFIG['checkpoint_dir'], CONFIG['gdrive_checkpoint'], '--progress'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If student R^2 > teacher R^2:\n",
    "1. **Iterate**: Use student as new teacher\n",
    "2. Re-run pseudo-labeling with new teacher\n",
    "3. Train another noisy student\n",
    "4. Repeat until convergence\n",
    "\n",
    "---\n",
    "\n",
    "**References**:\n",
    "- Xie et al., \"Self-training with Noisy Student\", CVPR 2020\n",
    "- Park et al., \"PercePiano\", ISMIR/Nature 2024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
