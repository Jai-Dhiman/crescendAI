{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI-Only Piano Performance Evaluation - PercePiano Training\n",
    "\n",
    "**Goal**: Train MIDI-only model on PercePiano expert labels to validate symbolic-only analysis.\n",
    "\n",
    "**Target**: R^2 >= 0.185 (match PercePiano Bi-LSTM baseline)\n",
    "\n",
    "**Stretch Goal**: R^2 >= 0.30 (near best published result of 0.397)\n",
    "\n",
    "## What You Need on Google Drive\n",
    "\n",
    "Upload this folder to your Google Drive root:\n",
    "- `gdrive:percepiano_data/` containing:\n",
    "  - `percepiano_train.json`\n",
    "  - `percepiano_val.json`\n",
    "  - `percepiano_test.json`\n",
    "  - `PercePiano/` (the cloned repository with MIDI files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv and rclone\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\"\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure rclone (Run Once)\n",
    "\n",
    "Run this in a terminal:\n",
    "```bash\n",
    "rclone config\n",
    "```\n",
    "\n",
    "Follow prompts to set up `gdrive` remote for Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Paths\n",
    "CHECKPOINT_ROOT = '/tmp/checkpoints/midi_only_percepiano'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/midi_only_percepiano'\n",
    "GDRIVE_DATA_PATH = 'gdrive:percepiano_data'\n",
    "DATA_ROOT = Path('/tmp/percepiano_data')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SETUP: CHECKPOINTS AND DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CHECKPOINT_ROOT, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "print(\"\\nChecking rclone configuration...\")\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "\n",
    "if 'gdrive:' in result.stdout:\n",
    "    print(\"  rclone 'gdrive' remote: CONFIGURED\")\n",
    "    RCLONE_AVAILABLE = True\n",
    "    \n",
    "    # Restore existing checkpoints\n",
    "    print(\"\\nRestoring checkpoints from Google Drive (if any)...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', GDRIVE_CHECKPOINT_PATH, CHECKPOINT_ROOT, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "else:\n",
    "    print(\"  rclone 'gdrive' remote: NOT CONFIGURED\")\n",
    "    print(\"  Run 'rclone config' in terminal to set up Google Drive\")\n",
    "    RCLONE_AVAILABLE = False\n",
    "\n",
    "print(f\"\\nCheckpoint directory: {CHECKPOINT_ROOT}\")\n",
    "print(f\"rclone available: {RCLONE_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download PercePiano Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "DATA_ROOT = Path('/tmp/percepiano_data')\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if data already exists\n",
    "train_file = DATA_ROOT / 'percepiano_train.json'\n",
    "if train_file.exists():\n",
    "    print(f\"Data already exists at {DATA_ROOT}\")\n",
    "else:\n",
    "    print(\"Downloading PercePiano data from Google Drive...\")\n",
    "    result = subprocess.run(\n",
    "        ['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "\n",
    "# Verify data\n",
    "for split in ['train', 'val', 'test']:\n",
    "    path = DATA_ROOT / f'percepiano_{split}.json'\n",
    "    if path.exists():\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"{split}: {len(data)} samples\")\n",
    "    else:\n",
    "        print(f\"ERROR: {path} not found!\")\n",
    "\n",
    "# Check MIDI files\n",
    "midi_dir = DATA_ROOT / 'PercePiano' / 'virtuoso' / 'data' / 'all_2rounds'\n",
    "if midi_dir.exists():\n",
    "    midi_files = list(midi_dir.glob('*.mid'))\n",
    "    print(f\"\\nMIDI files: {len(midi_files)}\")\n",
    "else:\n",
    "    print(f\"\\nERROR: MIDI directory not found at {midi_dir}\")\n",
    "    print(\"Make sure to upload the full PercePiano repository\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Update MIDI Paths in JSON Files\n",
    "\n",
    "The JSON files have local paths - we need to update them to point to Thunder Compute paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path('/tmp/percepiano_data')\n",
    "\n",
    "# Update paths in JSON files\n",
    "for split in ['train', 'val', 'test']:\n",
    "    path = DATA_ROOT / f'percepiano_{split}.json'\n",
    "    \n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Update MIDI paths\n",
    "    for sample in data:\n",
    "        old_path = sample['midi_path']\n",
    "        # Extract just the filename\n",
    "        filename = Path(old_path).name\n",
    "        # Set new path\n",
    "        sample['midi_path'] = str(DATA_ROOT / 'PercePiano' / 'virtuoso' / 'data' / 'all_2rounds' / filename)\n",
    "    \n",
    "    # Save updated file\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"Updated {split}: {len(data)} samples\")\n",
    "\n",
    "# Verify a path\n",
    "with open(DATA_ROOT / 'percepiano_train.json') as f:\n",
    "    data = json.load(f)\n",
    "sample_path = Path(data[0]['midi_path'])\n",
    "print(f\"\\nSample MIDI path: {sample_path}\")\n",
    "print(f\"Exists: {sample_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')  # Tensor Core optimization\n",
    "\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data_dir': '/tmp/percepiano_data',\n",
    "    \n",
    "    # Model Architecture (matches configs/midi_only_percepiano.yaml)\n",
    "    'midi_hidden_dim': 256,\n",
    "    'midi_num_layers': 6,\n",
    "    'midi_num_heads': 8,\n",
    "    'max_seq_length': 1024,\n",
    "    'lstm_hidden': 256,\n",
    "    'lstm_layers': 2,\n",
    "    'attention_heads': 4,\n",
    "    'shared_hidden': 256,\n",
    "    'task_hidden': 128,\n",
    "    'dropout': 0.1,\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 16,  # T4: 16, A100: 32\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'max_epochs': 30,\n",
    "    'early_stopping_patience': 7,\n",
    "    'gradient_clip_val': 1.0,\n",
    "    'precision': '16-mixed',\n",
    "    \n",
    "    # Checkpoints\n",
    "    'checkpoint_dir': '/tmp/checkpoints/midi_only_percepiano',\n",
    "    'gdrive_checkpoint': 'gdrive:crescendai_checkpoints/midi_only_percepiano',\n",
    "}\n",
    "\n",
    "# Print config\n",
    "print(\"Training Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.data.percepiano_dataset import create_dataloaders\n",
    "\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    data_dir=Path(CONFIG['data_dir']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    max_seq_length=CONFIG['max_seq_length'],\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Test a batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  midi_tokens: {batch['midi_tokens'].shape}\")\n",
    "print(f\"  attention_mask: {batch['attention_mask'].shape}\")\n",
    "print(f\"  scores: {batch['scores'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.midi_only_module import MIDIOnlyModule\n",
    "\n",
    "model = MIDIOnlyModule(\n",
    "    midi_hidden_dim=CONFIG['midi_hidden_dim'],\n",
    "    midi_num_layers=CONFIG['midi_num_layers'],\n",
    "    midi_num_heads=CONFIG['midi_num_heads'],\n",
    "    max_seq_length=CONFIG['max_seq_length'],\n",
    "    lstm_hidden=CONFIG['lstm_hidden'],\n",
    "    lstm_layers=CONFIG['lstm_layers'],\n",
    "    attention_heads=CONFIG['attention_heads'],\n",
    "    shared_hidden=CONFIG['shared_hidden'],\n",
    "    task_hidden=CONFIG['task_hidden'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay'],\n",
    "    dropout=CONFIG['dropout'],\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"\\nDimensions: {model.dimensions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CONFIG['checkpoint_dir'],\n",
    "    filename='midi_only-{epoch:02d}-{val_mean_r:.3f}',\n",
    "    monitor='val/mean_r',\n",
    "    mode='max',\n",
    "    save_top_k=3,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val/mean_r',\n",
    "    patience=CONFIG['early_stopping_patience'],\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "# LR monitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir='/tmp/logs',\n",
    "    name='midi_only_percepiano',\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=CONFIG['max_epochs'],\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    precision=CONFIG['precision'],\n",
    "    gradient_clip_val=CONFIG['gradient_clip_val'],\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "print(\"Trainer configured!\")\n",
    "print(f\"  Precision: {CONFIG['precision']}\")\n",
    "print(f\"  Max epochs: {CONFIG['max_epochs']}\")\n",
    "print(f\"  Early stopping patience: {CONFIG['early_stopping_patience']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync checkpoints to Google Drive\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(\"Syncing checkpoints to Google Drive...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', CONFIG['checkpoint_dir'], CONFIG['gdrive_checkpoint'], '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    print(\"Sync complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with best checkpoint\n",
    "print(\"\\nRunning test with best checkpoint...\")\n",
    "best_path = checkpoint_callback.best_model_path\n",
    "print(f\"Best checkpoint: {best_path}\")\n",
    "\n",
    "if best_path:\n",
    "    test_results = trainer.test(model, test_loader, ckpt_path=best_path)\n",
    "    print(\"\\nTest Results:\")\n",
    "    for k, v in test_results[0].items():\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Load best model\n",
    "best_model = MIDIOnlyModule.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "best_model.eval()\n",
    "best_model.cuda()\n",
    "\n",
    "# Collect predictions\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        outputs = best_model(batch['midi_tokens'], batch['attention_mask'])\n",
    "        all_preds.append(outputs['predictions'].cpu())\n",
    "        all_targets.append(batch['scores'].cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "print(\"Per-Dimension Results:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Dimension':<20} {'Pearson r':<12} {'R^2':<12} {'MAE':<12}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "dimensions = best_model.dimensions\n",
    "results = {}\n",
    "\n",
    "for i, dim in enumerate(dimensions):\n",
    "    preds = all_preds[:, i]\n",
    "    targets = all_targets[:, i]\n",
    "    \n",
    "    # Pearson correlation\n",
    "    r, p = stats.pearsonr(preds, targets)\n",
    "    \n",
    "    # R-squared\n",
    "    ss_res = np.sum((targets - preds) ** 2)\n",
    "    ss_tot = np.sum((targets - np.mean(targets)) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n",
    "    \n",
    "    # MAE\n",
    "    mae = np.mean(np.abs(preds - targets))\n",
    "    \n",
    "    results[dim] = {'r': r, 'r2': r2, 'mae': mae}\n",
    "    print(f\"{dim:<20} {r:<12.4f} {r2:<12.4f} {mae:<12.4f}\")\n",
    "\n",
    "# Overall metrics\n",
    "mean_r = np.mean([v['r'] for v in results.values()])\n",
    "mean_r2 = np.mean([v['r2'] for v in results.values()])\n",
    "mean_mae = np.mean([v['mae'] for v in results.values()])\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"{'MEAN':<20} {mean_r:<12.4f} {mean_r2:<12.4f} {mean_mae:<12.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare to baselines\n",
    "print(\"\\nComparison to PercePiano Baselines:\")\n",
    "print(f\"  Bi-LSTM baseline: R^2 = 0.185\")\n",
    "print(f\"  MidiBERT:         R^2 = 0.313\")\n",
    "print(f\"  Best (HAN):       R^2 = 0.397\")\n",
    "print(f\"  Our model:        R^2 = {mean_r2:.3f}\")\n",
    "\n",
    "if mean_r2 >= 0.185:\n",
    "    print(\"\\n  SUCCESS: Meets baseline target!\")\n",
    "if mean_r2 >= 0.30:\n",
    "    print(\"  SUCCESS: Meets stretch goal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Save Final Model and Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Save final model for inference\n",
    "final_path = Path(CONFIG['checkpoint_dir']) / 'midi_scorer_final.pt'\n",
    "torch.save({\n",
    "    'state_dict': best_model.state_dict(),\n",
    "    'hparams': dict(best_model.hparams),\n",
    "    'dimensions': best_model.dimensions,\n",
    "    'results': results,\n",
    "    'mean_r2': mean_r2,\n",
    "    'mean_r': mean_r,\n",
    "}, final_path)\n",
    "print(f\"Saved final model to {final_path}\")\n",
    "\n",
    "# Final sync to Google Drive\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(\"\\nFinal sync to Google Drive...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', CONFIG['checkpoint_dir'], CONFIG['gdrive_checkpoint'], '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    print(\"Sync complete!\")\n",
    "    print(f\"Checkpoints available at: {CONFIG['gdrive_checkpoint']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
