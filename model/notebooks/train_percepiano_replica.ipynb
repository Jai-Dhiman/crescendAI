{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PercePiano Replica Training (4-Fold Cross-Validation)\n",
    "\n",
    "Train the PercePiano replica model using 4-fold piece-based cross-validation,\n",
    "matching the methodology from the PercePiano paper.\n",
    "\n",
    "## Attribution\n",
    "\n",
    "> **PercePiano: A Benchmark for Perceptual Evaluation of Piano Performance**  \n",
    "> Park, Jongho and Kim, Dasaem et al.  \n",
    "> ISMIR 2024 / Nature Scientific Reports 2024  \n",
    "> GitHub: https://github.com/JonghoKimSNU/PercePiano\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- **Piece-based splits**: All performances of the same piece stay in the same fold\n",
    "- **4-fold CV**: Each fold takes turns as validation set\n",
    "- **Test set**: 15% of pieces held out for final evaluation\n",
    "- **Per-fold normalization**: Stats computed from training folds only\n",
    "\n",
    "## Expected Results\n",
    "\n",
    "- Target R2: 0.35-0.40 (matching published SOTA)\n",
    "- Training time: ~2-4 hours on T4/A100 (all 4 folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv and clone repository\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths and Check rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path('/tmp/percepiano_vnet_split')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_kfold')\n",
    "LOG_ROOT = Path('/tmp/logs/percepiano_kfold')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_vnet_split'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/percepiano_kfold'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERCEPIANO REPLICA TRAINING (4-FOLD CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "\n",
    "if 'gdrive:' in result.stdout:\n",
    "    print(\"rclone 'gdrive' remote: CONFIGURED\")\n",
    "    RCLONE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"rclone 'gdrive' remote: NOT CONFIGURED\")\n",
    "    print(\"Run 'rclone config' in terminal to set up Google Drive\")\n",
    "    RCLONE_AVAILABLE = False\n",
    "\n",
    "print(f\"\\nData directory: {DATA_ROOT}\")\n",
    "print(f\"Checkpoint directory: {CHECKPOINT_ROOT}\")\n",
    "print(f\"Log directory: {LOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Download Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if not RCLONE_AVAILABLE:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "# Download preprocessed data\n",
    "print(\"Downloading preprocessed VirtuosoNet features from Google Drive...\")\n",
    "subprocess.run(\n",
    "    ['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'],\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_samples = 0\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = DATA_ROOT / split\n",
    "    if split_dir.exists():\n",
    "        count = len(list(split_dir.glob('*.pkl')))\n",
    "        total_samples += count\n",
    "        print(f\"  {split}: {count} samples\")\n",
    "    else:\n",
    "        print(f\"  {split}: MISSING!\")\n",
    "\n",
    "print(f\"  Total: {total_samples} samples\")\n",
    "\n",
    "stat_file = DATA_ROOT / 'stat.pkl'\n",
    "print(f\"  stat.pkl: {'present' if stat_file.exists() else 'MISSING!'}\")\n",
    "\n",
    "fold_file = DATA_ROOT / 'fold_assignments.json'\n",
    "print(f\"  fold_assignments.json: {'present' if fold_file.exists() else 'will be created'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Create Fold Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.data.kfold_split import (\n",
    "    create_piece_based_folds,\n",
    "    save_fold_assignments,\n",
    "    load_fold_assignments,\n",
    "    print_fold_statistics,\n",
    ")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'fold_assignments.json'\n",
    "N_FOLDS = 4\n",
    "TEST_RATIO = 0.15\n",
    "SEED = 42\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FOLD ASSIGNMENT CREATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create fold assignments (or load existing)\n",
    "if FOLD_FILE.exists():\n",
    "    print(f\"\\nLoading existing fold assignments from {FOLD_FILE}\")\n",
    "    fold_assignments = load_fold_assignments(FOLD_FILE)\n",
    "else:\n",
    "    print(f\"\\nCreating new {N_FOLDS}-fold piece-based splits...\")\n",
    "    fold_assignments = create_piece_based_folds(\n",
    "        data_dir=DATA_ROOT,\n",
    "        n_folds=N_FOLDS,\n",
    "        test_ratio=TEST_RATIO,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    save_fold_assignments(fold_assignments, FOLD_FILE)\n",
    "\n",
    "# Print statistics\n",
    "print_fold_statistics(fold_assignments, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# PercePiano Configuration (matched to original paper)\n",
    "CONFIG = {\n",
    "    # K-Fold settings\n",
    "    'n_folds': N_FOLDS,\n",
    "    'test_ratio': TEST_RATIO,\n",
    "    \n",
    "    # Data\n",
    "    'data_dir': str(DATA_ROOT),\n",
    "    'checkpoint_dir': str(CHECKPOINT_ROOT),\n",
    "    'log_dir': str(LOG_ROOT),\n",
    "    \n",
    "    # Model input (79 normalized features, unnorm used for augmentation only)\n",
    "    'input_size': 79,\n",
    "    \n",
    "    # HAN Architecture (han_bigger256_concat.yml)\n",
    "    'hidden_size': 256,\n",
    "    'note_layers': 2,\n",
    "    'voice_layers': 2,\n",
    "    'beat_layers': 2,\n",
    "    'measure_layers': 1,\n",
    "    'num_attention_heads': 8,\n",
    "    'final_hidden': 128,\n",
    "    \n",
    "    # Training (parser.py defaults)\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 32,\n",
    "    'max_epochs': 100,\n",
    "    'early_stopping_patience': 20,\n",
    "    'gradient_clip_val': 2.0,\n",
    "    'precision': '16-mixed',\n",
    "    \n",
    "    # Dataset\n",
    "    'max_notes': 1024,\n",
    "    'num_workers': 0,  # Avoid shared memory issues on Thunder Compute\n",
    "    'augment_train': True,\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Initialize K-Fold Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.training.kfold_trainer import KFoldTrainer\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Set seed for reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Create K-Fold trainer\n",
    "kfold_trainer = KFoldTrainer(\n",
    "    config=CONFIG,\n",
    "    fold_assignments=fold_assignments,\n",
    "    data_dir=DATA_ROOT,\n",
    "    checkpoint_dir=CHECKPOINT_ROOT,\n",
    "    log_dir=LOG_ROOT,\n",
    "    n_folds=N_FOLDS,\n",
    ")\n",
    "\n",
    "print(\"K-Fold Trainer initialized\")\n",
    "print(f\"  Folds: {N_FOLDS}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_ROOT}\")\n",
    "print(f\"  Logs: {LOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Train All Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STARTING 4-FOLD CROSS-VALIDATION TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPercePiano SOTA baselines:\")\n",
    "print(\"  Bi-LSTM: R2 = 0.185\")\n",
    "print(\"  MidiBERT: R2 = 0.313\")\n",
    "print(\"  Bi-LSTM + SA + HAN: R2 = 0.397 (SOTA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train all folds\n",
    "aggregate_metrics = kfold_trainer.train_all_folds(verbose=True)\n",
    "\n",
    "# Save results\n",
    "kfold_trainer.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync checkpoints to Google Drive after training\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(\"Syncing checkpoints to Google Drive...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    print(\"Sync complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 8: Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all fold models on held-out test set\n",
    "test_results = kfold_trainer.evaluate_on_test(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 9: Per-Fold Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PER-FOLD VALIDATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Fold':<6} {'Val R2':>10} {'Val Pearson':>12} {'Val MAE':>10} {'Val RMSE':>10} {'Epochs':>8} {'Time (s)':>10}\")\n",
    "print(f\"{'-'*6} {'-'*10} {'-'*12} {'-'*10} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "\n",
    "for m in kfold_trainer.fold_metrics:\n",
    "    print(f\"{m.fold_id:<6} {m.val_r2:>+10.4f} {m.val_pearson:>+12.4f} {m.val_mae:>10.4f} {m.val_rmse:>10.4f} {m.epochs_trained:>8} {m.training_time_seconds:>10.1f}\")\n",
    "\n",
    "print(f\"{'-'*6} {'-'*10} {'-'*12} {'-'*10} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "print(f\"{'Mean':<6} {aggregate_metrics.mean_r2:>+10.4f} {aggregate_metrics.mean_pearson:>+12.4f} {aggregate_metrics.mean_mae:>10.4f} {aggregate_metrics.mean_rmse:>10.4f}\")\n",
    "print(f\"{'Std':<6} {aggregate_metrics.std_r2:>+10.4f} {aggregate_metrics.std_pearson:>+12.4f} {aggregate_metrics.std_mae:>10.4f} {aggregate_metrics.std_rmse:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 10: Per-Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PER-DIMENSION R2 (Mean +/- Std across folds)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort dimensions by mean R2\n",
    "sorted_dims = sorted(\n",
    "    aggregate_metrics.per_dim_mean_r2.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{'Dimension':<25} {'Mean R2':>10} {'Std R2':>10} {'Status':<12}\")\n",
    "print(f\"{'-'*25} {'-'*10} {'-'*10} {'-'*12}\")\n",
    "\n",
    "for dim, mean_r2 in sorted_dims:\n",
    "    std_r2 = aggregate_metrics.per_dim_std_r2[dim]\n",
    "    \n",
    "    if mean_r2 >= 0.3:\n",
    "        status = \"[GOOD]\"\n",
    "    elif mean_r2 >= 0.1:\n",
    "        status = \"[OK]\"\n",
    "    elif mean_r2 >= 0:\n",
    "        status = \"[WEAK]\"\n",
    "    else:\n",
    "        status = \"[FAILED]\"\n",
    "    \n",
    "    print(f\"{dim:<25} {mean_r2:>+10.4f} {std_r2:>10.4f} {status:<12}\")\n",
    "\n",
    "# Summary\n",
    "positive = sum(1 for d, r in sorted_dims if r > 0)\n",
    "strong = sum(1 for d, r in sorted_dims if r >= 0.2)\n",
    "n_dims = len(sorted_dims)\n",
    "\n",
    "print(f\"\\nSummary: {positive}/{n_dims} positive R2, {strong}/{n_dims} strong (>= 0.2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Step 11: Final Summary and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport torch\nfrom pathlib import Path\n\nprint(\"=\"*80)\nprint(\"FINAL SUMMARY\")\nprint(\"=\"*80)\n\n# Cross-validation results\nprint(f\"\\n4-Fold Cross-Validation Results:\")\nprint(f\"  Mean R2:       {aggregate_metrics.mean_r2:.4f} +/- {aggregate_metrics.std_r2:.4f}\")\nprint(f\"  Mean Pearson:  {aggregate_metrics.mean_pearson:.4f} +/- {aggregate_metrics.std_pearson:.4f}\")\nprint(f\"  Mean Spearman: {aggregate_metrics.mean_spearman:.4f} +/- {aggregate_metrics.std_spearman:.4f}\")\nprint(f\"  Mean MAE:      {aggregate_metrics.mean_mae:.4f} +/- {aggregate_metrics.std_mae:.4f}\")\nprint(f\"  Mean RMSE:     {aggregate_metrics.mean_rmse:.4f} +/- {aggregate_metrics.std_rmse:.4f}\")\nprint(f\"  Training time: {aggregate_metrics.total_training_time/60:.1f} minutes\")\n\n# Test set results\nprint(f\"\\nTest Set (Ensemble of 4 models):\")\nprint(f\"  R2:       {test_results['ensemble']['r2']:.4f}\")\nprint(f\"  Pearson:  {test_results['ensemble']['pearson']:.4f}\")\nprint(f\"  Spearman: {test_results['ensemble']['spearman']:.4f}\")\nprint(f\"  MAE:      {test_results['ensemble']['mae']:.4f}\")\nprint(f\"  RMSE:     {test_results['ensemble']['rmse']:.4f}\")\n\n# Comparison to baselines\nprint(f\"\\nComparison to PercePiano baselines:\")\nprint(f\"  Bi-LSTM:      R2 = 0.185\")\nprint(f\"  MidiBERT:     R2 = 0.313\")\nprint(f\"  HAN SOTA:     R2 = 0.397\")\nprint(f\"  Ours (CV):    R2 = {aggregate_metrics.mean_r2:.3f} +/- {aggregate_metrics.std_r2:.3f}\")\nprint(f\"  Ours (Test):  R2 = {test_results['ensemble']['r2']:.3f}\")\n\n# Interpretation\ncv_r2 = aggregate_metrics.mean_r2\ntest_r2 = test_results['ensemble']['r2']\n\nprint(f\"\\nInterpretation:\")\nif cv_r2 >= 0.35:\n    print(f\"  [EXCELLENT] CV R2 >= 0.35 matches published SOTA!\")\nelif cv_r2 >= 0.25:\n    print(f\"  [GOOD] CV R2 >= 0.25 is usable for pseudo-labeling\")\nelif cv_r2 >= 0.10:\n    print(f\"  [FAIR] CV R2 >= 0.10 shows learning, needs improvement\")\nelse:\n    print(f\"  [NEEDS WORK] CV R2 < 0.10, significant improvement needed\")\n\n# Save ensemble model if good enough\nif cv_r2 >= 0.25:\n    print(f\"\\nModel qualifies for pseudo-labeling MAESTRO!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sync to Google Drive\n",
    "print(\"=\"*60)\n",
    "print(\"SYNC TO GOOGLE DRIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(f\"\\nSyncing all checkpoints and results...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    # Also sync fold assignments back to data directory\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(FOLD_FILE), GDRIVE_DATA_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSync complete!\")\n",
    "    print(f\"  Checkpoints: {GDRIVE_CHECKPOINT_PATH}\")\n",
    "    print(f\"  Fold assignments: {GDRIVE_DATA_PATH}\")\n",
    "else:\n",
    "    print(f\"\\nrclone not available - skipping sync\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}