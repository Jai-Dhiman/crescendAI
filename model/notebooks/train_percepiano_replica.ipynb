{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PercePiano Replica Training - Phase 2 Incremental Build\n",
    "\n",
    "**Upload and Run**: Configure the cell below, then Run All.\n",
    "\n",
    "## Phase 2 Hierarchy Isolation\n",
    "```\n",
    "VirtuosoNetSingle (7-layer flat)     -> R2 = 0.19 (validated)\n",
    "    + Beat hierarchy                  -> R2 = ??? (target: ~0.25-0.30)\n",
    "    + Measure hierarchy               -> R2 = ??? (target: ~0.35-0.40)\n",
    "Full HAN (VirtuosoNetMultiLevel)     -> R2 = 0.40 (SOTA target)\n",
    "```\n",
    "\n",
    "## Model Types\n",
    "| Model | Architecture | Expected R2 |\n",
    "|-------|-------------|-------------|\n",
    "| `baseline` | 7-layer BiLSTM | ~0.19 |\n",
    "| `baseline_beat` | 7-layer BiLSTM + Beat hierarchy | ~0.25-0.30 |\n",
    "| `baseline_beat_measure` | 7-layer BiLSTM + Beat + Measure | ~0.35-0.40 |\n",
    "| `han` | Full HAN (note+voice+beat+measure) | ~0.40 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8qzbla1rme3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv and clone repository\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Config Vars\n",
    "\n",
    "# Which models to train (Phase 2 hierarchy isolation)\n",
    "TRAIN_BASELINE = True\n",
    "TRAIN_BASELINE_BEAT = True          # + Beat hierarchy (~0.25-0.30)\n",
    "TRAIN_BASELINE_BEAT_MEASURE = True  # + Measure hierarchy (~0.35-0.40)\n",
    "TRAIN_HAN = True\n",
    "\n",
    "# Training settings\n",
    "FOLD_ID = 2\n",
    "MAX_EPOCHS = 200\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "RESTART_TRAINING = True\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Models: baseline={TRAIN_BASELINE}, beat={TRAIN_BASELINE_BEAT}, beat+measure={TRAIN_BASELINE_BEAT_MEASURE}, han={TRAIN_HAN}\")\n",
    "print(f\"  Fold: {FOLD_ID}, Epochs: {MAX_EPOCHS}, Patience: {EARLY_STOPPING_PATIENCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path('/tmp/percepiano_vnet_84dim')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_kfold')\n",
    "LOG_ROOT = Path('/tmp/logs/percepiano_kfold')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_vnet_84dim'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/percepiano_kfold'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERCEPIANO REPLICA TRAINING - PHASE 2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clear checkpoints if restarting (uses RESTART_TRAINING from config)\n",
    "if RESTART_TRAINING and CHECKPOINT_ROOT.exists():\n",
    "    print(f\"\\nRESTART_TRAINING=True: Clearing checkpoints\")\n",
    "    shutil.rmtree(CHECKPOINT_ROOT)\n",
    "\n",
    "if RESTART_TRAINING and LOG_ROOT.exists():\n",
    "    shutil.rmtree(LOG_ROOT)\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "RCLONE_AVAILABLE = 'gdrive:' in result.stdout\n",
    "print(f\"\\nrclone gdrive: {'CONFIGURED' if RCLONE_AVAILABLE else 'NOT CONFIGURED'}\")\n",
    "print(f\"Data: {DATA_ROOT}\")\n",
    "print(f\"Checkpoints: {CHECKPOINT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RCLONE_AVAILABLE:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "print(\"Downloading data from Google Drive...\")\n",
    "subprocess.run(['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'], capture_output=False)\n",
    "\n",
    "# Verify\n",
    "total = sum(1 for _ in DATA_ROOT.glob('**/*.pkl'))\n",
    "print(f\"\\nTotal samples: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Create Fold Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.data.kfold_split import (\n",
    "    create_piece_based_folds,\n",
    "    save_fold_assignments,\n",
    "    load_fold_assignments,\n",
    "    print_fold_statistics,\n",
    ")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'fold_assignments.json'\n",
    "N_FOLDS = 4\n",
    "SEED = 42\n",
    "\n",
    "if FOLD_FILE.exists():\n",
    "    fold_assignments = load_fold_assignments(FOLD_FILE)\n",
    "    print(\"Loaded existing fold assignments\")\n",
    "else:\n",
    "    fold_assignments = create_piece_based_folds(DATA_ROOT, N_FOLDS, test_ratio=0.15, seed=SEED)\n",
    "    save_fold_assignments(fold_assignments, FOLD_FILE)\n",
    "    print(\"Created new fold assignments\")\n",
    "\n",
    "print_fold_statistics(fold_assignments, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from src.percepiano.training.kfold_trainer import (\n",
    "    MODEL_TYPE_BASELINE,\n",
    "    MODEL_TYPE_BASELINE_BEAT,\n",
    "    MODEL_TYPE_BASELINE_BEAT_MEASURE,\n",
    "    MODEL_TYPE_HAN,\n",
    ")\n",
    "\n",
    "# Build MODELS_TO_TRAIN from config booleans\n",
    "MODELS_TO_TRAIN = []\n",
    "if TRAIN_BASELINE:\n",
    "    MODELS_TO_TRAIN.append(MODEL_TYPE_BASELINE)\n",
    "if TRAIN_BASELINE_BEAT:\n",
    "    MODELS_TO_TRAIN.append(MODEL_TYPE_BASELINE_BEAT)\n",
    "if TRAIN_BASELINE_BEAT_MEASURE:\n",
    "    MODELS_TO_TRAIN.append(MODEL_TYPE_BASELINE_BEAT_MEASURE)\n",
    "if TRAIN_HAN:\n",
    "    MODELS_TO_TRAIN.append(MODEL_TYPE_HAN)\n",
    "\n",
    "CONFIG = {\n",
    "    'n_folds': N_FOLDS,\n",
    "    'test_ratio': 0.15,\n",
    "    'data_dir': str(DATA_ROOT),\n",
    "    'checkpoint_dir': str(CHECKPOINT_ROOT),\n",
    "    'log_dir': str(LOG_ROOT),\n",
    "    'input_size': 79,\n",
    "    'hidden_size': 256,\n",
    "    'note_layers': 2,\n",
    "    'voice_layers': 2,\n",
    "    'beat_layers': 2,\n",
    "    'measure_layers': 1,\n",
    "    'num_attention_heads': 8,\n",
    "    'learning_rate': 2.5e-5,\n",
    "    'weight_decay': 1e-5,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 8,\n",
    "    'max_epochs': MAX_EPOCHS,\n",
    "    'early_stopping_patience': EARLY_STOPPING_PATIENCE,\n",
    "    'gradient_clip_val': 2.0,\n",
    "    'precision': '32',\n",
    "    'max_notes': 5000,\n",
    "    'slice_len': 5000,\n",
    "    'num_workers': 4,\n",
    "    'augment_train': False,\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING PLAN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModels to train on Fold {FOLD_ID}:\")\n",
    "for m in MODELS_TO_TRAIN:\n",
    "    expected = {\"baseline\": \"~0.19\", \"baseline_beat\": \"~0.25-0.30\", \n",
    "                \"baseline_beat_measure\": \"~0.35-0.40\", \"han\": \"~0.40\"}.get(m, \"?\")\n",
    "    print(f\"  - {m} (expected R2: {expected})\")\n",
    "print(f\"\\nMax epochs: {MAX_EPOCHS}, Early stopping: {EARLY_STOPPING_PATIENCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Pre-Training Data Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from src.percepiano.data.percepiano_vnet_dataset import PercePianoKFoldDataset\n",
    "from src.percepiano.training.diagnostics import analyze_indices\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PRE-TRAINING DATA DIAGNOSTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_ds = PercePianoKFoldDataset(\n",
    "    data_dir=DATA_ROOT, fold_assignments=fold_assignments, fold_id=0, mode=\"train\",\n",
    "    max_notes=CONFIG['max_notes'], slice_len=CONFIG['slice_len'],\n",
    ")\n",
    "batch = next(iter(DataLoader(test_ds, batch_size=4, shuffle=False)))\n",
    "\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  input_features: {batch['input_features'].shape}\")\n",
    "print(f\"  beat indices: {batch['note_locations_beat'].shape}\")\n",
    "print(f\"  measure indices: {batch['note_locations_measure'].shape}\")\n",
    "\n",
    "idx_stats = analyze_indices(batch['note_locations_beat'], batch['note_locations_measure'])\n",
    "print(f\"\\nIndex analysis:\")\n",
    "print(f\"  Beat range: [{idx_stats['beat_min']}, {idx_stats['beat_max']}]\")\n",
    "print(f\"  Measure range: [{idx_stats['measure_min']}, {idx_stats['measure_max']}]\")\n",
    "\n",
    "issues = []\n",
    "if idx_stats['beat_min'] != 1:\n",
    "    issues.append(f\"Beat indices start from {idx_stats['beat_min']} (expected 1)\")\n",
    "if idx_stats['negative_beat_count'] > 0:\n",
    "    issues.append(f\"{idx_stats['negative_beat_count']} negative zero-shifted beat values\")\n",
    "\n",
    "if issues:\n",
    "    print(f\"\\n[ISSUES FOUND]\")\n",
    "    for issue in issues:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(f\"\\n[OK] Data pipeline looks correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Train Model\n",
    "\n",
    "Select model type and folds to train below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.training.kfold_trainer import KFoldTrainer\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Uses FOLD_ID and MODELS_TO_TRAIN from config cells above\n",
    "all_results = {}\n",
    "\n",
    "for MODEL_TYPE in MODELS_TO_TRAIN:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"TRAINING: {MODEL_TYPE} on Fold {FOLD_ID}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    trainer = KFoldTrainer(\n",
    "        config=CONFIG,\n",
    "        fold_assignments=fold_assignments,\n",
    "        data_dir=DATA_ROOT,\n",
    "        checkpoint_dir=CHECKPOINT_ROOT,\n",
    "        log_dir=LOG_ROOT,\n",
    "        n_folds=N_FOLDS,\n",
    "        model_type=MODEL_TYPE,\n",
    "    )\n",
    "    \n",
    "    metrics = trainer.train_fold(fold_id=FOLD_ID, verbose=True, resume_from_checkpoint=False)\n",
    "    trainer.save_results()\n",
    "    \n",
    "    all_results[MODEL_TYPE] = {\n",
    "        'r2': metrics.val_r2,\n",
    "        'pearson': metrics.val_pearson,\n",
    "        'mae': metrics.val_mae,\n",
    "        'epochs': metrics.epochs_trained,\n",
    "        'trainer': trainer,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  {MODEL_TYPE}: R2 = {metrics.val_r2:+.4f}\")\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"PHASE 2 RESULTS COMPARISON (Fold {FOLD_ID})\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "baseline_r2 = 0.1931  # Validated baseline\n",
    "\n",
    "print(f\"\\n  {'Model':<30} {'R2':>10} {'Gain':>10} {'Expected':>12}\")\n",
    "print(f\"  {'-'*30} {'-'*10} {'-'*10} {'-'*12}\")\n",
    "print(f\"  {'baseline (reference)':<30} {'+0.1931':>10} {'---':>10} {'~0.19':>12}\")\n",
    "\n",
    "for model_type, result in all_results.items():\n",
    "    gain = result['r2'] - baseline_r2\n",
    "    expected = {\n",
    "        MODEL_TYPE_BASELINE: \"~0.19\",\n",
    "        MODEL_TYPE_BASELINE_BEAT: \"~0.25-0.30\",\n",
    "        MODEL_TYPE_BASELINE_BEAT_MEASURE: \"~0.35-0.40\",\n",
    "        MODEL_TYPE_HAN: \"~0.40\",\n",
    "    }.get(model_type, \"?\")\n",
    "    print(f\"  {model_type:<30} {result['r2']:>+10.4f} {gain:>+10.4f} {expected:>12}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Step 8: Post-Training Analysis\n",
    "\n",
    "Copy/paste these results for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "\n",
    "from src.percepiano.data.percepiano_vnet_dataset import (\n",
    "    PercePianoKFoldDataset,\n",
    "    percepiano_pack_collate,\n",
    ")\n",
    "from src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n",
    "\n",
    "# Analyze last trained model\n",
    "if not MODELS_TO_TRAIN:\n",
    "    print(\"[ERROR] No models were trained. Check config.\")\n",
    "else:\n",
    "    LAST_MODEL_TYPE = MODELS_TO_TRAIN[-1]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"POST-TRAINING ANALYSIS: {LAST_MODEL_TYPE}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Get trained model from last trainer\n",
    "    model = None\n",
    "    if 'trainer' in dir() and trainer is not None:\n",
    "        model = trainer.get_trained_model(FOLD_ID)\n",
    "        if model:\n",
    "            model = model.to(device).eval()\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"\\n[ERROR] No model available. Run training first.\")\n",
    "    else:\n",
    "        # Create validation dataloader\n",
    "        val_ds = PercePianoKFoldDataset(\n",
    "            data_dir=DATA_ROOT, fold_assignments=fold_assignments, fold_id=FOLD_ID,\n",
    "            mode=\"val\", max_notes=CONFIG['max_notes'], slice_len=CONFIG['slice_len'],\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_ds, batch_size=4, shuffle=False, num_workers=0, collate_fn=percepiano_pack_collate,\n",
    "        )\n",
    "        \n",
    "        # Collect predictions\n",
    "        all_preds, all_targets = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch_on_device = {}\n",
    "                for k, v in batch.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        batch_on_device[k] = v.to(device)\n",
    "                    elif isinstance(v, PackedSequence):\n",
    "                        batch_on_device[k] = PackedSequence(\n",
    "                            v.data.to(device), v.batch_sizes,\n",
    "                            v.sorted_indices.to(device) if v.sorted_indices is not None else None,\n",
    "                            v.unsorted_indices.to(device) if v.unsorted_indices is not None else None,\n",
    "                        )\n",
    "                    else:\n",
    "                        batch_on_device[k] = v\n",
    "                \n",
    "                note_locations = {\n",
    "                    'beat': batch_on_device['note_locations_beat'],\n",
    "                    'measure': batch_on_device['note_locations_measure'],\n",
    "                    'voice': batch_on_device['note_locations_voice'],\n",
    "                }\n",
    "                \n",
    "                outputs = model(\n",
    "                    batch_on_device['input_features'], note_locations,\n",
    "                    batch_on_device.get('attention_mask'), batch_on_device.get('lengths'),\n",
    "                )\n",
    "                all_preds.append(outputs['predictions'].cpu())\n",
    "                all_targets.append(batch_on_device['scores'].cpu())\n",
    "        \n",
    "        preds = torch.cat(all_preds).numpy()\n",
    "        targets = torch.cat(all_targets).numpy()\n",
    "        \n",
    "        # Overall metrics\n",
    "        r2 = r2_score(targets, preds)\n",
    "        pearson_r = np.mean([pearsonr(targets[:, i], preds[:, i])[0] for i in range(19)])\n",
    "        mae = np.mean(np.abs(targets - preds))\n",
    "        \n",
    "        print(f\"\\n  Model:   {LAST_MODEL_TYPE}\")\n",
    "        print(f\"  R2:      {r2:+.4f}\")\n",
    "        print(f\"  Pearson: {pearson_r:+.4f}\")\n",
    "        print(f\"  MAE:     {mae:.4f}\")\n",
    "        \n",
    "        # Prediction health\n",
    "        pred_std = preds.std()\n",
    "        target_std = targets.std()\n",
    "        print(f\"\\n  Prediction std: {pred_std:.4f} (target: {target_std:.4f})\")\n",
    "        if pred_std < target_std * 0.5:\n",
    "            print(f\"  [WARN] Prediction collapse detected!\")\n",
    "        \n",
    "        # Per-dimension R2\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"PER-DIMENSION R2\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        dim_r2s = [(dim, r2_score(targets[:, i], preds[:, i])) for i, dim in enumerate(PERCEPIANO_DIMENSIONS)]\n",
    "        dim_r2s.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\n  {'Dimension':<30} {'R2':>10} {'Status':>10}\")\n",
    "        print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n",
    "        for dim, dim_r2 in dim_r2s:\n",
    "            status = \"[GOOD]\" if dim_r2 >= 0.3 else \"[OK]\" if dim_r2 >= 0.1 else \"[WEAK]\" if dim_r2 >= 0 else \"[NEG]\"\n",
    "            print(f\"  {dim:<30} {dim_r2:>+10.4f} {status:>10}\")\n",
    "        \n",
    "        positive_dims = sum(1 for _, r2 in dim_r2s if r2 > 0)\n",
    "        print(f\"\\n  Positive R2: {positive_dims}/19\")\n",
    "        \n",
    "        # Hierarchy diagnostics (for models with hierarchy)\n",
    "        if hasattr(model, 'beat_attention'):\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"HIERARCHY DIAGNOSTICS\")\n",
    "            print(f\"{'='*70}\")\n",
    "            \n",
    "            # Run one batch with diagnose=True\n",
    "            batch = next(iter(val_loader))\n",
    "            batch_on_device = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "            if isinstance(batch_on_device['input_features'], PackedSequence):\n",
    "                batch_on_device['input_features'] = PackedSequence(\n",
    "                    batch['input_features'].data.to(device),\n",
    "                    batch['input_features'].batch_sizes,\n",
    "                    batch['input_features'].sorted_indices.to(device) if batch['input_features'].sorted_indices is not None else None,\n",
    "                    batch['input_features'].unsorted_indices.to(device) if batch['input_features'].unsorted_indices is not None else None,\n",
    "                )\n",
    "            \n",
    "            note_locations = {\n",
    "                'beat': batch_on_device['note_locations_beat'],\n",
    "                'measure': batch_on_device['note_locations_measure'],\n",
    "                'voice': batch_on_device['note_locations_voice'],\n",
    "            }\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _ = model(batch_on_device['input_features'], note_locations, diagnose=True)\n",
    "            \n",
    "            # Contractor weight analysis\n",
    "            if hasattr(model, 'note_contractor'):\n",
    "                w = model.note_contractor.weight.data\n",
    "                if w.shape[1] == 1024:  # baseline_beat\n",
    "                    lstm_w = w[:, :512].abs().mean().item()\n",
    "                    beat_w = w[:, 512:].abs().mean().item()\n",
    "                    print(f\"\\n  Contractor weights:\")\n",
    "                    print(f\"    LSTM branch:  {lstm_w:.4f}\")\n",
    "                    print(f\"    Beat branch:  {beat_w:.4f}\")\n",
    "                    print(f\"    Ratio (Beat/LSTM): {beat_w/lstm_w:.2f}x\")\n",
    "                    if beat_w < lstm_w * 0.1:\n",
    "                        print(f\"    [WARN] Contractor may be ignoring beat branch!\")\n",
    "                elif w.shape[1] == 1536:  # baseline_beat_measure\n",
    "                    lstm_w = w[:, :512].abs().mean().item()\n",
    "                    beat_w = w[:, 512:1024].abs().mean().item()\n",
    "                    meas_w = w[:, 1024:].abs().mean().item()\n",
    "                    print(f\"\\n  Contractor weights:\")\n",
    "                    print(f\"    LSTM branch:    {lstm_w:.4f}\")\n",
    "                    print(f\"    Beat branch:    {beat_w:.4f}\")\n",
    "                    print(f\"    Measure branch: {meas_w:.4f}\")\n",
    "        \n",
    "        # Comparison to baseline\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"COMPARISON TO BASELINE\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        baseline_r2 = 0.1931\n",
    "        hierarchy_gain = r2 - baseline_r2\n",
    "        \n",
    "        print(f\"\\n  {'Model':<30} {'R2':>10} {'Expected':>10}\")\n",
    "        print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n",
    "        print(f\"  {'Baseline (7-layer BiLSTM)':<30} {'+0.1931':>10} {'~0.19':>10}\")\n",
    "        \n",
    "        expected = {\"baseline_beat\": \"~0.25-0.30\", \"baseline_beat_measure\": \"~0.35-0.40\", \"han\": \"~0.40\"}.get(LAST_MODEL_TYPE, \"~0.19\")\n",
    "        print(f\"  {LAST_MODEL_TYPE:<30} {r2:>+10.4f} {expected:>10}\")\n",
    "        print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n",
    "        print(f\"  {'Hierarchy Gain':<30} {hierarchy_gain:>+10.4f}\")\n",
    "        \n",
    "        if hierarchy_gain > 0.15:\n",
    "            print(f\"\\n  [GOOD] Significant hierarchy contribution!\")\n",
    "        elif hierarchy_gain > 0.05:\n",
    "            print(f\"\\n  [PARTIAL] Some hierarchy contribution\")\n",
    "        elif hierarchy_gain > 0:\n",
    "            print(f\"\\n  [WEAK] Minimal hierarchy contribution\")\n",
    "        else:\n",
    "            print(f\"\\n  [NONE] No hierarchy contribution (may be hurting)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Step 9: Test Set Evaluation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set evaluation requires training all 4 folds\n",
    "# For Phase 2 hierarchy isolation, we only train fold 2\n",
    "print(\"Skipping test evaluation (Phase 2 trains single fold only)\")\n",
    "print(\"To evaluate on test set, train all 4 folds with full K-fold training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Step 10: Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SYNC TO GOOGLE DRIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(f\"\\nSyncing checkpoints...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSyncing fold assignments...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(FOLD_FILE), GDRIVE_DATA_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSync complete!\")\n",
    "    print(f\"  Checkpoints: {GDRIVE_CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(\"rclone not available - skipping sync\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DONE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
