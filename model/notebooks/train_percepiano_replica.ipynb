{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PercePiano Replica Training (4-Fold Cross-Validation)\n",
    "\n",
    "Train the PercePiano replica model using 4-fold piece-based cross-validation,\n",
    "matching the methodology and hyperparameters from the PercePiano paper SOTA.\n",
    "\n",
    "## Attribution\n",
    "\n",
    "> **PercePiano: Piano Performance Evaluation Dataset with Multi-level Perceptual Features**  \n",
    "> Park, Kim et al.  \n",
    "> Nature Scientific Reports 2024  \n",
    "> Paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11450231/  \n",
    "> GitHub: https://github.com/JonghoKimSNU/PercePiano\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Following the exact approach from `m2pf_dataset_compositionfold.py`:\n",
    "\n",
    "- **Piece-based splits**: All performances of the same piece stay in the same fold\n",
    "- **Test set**: Select pieces randomly until reaching ~15% of SAMPLES (not pieces)\n",
    "- **4-fold CV**: Remaining pieces distributed round-robin across folds\n",
    "- **Per-fold normalization**: Stats computed from training folds only\n",
    "\n",
    "## Hyperparameters (SOTA Configuration - R2 = 0.397)\n",
    "\n",
    "These parameters match the published SOTA from `2_run_comp_multilevel_total.sh` and `han_bigger256_concat.yml`:\n",
    "\n",
    "| Parameter | SOTA Value | Notes |\n",
    "|-----------|------------|-------|\n",
    "| input_size | 79 | SOTA uses 79 base features (includes section_tempo) |\n",
    "| batch_size | 8 | From SOTA training script |\n",
    "| learning_rate | 2.5e-5 | From SOTA training script |\n",
    "| hidden_size | 256 | HAN encoder dimension |\n",
    "| prediction_head | 512->512->19 | From model_m2pf.py (NOT config's final_fc_size) |\n",
    "| dropout | 0.2 | Regularization |\n",
    "| augment_train | False | SOTA doesn't use key augmentation |\n",
    "| max_epochs | 200 | Extended training window |\n",
    "| early_stopping_patience | 40 | More patience for convergence |\n",
    "| gradient_clip_val | 2.0 | From parser.py |\n",
    "| **precision** | **32** | **FP32 (original uses FP32, not mixed precision)** |\n",
    "| **max_notes/slice_len** | **5000** | **SOTA slice size for overlapping sampling** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv and clone repository\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Clone original PercePiano for comparison (needed for data diagnostics)\n",
    "PERCEPIANO_PATH = '/tmp/crescendai/model/data/raw/PercePiano'\n",
    "if not os.path.exists(PERCEPIANO_PATH):\n",
    "    print(\"\\nCloning original PercePiano repository...\")\n",
    "    !git clone https://github.com/JonghoKimSNU/PercePiano.git {PERCEPIANO_PATH}\n",
    "else:\n",
    "    print(f\"\\nPercePiano already present at {PERCEPIANO_PATH}\")\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths and Check rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path('/tmp/percepiano_vnet_84dim')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_kfold')\n",
    "LOG_ROOT = Path('/tmp/logs/percepiano_kfold')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_vnet_84dim'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/percepiano_kfold'\n",
    "\n",
    "# Training control\n",
    "RESTART_TRAINING = True  # Set to True to clear checkpoints and start fresh\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERCEPIANO REPLICA TRAINING (4-FOLD CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clear checkpoints if restarting\n",
    "if RESTART_TRAINING and CHECKPOINT_ROOT.exists():\n",
    "    print(f\"\\nRESTART_TRAINING=True: Clearing checkpoints at {CHECKPOINT_ROOT}\")\n",
    "    shutil.rmtree(CHECKPOINT_ROOT)\n",
    "    print(\"  Checkpoints cleared!\")\n",
    "\n",
    "if RESTART_TRAINING and LOG_ROOT.exists():\n",
    "    print(f\"RESTART_TRAINING=True: Clearing logs at {LOG_ROOT}\")\n",
    "    shutil.rmtree(LOG_ROOT)\n",
    "    print(\"  Logs cleared!\")\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "\n",
    "if 'gdrive:' in result.stdout:\n",
    "    print(\"\\nrclone 'gdrive' remote: CONFIGURED\")\n",
    "    RCLONE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"\\nrclone 'gdrive' remote: NOT CONFIGURED\")\n",
    "    print(\"Run 'rclone config' in terminal to set up Google Drive\")\n",
    "    RCLONE_AVAILABLE = False\n",
    "\n",
    "print(f\"\\nData directory: {DATA_ROOT}\")\n",
    "print(f\"Checkpoint directory: {CHECKPOINT_ROOT}\")\n",
    "print(f\"Log directory: {LOG_ROOT}\")\n",
    "print(f\"\\nRESTART_TRAINING: {RESTART_TRAINING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Download Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if not RCLONE_AVAILABLE:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "# Download preprocessed data\n",
    "print(\"Downloading preprocessed VirtuosoNet features from Google Drive...\")\n",
    "subprocess.run(\n",
    "    ['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'],\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_samples = 0\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = DATA_ROOT / split\n",
    "    if split_dir.exists():\n",
    "        count = len(list(split_dir.glob('*.pkl')))\n",
    "        total_samples += count\n",
    "        print(f\"  {split}: {count} samples\")\n",
    "    else:\n",
    "        print(f\"  {split}: MISSING!\")\n",
    "\n",
    "print(f\"  Total: {total_samples} samples\")\n",
    "\n",
    "stat_file = DATA_ROOT / 'stat.pkl'\n",
    "print(f\"  stat.pkl: {'present' if stat_file.exists() else 'MISSING!'}\")\n",
    "\n",
    "fold_file = DATA_ROOT / 'fold_assignments.json'\n",
    "print(f\"  fold_assignments.json: {'present' if fold_file.exists() else 'will be created'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Create Fold Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.data.kfold_split import (\n",
    "    create_piece_based_folds,\n",
    "    save_fold_assignments,\n",
    "    load_fold_assignments,\n",
    "    print_fold_statistics,\n",
    ")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'fold_assignments.json'\n",
    "N_FOLDS = 4\n",
    "TEST_RATIO = 0.15\n",
    "SEED = 42\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FOLD ASSIGNMENT CREATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Force regeneration to use corrected methodology\n",
    "# - Test set: select pieces until ~15% of SAMPLES (PercePiano methodology)\n",
    "# - CV folds: greedy bin-packing for balanced sample counts (improvement over round-robin)\n",
    "FORCE_REGENERATE = True\n",
    "\n",
    "if FOLD_FILE.exists() and not FORCE_REGENERATE:\n",
    "    print(f\"\\nLoading existing fold assignments from {FOLD_FILE}\")\n",
    "    fold_assignments = load_fold_assignments(FOLD_FILE)\n",
    "else:\n",
    "    if FOLD_FILE.exists():\n",
    "        print(f\"\\nRemoving old fold assignments (regenerating with balanced methodology)...\")\n",
    "        FOLD_FILE.unlink()\n",
    "    \n",
    "    print(f\"\\nCreating new {N_FOLDS}-fold piece-based splits...\")\n",
    "    print(\"  Test set: select pieces until ~15% of SAMPLES\")\n",
    "    print(\"  CV folds: greedy bin-packing for balanced sample counts\")\n",
    "    fold_assignments = create_piece_based_folds(\n",
    "        data_dir=DATA_ROOT,\n",
    "        n_folds=N_FOLDS,\n",
    "        test_ratio=TEST_RATIO,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    save_fold_assignments(fold_assignments, FOLD_FILE)\n",
    "\n",
    "# Print statistics\n",
    "print_fold_statistics(fold_assignments, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Enable better CUDA error reporting\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Import model type constants\n",
    "from src.percepiano.training.kfold_trainer import MODEL_TYPE_HAN, MODEL_TYPE_BASELINE\n",
    "\n",
    "CONFIG = {\n",
    "    # K-Fold settings\n",
    "    'n_folds': N_FOLDS,\n",
    "    'test_ratio': TEST_RATIO,\n",
    "    # Data\n",
    "    'data_dir': str(DATA_ROOT),\n",
    "    'checkpoint_dir': str(CHECKPOINT_ROOT),\n",
    "    'log_dir': str(LOG_ROOT),\n",
    "    'input_size': 79,\n",
    "    'hidden_size': 256,\n",
    "    'note_layers': 2,\n",
    "    'voice_layers': 2,\n",
    "    'beat_layers': 2,\n",
    "    'measure_layers': 1,\n",
    "    'num_attention_heads': 8,\n",
    "    'learning_rate': 2.5e-5,\n",
    "    'weight_decay': 1e-5,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 8,\n",
    "    'max_epochs': 200,\n",
    "    'early_stopping_patience': 20,\n",
    "    'gradient_clip_val': 2.0,\n",
    "    'precision': '32',\n",
    "    'max_notes': 5000,\n",
    "    'slice_len': 5000,\n",
    "    'num_workers': 4,\n",
    "    'augment_train': False,\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION (SOTA - ROUND 13)\")\n",
    "print(\"=\"*60)\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"\\nModel types available:\")\n",
    "print(f\"  MODEL_TYPE_BASELINE = '{MODEL_TYPE_BASELINE}' (7-layer Bi-LSTM, expected R2 ~0.19)\")\n",
    "print(f\"  MODEL_TYPE_HAN = '{MODEL_TYPE_HAN}' (Hierarchical, expected R2 ~0.40)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Initialize Phase 2 Trainers\n",
    "\n",
    "Create trainers for all 3 incremental models:\n",
    "1. Baseline (7-layer Bi-LSTM)\n",
    "2. Baseline + Beat hierarchy\n",
    "3. Baseline + Beat + Measure hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.training.kfold_trainer import (\n",
    "    KFoldTrainer,\n",
    "    MODEL_TYPE_BASELINE,\n",
    "    MODEL_TYPE_BASELINE_BEAT,\n",
    "    MODEL_TYPE_BASELINE_BEAT_MEASURE,\n",
    ")\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Set seed for reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Phase 2: Train 3 incremental models on Fold 2\n",
    "# 1. Baseline (7-layer Bi-LSTM) - R2 ~0.19 (Phase 1 validated)\n",
    "# 2. Baseline + Beat - R2 ~0.25-0.30 (expected +0.10 gain)\n",
    "# 3. Baseline + Beat + Measure - R2 ~0.35-0.40 (expected +0.05-0.10 more)\n",
    "\n",
    "FOLD_ID = 2  # Best performing fold with longest pieces (1-54 beats)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 2: INITIALIZE INCREMENTAL TRAINERS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Fold: {FOLD_ID}\")\n",
    "print(\"\\nModels to train:\")\n",
    "print(\"  1. Baseline (7-layer Bi-LSTM) - expected R2 ~0.19\")\n",
    "print(\"  2. Baseline + Beat hierarchy - expected R2 ~0.25-0.30\")\n",
    "print(\"  3. Baseline + Beat + Measure - expected R2 ~0.35-0.40\")\n",
    "\n",
    "# 1. Baseline trainer (7-layer Bi-LSTM)\n",
    "print(\"\\n[1] Bi-LSTM Baseline Trainer:\")\n",
    "baseline_trainer = KFoldTrainer(\n",
    "    config=CONFIG,\n",
    "    fold_assignments=fold_assignments,\n",
    "    data_dir=DATA_ROOT,\n",
    "    checkpoint_dir=CHECKPOINT_ROOT,\n",
    "    log_dir=LOG_ROOT,\n",
    "    n_folds=N_FOLDS,\n",
    "    model_type=MODEL_TYPE_BASELINE,\n",
    ")\n",
    "\n",
    "# 2. Baseline + Beat trainer\n",
    "print(\"\\n[2] Baseline + Beat Trainer:\")\n",
    "beat_trainer = KFoldTrainer(\n",
    "    config=CONFIG,\n",
    "    fold_assignments=fold_assignments,\n",
    "    data_dir=DATA_ROOT,\n",
    "    checkpoint_dir=CHECKPOINT_ROOT,\n",
    "    log_dir=LOG_ROOT,\n",
    "    n_folds=N_FOLDS,\n",
    "    model_type=MODEL_TYPE_BASELINE_BEAT,\n",
    ")\n",
    "\n",
    "# 3. Baseline + Beat + Measure trainer\n",
    "print(\"\\n[3] Baseline + Beat + Measure Trainer:\")\n",
    "beat_measure_trainer = KFoldTrainer(\n",
    "    config=CONFIG,\n",
    "    fold_assignments=fold_assignments,\n",
    "    data_dir=DATA_ROOT,\n",
    "    checkpoint_dir=CHECKPOINT_ROOT,\n",
    "    log_dir=LOG_ROOT,\n",
    "    n_folds=N_FOLDS,\n",
    "    model_type=MODEL_TYPE_BASELINE_BEAT_MEASURE,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All 3 trainers initialized!\")\n",
    "print(f\"  Baseline checkpoints: {baseline_trainer.checkpoint_dir}\")\n",
    "print(f\"  Beat checkpoints: {beat_trainer.checkpoint_dir}\")\n",
    "print(f\"  Beat+Measure checkpoints: {beat_measure_trainer.checkpoint_dir}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Phase 2 Incremental Training\n",
    "\n",
    "Train three models incrementally on Fold 2 to isolate where hierarchy helps:\n",
    "1. **Baseline** (7-layer Bi-LSTM) - R2 ~0.19 (skip if checkpoint exists)\n",
    "2. **Baseline + Beat** - R2 ~0.25-0.30 (expected beat gain: +0.10-0.15)\n",
    "3. **Baseline + Beat + Measure** - R2 ~0.35-0.40 (expected measure gain: +0.05-0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nPHASE 2: INCREMENTAL HIERARCHY TRAINING\n\nTrain three models incrementally to isolate where hierarchy helps:\n1. Baseline (7-layer Bi-LSTM) - R2 ~0.19 (validated in Phase 1, skip if checkpoint exists)\n2. Baseline + Beat hierarchy - R2 ~0.25-0.30 (expected beat gain: +0.10-0.15)\n3. Baseline + Beat + Measure hierarchy - R2 ~0.35-0.40 (expected measure gain: +0.05-0.10)\n\"\"\"\n\nprint(\"=\"*70)\nprint(\"PHASE 2: INCREMENTAL HIERARCHY TRAINING\")\nprint(\"=\"*70)\nprint(\"\\nGoal: Isolate where hierarchy contributes to performance\")\nprint(\"Expected gains:\")\nprint(\"  Beat hierarchy: +0.10 to +0.15 R2\")\nprint(\"  Measure hierarchy: +0.05 to +0.10 R2\")\nprint(\"  Total hierarchy gain: ~+0.21 R2\")\nprint(\"=\"*70)\n\n# ========================================\n# Model 1: Baseline (skip if checkpoint exists)\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL 1: BASELINE (7-layer Bi-LSTM)\")\nprint(\"=\"*70)\nprint(\"Expected R2: ~0.19 (matching VirtuosoNetSingle)\")\n\n# Check for existing checkpoint\nbaseline_checkpoint = baseline_trainer._find_checkpoint(FOLD_ID, \"best\")\nif baseline_checkpoint:\n    print(f\"\\nFound existing baseline checkpoint: {baseline_checkpoint}\")\n    print(\"Loading metrics from saved results...\")\n    \n    # Try to load saved metrics from training_results.json\n    import json\n    results_file = baseline_trainer.checkpoint_dir / \"training_results.json\"\n    baseline_metrics = None\n    \n    if results_file.exists():\n        with open(results_file) as f:\n            saved_results = json.load(f)\n        if str(FOLD_ID) in saved_results.get('fold_metrics', {}):\n            fm = saved_results['fold_metrics'][str(FOLD_ID)]\n            # Load model from checkpoint using Lightning's method\n            from src.percepiano.models.percepiano_replica import PercePianoBiLSTMBaseline\n            baseline_model = PercePianoBiLSTMBaseline.load_from_checkpoint(\n                str(baseline_checkpoint),\n                strict=False,\n            )\n            baseline_trainer.trained_folds[FOLD_ID] = baseline_model\n            \n            # Create a simple namespace to hold the metrics we need\n            class SimpleMetrics:\n                def __init__(self, d):\n                    self.val_r2 = d.get('val_r2', 0)\n                    self.val_pearson = d.get('val_pearson', 0)\n                    self.val_mae = d.get('val_mae', 0)\n                    self.val_rmse = d.get('val_rmse', 0)\n                    self.epochs_trained = d.get('epochs_trained', 0)\n                    self.per_dim_r2 = d.get('per_dim_r2', {})\n            \n            baseline_metrics = SimpleMetrics(fm)\n            print(f\"Loaded baseline metrics: Val R2 = {baseline_metrics.val_r2:+.4f}\")\n        else:\n            print(\"[WARNING] No saved metrics for this fold - will retrain\")\n    \n    if baseline_metrics is None:\n        print(\"Retraining baseline to get metrics...\")\n        baseline_metrics = baseline_trainer.train_fold(\n            fold_id=FOLD_ID,\n            verbose=True,\n            resume_from_checkpoint=True,\n        )\n        baseline_trainer.save_results()\nelse:\n    print(\"\\nNo checkpoint found - training baseline...\")\n    baseline_metrics = baseline_trainer.train_fold(\n        fold_id=FOLD_ID,\n        verbose=True,\n        resume_from_checkpoint=False,\n    )\n    baseline_trainer.save_results()\n    print(f\"\\nBaseline training complete! Val R2 = {baseline_metrics.val_r2:+.4f}\")\n\nif baseline_metrics and baseline_metrics.val_r2 < 0.10:\n    print(\"\\n[WARNING] Baseline underperforming - check data pipeline before continuing!\")\nelse:\n    print(\"\\n[OK] Baseline validated - proceeding to incremental hierarchy\")\n\n# ========================================\n# Model 2: Baseline + Beat\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL 2: BASELINE + BEAT HIERARCHY\")\nprint(\"=\"*70)\nprint(\"Expected R2: ~0.25-0.30 (beat contribution: +0.10-0.15)\")\n\nbeat_metrics = beat_trainer.train_fold(\n    fold_id=FOLD_ID,\n    verbose=True,\n    resume_from_checkpoint=False,\n)\nbeat_trainer.save_results()\n\nif baseline_metrics:\n    beat_gain = beat_metrics.val_r2 - baseline_metrics.val_r2\n    print(f\"\\nBaseline + Beat training complete!\")\n    print(f\"  Val R2: {beat_metrics.val_r2:+.4f}\")\n    print(f\"  Beat gain: {beat_gain:+.4f} (expected: +0.10 to +0.15)\")\nelse:\n    print(f\"\\nBaseline + Beat training complete! Val R2 = {beat_metrics.val_r2:+.4f}\")\n\n# ========================================\n# Model 3: Baseline + Beat + Measure\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL 3: BASELINE + BEAT + MEASURE HIERARCHY\")\nprint(\"=\"*70)\nprint(\"Expected R2: ~0.35-0.40 (approaching SOTA)\")\n\nbeat_measure_metrics = beat_measure_trainer.train_fold(\n    fold_id=FOLD_ID,\n    verbose=True,\n    resume_from_checkpoint=False,\n)\nbeat_measure_trainer.save_results()\n\nmeasure_gain = beat_measure_metrics.val_r2 - beat_metrics.val_r2\nprint(f\"\\nBaseline + Beat + Measure training complete!\")\nprint(f\"  Val R2: {beat_measure_metrics.val_r2:+.4f}\")\nprint(f\"  Measure gain: {measure_gain:+.4f} (expected: +0.05 to +0.10)\")\n\n# ========================================\n# Store models and metrics for diagnostics\n# ========================================\ntrained_models = {\n    'baseline': baseline_trainer.get_trained_model(FOLD_ID),\n    'baseline_beat': beat_trainer.get_trained_model(FOLD_ID),\n    'baseline_beat_measure': beat_measure_trainer.get_trained_model(FOLD_ID),\n}\n\ntrained_metrics = {\n    'baseline': baseline_metrics,\n    'baseline_beat': beat_metrics,\n    'baseline_beat_measure': beat_measure_metrics,\n}\n\n# ========================================\n# Quick Progress Summary\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"PHASE 2 TRAINING COMPLETE\")\nprint(\"=\"*70)\n\nif baseline_metrics:\n    total_gain = beat_measure_metrics.val_r2 - baseline_metrics.val_r2\n    beat_contribution = beat_metrics.val_r2 - baseline_metrics.val_r2\n    measure_contribution = beat_measure_metrics.val_r2 - beat_metrics.val_r2\n    \n    print(f\"\\n  {'Model':<30} {'Val R2':>10} {'Gain':>10}\")\n    print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n    print(f\"  {'Baseline (7-layer BiLSTM)':<30} {baseline_metrics.val_r2:>+10.4f} {'-':>10}\")\n    print(f\"  {'Baseline + Beat':<30} {beat_metrics.val_r2:>+10.4f} {beat_contribution:>+10.4f}\")\n    print(f\"  {'Baseline + Beat + Measure':<30} {beat_measure_metrics.val_r2:>+10.4f} {measure_contribution:>+10.4f}\")\n    print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n    print(f\"  {'Total Hierarchy Gain':<30} {'-':>10} {total_gain:>+10.4f}\")\n    \n    print(f\"\\n  Expected total gain: ~+0.21\")\n    \n    if total_gain >= 0.15:\n        print(f\"  [SUCCESS] Hierarchy providing significant gain!\")\n    elif total_gain >= 0.10:\n        print(f\"  [GOOD] Hierarchy helping but slightly below expected\")\n    elif total_gain >= 0.05:\n        print(f\"  [PARTIAL] Hierarchy providing modest gain\")\n    else:\n        print(f\"  [ISSUE] Hierarchy not contributing enough - run diagnostics\")\nelse:\n    print(\"\\n[WARNING] Baseline metrics not available for comparison\")\n    print(f\"  Baseline + Beat Val R2: {beat_metrics.val_r2:+.4f}\")\n    print(f\"  Baseline + Beat + Measure Val R2: {beat_measure_metrics.val_r2:+.4f}\")\n\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 8: Phase 2 Hierarchy Diagnostics\n",
    "\n",
    "Three diagnostic checks to understand why hierarchy may or may not be contributing:\n",
    "1. **span_beat_to_note_num Check**: Verify beat representations are properly distributed to notes\n",
    "2. **Attention Entropy**: Check if beat/measure attention weights are near-uniform (not learning)\n",
    "3. **Contractor Weight Analysis**: Check if contractor layer ignores beat/measure dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PHASE 2: POST-TRAINING HIERARCHY DIAGNOSTICS\n",
    "\n",
    "Three diagnostic checks to understand hierarchy contribution:\n",
    "1. span_beat_to_note_num: Verify beat representations properly distributed\n",
    "2. Attention entropy: Check if beat/measure attention is near-uniform\n",
    "3. Contractor weights: Check if contractor ignores beat/measure dimensions\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, PackedSequence\n",
    "from src.percepiano.data.percepiano_vnet_dataset import (\n",
    "    PercePianoKFoldDataset,\n",
    "    percepiano_pack_collate,\n",
    ")\n",
    "from src.percepiano.models.hierarchy_utils import (\n",
    "    span_beat_to_note_num,\n",
    "    compute_actual_lengths,\n",
    ")\n",
    "\n",
    "# ========================================\n",
    "# Diagnostic Functions\n",
    "# ========================================\n",
    "\n",
    "def diagnose_span_beat_to_note_num(beat_numbers, device):\n",
    "    \"\"\"\n",
    "    Verify beat representations are correctly mapped back to note level.\n",
    "    \n",
    "    CHECKS:\n",
    "    1. Beat indices are monotonically non-decreasing within valid positions\n",
    "    2. Zero-shifted indices have no negative values\n",
    "    3. Beat-to-note mapping produces correct shapes\n",
    "    \"\"\"\n",
    "    results = {'status': 'OK', 'issues': []}\n",
    "    \n",
    "    actual_lengths = compute_actual_lengths(beat_numbers)\n",
    "    \n",
    "    # Check 1: Beat indices are valid (monotonically non-decreasing)\n",
    "    for i in range(beat_numbers.shape[0]):\n",
    "        valid_len = actual_lengths[i].item()\n",
    "        if valid_len > 1:\n",
    "            valid_beats = beat_numbers[i, :valid_len]\n",
    "            diffs = valid_beats[1:] - valid_beats[:-1]\n",
    "            if (diffs < 0).any():\n",
    "                results['issues'].append(f\"Sample {i}: Non-monotonic beat indices\")\n",
    "                results['status'] = 'FAIL'\n",
    "    \n",
    "    # Check 2: Zero-shifted values\n",
    "    first_beats = beat_numbers[:, 0:1]\n",
    "    zero_shifted = beat_numbers - first_beats\n",
    "    for i in range(beat_numbers.shape[0]):\n",
    "        valid_len = actual_lengths[i].item()\n",
    "        if valid_len > 0 and (zero_shifted[i, :valid_len] < 0).any():\n",
    "            results['issues'].append(f\"Sample {i}: Negative zero-shifted values\")\n",
    "            results['status'] = 'FAIL'\n",
    "    \n",
    "    # Check 3: Test span_beat_to_note_num function\n",
    "    batch_size, num_notes = beat_numbers.shape\n",
    "    max_beat = beat_numbers.max().item()\n",
    "    if max_beat > 0:\n",
    "        num_beats = max_beat + 1\n",
    "        dummy_beat_out = torch.randn(batch_size, num_beats, 512, device=device)\n",
    "        \n",
    "        try:\n",
    "            spanned = span_beat_to_note_num(dummy_beat_out, beat_numbers, actual_lengths)\n",
    "            results['spanned_shape'] = tuple(spanned.shape)\n",
    "            results['spanned_non_zero'] = (spanned.abs() > 1e-6).any().item()\n",
    "            \n",
    "            if not results['spanned_non_zero']:\n",
    "                results['issues'].append(\"span_beat_to_note_num output is all zeros!\")\n",
    "                results['status'] = 'FAIL'\n",
    "        except Exception as e:\n",
    "            results['issues'].append(f\"span_beat_to_note_num failed: {str(e)}\")\n",
    "            results['status'] = 'FAIL'\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def diagnose_attention_entropy(model, x_embedded, actual_lengths, model_name):\n",
    "    \"\"\"\n",
    "    Analyze attention weight distribution in hierarchical components.\n",
    "    \n",
    "    CHECKS:\n",
    "    1. Beat attention entropy (normalized 0-1, where 1=uniform)\n",
    "    2. Whether attention is too uniform (>0.95) or too collapsed (<0.1)\n",
    "    \"\"\"\n",
    "    results = {'beat_entropy': None, 'status': 'OK', 'issues': []}\n",
    "    \n",
    "    if not hasattr(model, 'beat_attention'):\n",
    "        results['status'] = 'SKIPPED'\n",
    "        results['issues'].append(f\"{model_name} has no beat_attention\")\n",
    "        return results\n",
    "    \n",
    "    try:\n",
    "        # Run through LSTM to get hidden states\n",
    "        x_packed = pack_padded_sequence(\n",
    "            x_embedded, actual_lengths.cpu().clamp(min=1),\n",
    "            batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        lstm_out, _ = model.lstm(x_packed)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True, total_length=x_embedded.shape[1])\n",
    "        \n",
    "        # Get beat attention weights\n",
    "        beat_similarity = model.beat_attention.get_attention(lstm_out)  # [B, T, num_head]\n",
    "        \n",
    "        # Apply softmax with temperature\n",
    "        temp = getattr(model.beat_attention, 'temperature', 1.0)\n",
    "        beat_attention = torch.softmax(beat_similarity / temp, dim=1)\n",
    "        \n",
    "        # Compute entropy (averaged over batch and heads)\n",
    "        eps = 1e-10\n",
    "        # Shape: [B, T, H] -> entropy per head per sample\n",
    "        beat_entropy = -torch.sum(beat_attention * torch.log(beat_attention + eps), dim=1)  # [B, H]\n",
    "        \n",
    "        # Normalize by max possible entropy (log of sequence length)\n",
    "        max_entropy = torch.log(torch.tensor(float(lstm_out.shape[1]), device=lstm_out.device))\n",
    "        normalized_entropy = (beat_entropy / max_entropy).mean().item()\n",
    "        \n",
    "        results['beat_entropy'] = normalized_entropy\n",
    "        results['raw_entropy'] = beat_entropy.mean().item()\n",
    "        results['max_entropy'] = max_entropy.item()\n",
    "        \n",
    "        # Check for issues\n",
    "        if normalized_entropy > 0.95:\n",
    "            results['issues'].append(f\"Beat attention near-uniform (entropy={normalized_entropy:.3f})\")\n",
    "            results['status'] = 'WARNING'\n",
    "        elif normalized_entropy < 0.1:\n",
    "            results['issues'].append(f\"Beat attention collapsed (entropy={normalized_entropy:.3f})\")\n",
    "            results['status'] = 'WARNING'\n",
    "            \n",
    "    except Exception as e:\n",
    "        results['issues'].append(f\"Attention analysis failed: {str(e)}\")\n",
    "        results['status'] = 'ERROR'\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def diagnose_contractor_weights(model, model_name):\n",
    "    \"\"\"\n",
    "    Analyze contractor weights to check if hierarchy dimensions are being used.\n",
    "    \n",
    "    CHECKS:\n",
    "    1. Weight magnitude for LSTM vs beat vs measure input dimensions\n",
    "    2. Whether hierarchy weights are significantly smaller (model ignoring them)\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'lstm_weight_mag': None,\n",
    "        'beat_weight_mag': None,\n",
    "        'measure_weight_mag': None,\n",
    "        'ratio_beat_to_lstm': None,\n",
    "        'ratio_measure_to_lstm': None,\n",
    "        'status': 'OK',\n",
    "        'issues': [],\n",
    "    }\n",
    "    \n",
    "    if not hasattr(model, 'note_contractor'):\n",
    "        results['status'] = 'SKIPPED'\n",
    "        results['issues'].append(f\"{model_name} has no note_contractor\")\n",
    "        return results\n",
    "    \n",
    "    contractor = model.note_contractor.weight.data  # [out_dim, in_dim]\n",
    "    in_dim = contractor.shape[1]\n",
    "    \n",
    "    # Determine layout based on input dimension\n",
    "    if in_dim == 1536:\n",
    "        # Baseline + Beat + Measure: [LSTM:512, beat:512, measure:512]\n",
    "        results['lstm_weight_mag'] = contractor[:, :512].abs().mean().item()\n",
    "        results['beat_weight_mag'] = contractor[:, 512:1024].abs().mean().item()\n",
    "        results['measure_weight_mag'] = contractor[:, 1024:].abs().mean().item()\n",
    "        \n",
    "        results['ratio_beat_to_lstm'] = results['beat_weight_mag'] / (results['lstm_weight_mag'] + 1e-8)\n",
    "        results['ratio_measure_to_lstm'] = results['measure_weight_mag'] / (results['lstm_weight_mag'] + 1e-8)\n",
    "        \n",
    "        if results['ratio_beat_to_lstm'] < 0.1:\n",
    "            results['issues'].append(f\"Contractor ignoring beat (ratio={results['ratio_beat_to_lstm']:.3f})\")\n",
    "            results['status'] = 'WARNING'\n",
    "        if results['ratio_measure_to_lstm'] < 0.1:\n",
    "            results['issues'].append(f\"Contractor ignoring measure (ratio={results['ratio_measure_to_lstm']:.3f})\")\n",
    "            results['status'] = 'WARNING'\n",
    "            \n",
    "    elif in_dim == 1024:\n",
    "        # Baseline + Beat: [LSTM:512, beat:512]\n",
    "        results['lstm_weight_mag'] = contractor[:, :512].abs().mean().item()\n",
    "        results['beat_weight_mag'] = contractor[:, 512:].abs().mean().item()\n",
    "        \n",
    "        results['ratio_beat_to_lstm'] = results['beat_weight_mag'] / (results['lstm_weight_mag'] + 1e-8)\n",
    "        \n",
    "        if results['ratio_beat_to_lstm'] < 0.1:\n",
    "            results['issues'].append(f\"Contractor ignoring beat (ratio={results['ratio_beat_to_lstm']:.3f})\")\n",
    "            results['status'] = 'WARNING'\n",
    "    else:\n",
    "        results['status'] = 'SKIPPED'\n",
    "        results['issues'].append(f\"Unexpected contractor input dim: {in_dim}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# Run Diagnostics\n",
    "# ========================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PHASE 2 HIERARCHY DIAGNOSTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Prepare validation batch\n",
    "val_ds = PercePianoKFoldDataset(\n",
    "    data_dir=DATA_ROOT,\n",
    "    fold_assignments=fold_assignments,\n",
    "    fold_id=FOLD_ID,\n",
    "    mode=\"val\",\n",
    "    max_notes=CONFIG['max_notes'],\n",
    "    slice_len=CONFIG.get('slice_len', CONFIG['max_notes']),\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=0)\n",
    "batch = next(iter(val_loader))\n",
    "\n",
    "# Move batch to device\n",
    "input_features = batch['input_features'].to(device)\n",
    "beat_numbers = batch['note_locations_beat'].to(device)\n",
    "measure_numbers = batch['note_locations_measure'].to(device)\n",
    "actual_lengths = compute_actual_lengths(beat_numbers)\n",
    "\n",
    "# Models to diagnose (only the ones with hierarchy)\n",
    "models_to_diagnose = [\n",
    "    ('baseline_beat', trained_models.get('baseline_beat')),\n",
    "    ('baseline_beat_measure', trained_models.get('baseline_beat_measure')),\n",
    "]\n",
    "\n",
    "for model_name, model in models_to_diagnose:\n",
    "    if model is None:\n",
    "        print(f\"\\n[SKIPPED] {model_name} not available\")\n",
    "        continue\n",
    "    \n",
    "    model = model.to(device).eval()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"DIAGNOSTICS: {model_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Prepare embedded input for attention analysis\n",
    "    with torch.no_grad():\n",
    "        x_embedded = model.note_embedder(input_features)\n",
    "    \n",
    "    # Diagnostic 1: span_beat_to_note_num check\n",
    "    print(\"\\n[1] SPAN_BEAT_TO_NOTE_NUM CHECK:\")\n",
    "    span_results = diagnose_span_beat_to_note_num(beat_numbers, device)\n",
    "    print(f\"    Status: {span_results['status']}\")\n",
    "    if span_results.get('spanned_shape'):\n",
    "        print(f\"    Spanned output shape: {span_results['spanned_shape']}\")\n",
    "        print(f\"    Non-zero output: {span_results['spanned_non_zero']}\")\n",
    "    if span_results['issues']:\n",
    "        for issue in span_results['issues']:\n",
    "            print(f\"    - {issue}\")\n",
    "    else:\n",
    "        print(\"    All checks passed\")\n",
    "    \n",
    "    # Diagnostic 2: Attention entropy\n",
    "    print(\"\\n[2] ATTENTION ENTROPY CHECK:\")\n",
    "    with torch.no_grad():\n",
    "        entropy_results = diagnose_attention_entropy(model, x_embedded, actual_lengths, model_name)\n",
    "    \n",
    "    if entropy_results['beat_entropy'] is not None:\n",
    "        print(f\"    Beat attention entropy: {entropy_results['beat_entropy']:.3f} (1.0=uniform, 0.0=focused)\")\n",
    "        print(f\"    Raw entropy: {entropy_results['raw_entropy']:.3f}, Max possible: {entropy_results['max_entropy']:.3f}\")\n",
    "        \n",
    "        if entropy_results['beat_entropy'] > 0.8:\n",
    "            print(\"    [WARNING] Attention is relatively uniform - may not be learning to focus\")\n",
    "        elif entropy_results['beat_entropy'] < 0.3:\n",
    "            print(\"    [GOOD] Attention is focused on specific positions\")\n",
    "        else:\n",
    "            print(\"    [OK] Attention entropy in reasonable range\")\n",
    "    \n",
    "    print(f\"    Status: {entropy_results['status']}\")\n",
    "    if entropy_results['issues']:\n",
    "        for issue in entropy_results['issues']:\n",
    "            print(f\"    - {issue}\")\n",
    "    \n",
    "    # Diagnostic 3: Contractor weights\n",
    "    print(\"\\n[3] CONTRACTOR WEIGHT ANALYSIS:\")\n",
    "    contractor_results = diagnose_contractor_weights(model, model_name)\n",
    "    \n",
    "    if contractor_results['lstm_weight_mag'] is not None:\n",
    "        print(f\"    LSTM weight magnitude: {contractor_results['lstm_weight_mag']:.4f}\")\n",
    "        print(f\"    Beat weight magnitude: {contractor_results['beat_weight_mag']:.4f}\")\n",
    "        if contractor_results['measure_weight_mag'] is not None:\n",
    "            print(f\"    Measure weight magnitude: {contractor_results['measure_weight_mag']:.4f}\")\n",
    "        \n",
    "        print(f\"    Beat/LSTM ratio: {contractor_results['ratio_beat_to_lstm']:.3f}\")\n",
    "        if contractor_results['ratio_measure_to_lstm'] is not None:\n",
    "            print(f\"    Measure/LSTM ratio: {contractor_results['ratio_measure_to_lstm']:.3f}\")\n",
    "        \n",
    "        # Interpretation\n",
    "        if contractor_results['ratio_beat_to_lstm'] >= 0.5:\n",
    "            print(\"    [GOOD] Contractor using beat branch effectively\")\n",
    "        elif contractor_results['ratio_beat_to_lstm'] >= 0.2:\n",
    "            print(\"    [OK] Contractor partially using beat branch\")\n",
    "        else:\n",
    "            print(\"    [WARNING] Contractor may be ignoring beat branch\")\n",
    "    \n",
    "    print(f\"    Status: {contractor_results['status']}\")\n",
    "    if contractor_results['issues']:\n",
    "        for issue in contractor_results['issues']:\n",
    "            print(f\"    - {issue}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSTICS COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nInterpretation guide:\")\n",
    "print(\"  - span_beat_to_note_num: Should produce non-zero output with correct shapes\")\n",
    "print(\"  - Attention entropy: 0.3-0.8 is good; >0.95 means uniform (not learning)\")\n",
    "print(\"  - Contractor ratio: >0.2 means hierarchy is being used; <0.1 means ignored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tsmwiy2nm7p",
   "metadata": {},
   "source": [
    "## Step 9: Comprehensive Analysis\n",
    "\n",
    "Single analysis cell comparing all 3 incremental models with 5 sections:\n",
    "1. Overall metrics table\n",
    "2. Per-dimension R2 comparison\n",
    "3. Hierarchy contribution analysis\n",
    "4. Comparison to PercePiano paper\n",
    "5. Next steps recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dzp8ujd2miw",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PHASE 2: COMPREHENSIVE ANALYSIS\n",
    "\n",
    "Compare all three incremental models and analyze hierarchy contribution.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2 COMPREHENSIVE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Validate we have metrics\n",
    "if 'trained_metrics' not in dir():\n",
    "    raise RuntimeError(\"No trained_metrics found - run training cell first!\")\n",
    "\n",
    "baseline_m = trained_metrics.get('baseline')\n",
    "beat_m = trained_metrics.get('baseline_beat')\n",
    "beat_measure_m = trained_metrics.get('baseline_beat_measure')\n",
    "\n",
    "if not all([baseline_m, beat_m, beat_measure_m]):\n",
    "    missing = [k for k, v in [('baseline', baseline_m), ('baseline_beat', beat_m), \n",
    "                               ('baseline_beat_measure', beat_measure_m)] if v is None]\n",
    "    print(f\"\\n[WARNING] Missing metrics for: {missing}\")\n",
    "    print(\"Some analysis sections will be incomplete.\")\n",
    "\n",
    "# ========================================\n",
    "# Section 1: Overall Metrics Table\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SECTION 1: OVERALL METRICS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n  {'Model':<32} {'Val R2':>10} {'Epochs':>8} {'Gain':>10}\")\n",
    "print(f\"  {'-'*32} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "\n",
    "if baseline_m:\n",
    "    print(f\"  {'Baseline (7-layer BiLSTM)':<32} {baseline_m.val_r2:>+10.4f} {baseline_m.epochs_trained:>8} {'-':>10}\")\n",
    "\n",
    "if beat_m:\n",
    "    beat_gain = beat_m.val_r2 - baseline_m.val_r2 if baseline_m else 0\n",
    "    print(f\"  {'Baseline + Beat':<32} {beat_m.val_r2:>+10.4f} {beat_m.epochs_trained:>8} {beat_gain:>+10.4f}\")\n",
    "\n",
    "if beat_measure_m:\n",
    "    measure_gain = beat_measure_m.val_r2 - beat_m.val_r2 if beat_m else 0\n",
    "    print(f\"  {'Baseline + Beat + Measure':<32} {beat_measure_m.val_r2:>+10.4f} {beat_measure_m.epochs_trained:>8} {measure_gain:>+10.4f}\")\n",
    "\n",
    "if baseline_m and beat_measure_m:\n",
    "    total_gain = beat_measure_m.val_r2 - baseline_m.val_r2\n",
    "    print(f\"  {'-'*32} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "    print(f\"  {'Total Hierarchy Gain':<32} {'-':>10} {'-':>8} {total_gain:>+10.4f}\")\n",
    "    print(f\"\\n  Expected total gain: ~+0.21\")\n",
    "\n",
    "# ========================================\n",
    "# Section 2: Per-Dimension R2 Comparison\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SECTION 2: PER-DIMENSION R2 COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Check if we have per-dimension metrics\n",
    "has_per_dim = (baseline_m and hasattr(baseline_m, 'per_dim_r2') and baseline_m.per_dim_r2 and\n",
    "               beat_m and hasattr(beat_m, 'per_dim_r2') and beat_m.per_dim_r2 and\n",
    "               beat_measure_m and hasattr(beat_measure_m, 'per_dim_r2') and beat_measure_m.per_dim_r2)\n",
    "\n",
    "if has_per_dim:\n",
    "    print(f\"\\n  {'Dimension':<22} {'Baseline':>10} {'+Beat':>10} {'+Beat+Meas':>12} {'Beat Gain':>10} {'Meas Gain':>10}\")\n",
    "    print(f\"  {'-'*22} {'-'*10} {'-'*10} {'-'*12} {'-'*10} {'-'*10}\")\n",
    "    \n",
    "    dim_data = []\n",
    "    for dim in PERCEPIANO_DIMENSIONS:\n",
    "        b_r2 = baseline_m.per_dim_r2.get(dim, 0)\n",
    "        bb_r2 = beat_m.per_dim_r2.get(dim, 0)\n",
    "        bbm_r2 = beat_measure_m.per_dim_r2.get(dim, 0)\n",
    "        beat_gain = bb_r2 - b_r2\n",
    "        meas_gain = bbm_r2 - bb_r2\n",
    "        dim_data.append((dim, b_r2, bb_r2, bbm_r2, beat_gain, meas_gain))\n",
    "    \n",
    "    # Sort by final model R2 (best first)\n",
    "    dim_data.sort(key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "    for dim, b_r2, bb_r2, bbm_r2, beat_gain, meas_gain in dim_data:\n",
    "        print(f\"  {dim:<22} {b_r2:>+10.4f} {bb_r2:>+10.4f} {bbm_r2:>+12.4f} {beat_gain:>+10.4f} {meas_gain:>+10.4f}\")\n",
    "    \n",
    "    # Summary\n",
    "    positive_beat_gains = sum(1 for _, _, _, _, bg, _ in dim_data if bg > 0)\n",
    "    positive_meas_gains = sum(1 for _, _, _, _, _, mg in dim_data if mg > 0)\n",
    "    print(f\"\\n  Beat helps {positive_beat_gains}/{len(PERCEPIANO_DIMENSIONS)} dimensions\")\n",
    "    print(f\"  Measure helps {positive_meas_gains}/{len(PERCEPIANO_DIMENSIONS)} dimensions\")\n",
    "else:\n",
    "    print(\"\\n  [Per-dimension R2 not available in saved metrics]\")\n",
    "    print(\"  To enable: ensure trainer saves per_dim_r2 in FoldMetrics\")\n",
    "\n",
    "# ========================================\n",
    "# Section 3: Hierarchy Contribution Analysis\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SECTION 3: HIERARCHY CONTRIBUTION ANALYSIS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if baseline_m and beat_m and beat_measure_m:\n",
    "    beat_contribution = beat_m.val_r2 - baseline_m.val_r2\n",
    "    measure_contribution = beat_measure_m.val_r2 - beat_m.val_r2\n",
    "    total_hierarchy = beat_contribution + measure_contribution\n",
    "    \n",
    "    # Expected values from PercePiano paper\n",
    "    expected_beat = 0.15  # approximate\n",
    "    expected_measure = 0.06  # approximate\n",
    "    expected_total = 0.21\n",
    "    \n",
    "    print(f\"\\n  {'Component':<30} {'Actual':>10} {'Expected':>10} {'%Achieved':>12}\")\n",
    "    print(f\"  {'-'*30} {'-'*10} {'-'*10} {'-'*12}\")\n",
    "    print(f\"  {'Beat hierarchy contribution':<30} {beat_contribution:>+10.4f} {'+0.10-0.15':>10} {100*beat_contribution/expected_beat:>11.0f}%\")\n",
    "    print(f\"  {'Measure hierarchy contribution':<30} {measure_contribution:>+10.4f} {'+0.05-0.10':>10} {100*measure_contribution/expected_measure:>11.0f}%\")\n",
    "    print(f\"  {'-'*30} {'-'*10} {'-'*10} {'-'*12}\")\n",
    "    print(f\"  {'Total hierarchy gain':<30} {total_hierarchy:>+10.4f} {'~+0.21':>10} {100*total_hierarchy/expected_total:>11.0f}%\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\n  Interpretation:\")\n",
    "    if beat_contribution >= 0.10:\n",
    "        print(\"    - Beat hierarchy: SIGNIFICANT contribution [OK]\")\n",
    "    elif beat_contribution >= 0.05:\n",
    "        print(\"    - Beat hierarchy: PARTIAL contribution [CHECK DIAGNOSTICS]\")\n",
    "    else:\n",
    "        print(\"    - Beat hierarchy: MINIMAL contribution [INVESTIGATE]\")\n",
    "    \n",
    "    if measure_contribution >= 0.05:\n",
    "        print(\"    - Measure hierarchy: SIGNIFICANT contribution [OK]\")\n",
    "    elif measure_contribution >= 0.02:\n",
    "        print(\"    - Measure hierarchy: PARTIAL contribution [CHECK DIAGNOSTICS]\")\n",
    "    else:\n",
    "        print(\"    - Measure hierarchy: MINIMAL contribution [INVESTIGATE]\")\n",
    "\n",
    "# ========================================\n",
    "# Section 4: Comparison to PercePiano Paper\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SECTION 4: COMPARISON TO PERCEPIANO PAPER\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n  {'Model':<32} {'Paper R2':>10} {'Our R2':>10} {'Match':>10}\")\n",
    "print(f\"  {'-'*32} {'-'*10} {'-'*10} {'-'*10}\")\n",
    "\n",
    "if baseline_m:\n",
    "    status = \"[OK]\" if baseline_m.val_r2 >= 0.15 else \"[LOW]\"\n",
    "    print(f\"  {'VirtuosoNetSingle (Baseline)':<32} {'0.185':>10} {baseline_m.val_r2:>+10.4f} {status:>10}\")\n",
    "\n",
    "if beat_measure_m:\n",
    "    if beat_measure_m.val_r2 >= 0.35:\n",
    "        status = \"[OK]\"\n",
    "    elif beat_measure_m.val_r2 >= 0.30:\n",
    "        status = \"[CLOSE]\"\n",
    "    elif beat_measure_m.val_r2 >= 0.25:\n",
    "        status = \"[PARTIAL]\"\n",
    "    else:\n",
    "        status = \"[LOW]\"\n",
    "    print(f\"  {'VirtuosoNetMultiLevel (Full)':<32} {'0.397':>10} {beat_measure_m.val_r2:>+10.4f} {status:>10}\")\n",
    "\n",
    "if baseline_m and beat_measure_m:\n",
    "    total_gain = beat_measure_m.val_r2 - baseline_m.val_r2\n",
    "    status = \"[GOOD]\" if total_gain >= 0.15 else \"[PARTIAL]\" if total_gain >= 0.05 else \"[NONE]\"\n",
    "    print(f\"  {'Hierarchy Gain':<32} {'+0.212':>10} {total_gain:>+10.4f} {status:>10}\")\n",
    "\n",
    "# ========================================\n",
    "# Section 5: Next Steps Recommendations\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SECTION 5: NEXT STEPS RECOMMENDATIONS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if baseline_m and beat_m and beat_measure_m:\n",
    "    beat_contribution = beat_m.val_r2 - baseline_m.val_r2\n",
    "    measure_contribution = beat_measure_m.val_r2 - beat_m.val_r2\n",
    "    total_hierarchy = beat_contribution + measure_contribution\n",
    "    \n",
    "    print(\"\\n  Based on Phase 2 results:\")\n",
    "    \n",
    "    if total_hierarchy >= 0.15:\n",
    "        print(\"\\n  [SUCCESS] Hierarchy contributing as expected!\")\n",
    "        print(\"    - Ready for Phase 3: MERT embeddings, Conformer, etc.\")\n",
    "        print(\"    - Consider training on all 4 folds for robust evaluation\")\n",
    "    elif total_hierarchy >= 0.10:\n",
    "        print(\"\\n  [GOOD] Hierarchy helping but slightly below expected\")\n",
    "        print(\"    - Check diagnostics for attention entropy and contractor weights\")\n",
    "        print(\"    - May proceed to Phase 3 or investigate further\")\n",
    "    elif beat_contribution < 0.05:\n",
    "        print(\"\\n  [ACTION NEEDED] Beat hierarchy underperforming\")\n",
    "        print(\"    Recommendations:\")\n",
    "        print(\"    1. Check beat attention entropy - if >0.95, attention not learning\")\n",
    "        print(\"    2. Check span_beat_to_note_num - verify beat indices are valid\")\n",
    "        print(\"    3. Check contractor beat/lstm ratio - if <0.1, model ignoring beat\")\n",
    "        print(\"    4. Try longer training or different learning rate\")\n",
    "    elif measure_contribution < 0.02:\n",
    "        print(\"\\n  [ACTION NEEDED] Measure hierarchy not contributing\")\n",
    "        print(\"    Recommendations:\")\n",
    "        print(\"    1. Check measure attention entropy\")\n",
    "        print(\"    2. Verify beat-to-measure boundary detection\")\n",
    "        print(\"    3. Check contractor measure/lstm ratio\")\n",
    "        print(\"    4. Consider piece length distribution in fold\")\n",
    "    else:\n",
    "        print(\"\\n  [PARTIAL] Some hierarchy contribution but below target\")\n",
    "        print(\"    - Review diagnostics for specific issues\")\n",
    "        print(\"    - Consider hyperparameter tuning\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vhlsirr5pb",
   "metadata": {},
   "source": [
    "## Step 10: Sync Checkpoints to Google Drive\n",
    "\n",
    "Single checkpoint sync cell for all Phase 2 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vaomaz2syki",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PHASE 2: SYNC ALL CHECKPOINTS TO GOOGLE DRIVE\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SYNC ALL PHASE 2 CHECKPOINTS TO GOOGLE DRIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if RCLONE_AVAILABLE:\n",
    "    # Sync all model checkpoints\n",
    "    model_dirs = [\n",
    "        ('baseline', baseline_trainer.checkpoint_dir),\n",
    "        ('baseline_beat', beat_trainer.checkpoint_dir),\n",
    "        ('baseline_beat_measure', beat_measure_trainer.checkpoint_dir),\n",
    "    ]\n",
    "    \n",
    "    for model_name, ckpt_dir in model_dirs:\n",
    "        if ckpt_dir.exists():\n",
    "            gdrive_path = f\"{GDRIVE_CHECKPOINT_PATH}/{ckpt_dir.name}\"\n",
    "            print(f\"\\nSyncing {model_name} ({ckpt_dir.name})...\")\n",
    "            subprocess.run(\n",
    "                ['rclone', 'copy', str(ckpt_dir), gdrive_path, '--progress'],\n",
    "                capture_output=False\n",
    "            )\n",
    "        else:\n",
    "            print(f\"\\n[SKIP] {model_name} checkpoint dir not found: {ckpt_dir}\")\n",
    "    \n",
    "    # Sync fold assignments\n",
    "    print(f\"\\nSyncing fold assignments...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(FOLD_FILE), GDRIVE_DATA_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SYNC COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nCheckpoints synced to: {GDRIVE_CHECKPOINT_PATH}\")\n",
    "    print(f\"Fold assignments synced to: {GDRIVE_DATA_PATH}\")\n",
    "else:\n",
    "    print(\"\\nrclone not available - skipping sync\")\n",
    "    print(\"Checkpoints saved locally at:\", CHECKPOINT_ROOT)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 2 COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}