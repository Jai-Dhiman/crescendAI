{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# PercePiano Replica Training (4-Fold Cross-Validation)\n\nTrain the PercePiano replica model using 4-fold piece-based cross-validation,\nmatching the methodology and hyperparameters from the PercePiano paper SOTA.\n\n## Attribution\n\n> **PercePiano: Piano Performance Evaluation Dataset with Multi-level Perceptual Features**  \n> Park, Kim et al.  \n> Nature Scientific Reports 2024  \n> Paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11450231/  \n> GitHub: https://github.com/JonghoKimSNU/PercePiano\n\n## Methodology\n\nFollowing the exact approach from `m2pf_dataset_compositionfold.py`:\n\n- **Piece-based splits**: All performances of the same piece stay in the same fold\n- **Test set**: Select pieces randomly until reaching ~15% of SAMPLES (not pieces)\n- **4-fold CV**: Remaining pieces distributed round-robin across folds\n- **Per-fold normalization**: Stats computed from training folds only\n\n## Hyperparameters (SOTA Configuration - R2 = 0.397)\n\nThese parameters match the published SOTA from `2_run_comp_multilevel_total.sh` and `han_bigger256_concat.yml`:\n\n| Parameter | SOTA Value | Notes |\n|-----------|------------|-------|\n| input_size | 78 | SOTA uses 78 features (excludes section_tempo) |\n| batch_size | 8 | From SOTA training script |\n| learning_rate | 2.5e-5 | From SOTA training script |\n| hidden_size | 256 | HAN encoder dimension |\n| dropout | 0.2 | Regularization |\n| augment_train | False | SOTA doesn't use key augmentation |\n| max_epochs | 200 | Extended training window |\n| early_stopping_patience | 40 | More patience for convergence |\n| gradient_clip_val | 2.0 | From parser.py |\n\n## Expected Results\n\n- Target R2: 0.35-0.40 (matching published SOTA of 0.397)\n- Training time: ~8-12 hours on T4, ~3-5 hours on A100 (all 4 folds)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.14' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/Users/jdhiman/.local/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# Install uv and clone repository\n!curl -LsSf https://astral.sh/uv/install.sh | sh\n\nimport os\nos.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n\n# Clone repository\nif not os.path.exists('/tmp/crescendai'):\n    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n\n%cd /tmp/crescendai/model\n!git pull\n!git log -1 --oneline\n\n# Clone original PercePiano for comparison (needed for data diagnostics)\nPERCEPIANO_PATH = '/tmp/crescendai/model/data/raw/PercePiano'\nif not os.path.exists(PERCEPIANO_PATH):\n    print(\"\\nCloning original PercePiano repository...\")\n    !git clone https://github.com/JonghoKimSNU/PercePiano.git {PERCEPIANO_PATH}\nelse:\n    print(f\"\\nPercePiano already present at {PERCEPIANO_PATH}\")\n\n# Install dependencies\n!uv pip install --system -e .\n!pip install tensorboard rich\n\nimport torch\nimport pytorch_lightning as pl\nprint(f\"\\nPyTorch: {torch.__version__}\")\nprint(f\"Lightning: {pl.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths and Check rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path('/tmp/percepiano_vnet_split')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_kfold')\n",
    "LOG_ROOT = Path('/tmp/logs/percepiano_kfold')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_vnet_split'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/percepiano_kfold'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERCEPIANO REPLICA TRAINING (4-FOLD CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "\n",
    "if 'gdrive:' in result.stdout:\n",
    "    print(\"rclone 'gdrive' remote: CONFIGURED\")\n",
    "    RCLONE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"rclone 'gdrive' remote: NOT CONFIGURED\")\n",
    "    print(\"Run 'rclone config' in terminal to set up Google Drive\")\n",
    "    RCLONE_AVAILABLE = False\n",
    "\n",
    "print(f\"\\nData directory: {DATA_ROOT}\")\n",
    "print(f\"Checkpoint directory: {CHECKPOINT_ROOT}\")\n",
    "print(f\"Log directory: {LOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Download Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if not RCLONE_AVAILABLE:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "# Download preprocessed data\n",
    "print(\"Downloading preprocessed VirtuosoNet features from Google Drive...\")\n",
    "subprocess.run(\n",
    "    ['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'],\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_samples = 0\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = DATA_ROOT / split\n",
    "    if split_dir.exists():\n",
    "        count = len(list(split_dir.glob('*.pkl')))\n",
    "        total_samples += count\n",
    "        print(f\"  {split}: {count} samples\")\n",
    "    else:\n",
    "        print(f\"  {split}: MISSING!\")\n",
    "\n",
    "print(f\"  Total: {total_samples} samples\")\n",
    "\n",
    "stat_file = DATA_ROOT / 'stat.pkl'\n",
    "print(f\"  stat.pkl: {'present' if stat_file.exists() else 'MISSING!'}\")\n",
    "\n",
    "fold_file = DATA_ROOT / 'fold_assignments.json'\n",
    "print(f\"  fold_assignments.json: {'present' if fold_file.exists() else 'will be created'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r5kqq8nt5x",
   "source": "## Step 3b: Data Diagnostics (Priority 1)\n\nCompare our data loading with original PercePiano to identify any mismatches.\nThis is critical for reproducing SOTA results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eea3zn1ajph",
   "source": "import pickle\nimport numpy as np\nfrom pathlib import Path\n\nprint(\"=\"*70)\nprint(\"DATA DIAGNOSTICS - Comparing with PercePiano SOTA\")\nprint(\"=\"*70)\n\n# Load a sample file\nsample_files = list((DATA_ROOT / 'train').glob('*.pkl'))[:5]\nif not sample_files:\n    raise RuntimeError(\"No training data found!\")\n\nprint(f\"\\nFound {len(list((DATA_ROOT / 'train').glob('*.pkl')))} training samples\")\n\n# Inspect first sample structure\nprint(\"\\n\" + \"-\"*70)\nprint(\"SAMPLE DATA STRUCTURE\")\nprint(\"-\"*70)\n\nwith open(sample_files[0], 'rb') as f:\n    sample = pickle.load(f)\n\nprint(f\"Sample keys: {list(sample.keys())}\")\nprint(f\"Input shape: {sample['input'].shape}\")\nprint(f\"Scores shape: {sample['scores'].shape if 'scores' in sample else 'N/A'}\")\n\nif 'note_location' in sample:\n    print(f\"Note location keys: {list(sample['note_location'].keys())}\")\n    for k, v in sample['note_location'].items():\n        print(f\"  {k}: shape={np.array(v).shape}, range=[{np.min(v)}, {np.max(v)}]\")\n\n# Check input feature dimensions\ninput_dim = sample['input'].shape[-1]\nprint(f\"\\nInput dimension: {input_dim}\")\nif input_dim == 78:\n    print(\"  [OK] Matches SOTA (78 features, excludes section_tempo)\")\nelif input_dim == 79:\n    print(\"  [WARNING] Has 79 features (includes section_tempo) - SOTA uses 78\")\nelif input_dim == 83:\n    print(\"  [INFO] Has 83 features (78 base + 5 unnorm)\")\nelif input_dim == 84:\n    print(\"  [WARNING] Has 84 features - original VirtuosoNet config\")\nelse:\n    print(f\"  [ERROR] Unexpected dimension: {input_dim}\")\n\n# Check target scores\nif 'scores' in sample:\n    scores = np.array(sample['scores'])\n    print(f\"\\nTarget scores:\")\n    print(f\"  Shape: {scores.shape}\")\n    print(f\"  Range: [{scores.min():.4f}, {scores.max():.4f}]\")\n    print(f\"  Mean: {scores.mean():.4f}, Std: {scores.std():.4f}\")\n    \n    if scores.min() >= 0 and scores.max() <= 1:\n        print(\"  [OK] Targets normalized to [0, 1]\")\n    else:\n        print(\"  [ERROR] Targets NOT in [0, 1] range - needs normalization!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a00v4gpgvep",
   "source": "print(\"\\n\" + \"-\"*70)\nprint(\"FEATURE STATISTICS (Priority 2)\")\nprint(\"-\"*70)\nprint(\"Checking if our feature normalization matches original PercePiano...\")\n\n# Load stat.pkl if available\nstat_file = DATA_ROOT / 'stat.pkl'\nif stat_file.exists():\n    with open(stat_file, 'rb') as f:\n        stats = pickle.load(f)\n    print(f\"\\nstat.pkl contents:\")\n    print(f\"  Keys: {list(stats.keys())}\")\n    \n    if 'mean' in stats and 'std' in stats:\n        # Handle both dict and array formats\n        if isinstance(stats['mean'], dict):\n            mean = np.array(list(stats['mean'].values()))\n            std = np.array(list(stats['std'].values()))\n            print(f\"  Format: dict with {len(stats['mean'])} features\")\n            print(f\"  Feature names: {list(stats['mean'].keys())[:5]}...\")\n        else:\n            mean = np.array(stats['mean'])\n            std = np.array(stats['std'])\n        print(f\"  Mean shape: {mean.shape}, Std shape: {std.shape}\")\n        print(f\"  Mean range: [{mean.min():.4f}, {mean.max():.4f}]\")\n        print(f\"  Std range: [{std.min():.4f}, {std.max():.4f}]\")\nelse:\n    print(\"\\n[WARNING] stat.pkl not found - normalization may be different\")\n\n# Compute actual feature statistics from training data\nprint(\"\\nComputing actual feature statistics from training samples...\")\nall_features = []\nfor pkl_file in list((DATA_ROOT / 'train').glob('*.pkl'))[:50]:  # Sample 50 files\n    with open(pkl_file, 'rb') as f:\n        data = pickle.load(f)\n    all_features.append(data['input'])\n\nall_features = np.concatenate(all_features, axis=0)\nprint(f\"Sampled features shape: {all_features.shape}\")\n\n# Compute statistics\nactual_mean = all_features.mean(axis=0)\nactual_std = all_features.std(axis=0)\n\nprint(f\"\\nFeature statistics (computed from data):\")\nprint(f\"  Mean range: [{actual_mean.min():.4f}, {actual_mean.max():.4f}]\")\nprint(f\"  Std range:  [{actual_std.min():.4f}, {actual_std.max():.4f}]\")\n\n# Check z-score normalization for first 8 features (should be ~0 mean, ~1 std)\nz_scored_features = ['midi_pitch', 'duration', 'beat_importance', 'measure_length', \n                     'qpm_primo', 'following_rest', 'distance_from_abs_dynamic', \n                     'distance_from_recent_tempo']\n\nprint(f\"\\nZ-scored features check (first 8 should have mean~0, std~1):\")\nfor i, name in enumerate(z_scored_features[:min(8, all_features.shape[1])]):\n    m, s = actual_mean[i], actual_std[i]\n    status = \"[OK]\" if abs(m) < 0.5 and 0.5 < s < 2.0 else \"[CHECK]\"\n    print(f\"  {i}: {name:30s} mean={m:+.4f}, std={s:.4f} {status}\")\n\n# Verify categorical features (should be 0/1 or small range)\nprint(f\"\\nOther features (indices 8-13):\")\nfor i in range(8, min(14, all_features.shape[1])):\n    m, s = actual_mean[i], actual_std[i]\n    unique_count = len(np.unique(all_features[:100, i].round(2)))\n    print(f\"  {i}: mean={m:+.4f}, std={s:.4f}, ~{unique_count} unique values\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cxlwmkoai7l",
   "source": "print(\"\\n\" + \"-\"*70)\nprint(\"COMPARISON WITH ORIGINAL PERCEPIANO\")\nprint(\"-\"*70)\n\n# Check if original PercePiano data is available for comparison\noriginal_data_path = Path('/tmp/crescendai/model/data/raw/PercePiano')\nif not original_data_path.exists():\n    print(\"[INFO] Original PercePiano data not available for comparison\")\n    print(\"       Repository should be cloned in Step 1\")\nelse:\n    print(f\"[OK] PercePiano repository found at {original_data_path}\")\n    \n    # Check for the fold splitting code\n    fold_script = original_data_path / 'virtuoso/virtuoso/pyScoreParser/m2pf_dataset_compositionfold.py'\n    if fold_script.exists():\n        print(f\"[OK] Found original fold split code: m2pf_dataset_compositionfold.py\")\n        print(\"\\n  Key methodology from original code:\")\n        print(\"  - Test set: select pieces until reaching 15% of SAMPLES\")\n        print(\"  - CV folds: round-robin distribution by piece index\")\n        print(\"  - Only pieces with >1 sample are eligible for test set\")\n    \n    # Try to load original pickle files if any exist\n    original_pkls = list(original_data_path.glob('**/*.pkl'))\n    if original_pkls:\n        print(f\"\\nFound {len(original_pkls)} original pickle files\")\n        \n        # Load one and compare structure\n        try:\n            with open(original_pkls[0], 'rb') as f:\n                orig_sample = pickle.load(f)\n            \n            print(f\"\\nOriginal sample structure ({original_pkls[0].name}):\")\n            if isinstance(orig_sample, dict):\n                print(f\"  Keys: {list(orig_sample.keys())}\")\n                for k, v in orig_sample.items():\n                    if hasattr(v, 'shape'):\n                        print(f\"    {k}: shape={v.shape}\")\n                    elif isinstance(v, (list, np.ndarray)):\n                        print(f\"    {k}: len={len(v)}\")\n            elif isinstance(orig_sample, list):\n                print(f\"  List of {len(orig_sample)} items\")\n                if orig_sample and isinstance(orig_sample[0], dict):\n                    print(f\"  First item keys: {list(orig_sample[0].keys())}\")\n        except Exception as e:\n            print(f\"  Could not load sample: {e}\")\n    else:\n        print(\"\\n[INFO] No preprocessed pickle files in PercePiano repo\")\n        print(\"       (Original data requires running their preprocessing pipeline)\")\n\n# Check our data against expected SOTA format\nprint(\"\\n\" + \"-\"*70)\nprint(\"DATA FORMAT VALIDATION\")\nprint(\"-\"*70)\n\nexpected_keys = ['input', 'scores', 'note_location']\nsample_keys = list(sample.keys())\n\nprint(f\"Expected keys: {expected_keys}\")\nprint(f\"Our keys: {sample_keys}\")\n\n# Check for 'labels' key (used in our format instead of 'scores')\nif 'labels' in sample_keys:\n    print(\"[OK] 'labels' key present (mapped to 'scores' by dataset loader)\")\nelif 'scores' in sample_keys:\n    print(\"[OK] 'scores' key present\")\nelse:\n    print(\"[ERROR] Neither 'labels' nor 'scores' key found!\")\n\nmissing_keys = set(['input', 'note_location']) - set(sample_keys)\nif not missing_keys:\n    print(\"[OK] Required keys (input, note_location) present\")\nelse:\n    print(f\"[ERROR] Missing keys: {missing_keys}\")\n\nextra_keys = set(sample_keys) - set(['input', 'note_location', 'labels', 'scores'])\nif extra_keys:\n    print(f\"[INFO] Extra keys (OK): {extra_keys}\")\n\n# Validate note_location format\nif 'note_location' in sample:\n    nl = sample['note_location']\n    expected_nl_keys = {'beat', 'measure', 'voice'}\n    nl_keys = set(nl.keys())\n    \n    if expected_nl_keys.issubset(nl_keys):\n        print(\"[OK] note_location has required keys (beat, measure, voice)\")\n    else:\n        print(f\"[ERROR] note_location missing: {expected_nl_keys - nl_keys}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DATA DIAGNOSTICS COMPLETE\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Create Fold Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "from src.percepiano.data.kfold_split import (\n    create_piece_based_folds,\n    save_fold_assignments,\n    load_fold_assignments,\n    print_fold_statistics,\n)\n\nFOLD_FILE = DATA_ROOT / 'fold_assignments.json'\nN_FOLDS = 4\nTEST_RATIO = 0.15\nSEED = 42\n\nprint(\"=\"*60)\nprint(\"FOLD ASSIGNMENT CREATION\")\nprint(\"=\"*60)\n\n# Force regeneration to use corrected methodology\n# - Test set: select pieces until ~15% of SAMPLES (PercePiano methodology)\n# - CV folds: greedy bin-packing for balanced sample counts (improvement over round-robin)\nFORCE_REGENERATE = True\n\nif FOLD_FILE.exists() and not FORCE_REGENERATE:\n    print(f\"\\nLoading existing fold assignments from {FOLD_FILE}\")\n    fold_assignments = load_fold_assignments(FOLD_FILE)\nelse:\n    if FOLD_FILE.exists():\n        print(f\"\\nRemoving old fold assignments (regenerating with balanced methodology)...\")\n        FOLD_FILE.unlink()\n    \n    print(f\"\\nCreating new {N_FOLDS}-fold piece-based splits...\")\n    print(\"  Test set: select pieces until ~15% of SAMPLES\")\n    print(\"  CV folds: greedy bin-packing for balanced sample counts\")\n    fold_assignments = create_piece_based_folds(\n        data_dir=DATA_ROOT,\n        n_folds=N_FOLDS,\n        test_ratio=TEST_RATIO,\n        seed=SEED,\n    )\n    save_fold_assignments(fold_assignments, FOLD_FILE)\n\n# Print statistics\nprint_fold_statistics(fold_assignments, n_folds=N_FOLDS)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": "## Step 5: Training Configuration (SOTA)\n\nConfiguration matched to published SOTA (R2 = 0.397):\n- `input_size = 78` (excludes section_tempo)\n- `learning_rate = 2.5e-5`\n- `batch_size = 8`\n- `augment_train = False`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "import torch\ntorch.set_float32_matmul_precision('medium')\n\n# Enable better CUDA error reporting\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n# PercePiano SOTA Configuration\n# Hyperparameters matched to published SOTA (R2 = 0.397)\n# Sources:\n#   - Training script: 2_run_comp_multilevel_total.sh\n#   - Config: han_bigger256_concat.yml\n#   - Paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11450231/\nCONFIG = {\n    # K-Fold settings\n    'n_folds': N_FOLDS,\n    'test_ratio': TEST_RATIO,\n    \n    # Data\n    'data_dir': str(DATA_ROOT),\n    'checkpoint_dir': str(CHECKPOINT_ROOT),\n    'log_dir': str(LOG_ROOT),\n    \n    # Model input (SOTA uses 78 features, excludes section_tempo)\n    'input_size': 78,\n    \n    # HAN Architecture (han_bigger256_concat.yml)\n    'hidden_size': 256,\n    'note_layers': 2,\n    'voice_layers': 2,\n    'beat_layers': 2,\n    'measure_layers': 1,\n    'num_attention_heads': 8,\n    'final_hidden': 128,\n    \n    # Training - MATCHED TO SOTA (2_run_comp_multilevel_total.sh)\n    'learning_rate': 2.5e-5,  # SOTA value\n    'weight_decay': 1e-5,\n    'dropout': 0.2,\n    'batch_size': 8,          # SOTA value\n    'max_epochs': 200,\n    'early_stopping_patience': 40,\n    'gradient_clip_val': 2.0,\n    'precision': '16-mixed',\n    \n    # Dataset\n    'max_notes': 1024,\n    'num_workers': 0,  # Avoid shared memory issues on Thunder Compute\n    'augment_train': False,  # SOTA doesn't use augmentation\n}\n\nprint(\"=\"*60)\nprint(\"TRAINING CONFIGURATION (SOTA)\")\nprint(\"=\"*60)\nfor k, v in CONFIG.items():\n    print(f\"  {k}: {v}\")\n\n# Print training dynamics info\nsteps_per_epoch = 477 // CONFIG['batch_size']  # approximate\nlr_decay_epoch = 3000 // steps_per_epoch if steps_per_epoch > 0 else 999\nprint(f\"\\nTraining dynamics:\")\nprint(f\"  Steps per epoch (approx): {steps_per_epoch}\")\nprint(f\"  LR decay (StepLR) at epoch: ~{lr_decay_epoch}\")\nprint(f\"  LR after decay: {CONFIG['learning_rate'] * 0.98:.2e}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Initialize K-Fold Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.training.kfold_trainer import KFoldTrainer\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Set seed for reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Create K-Fold trainer\n",
    "kfold_trainer = KFoldTrainer(\n",
    "    config=CONFIG,\n",
    "    fold_assignments=fold_assignments,\n",
    "    data_dir=DATA_ROOT,\n",
    "    checkpoint_dir=CHECKPOINT_ROOT,\n",
    "    log_dir=LOG_ROOT,\n",
    "    n_folds=N_FOLDS,\n",
    ")\n",
    "\n",
    "print(\"K-Fold Trainer initialized\")\n",
    "print(f\"  Folds: {N_FOLDS}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_ROOT}\")\n",
    "print(f\"  Logs: {LOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Train All Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STARTING 4-FOLD CROSS-VALIDATION TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPercePiano SOTA baselines:\")\n",
    "print(\"  Bi-LSTM: R2 = 0.185\")\n",
    "print(\"  MidiBERT: R2 = 0.313\")\n",
    "print(\"  Bi-LSTM + SA + HAN: R2 = 0.397 (SOTA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train all folds\n",
    "aggregate_metrics = kfold_trainer.train_all_folds(verbose=True)\n",
    "\n",
    "# Save results\n",
    "kfold_trainer.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6siiy8yu5wh",
   "source": "## Step 7b: Training Diagnostics\n\nAnalyze prediction statistics to identify collapsed dimensions or other issues.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cgj36thyvvt",
   "source": "import torch\nimport numpy as np\nfrom src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n\nprint(\"=\"*70)\nprint(\"TRAINING DIAGNOSTICS - Prediction Analysis\")\nprint(\"=\"*70)\n\n# Get the best model from fold 0 for analysis\nfold_0_ckpt = list(CHECKPOINT_ROOT.glob('fold_0/*.ckpt'))\nif not fold_0_ckpt:\n    print(\"[WARNING] No fold 0 checkpoint found - run training first\")\nelse:\n    from src.percepiano.models.percepiano_replica import PercePianoVNetModule\n    from src.percepiano.data.percepiano_vnet_dataset import PercePianoVNetDataset\n    from torch.utils.data import DataLoader\n    \n    # Load model\n    model = PercePianoVNetModule.load_from_checkpoint(fold_0_ckpt[0])\n    model.eval()\n    model.cuda() if torch.cuda.is_available() else model.cpu()\n    \n    # Load validation data for fold 0\n    val_dataset = PercePianoVNetDataset(\n        data_dir=DATA_ROOT,\n        split='val',\n        max_notes=CONFIG['max_notes'],\n    )\n    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n    \n    # Collect predictions\n    all_preds = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            # Move to device\n            device = next(model.parameters()).device\n            input_features = batch['input_features'].to(device)\n            note_locations = {\n                'beat': batch['note_locations_beat'].to(device),\n                'measure': batch['note_locations_measure'].to(device),\n                'voice': batch['note_locations_voice'].to(device),\n            }\n            \n            outputs = model(input_features, note_locations)\n            all_preds.append(outputs['predictions'].cpu())\n            all_targets.append(batch['scores'])\n    \n    all_preds = torch.cat(all_preds).numpy()\n    all_targets = torch.cat(all_targets).numpy()\n    \n    # Analyze predictions\n    print(\"\\n\" + \"-\"*70)\n    print(\"PREDICTION STATISTICS\")\n    print(\"-\"*70)\n    \n    print(f\"\\nOverall:\")\n    print(f\"  Predictions - mean: {all_preds.mean():.4f}, std: {all_preds.std():.4f}\")\n    print(f\"  Predictions - range: [{all_preds.min():.4f}, {all_preds.max():.4f}]\")\n    print(f\"  Targets     - mean: {all_targets.mean():.4f}, std: {all_targets.std():.4f}\")\n    print(f\"  Targets     - range: [{all_targets.min():.4f}, {all_targets.max():.4f}]\")\n    \n    # Per-dimension analysis\n    print(\"\\n\" + \"-\"*70)\n    print(\"PER-DIMENSION ANALYSIS (Collapsed = std < 0.05)\")\n    print(\"-\"*70)\n    \n    collapsed_dims = []\n    print(f\"\\n{'Dimension':<25} {'Pred Mean':>10} {'Pred Std':>10} {'Tgt Std':>10} {'Status':<12}\")\n    print(f\"{'-'*25} {'-'*10} {'-'*10} {'-'*10} {'-'*12}\")\n    \n    for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n        pred_mean = all_preds[:, i].mean()\n        pred_std = all_preds[:, i].std()\n        tgt_std = all_targets[:, i].std()\n        \n        if pred_std < 0.05:\n            status = \"[COLLAPSED]\"\n            collapsed_dims.append(dim)\n        elif pred_std < tgt_std * 0.5:\n            status = \"[NARROW]\"\n        else:\n            status = \"[OK]\"\n        \n        print(f\"{dim:<25} {pred_mean:>10.4f} {pred_std:>10.4f} {tgt_std:>10.4f} {status:<12}\")\n    \n    print(f\"\\n{'-'*70}\")\n    print(f\"SUMMARY: {len(collapsed_dims)}/19 dimensions collapsed\")\n    if collapsed_dims:\n        print(f\"Collapsed: {', '.join(collapsed_dims)}\")\n    \n    # Check if sigmoid is working\n    print(\"\\n\" + \"-\"*70)\n    print(\"SIGMOID CHECK\")\n    print(\"-\"*70)\n    \n    if all_preds.min() >= 0 and all_preds.max() <= 1:\n        print(\"[OK] Predictions bounded in [0, 1] - sigmoid working\")\n    else:\n        print(f\"[ERROR] Predictions outside [0, 1]: [{all_preds.min():.4f}, {all_preds.max():.4f}]\")\n        print(\"        Check if sigmoid is applied in forward pass!\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DIAGNOSTICS COMPLETE\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fuojlu0pckj",
   "source": "## Priority 3: Sequence Iteration Gap\n\nThe SOTA config uses `sequence_iteration: 3` which iteratively refines the hierarchy.\nOur current implementation does a single pass. This may contribute to the R2 gap.\n\n**From original `encoder_score.py:33`:**\n```python\nfor i in range(self.num_sequence_iteration):\n    # Refine hierarchy representations\n```\n\n**Implementation TODO:**\n- Add `sequence_iterations` parameter to `PercePianoHAN`\n- Wrap hierarchy processing in iteration loop\n- Each iteration feeds measure context back to note level",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync checkpoints to Google Drive after training\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(\"Syncing checkpoints to Google Drive...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    print(\"Sync complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 8: Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all fold models on held-out test set\n",
    "test_results = kfold_trainer.evaluate_on_test(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 9: Per-Fold Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PER-FOLD VALIDATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Fold':<6} {'Val R2':>10} {'Val Pearson':>12} {'Val MAE':>10} {'Val RMSE':>10} {'Epochs':>8} {'Time (s)':>10}\")\n",
    "print(f\"{'-'*6} {'-'*10} {'-'*12} {'-'*10} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "\n",
    "for m in kfold_trainer.fold_metrics:\n",
    "    print(f\"{m.fold_id:<6} {m.val_r2:>+10.4f} {m.val_pearson:>+12.4f} {m.val_mae:>10.4f} {m.val_rmse:>10.4f} {m.epochs_trained:>8} {m.training_time_seconds:>10.1f}\")\n",
    "\n",
    "print(f\"{'-'*6} {'-'*10} {'-'*12} {'-'*10} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "print(f\"{'Mean':<6} {aggregate_metrics.mean_r2:>+10.4f} {aggregate_metrics.mean_pearson:>+12.4f} {aggregate_metrics.mean_mae:>10.4f} {aggregate_metrics.mean_rmse:>10.4f}\")\n",
    "print(f\"{'Std':<6} {aggregate_metrics.std_r2:>+10.4f} {aggregate_metrics.std_pearson:>+12.4f} {aggregate_metrics.std_mae:>10.4f} {aggregate_metrics.std_rmse:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 10: Per-Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PER-DIMENSION R2 (Mean +/- Std across folds)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort dimensions by mean R2\n",
    "sorted_dims = sorted(\n",
    "    aggregate_metrics.per_dim_mean_r2.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{'Dimension':<25} {'Mean R2':>10} {'Std R2':>10} {'Status':<12}\")\n",
    "print(f\"{'-'*25} {'-'*10} {'-'*10} {'-'*12}\")\n",
    "\n",
    "for dim, mean_r2 in sorted_dims:\n",
    "    std_r2 = aggregate_metrics.per_dim_std_r2[dim]\n",
    "    \n",
    "    if mean_r2 >= 0.3:\n",
    "        status = \"[GOOD]\"\n",
    "    elif mean_r2 >= 0.1:\n",
    "        status = \"[OK]\"\n",
    "    elif mean_r2 >= 0:\n",
    "        status = \"[WEAK]\"\n",
    "    else:\n",
    "        status = \"[FAILED]\"\n",
    "    \n",
    "    print(f\"{dim:<25} {mean_r2:>+10.4f} {std_r2:>10.4f} {status:<12}\")\n",
    "\n",
    "# Summary\n",
    "positive = sum(1 for d, r in sorted_dims if r > 0)\n",
    "strong = sum(1 for d, r in sorted_dims if r >= 0.2)\n",
    "n_dims = len(sorted_dims)\n",
    "\n",
    "print(f\"\\nSummary: {positive}/{n_dims} positive R2, {strong}/{n_dims} strong (>= 0.2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Step 11: Final Summary and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cross-validation results\n",
    "print(f\"\\n4-Fold Cross-Validation Results:\")\n",
    "print(f\"  Mean R2:       {aggregate_metrics.mean_r2:.4f} +/- {aggregate_metrics.std_r2:.4f}\")\n",
    "print(f\"  Mean Pearson:  {aggregate_metrics.mean_pearson:.4f} +/- {aggregate_metrics.std_pearson:.4f}\")\n",
    "print(f\"  Mean Spearman: {aggregate_metrics.mean_spearman:.4f} +/- {aggregate_metrics.std_spearman:.4f}\")\n",
    "print(f\"  Mean MAE:      {aggregate_metrics.mean_mae:.4f} +/- {aggregate_metrics.std_mae:.4f}\")\n",
    "print(f\"  Mean RMSE:     {aggregate_metrics.mean_rmse:.4f} +/- {aggregate_metrics.std_rmse:.4f}\")\n",
    "print(f\"  Training time: {aggregate_metrics.total_training_time/60:.1f} minutes\")\n",
    "\n",
    "# Test set results\n",
    "print(f\"\\nTest Set (Ensemble of 4 models):\")\n",
    "print(f\"  R2:       {test_results['ensemble']['r2']:.4f}\")\n",
    "print(f\"  Pearson:  {test_results['ensemble']['pearson']:.4f}\")\n",
    "print(f\"  Spearman: {test_results['ensemble']['spearman']:.4f}\")\n",
    "print(f\"  MAE:      {test_results['ensemble']['mae']:.4f}\")\n",
    "print(f\"  RMSE:     {test_results['ensemble']['rmse']:.4f}\")\n",
    "\n",
    "# Comparison to baselines\n",
    "print(f\"\\nComparison to PercePiano baselines:\")\n",
    "print(f\"  Bi-LSTM:      R2 = 0.185\")\n",
    "print(f\"  MidiBERT:     R2 = 0.313\")\n",
    "print(f\"  HAN SOTA:     R2 = 0.397\")\n",
    "print(f\"  Ours (CV):    R2 = {aggregate_metrics.mean_r2:.3f} +/- {aggregate_metrics.std_r2:.3f}\")\n",
    "print(f\"  Ours (Test):  R2 = {test_results['ensemble']['r2']:.3f}\")\n",
    "\n",
    "# Interpretation\n",
    "cv_r2 = aggregate_metrics.mean_r2\n",
    "test_r2 = test_results['ensemble']['r2']\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if cv_r2 >= 0.35:\n",
    "    print(f\"  [EXCELLENT] CV R2 >= 0.35 matches published SOTA!\")\n",
    "elif cv_r2 >= 0.25:\n",
    "    print(f\"  [GOOD] CV R2 >= 0.25 is usable for pseudo-labeling\")\n",
    "elif cv_r2 >= 0.10:\n",
    "    print(f\"  [FAIR] CV R2 >= 0.10 shows learning, needs improvement\")\n",
    "else:\n",
    "    print(f\"  [NEEDS WORK] CV R2 < 0.10, significant improvement needed\")\n",
    "\n",
    "# Save ensemble model if good enough\n",
    "if cv_r2 >= 0.25:\n",
    "    print(f\"\\nModel qualifies for pseudo-labeling MAESTRO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sync to Google Drive\n",
    "print(\"=\"*60)\n",
    "print(\"SYNC TO GOOGLE DRIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(f\"\\nSyncing all checkpoints and results...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    # Also sync fold assignments back to data directory\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(FOLD_FILE), GDRIVE_DATA_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSync complete!\")\n",
    "    print(f\"  Checkpoints: {GDRIVE_CHECKPOINT_PATH}\")\n",
    "    print(f\"  Fold assignments: {GDRIVE_DATA_PATH}\")\n",
    "else:\n",
    "    print(f\"\\nrclone not available - skipping sync\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}