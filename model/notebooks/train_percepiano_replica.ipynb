{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PercePiano Replica Training (4-Fold Cross-Validation)\n",
    "\n",
    "Train the PercePiano replica model using 4-fold piece-based cross-validation,\n",
    "matching the methodology and hyperparameters from the PercePiano paper SOTA.\n",
    "\n",
    "## Attribution\n",
    "\n",
    "> **PercePiano: Piano Performance Evaluation Dataset with Multi-level Perceptual Features**  \n",
    "> Park, Kim et al.  \n",
    "> Nature Scientific Reports 2024  \n",
    "> Paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11450231/  \n",
    "> GitHub: https://github.com/JonghoKimSNU/PercePiano\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Following the exact approach from `m2pf_dataset_compositionfold.py`:\n",
    "\n",
    "- **Piece-based splits**: All performances of the same piece stay in the same fold\n",
    "- **Test set**: Select pieces randomly until reaching ~15% of SAMPLES (not pieces)\n",
    "- **4-fold CV**: Remaining pieces distributed round-robin across folds\n",
    "- **Per-fold normalization**: Stats computed from training folds only\n",
    "\n",
    "## Hyperparameters (SOTA Configuration - R2 = 0.397)\n",
    "\n",
    "These parameters match the published SOTA from `2_run_comp_multilevel_total.sh` and `han_bigger256_concat.yml`:\n",
    "\n",
    "| Parameter | SOTA Value | Notes |\n",
    "|-----------|------------|-------|\n",
    "| input_size | 79 | SOTA uses 79 base features (includes section_tempo) |\n",
    "| batch_size | 8 | From SOTA training script |\n",
    "| learning_rate | 2.5e-5 | From SOTA training script |\n",
    "| hidden_size | 256 | HAN encoder dimension |\n",
    "| prediction_head | 512->512->19 | From model_m2pf.py (NOT config's final_fc_size) |\n",
    "| dropout | 0.2 | Regularization |\n",
    "| augment_train | False | SOTA doesn't use key augmentation |\n",
    "| max_epochs | 200 | Extended training window |\n",
    "| early_stopping_patience | 40 | More patience for convergence |\n",
    "| gradient_clip_val | 2.0 | From parser.py |\n",
    "| **precision** | **32** | **FP32 (original uses FP32, not mixed precision)** |\n",
    "| **max_notes/slice_len** | **5000** | **SOTA slice size for overlapping sampling** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv and clone repository\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Clone original PercePiano for comparison (needed for data diagnostics)\n",
    "PERCEPIANO_PATH = '/tmp/crescendai/model/data/raw/PercePiano'\n",
    "if not os.path.exists(PERCEPIANO_PATH):\n",
    "    print(\"\\nCloning original PercePiano repository...\")\n",
    "    !git clone https://github.com/JonghoKimSNU/PercePiano.git {PERCEPIANO_PATH}\n",
    "else:\n",
    "    print(f\"\\nPercePiano already present at {PERCEPIANO_PATH}\")\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths and Check rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path('/tmp/percepiano_vnet_84dim')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_kfold')\n",
    "LOG_ROOT = Path('/tmp/logs/percepiano_kfold')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_vnet_84dim'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/percepiano_kfold'\n",
    "\n",
    "# Training control\n",
    "RESTART_TRAINING = True  # Set to True to clear checkpoints and start fresh\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERCEPIANO REPLICA TRAINING (4-FOLD CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clear checkpoints if restarting\n",
    "if RESTART_TRAINING and CHECKPOINT_ROOT.exists():\n",
    "    print(f\"\\nRESTART_TRAINING=True: Clearing checkpoints at {CHECKPOINT_ROOT}\")\n",
    "    shutil.rmtree(CHECKPOINT_ROOT)\n",
    "    print(\"  Checkpoints cleared!\")\n",
    "\n",
    "if RESTART_TRAINING and LOG_ROOT.exists():\n",
    "    print(f\"RESTART_TRAINING=True: Clearing logs at {LOG_ROOT}\")\n",
    "    shutil.rmtree(LOG_ROOT)\n",
    "    print(\"  Logs cleared!\")\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "\n",
    "if 'gdrive:' in result.stdout:\n",
    "    print(\"\\nrclone 'gdrive' remote: CONFIGURED\")\n",
    "    RCLONE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"\\nrclone 'gdrive' remote: NOT CONFIGURED\")\n",
    "    print(\"Run 'rclone config' in terminal to set up Google Drive\")\n",
    "    RCLONE_AVAILABLE = False\n",
    "\n",
    "print(f\"\\nData directory: {DATA_ROOT}\")\n",
    "print(f\"Checkpoint directory: {CHECKPOINT_ROOT}\")\n",
    "print(f\"Log directory: {LOG_ROOT}\")\n",
    "print(f\"\\nRESTART_TRAINING: {RESTART_TRAINING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Download Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if not RCLONE_AVAILABLE:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "# Download preprocessed data\n",
    "print(\"Downloading preprocessed VirtuosoNet features from Google Drive...\")\n",
    "subprocess.run(\n",
    "    ['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'],\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_samples = 0\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = DATA_ROOT / split\n",
    "    if split_dir.exists():\n",
    "        count = len(list(split_dir.glob('*.pkl')))\n",
    "        total_samples += count\n",
    "        print(f\"  {split}: {count} samples\")\n",
    "    else:\n",
    "        print(f\"  {split}: MISSING!\")\n",
    "\n",
    "print(f\"  Total: {total_samples} samples\")\n",
    "\n",
    "stat_file = DATA_ROOT / 'stat.pkl'\n",
    "print(f\"  stat.pkl: {'present' if stat_file.exists() else 'MISSING!'}\")\n",
    "\n",
    "fold_file = DATA_ROOT / 'fold_assignments.json'\n",
    "print(f\"  fold_assignments.json: {'present' if fold_file.exists() else 'will be created'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Create Fold Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.data.kfold_split import (\n",
    "    create_piece_based_folds,\n",
    "    save_fold_assignments,\n",
    "    load_fold_assignments,\n",
    "    print_fold_statistics,\n",
    ")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'fold_assignments.json'\n",
    "N_FOLDS = 4\n",
    "TEST_RATIO = 0.15\n",
    "SEED = 42\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FOLD ASSIGNMENT CREATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Force regeneration to use corrected methodology\n",
    "# - Test set: select pieces until ~15% of SAMPLES (PercePiano methodology)\n",
    "# - CV folds: greedy bin-packing for balanced sample counts (improvement over round-robin)\n",
    "FORCE_REGENERATE = True\n",
    "\n",
    "if FOLD_FILE.exists() and not FORCE_REGENERATE:\n",
    "    print(f\"\\nLoading existing fold assignments from {FOLD_FILE}\")\n",
    "    fold_assignments = load_fold_assignments(FOLD_FILE)\n",
    "else:\n",
    "    if FOLD_FILE.exists():\n",
    "        print(f\"\\nRemoving old fold assignments (regenerating with balanced methodology)...\")\n",
    "        FOLD_FILE.unlink()\n",
    "    \n",
    "    print(f\"\\nCreating new {N_FOLDS}-fold piece-based splits...\")\n",
    "    print(\"  Test set: select pieces until ~15% of SAMPLES\")\n",
    "    print(\"  CV folds: greedy bin-packing for balanced sample counts\")\n",
    "    fold_assignments = create_piece_based_folds(\n",
    "        data_dir=DATA_ROOT,\n",
    "        n_folds=N_FOLDS,\n",
    "        test_ratio=TEST_RATIO,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    save_fold_assignments(fold_assignments, FOLD_FILE)\n",
    "\n",
    "# Print statistics\n",
    "print_fold_statistics(fold_assignments, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "import torch\ntorch.set_float32_matmul_precision('medium')\n\n# Enable better CUDA error reporting\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n# Import model type constants (including Round 17 true incremental models)\nfrom src.percepiano.training.kfold_trainer import (\n    MODEL_TYPE_HAN,\n    MODEL_TYPE_BASELINE,\n    MODEL_TYPE_BASELINE_BEAT,\n    MODEL_TYPE_BASELINE_BEAT_MEASURE,\n    # True incremental models (Round 17)\n    MODEL_TYPE_NOTE_ONLY,\n    MODEL_TYPE_NOTE_VOICE,\n    MODEL_TYPE_NOTE_VOICE_BEAT,\n)\n\n# Round 17 Configuration: True Incremental Architecture\n# \n# KEY INSIGHT: The original HAN architecture has note and voice LSTMs\n# process the SAME embedded input IN PARALLEL, then concatenate.\n# The previous \"incremental\" approach (7-layer LSTM + beat) was wrong.\n#\n# True incremental progression:\n# 1. NoteOnly: 2-layer note BiLSTM (expected R2 ~0.10)\n# 2. NoteVoice: + parallel 2-layer voice LSTM (expected R2 ~0.15)\n# 3. NoteVoiceBeat: + beat hierarchy (expected R2 ~0.25-0.30)\n# 4. Full HAN: + measure hierarchy (expected R2 ~0.35-0.40)\n\nCONFIG = {\n    # K-Fold settings\n    'n_folds': N_FOLDS,\n    'test_ratio': TEST_RATIO,\n    # Data\n    'data_dir': str(DATA_ROOT),\n    'checkpoint_dir': str(CHECKPOINT_ROOT),\n    'log_dir': str(LOG_ROOT),\n    'input_size': 79,\n    'hidden_size': 256,\n    'note_layers': 2,\n    'voice_layers': 2,\n    'beat_layers': 2,\n    'measure_layers': 1,\n    'num_attention_heads': 8,\n    'learning_rate': 2.5e-5,\n    'weight_decay': 1e-5,\n    'dropout': 0.2,\n    'batch_size': 8,\n    'max_epochs': 200,\n    'early_stopping_patience': 20,\n    'gradient_clip_val': 2.0,\n    'precision': '32',\n    'max_notes': 5000,\n    'slice_len': 5000,\n    'num_workers': 4,\n    'augment_train': False,\n    # Attention improvement hyperparameters\n    'attention_lr_multiplier': 10.0,  # Higher LR for attention params\n    'entropy_weight': 0.01,           # Penalty for uniform attention\n    'entropy_target': 0.6,            # Target entropy (0=focused, 1=uniform)\n}\n\nprint(\"=\"*60)\nprint(\"TRAINING CONFIGURATION (ROUND 17 - TRUE INCREMENTAL)\")\nprint(\"=\"*60)\nprint(\"\\nRound 17 Changes:\")\nprint(\"  - Fixed architecture: note + voice process SAME input in PARALLEL\")\nprint(\"  - New true incremental models: NoteOnly, NoteVoice, NoteVoiceBeat\")\nprint(\"  - DiagnosticCallback runs automatically at end of training\")\nprint(\"  - Model-specific diagnostic insights for each architecture\")\nprint(\"\\n\" + \"-\"*60)\nfor k, v in CONFIG.items():\n    print(f\"  {k}: {v}\")\n\nprint(f\"\\nModel types available:\")\nprint(f\"  MODEL_TYPE_BASELINE = '{MODEL_TYPE_BASELINE}' (7-layer Bi-LSTM, R2 ~0.19)\")\nprint(f\"  MODEL_TYPE_NOTE_ONLY = '{MODEL_TYPE_NOTE_ONLY}' (2-layer note, R2 ~0.10)\")\nprint(f\"  MODEL_TYPE_NOTE_VOICE = '{MODEL_TYPE_NOTE_VOICE}' (note + voice parallel, R2 ~0.15)\")\nprint(f\"  MODEL_TYPE_NOTE_VOICE_BEAT = '{MODEL_TYPE_NOTE_VOICE_BEAT}' (+ beat, R2 ~0.25-0.30)\")\nprint(f\"  MODEL_TYPE_HAN = '{MODEL_TYPE_HAN}' (full hierarchical, R2 ~0.40)\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": "## Step 6: Initialize True Incremental Trainers (Round 17)\n\nCreate trainers for the TRUE incremental models that match the actual HAN architecture:\n1. NoteOnly (2-layer note BiLSTM) - expected R2 ~0.10\n2. NoteVoice (+ parallel 2-layer voice LSTM) - expected R2 ~0.15\n3. NoteVoiceBeat (+ beat hierarchy) - expected R2 ~0.25-0.30\n4. Full HAN (+ measure hierarchy) - expected R2 ~0.35-0.40\n\n**Key Insight**: The original HAN has note and voice LSTMs process the SAME embedded input IN PARALLEL, then concatenate. This is different from the old \"incremental\" approach which added beat on top of a 7-layer LSTM."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "from src.percepiano.training.kfold_trainer import (\n    KFoldTrainer,\n    MODEL_TYPE_BASELINE,\n    MODEL_TYPE_NOTE_ONLY,\n    MODEL_TYPE_NOTE_VOICE,\n    MODEL_TYPE_NOTE_VOICE_BEAT,\n    MODEL_TYPE_HAN,\n)\nimport pytorch_lightning as pl\n\n# Set seed for reproducibility\npl.seed_everything(42, workers=True)\n\n# Round 17: True Incremental Training on Fold 2\n# This matches the ACTUAL HAN architecture progression\nFOLD_ID = 2  # Best performing fold with longest pieces (1-54 beats)\n\nprint(\"=\"*60)\nprint(\"ROUND 17: TRUE INCREMENTAL TRAINERS\")\nprint(\"=\"*60)\nprint(f\"\\nTraining Fold: {FOLD_ID}\")\nprint(\"\\nTrue Incremental Models (matching HAN architecture):\")\nprint(\"  1. NoteOnly (2-layer note BiLSTM) - R2 ~0.10\")\nprint(\"  2. NoteVoice (+ parallel voice LSTM) - R2 ~0.15\")\nprint(\"  3. NoteVoiceBeat (+ beat hierarchy) - R2 ~0.25-0.30\")\nprint(\"  4. Full HAN (+ measure hierarchy) - R2 ~0.35-0.40\")\n\n# 1. NoteOnly trainer (2-layer note BiLSTM)\nprint(\"\\n[1] NoteOnly Trainer (2-layer note BiLSTM):\")\nnote_only_trainer = KFoldTrainer(\n    config=CONFIG,\n    fold_assignments=fold_assignments,\n    data_dir=DATA_ROOT,\n    checkpoint_dir=CHECKPOINT_ROOT / \"note_only\",\n    log_dir=LOG_ROOT / \"note_only\",\n    n_folds=N_FOLDS,\n    model_type=MODEL_TYPE_NOTE_ONLY,\n)\n\n# 2. NoteVoice trainer (+ parallel voice LSTM)\nprint(\"\\n[2] NoteVoice Trainer (+ parallel voice LSTM):\")\nnote_voice_trainer = KFoldTrainer(\n    config=CONFIG,\n    fold_assignments=fold_assignments,\n    data_dir=DATA_ROOT,\n    checkpoint_dir=CHECKPOINT_ROOT / \"note_voice\",\n    log_dir=LOG_ROOT / \"note_voice\",\n    n_folds=N_FOLDS,\n    model_type=MODEL_TYPE_NOTE_VOICE,\n)\n\n# 3. NoteVoiceBeat trainer (+ beat hierarchy)\nprint(\"\\n[3] NoteVoiceBeat Trainer (+ beat hierarchy):\")\nnote_voice_beat_trainer = KFoldTrainer(\n    config=CONFIG,\n    fold_assignments=fold_assignments,\n    data_dir=DATA_ROOT,\n    checkpoint_dir=CHECKPOINT_ROOT / \"note_voice_beat\",\n    log_dir=LOG_ROOT / \"note_voice_beat\",\n    n_folds=N_FOLDS,\n    model_type=MODEL_TYPE_NOTE_VOICE_BEAT,\n)\n\n# 4. Full HAN trainer (+ measure hierarchy)\nprint(\"\\n[4] Full HAN Trainer (+ measure hierarchy):\")\nhan_trainer = KFoldTrainer(\n    config=CONFIG,\n    fold_assignments=fold_assignments,\n    data_dir=DATA_ROOT,\n    checkpoint_dir=CHECKPOINT_ROOT / \"han\",\n    log_dir=LOG_ROOT / \"han\",\n    n_folds=N_FOLDS,\n    model_type=MODEL_TYPE_HAN,\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"All 4 trainers initialized!\")\nprint(\"Checkpoints will be saved to:\")\nprint(f\"  NoteOnly: {note_only_trainer.checkpoint_dir}\")\nprint(f\"  NoteVoice: {note_voice_trainer.checkpoint_dir}\")\nprint(f\"  NoteVoiceBeat: {note_voice_beat_trainer.checkpoint_dir}\")\nprint(f\"  Full HAN: {han_trainer.checkpoint_dir}\")\nprint(\"\\nDiagnostics run automatically at end of each training!\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "id": "qdk0xmb8i2q",
   "source": "# Optional: Enable hierarchy debug mode for detailed logging\n# This logs boundary detection, attention weights, and other internals\n\nfrom src.percepiano.models.hierarchy_utils import set_hierarchy_debug\n\n# Uncomment to enable debug mode:\n# set_hierarchy_debug(True)\n\nprint(\"Hierarchy debug mode: DISABLED\")\nprint(\"To enable, uncomment set_hierarchy_debug(True) above\")\nprint(\"\\nNote: Comprehensive diagnostics run automatically at end of each training!\")\nprint(\"Look for 'END OF TRAINING DIAGNOSTICS' in the output.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "## Step 7: True Incremental Training (Round 17)\n\nTrain the TRUE incremental models that match the actual HAN architecture:\n1. **NoteOnly** (2-layer note BiLSTM) - R2 ~0.10\n2. **NoteVoice** (+ parallel voice LSTM) - R2 ~0.15 (gain ~+0.05 from voice)\n3. **NoteVoiceBeat** (+ beat hierarchy) - R2 ~0.25-0.30 (gain ~+0.10 from beat)\n4. **Full HAN** (+ measure hierarchy) - R2 ~0.35-0.40 (gain ~+0.05 from measure)\n\nEach training run will automatically output comprehensive diagnostics at the end,\nincluding activation variances, attention entropy, and model-specific insights."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nROUND 17: TRUE INCREMENTAL TRAINING\n\nTrain the models that match the ACTUAL HAN architecture progression:\n1. NoteOnly (2-layer note BiLSTM) - R2 ~0.10\n2. NoteVoice (+ parallel voice LSTM) - R2 ~0.15\n3. NoteVoiceBeat (+ beat hierarchy) - R2 ~0.25-0.30\n4. Full HAN (+ measure hierarchy) - R2 ~0.35-0.40\n\nDiagnostics run automatically at the end of each training via on_fit_end callback.\n\"\"\"\n\nprint(\"=\"*70)\nprint(\"ROUND 17: TRUE INCREMENTAL TRAINING\")\nprint(\"=\"*70)\nprint(\"\\nGoal: Validate each hierarchy level contributes to performance\")\nprint(\"Expected gains:\")\nprint(\"  Voice (parallel LSTM): ~+0.05 R2\")\nprint(\"  Beat hierarchy: ~+0.10 R2\")\nprint(\"  Measure hierarchy: ~+0.05 R2\")\nprint(\"  Total gain from NoteOnly to HAN: ~+0.25-0.30 R2\")\nprint(\"\\nNote: Diagnostics run automatically at end of each training!\")\nprint(\"=\"*70)\n\n# ========================================\n# Model 1: NoteOnly (2-layer note BiLSTM)\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL 1: NoteOnly (2-layer note BiLSTM)\")\nprint(\"=\"*70)\nprint(\"Expected R2: ~0.10\")\n\nnote_only_metrics = note_only_trainer.train_fold(\n    fold_id=FOLD_ID,\n    verbose=True,\n    resume_from_checkpoint=False,\n)\nnote_only_trainer.save_results()\n\nprint(f\"\\nNoteOnly training complete! Val R2 = {note_only_metrics.val_r2:+.4f}\")\n\n# ========================================\n# Model 2: NoteVoice (+ parallel voice LSTM)\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL 2: NoteVoice (+ parallel voice LSTM)\")\nprint(\"=\"*70)\nprint(\"Expected R2: ~0.15 (voice contribution: +0.05)\")\n\nnote_voice_metrics = note_voice_trainer.train_fold(\n    fold_id=FOLD_ID,\n    verbose=True,\n    resume_from_checkpoint=False,\n)\nnote_voice_trainer.save_results()\n\nvoice_gain = note_voice_metrics.val_r2 - note_only_metrics.val_r2\nprint(f\"\\nNoteVoice training complete!\")\nprint(f\"  Val R2: {note_voice_metrics.val_r2:+.4f}\")\nprint(f\"  Voice gain: {voice_gain:+.4f} (expected: ~+0.05)\")\n\n# ========================================\n# Model 3: NoteVoiceBeat (+ beat hierarchy)\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL 3: NoteVoiceBeat (+ beat hierarchy)\")\nprint(\"=\"*70)\nprint(\"Expected R2: ~0.25-0.30 (beat contribution: +0.10)\")\n\nnote_voice_beat_metrics = note_voice_beat_trainer.train_fold(\n    fold_id=FOLD_ID,\n    verbose=True,\n    resume_from_checkpoint=False,\n)\nnote_voice_beat_trainer.save_results()\n\nbeat_gain = note_voice_beat_metrics.val_r2 - note_voice_metrics.val_r2\nprint(f\"\\nNoteVoiceBeat training complete!\")\nprint(f\"  Val R2: {note_voice_beat_metrics.val_r2:+.4f}\")\nprint(f\"  Beat gain: {beat_gain:+.4f} (expected: ~+0.10)\")\n\n# ========================================\n# Model 4: Full HAN (+ measure hierarchy)\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"MODEL 4: Full HAN (+ measure hierarchy)\")\nprint(\"=\"*70)\nprint(\"Expected R2: ~0.35-0.40 (approaching SOTA of 0.397)\")\n\nhan_metrics = han_trainer.train_fold(\n    fold_id=FOLD_ID,\n    verbose=True,\n    resume_from_checkpoint=False,\n)\nhan_trainer.save_results()\n\nmeasure_gain = han_metrics.val_r2 - note_voice_beat_metrics.val_r2\nprint(f\"\\nFull HAN training complete!\")\nprint(f\"  Val R2: {han_metrics.val_r2:+.4f}\")\nprint(f\"  Measure gain: {measure_gain:+.4f} (expected: ~+0.05)\")\n\n# ========================================\n# Store models and metrics for analysis\n# ========================================\ntrained_models = {\n    'note_only': note_only_trainer.get_trained_model(FOLD_ID),\n    'note_voice': note_voice_trainer.get_trained_model(FOLD_ID),\n    'note_voice_beat': note_voice_beat_trainer.get_trained_model(FOLD_ID),\n    'han': han_trainer.get_trained_model(FOLD_ID),\n}\n\ntrained_metrics = {\n    'note_only': note_only_metrics,\n    'note_voice': note_voice_metrics,\n    'note_voice_beat': note_voice_beat_metrics,\n    'han': han_metrics,\n}\n\n# ========================================\n# Training Summary\n# ========================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"TRUE INCREMENTAL TRAINING COMPLETE\")\nprint(\"=\"*70)\n\ntotal_gain = han_metrics.val_r2 - note_only_metrics.val_r2\n\nprint(f\"\\n  {'Model':<30} {'Val R2':>10} {'Gain':>10} {'Expected':>12}\")\nprint(f\"  {'-'*30} {'-'*10} {'-'*10} {'-'*12}\")\nprint(f\"  {'NoteOnly (2L note)':<30} {note_only_metrics.val_r2:>+10.4f} {'-':>10} {'~0.10':>12}\")\nprint(f\"  {'NoteVoice (+ voice)':<30} {note_voice_metrics.val_r2:>+10.4f} {voice_gain:>+10.4f} {'~0.15':>12}\")\nprint(f\"  {'NoteVoiceBeat (+ beat)':<30} {note_voice_beat_metrics.val_r2:>+10.4f} {beat_gain:>+10.4f} {'~0.25-0.30':>12}\")\nprint(f\"  {'Full HAN (+ measure)':<30} {han_metrics.val_r2:>+10.4f} {measure_gain:>+10.4f} {'~0.35-0.40':>12}\")\nprint(f\"  {'-'*30} {'-'*10} {'-'*10} {'-'*12}\")\nprint(f\"  {'Total Gain (NoteOnly->HAN)':<30} {'-':>10} {total_gain:>+10.4f} {'~+0.25':>12}\")\n\nprint(f\"\\n  Target: R2 = 0.397 (PercePiano SOTA)\")\n\nif han_metrics.val_r2 >= 0.35:\n    print(f\"  [SUCCESS] Approaching SOTA performance!\")\nelif han_metrics.val_r2 >= 0.30:\n    print(f\"  [GOOD] Strong performance, minor tuning may help\")\nelif han_metrics.val_r2 >= 0.25:\n    print(f\"  [PARTIAL] Hierarchy helping but below target - check diagnostics\")\nelse:\n    print(f\"  [ISSUE] Below expected - review end-of-training diagnostics above\")\n\n# Validate incremental gains\nprint(\"\\n  Incremental Validation:\")\nif voice_gain > 0:\n    print(f\"    Voice contribution: POSITIVE (+{voice_gain:.4f})\")\nelse:\n    print(f\"    Voice contribution: NEGATIVE ({voice_gain:.4f}) - INVESTIGATE\")\n\nif beat_gain > 0:\n    print(f\"    Beat contribution: POSITIVE (+{beat_gain:.4f})\")\nelse:\n    print(f\"    Beat contribution: NEGATIVE ({beat_gain:.4f}) - INVESTIGATE\")\n\nif measure_gain > 0:\n    print(f\"    Measure contribution: POSITIVE (+{measure_gain:.4f})\")\nelse:\n    print(f\"    Measure contribution: NEGATIVE ({measure_gain:.4f}) - may need longer pieces\")\n\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": "## Step 8: Post-Training Diagnostics (Optional)\n\n**Note**: Comprehensive diagnostics now run automatically at the end of each model's training via the `on_fit_end` callback. The output includes:\n- Activation variances at each level\n- Attention entropy analysis\n- Model-specific insights with expected R2 values\n\nThis cell provides **additional manual diagnostics** if you need to re-run analysis or investigate specific issues after training."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nPOST-TRAINING DIAGNOSTICS (OPTIONAL)\n\nDiagnostics already ran automatically at end of each training.\nThis cell provides additional manual analysis if needed.\n\nKey metrics to check from automatic diagnostics:\n1. Beat attention entropy: 0.3-0.8 is good; >0.95 means uniform (not learning)\n2. Activation variances: Should be in \"OK\" range, not \"LOW - ISSUE\"\n3. Incremental gains: Each level should improve over previous\n\"\"\"\n\nimport torch\nimport numpy as np\nfrom torch.utils.data import DataLoader\nfrom src.percepiano.data.percepiano_vnet_dataset import (\n    PercePianoKFoldDataset,\n    percepiano_pack_collate,\n)\nfrom src.percepiano.training.diagnostics import DiagnosticCallback\n\nprint(\"=\"*70)\nprint(\"POST-TRAINING DIAGNOSTICS (OPTIONAL)\")\nprint(\"=\"*70)\nprint(\"\\nNote: Diagnostics already ran automatically at end of each training!\")\nprint(\"This cell is for additional analysis if needed.\")\n\n# Check if we have trained models\nif 'trained_models' not in dir():\n    print(\"\\n[WARNING] No trained_models found - run training cell first!\")\nelse:\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # Prepare validation batch for manual diagnostics\n    val_ds = PercePianoKFoldDataset(\n        data_dir=DATA_ROOT,\n        fold_assignments=fold_assignments,\n        fold_id=FOLD_ID,\n        mode=\"val\",\n        max_notes=CONFIG['max_notes'],\n        slice_len=CONFIG.get('slice_len', CONFIG['max_notes']),\n    )\n    val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, num_workers=0)\n    \n    # Create diagnostic callback for manual analysis\n    diag = DiagnosticCallback()\n    \n    print(\"\\nModels available for manual diagnostics:\")\n    for name, model in trained_models.items():\n        if model is not None:\n            model_type = diag._detect_model_type(model)\n            print(f\"  - {name}: detected as '{model_type}'\")\n        else:\n            print(f\"  - {name}: not available\")\n    \n    print(\"\\nTo run manual diagnostics on a specific model:\")\n    print(\"  model = trained_models['note_voice_beat'].to(device).eval()\")\n    print(\"  batch = next(iter(val_loader))\")\n    print(\"  stats = diag._run_diagnostic_forward(model, {k: v.to(device) for k, v in batch.items()})\")\n    print(\"  diag._print_diagnostic_summary(stats, 0)\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"INTERPRETATION GUIDE\")\nprint(\"=\"*70)\nprint(\"\"\"\nKey metrics from automatic diagnostics:\n\n[1] ACTIVATION VARIANCES:\n    - Should show \"OK\" status for most components\n    - \"LOW - ISSUE\" indicates signal collapse\n    - predictions_std should be 0.10-0.25 (not 0.008!)\n\n[2] ATTENTION ENTROPY (for beat/measure models):\n    - 0.3-0.8: Good (attention is learning to focus)\n    - >0.95: Too uniform (attention not learning)\n    - <0.1: Too collapsed (may be overfitting)\n\n[3] HIERARCHY CONTRIBUTION (for beat/measure models):\n    - beat_spanned should contribute >10%\n    - measure_spanned should contribute >5%\n    - Low contribution = model ignoring that branch\n\n[5] MODEL-SPECIFIC INSIGHTS:\n    - Shows expected R2 for each model type\n    - Highlights specific issues for that architecture\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "id": "tsmwiy2nm7p",
   "metadata": {},
   "source": "## Step 9: Comprehensive Analysis\n\nCompare all 4 true incremental models:\n1. Overall metrics table with incremental gains\n2. Per-dimension R2 comparison\n3. Hierarchy contribution analysis\n4. Comparison to PercePiano paper\n5. Next steps recommendations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dzp8ujd2miw",
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nROUND 17: COMPREHENSIVE ANALYSIS\n\nCompare all four true incremental models and analyze hierarchy contribution.\n\"\"\"\n\nimport numpy as np\nfrom sklearn.metrics import r2_score\nfrom src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n\nprint(\"=\"*80)\nprint(\"ROUND 17 COMPREHENSIVE ANALYSIS\")\nprint(\"=\"*80)\n\n# Validate we have metrics\nif 'trained_metrics' not in dir():\n    raise RuntimeError(\"No trained_metrics found - run training cell first!\")\n\nnote_only_m = trained_metrics.get('note_only')\nnote_voice_m = trained_metrics.get('note_voice')\nnote_voice_beat_m = trained_metrics.get('note_voice_beat')\nhan_m = trained_metrics.get('han')\n\nif not all([note_only_m, note_voice_m, note_voice_beat_m, han_m]):\n    missing = [k for k, v in [('note_only', note_only_m), ('note_voice', note_voice_m), \n                               ('note_voice_beat', note_voice_beat_m), ('han', han_m)] if v is None]\n    print(f\"\\n[WARNING] Missing metrics for: {missing}\")\n    print(\"Some analysis sections will be incomplete.\")\n\n# ========================================\n# Section 1: Overall Metrics Table\n# ========================================\nprint(\"\\n\" + \"-\"*80)\nprint(\"SECTION 1: OVERALL METRICS\")\nprint(\"-\"*80)\n\nprint(f\"\\n  {'Model':<32} {'Val R2':>10} {'Epochs':>8} {'Gain':>10} {'Expected':>12}\")\nprint(f\"  {'-'*32} {'-'*10} {'-'*8} {'-'*10} {'-'*12}\")\n\nif note_only_m:\n    print(f\"  {'NoteOnly (2L note)':<32} {note_only_m.val_r2:>+10.4f} {note_only_m.epochs_trained:>8} {'-':>10} {'~0.10':>12}\")\n\nif note_voice_m:\n    voice_gain = note_voice_m.val_r2 - note_only_m.val_r2 if note_only_m else 0\n    print(f\"  {'NoteVoice (+ voice)':<32} {note_voice_m.val_r2:>+10.4f} {note_voice_m.epochs_trained:>8} {voice_gain:>+10.4f} {'~0.15':>12}\")\n\nif note_voice_beat_m:\n    beat_gain = note_voice_beat_m.val_r2 - note_voice_m.val_r2 if note_voice_m else 0\n    print(f\"  {'NoteVoiceBeat (+ beat)':<32} {note_voice_beat_m.val_r2:>+10.4f} {note_voice_beat_m.epochs_trained:>8} {beat_gain:>+10.4f} {'~0.25':>12}\")\n\nif han_m:\n    measure_gain = han_m.val_r2 - note_voice_beat_m.val_r2 if note_voice_beat_m else 0\n    print(f\"  {'Full HAN (+ measure)':<32} {han_m.val_r2:>+10.4f} {han_m.epochs_trained:>8} {measure_gain:>+10.4f} {'~0.35-0.40':>12}\")\n\nif note_only_m and han_m:\n    total_gain = han_m.val_r2 - note_only_m.val_r2\n    print(f\"  {'-'*32} {'-'*10} {'-'*8} {'-'*10} {'-'*12}\")\n    print(f\"  {'Total Gain (NoteOnly->HAN)':<32} {'-':>10} {'-':>8} {total_gain:>+10.4f} {'~+0.25':>12}\")\n\n# ========================================\n# Section 2: Per-Dimension R2 Comparison\n# ========================================\nprint(\"\\n\" + \"-\"*80)\nprint(\"SECTION 2: PER-DIMENSION R2 COMPARISON\")\nprint(\"-\"*80)\n\n# Check if we have per-dimension metrics\nhas_per_dim = all([\n    m and hasattr(m, 'per_dim_r2') and m.per_dim_r2\n    for m in [note_only_m, note_voice_m, note_voice_beat_m, han_m]\n])\n\nif has_per_dim:\n    print(f\"\\n  {'Dimension':<20} {'NoteOnly':>10} {'+ Voice':>10} {'+ Beat':>10} {'Full HAN':>10}\")\n    print(f\"  {'-'*20} {'-'*10} {'-'*10} {'-'*10} {'-'*10}\")\n    \n    dim_data = []\n    for dim in PERCEPIANO_DIMENSIONS:\n        no_r2 = note_only_m.per_dim_r2.get(dim, 0)\n        nv_r2 = note_voice_m.per_dim_r2.get(dim, 0)\n        nvb_r2 = note_voice_beat_m.per_dim_r2.get(dim, 0)\n        han_r2 = han_m.per_dim_r2.get(dim, 0)\n        dim_data.append((dim, no_r2, nv_r2, nvb_r2, han_r2))\n    \n    # Sort by final HAN R2 (best first)\n    dim_data.sort(key=lambda x: x[4], reverse=True)\n    \n    for dim, no_r2, nv_r2, nvb_r2, han_r2 in dim_data:\n        print(f\"  {dim:<20} {no_r2:>+10.4f} {nv_r2:>+10.4f} {nvb_r2:>+10.4f} {han_r2:>+10.4f}\")\nelse:\n    print(\"\\n  [Per-dimension R2 not available - check trainer saves per_dim_r2]\")\n\n# ========================================\n# Section 3: Hierarchy Contribution Analysis\n# ========================================\nprint(\"\\n\" + \"-\"*80)\nprint(\"SECTION 3: HIERARCHY CONTRIBUTION ANALYSIS\")\nprint(\"-\"*80)\n\nif all([note_only_m, note_voice_m, note_voice_beat_m, han_m]):\n    voice_contrib = note_voice_m.val_r2 - note_only_m.val_r2\n    beat_contrib = note_voice_beat_m.val_r2 - note_voice_m.val_r2\n    measure_contrib = han_m.val_r2 - note_voice_beat_m.val_r2\n    total_hierarchy = han_m.val_r2 - note_only_m.val_r2\n    \n    print(f\"\\n  {'Component':<30} {'Actual':>10} {'Expected':>10} {'Status':>12}\")\n    print(f\"  {'-'*30} {'-'*10} {'-'*10} {'-'*12}\")\n    \n    # Voice contribution\n    status = \"[OK]\" if voice_contrib >= 0.03 else \"[LOW]\" if voice_contrib >= 0 else \"[NEGATIVE]\"\n    print(f\"  {'Voice (parallel LSTM)':<30} {voice_contrib:>+10.4f} {'~+0.05':>10} {status:>12}\")\n    \n    # Beat contribution\n    status = \"[OK]\" if beat_contrib >= 0.07 else \"[LOW]\" if beat_contrib >= 0 else \"[NEGATIVE]\"\n    print(f\"  {'Beat hierarchy':<30} {beat_contrib:>+10.4f} {'~+0.10':>10} {status:>12}\")\n    \n    # Measure contribution\n    status = \"[OK]\" if measure_contrib >= 0.03 else \"[LOW]\" if measure_contrib >= 0 else \"[NEGATIVE]\"\n    print(f\"  {'Measure hierarchy':<30} {measure_contrib:>+10.4f} {'~+0.05':>10} {status:>12}\")\n    \n    print(f\"  {'-'*30} {'-'*10} {'-'*10} {'-'*12}\")\n    status = \"[OK]\" if total_hierarchy >= 0.20 else \"[PARTIAL]\" if total_hierarchy >= 0.10 else \"[LOW]\"\n    print(f\"  {'Total hierarchy gain':<30} {total_hierarchy:>+10.4f} {'~+0.25':>10} {status:>12}\")\n\n# ========================================\n# Section 4: Comparison to PercePiano Paper\n# ========================================\nprint(\"\\n\" + \"-\"*80)\nprint(\"SECTION 4: COMPARISON TO PERCEPIANO PAPER\")\nprint(\"-\"*80)\n\nprint(f\"\\n  {'Model':<32} {'Paper R2':>10} {'Our R2':>10} {'Match':>10}\")\nprint(f\"  {'-'*32} {'-'*10} {'-'*10} {'-'*10}\")\n\n# Note: Paper doesn't report intermediate models, but we can compare endpoints\nif note_only_m:\n    # No direct comparison for NoteOnly\n    print(f\"  {'NoteOnly (our baseline)':<32} {'N/A':>10} {note_only_m.val_r2:>+10.4f} {'-':>10}\")\n\nif han_m:\n    if han_m.val_r2 >= 0.35:\n        status = \"[OK]\"\n    elif han_m.val_r2 >= 0.30:\n        status = \"[CLOSE]\"\n    elif han_m.val_r2 >= 0.25:\n        status = \"[PARTIAL]\"\n    else:\n        status = \"[LOW]\"\n    print(f\"  {'VirtuosoNetMultiLevel (HAN)':<32} {'0.397':>10} {han_m.val_r2:>+10.4f} {status:>10}\")\n\nif note_only_m and han_m:\n    total_gain = han_m.val_r2 - note_only_m.val_r2\n    # Paper shows ~+0.21 gain from baseline to HAN\n    status = \"[GOOD]\" if total_gain >= 0.20 else \"[PARTIAL]\" if total_gain >= 0.10 else \"[LOW]\"\n    print(f\"  {'Hierarchy Gain (paper: +0.21)':<32} {'+0.212':>10} {total_gain:>+10.4f} {status:>10}\")\n\n# ========================================\n# Section 5: Next Steps Recommendations\n# ========================================\nprint(\"\\n\" + \"-\"*80)\nprint(\"SECTION 5: NEXT STEPS RECOMMENDATIONS\")\nprint(\"-\"*80)\n\nif all([note_only_m, note_voice_m, note_voice_beat_m, han_m]):\n    voice_contrib = note_voice_m.val_r2 - note_only_m.val_r2\n    beat_contrib = note_voice_beat_m.val_r2 - note_voice_m.val_r2\n    measure_contrib = han_m.val_r2 - note_voice_beat_m.val_r2\n    total_hierarchy = han_m.val_r2 - note_only_m.val_r2\n    \n    print(\"\\n  Based on Round 17 results:\")\n    \n    if han_m.val_r2 >= 0.35:\n        print(\"\\n  [SUCCESS] Approaching SOTA performance!\")\n        print(\"    - Model architecture is working correctly\")\n        print(\"    - Consider training on all 4 folds for robust evaluation\")\n        print(\"    - Ready to explore enhancements (MERT embeddings, etc.)\")\n    elif han_m.val_r2 >= 0.25:\n        print(\"\\n  [GOOD] Hierarchy contributing, some room for improvement\")\n        print(\"    - Check attention entropy in automatic diagnostics\")\n        print(\"    - Consider longer training or LR tuning\")\n        print(\"    - May proceed with experiments\")\n    else:\n        print(\"\\n  [INVESTIGATE] Performance below expected\")\n        \n        if voice_contrib < 0:\n            print(\"    - Voice contribution NEGATIVE: Check voice LSTM implementation\")\n        if beat_contrib < 0.05:\n            print(\"    - Beat contribution LOW: Check beat attention entropy (should be 0.3-0.8)\")\n        if measure_contrib < 0:\n            print(\"    - Measure contribution NEGATIVE: May need longer pieces in training fold\")\n        \n        print(\"\\n    Review the END OF TRAINING DIAGNOSTICS output for each model\")\n        print(\"    Look for: [WARNING] messages and [LOW - ISSUE] activations\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ANALYSIS COMPLETE\")\nprint(\"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "id": "vhlsirr5pb",
   "metadata": {},
   "source": "## Step 10: Sync Checkpoints to Google Drive\n\nSync all 4 true incremental model checkpoints to Google Drive."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vaomaz2syki",
   "metadata": {},
   "outputs": [],
   "source": "\"\"\"\nROUND 17: SYNC ALL CHECKPOINTS TO GOOGLE DRIVE\n\"\"\"\n\nimport subprocess\n\nprint(\"=\"*60)\nprint(\"SYNC ALL ROUND 17 CHECKPOINTS TO GOOGLE DRIVE\")\nprint(\"=\"*60)\n\nif RCLONE_AVAILABLE:\n    # Sync all model checkpoints\n    model_dirs = [\n        ('note_only', note_only_trainer.checkpoint_dir),\n        ('note_voice', note_voice_trainer.checkpoint_dir),\n        ('note_voice_beat', note_voice_beat_trainer.checkpoint_dir),\n        ('han', han_trainer.checkpoint_dir),\n    ]\n    \n    for model_name, ckpt_dir in model_dirs:\n        if ckpt_dir.exists():\n            gdrive_path = f\"{GDRIVE_CHECKPOINT_PATH}/{ckpt_dir.name}\"\n            print(f\"\\nSyncing {model_name} ({ckpt_dir.name})...\")\n            subprocess.run(\n                ['rclone', 'copy', str(ckpt_dir), gdrive_path, '--progress'],\n                capture_output=False\n            )\n        else:\n            print(f\"\\n[SKIP] {model_name} checkpoint dir not found: {ckpt_dir}\")\n    \n    # Sync fold assignments\n    print(f\"\\nSyncing fold assignments...\")\n    subprocess.run(\n        ['rclone', 'copy', str(FOLD_FILE), GDRIVE_DATA_PATH, '--progress'],\n        capture_output=False\n    )\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"SYNC COMPLETE\")\n    print(\"=\"*60)\n    print(f\"\\nCheckpoints synced to: {GDRIVE_CHECKPOINT_PATH}\")\n    print(\"  - note_only/\")\n    print(\"  - note_voice/\")\n    print(\"  - note_voice_beat/\")\n    print(\"  - han/\")\n    print(f\"\\nFold assignments synced to: {GDRIVE_DATA_PATH}\")\nelse:\n    print(\"\\nrclone not available - skipping sync\")\n    print(\"Checkpoints saved locally at:\", CHECKPOINT_ROOT)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ROUND 17 COMPLETE\")\nprint(\"=\"*60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}