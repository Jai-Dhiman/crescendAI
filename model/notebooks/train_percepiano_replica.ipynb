{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PercePiano Replica Training (4-Fold Cross-Validation)\n",
    "\n",
    "Train the PercePiano replica model using 4-fold piece-based cross-validation,\n",
    "matching the methodology and hyperparameters from the PercePiano paper.\n",
    "\n",
    "## Attribution\n",
    "\n",
    "> **PercePiano: Piano Performance Evaluation Dataset with Multi-level Perceptual Features**  \n",
    "> Park, Kim et al.  \n",
    "> Nature Scientific Reports 2024  \n",
    "> Paper: https://pmc.ncbi.nlm.nih.gov/articles/PMC11450231/  \n",
    "> GitHub: https://github.com/JonghoKimSNU/PercePiano\n",
    "\n",
    "## Methodology\n",
    "\n",
    "- **Piece-based splits**: All performances of the same piece stay in the same fold\n",
    "- **4-fold CV**: Each fold takes turns as validation set\n",
    "- **Test set**: 15% of pieces held out for final evaluation\n",
    "- **Per-fold normalization**: Stats computed from training folds only\n",
    "\n",
    "## Hyperparameters (Matched to Paper's Best Results)\n",
    "\n",
    "| Parameter | Value | Notes |\n",
    "|-----------|-------|-------|\n",
    "| batch_size | 8 | Paper's best (enables proper LR scheduling) |\n",
    "| learning_rate | 5e-5 | Paper's best for Bi-LSTM+SA+HAN |\n",
    "| hidden_size | 256 | HAN encoder dimension |\n",
    "| dropout | 0.2 | Regularization |\n",
    "| max_epochs | 200 | Extended training window |\n",
    "| early_stopping_patience | 40 | More patience for convergence |\n",
    "| LR scheduler | StepLR(3000, 0.98) | Decays ~epoch 50 with batch=8 |\n",
    "\n",
    "## Expected Results\n",
    "\n",
    "- Target R2: 0.35-0.40 (matching published SOTA of 0.397)\n",
    "- Training time: ~8-12 hours on T4, ~3-5 hours on A100 (all 4 folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.14' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/Users/jdhiman/.local/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv and clone repository\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths and Check rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path('/tmp/percepiano_vnet_split')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_kfold')\n",
    "LOG_ROOT = Path('/tmp/logs/percepiano_kfold')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_vnet_split'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/percepiano_kfold'\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERCEPIANO REPLICA TRAINING (4-FOLD CV)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "\n",
    "if 'gdrive:' in result.stdout:\n",
    "    print(\"rclone 'gdrive' remote: CONFIGURED\")\n",
    "    RCLONE_AVAILABLE = True\n",
    "else:\n",
    "    print(\"rclone 'gdrive' remote: NOT CONFIGURED\")\n",
    "    print(\"Run 'rclone config' in terminal to set up Google Drive\")\n",
    "    RCLONE_AVAILABLE = False\n",
    "\n",
    "print(f\"\\nData directory: {DATA_ROOT}\")\n",
    "print(f\"Checkpoint directory: {CHECKPOINT_ROOT}\")\n",
    "print(f\"Log directory: {LOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Download Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if not RCLONE_AVAILABLE:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "# Download preprocessed data\n",
    "print(\"Downloading preprocessed VirtuosoNet features from Google Drive...\")\n",
    "subprocess.run(\n",
    "    ['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'],\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "# Verify data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_samples = 0\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = DATA_ROOT / split\n",
    "    if split_dir.exists():\n",
    "        count = len(list(split_dir.glob('*.pkl')))\n",
    "        total_samples += count\n",
    "        print(f\"  {split}: {count} samples\")\n",
    "    else:\n",
    "        print(f\"  {split}: MISSING!\")\n",
    "\n",
    "print(f\"  Total: {total_samples} samples\")\n",
    "\n",
    "stat_file = DATA_ROOT / 'stat.pkl'\n",
    "print(f\"  stat.pkl: {'present' if stat_file.exists() else 'MISSING!'}\")\n",
    "\n",
    "fold_file = DATA_ROOT / 'fold_assignments.json'\n",
    "print(f\"  fold_assignments.json: {'present' if fold_file.exists() else 'will be created'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Create Fold Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.data.kfold_split import (\n",
    "    create_piece_based_folds,\n",
    "    save_fold_assignments,\n",
    "    load_fold_assignments,\n",
    "    print_fold_statistics,\n",
    ")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'fold_assignments.json'\n",
    "N_FOLDS = 4\n",
    "TEST_RATIO = 0.15\n",
    "SEED = 42\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FOLD ASSIGNMENT CREATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create fold assignments (or load existing)\n",
    "if FOLD_FILE.exists():\n",
    "    print(f\"\\nLoading existing fold assignments from {FOLD_FILE}\")\n",
    "    fold_assignments = load_fold_assignments(FOLD_FILE)\n",
    "else:\n",
    "    print(f\"\\nCreating new {N_FOLDS}-fold piece-based splits...\")\n",
    "    fold_assignments = create_piece_based_folds(\n",
    "        data_dir=DATA_ROOT,\n",
    "        n_folds=N_FOLDS,\n",
    "        test_ratio=TEST_RATIO,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    save_fold_assignments(fold_assignments, FOLD_FILE)\n",
    "\n",
    "# Print statistics\n",
    "print_fold_statistics(fold_assignments, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "import torch\ntorch.set_float32_matmul_precision('medium')\n\n# Enable better CUDA error reporting\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n\n# PercePiano Configuration\n# Hyperparameters matched to paper's best results (Table 2, Nature Scientific Reports 2024)\n# Reference: https://pmc.ncbi.nlm.nih.gov/articles/PMC11450231/\nCONFIG = {\n    # K-Fold settings\n    'n_folds': N_FOLDS,\n    'test_ratio': TEST_RATIO,\n    \n    # Data\n    'data_dir': str(DATA_ROOT),\n    'checkpoint_dir': str(CHECKPOINT_ROOT),\n    'log_dir': str(LOG_ROOT),\n    \n    # Model input (79 normalized features, unnorm used for augmentation only)\n    'input_size': 79,\n    \n    # HAN Architecture (han_bigger256_concat.yml)\n    'hidden_size': 256,\n    'note_layers': 2,\n    'voice_layers': 2,\n    'beat_layers': 2,\n    'measure_layers': 1,\n    'num_attention_heads': 8,\n    'final_hidden': 128,\n    \n    # Training - MATCHED TO PAPER'S BEST RESULTS\n    # Paper tested lr in {5e-5, 2.5e-5} for Bi-LSTM+SA+HAN\n    'learning_rate': 5e-5,   # Paper's best (was 1e-4 default in parser.py)\n    'weight_decay': 1e-5,\n    'dropout': 0.2,\n    'batch_size': 16,        # Compromise: smaller than 32, but safer than 8\n    'max_epochs': 200,       # Increased from 100 for longer training\n    'early_stopping_patience': 40,  # Increased from 20 for more patience\n    'gradient_clip_val': 2.0,\n    'precision': '16-mixed',\n    \n    # Dataset\n    'max_notes': 1024,\n    'num_workers': 0,  # Avoid shared memory issues on Thunder Compute\n    'augment_train': True,\n}\n\nprint(\"=\"*60)\nprint(\"TRAINING CONFIGURATION\")\nprint(\"=\"*60)\nfor k, v in CONFIG.items():\n    print(f\"  {k}: {v}\")\n\n# Print training dynamics info\nsteps_per_epoch = 477 // CONFIG['batch_size']  # approximate\nlr_decay_epoch = 3000 // steps_per_epoch if steps_per_epoch > 0 else 999\nprint(f\"\\nTraining dynamics:\")\nprint(f\"  Steps per epoch (approx): {steps_per_epoch}\")\nprint(f\"  LR decay (StepLR) at epoch: ~{lr_decay_epoch}\")\nprint(f\"  LR after decay: {CONFIG['learning_rate'] * 0.98:.2e}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Initialize K-Fold Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.training.kfold_trainer import KFoldTrainer\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Set seed for reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Create K-Fold trainer\n",
    "kfold_trainer = KFoldTrainer(\n",
    "    config=CONFIG,\n",
    "    fold_assignments=fold_assignments,\n",
    "    data_dir=DATA_ROOT,\n",
    "    checkpoint_dir=CHECKPOINT_ROOT,\n",
    "    log_dir=LOG_ROOT,\n",
    "    n_folds=N_FOLDS,\n",
    ")\n",
    "\n",
    "print(\"K-Fold Trainer initialized\")\n",
    "print(f\"  Folds: {N_FOLDS}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_ROOT}\")\n",
    "print(f\"  Logs: {LOG_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Train All Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STARTING 4-FOLD CROSS-VALIDATION TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPercePiano SOTA baselines:\")\n",
    "print(\"  Bi-LSTM: R2 = 0.185\")\n",
    "print(\"  MidiBERT: R2 = 0.313\")\n",
    "print(\"  Bi-LSTM + SA + HAN: R2 = 0.397 (SOTA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train all folds\n",
    "aggregate_metrics = kfold_trainer.train_all_folds(verbose=True)\n",
    "\n",
    "# Save results\n",
    "kfold_trainer.save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync checkpoints to Google Drive after training\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(\"Syncing checkpoints to Google Drive...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    print(\"Sync complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Step 8: Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all fold models on held-out test set\n",
    "test_results = kfold_trainer.evaluate_on_test(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Step 9: Per-Fold Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PER-FOLD VALIDATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Fold':<6} {'Val R2':>10} {'Val Pearson':>12} {'Val MAE':>10} {'Val RMSE':>10} {'Epochs':>8} {'Time (s)':>10}\")\n",
    "print(f\"{'-'*6} {'-'*10} {'-'*12} {'-'*10} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "\n",
    "for m in kfold_trainer.fold_metrics:\n",
    "    print(f\"{m.fold_id:<6} {m.val_r2:>+10.4f} {m.val_pearson:>+12.4f} {m.val_mae:>10.4f} {m.val_rmse:>10.4f} {m.epochs_trained:>8} {m.training_time_seconds:>10.1f}\")\n",
    "\n",
    "print(f\"{'-'*6} {'-'*10} {'-'*12} {'-'*10} {'-'*10} {'-'*8} {'-'*10}\")\n",
    "print(f\"{'Mean':<6} {aggregate_metrics.mean_r2:>+10.4f} {aggregate_metrics.mean_pearson:>+12.4f} {aggregate_metrics.mean_mae:>10.4f} {aggregate_metrics.mean_rmse:>10.4f}\")\n",
    "print(f\"{'Std':<6} {aggregate_metrics.std_r2:>+10.4f} {aggregate_metrics.std_pearson:>+12.4f} {aggregate_metrics.std_mae:>10.4f} {aggregate_metrics.std_rmse:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## Step 10: Per-Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PER-DIMENSION R2 (Mean +/- Std across folds)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort dimensions by mean R2\n",
    "sorted_dims = sorted(\n",
    "    aggregate_metrics.per_dim_mean_r2.items(),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(f\"\\n{'Dimension':<25} {'Mean R2':>10} {'Std R2':>10} {'Status':<12}\")\n",
    "print(f\"{'-'*25} {'-'*10} {'-'*10} {'-'*12}\")\n",
    "\n",
    "for dim, mean_r2 in sorted_dims:\n",
    "    std_r2 = aggregate_metrics.per_dim_std_r2[dim]\n",
    "    \n",
    "    if mean_r2 >= 0.3:\n",
    "        status = \"[GOOD]\"\n",
    "    elif mean_r2 >= 0.1:\n",
    "        status = \"[OK]\"\n",
    "    elif mean_r2 >= 0:\n",
    "        status = \"[WEAK]\"\n",
    "    else:\n",
    "        status = \"[FAILED]\"\n",
    "    \n",
    "    print(f\"{dim:<25} {mean_r2:>+10.4f} {std_r2:>10.4f} {status:<12}\")\n",
    "\n",
    "# Summary\n",
    "positive = sum(1 for d, r in sorted_dims if r > 0)\n",
    "strong = sum(1 for d, r in sorted_dims if r >= 0.2)\n",
    "n_dims = len(sorted_dims)\n",
    "\n",
    "print(f\"\\nSummary: {positive}/{n_dims} positive R2, {strong}/{n_dims} strong (>= 0.2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Step 11: Final Summary and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cross-validation results\n",
    "print(f\"\\n4-Fold Cross-Validation Results:\")\n",
    "print(f\"  Mean R2:       {aggregate_metrics.mean_r2:.4f} +/- {aggregate_metrics.std_r2:.4f}\")\n",
    "print(f\"  Mean Pearson:  {aggregate_metrics.mean_pearson:.4f} +/- {aggregate_metrics.std_pearson:.4f}\")\n",
    "print(f\"  Mean Spearman: {aggregate_metrics.mean_spearman:.4f} +/- {aggregate_metrics.std_spearman:.4f}\")\n",
    "print(f\"  Mean MAE:      {aggregate_metrics.mean_mae:.4f} +/- {aggregate_metrics.std_mae:.4f}\")\n",
    "print(f\"  Mean RMSE:     {aggregate_metrics.mean_rmse:.4f} +/- {aggregate_metrics.std_rmse:.4f}\")\n",
    "print(f\"  Training time: {aggregate_metrics.total_training_time/60:.1f} minutes\")\n",
    "\n",
    "# Test set results\n",
    "print(f\"\\nTest Set (Ensemble of 4 models):\")\n",
    "print(f\"  R2:       {test_results['ensemble']['r2']:.4f}\")\n",
    "print(f\"  Pearson:  {test_results['ensemble']['pearson']:.4f}\")\n",
    "print(f\"  Spearman: {test_results['ensemble']['spearman']:.4f}\")\n",
    "print(f\"  MAE:      {test_results['ensemble']['mae']:.4f}\")\n",
    "print(f\"  RMSE:     {test_results['ensemble']['rmse']:.4f}\")\n",
    "\n",
    "# Comparison to baselines\n",
    "print(f\"\\nComparison to PercePiano baselines:\")\n",
    "print(f\"  Bi-LSTM:      R2 = 0.185\")\n",
    "print(f\"  MidiBERT:     R2 = 0.313\")\n",
    "print(f\"  HAN SOTA:     R2 = 0.397\")\n",
    "print(f\"  Ours (CV):    R2 = {aggregate_metrics.mean_r2:.3f} +/- {aggregate_metrics.std_r2:.3f}\")\n",
    "print(f\"  Ours (Test):  R2 = {test_results['ensemble']['r2']:.3f}\")\n",
    "\n",
    "# Interpretation\n",
    "cv_r2 = aggregate_metrics.mean_r2\n",
    "test_r2 = test_results['ensemble']['r2']\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "if cv_r2 >= 0.35:\n",
    "    print(f\"  [EXCELLENT] CV R2 >= 0.35 matches published SOTA!\")\n",
    "elif cv_r2 >= 0.25:\n",
    "    print(f\"  [GOOD] CV R2 >= 0.25 is usable for pseudo-labeling\")\n",
    "elif cv_r2 >= 0.10:\n",
    "    print(f\"  [FAIR] CV R2 >= 0.10 shows learning, needs improvement\")\n",
    "else:\n",
    "    print(f\"  [NEEDS WORK] CV R2 < 0.10, significant improvement needed\")\n",
    "\n",
    "# Save ensemble model if good enough\n",
    "if cv_r2 >= 0.25:\n",
    "    print(f\"\\nModel qualifies for pseudo-labeling MAESTRO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sync to Google Drive\n",
    "print(\"=\"*60)\n",
    "print(\"SYNC TO GOOGLE DRIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(f\"\\nSyncing all checkpoints and results...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    # Also sync fold assignments back to data directory\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(FOLD_FILE), GDRIVE_DATA_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSync complete!\")\n",
    "    print(f\"  Checkpoints: {GDRIVE_CHECKPOINT_PATH}\")\n",
    "    print(f\"  Fold assignments: {GDRIVE_DATA_PATH}\")\n",
    "else:\n",
    "    print(f\"\\nrclone not available - skipping sync\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}