{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PercePiano Replica Training - Phase 2 Incremental Build\n",
    "\n",
    "Incremental approach to isolate hierarchy contribution:\n",
    "```\n",
    "VirtuosoNetSingle (7-layer flat)     -> R2 = 0.19 (validated)\n",
    "    + Beat hierarchy                  -> R2 = ??? (target: ~0.25-0.30)\n",
    "    + Measure hierarchy               -> R2 = ??? (target: ~0.35-0.40)\n",
    "Full HAN (VirtuosoNetMultiLevel)     -> R2 = 0.40 (SOTA target)\n",
    "```\n",
    "\n",
    "## Model Types\n",
    "| Model | Architecture | Expected R2 |\n",
    "|-------|-------------|-------------|\n",
    "| `baseline` | 7-layer BiLSTM | ~0.19 |\n",
    "| `baseline_beat` | 7-layer BiLSTM + Beat hierarchy | ~0.25-0.30 |\n",
    "| `baseline_beat_measure` | 7-layer BiLSTM + Beat + Measure | ~0.35-0.40 |\n",
    "| `han` | Full HAN (note+voice+beat+measure) | ~0.40 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv and clone repository\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\"\n",
    "\n",
    "# Clone repository\n",
    "if not os.path.exists('/tmp/crescendai'):\n",
    "    !git clone https://github.com/Jai-Dhiman/crescendai.git /tmp/crescendai\n",
    "\n",
    "%cd /tmp/crescendai/model\n",
    "!git pull\n",
    "!git log -1 --oneline\n",
    "\n",
    "# Install dependencies\n",
    "!uv pip install --system -e .\n",
    "!pip install tensorboard rich\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "print(f\"\\nPyTorch: {torch.__version__}\")\n",
    "print(f\"Lightning: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path('/tmp/percepiano_vnet_84dim')\n",
    "CHECKPOINT_ROOT = Path('/tmp/checkpoints/percepiano_kfold')\n",
    "LOG_ROOT = Path('/tmp/logs/percepiano_kfold')\n",
    "GDRIVE_DATA_PATH = 'gdrive:crescendai_data/percepiano_vnet_84dim'\n",
    "GDRIVE_CHECKPOINT_PATH = 'gdrive:crescendai_checkpoints/percepiano_kfold'\n",
    "\n",
    "# Training control\n",
    "RESTART_TRAINING = True  # Set to True to clear checkpoints and start fresh\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERCEPIANO REPLICA TRAINING - PHASE 2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Clear checkpoints if restarting\n",
    "if RESTART_TRAINING and CHECKPOINT_ROOT.exists():\n",
    "    print(f\"\\nRESTART_TRAINING=True: Clearing checkpoints\")\n",
    "    shutil.rmtree(CHECKPOINT_ROOT)\n",
    "\n",
    "if RESTART_TRAINING and LOG_ROOT.exists():\n",
    "    shutil.rmtree(LOG_ROOT)\n",
    "\n",
    "# Create directories\n",
    "CHECKPOINT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "LOG_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "RCLONE_AVAILABLE = 'gdrive:' in result.stdout\n",
    "print(f\"\\nrclone gdrive: {'CONFIGURED' if RCLONE_AVAILABLE else 'NOT CONFIGURED'}\")\n",
    "print(f\"Data: {DATA_ROOT}\")\n",
    "print(f\"Checkpoints: {CHECKPOINT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 3: Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RCLONE_AVAILABLE:\n",
    "    raise RuntimeError(\"rclone not configured. Run 'rclone config' first.\")\n",
    "\n",
    "print(\"Downloading data from Google Drive...\")\n",
    "subprocess.run(['rclone', 'copy', GDRIVE_DATA_PATH, str(DATA_ROOT), '--progress'], capture_output=False)\n",
    "\n",
    "# Verify\n",
    "total = sum(1 for _ in DATA_ROOT.glob('**/*.pkl'))\n",
    "print(f\"\\nTotal samples: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Create Fold Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.data.kfold_split import (\n",
    "    create_piece_based_folds,\n",
    "    save_fold_assignments,\n",
    "    load_fold_assignments,\n",
    "    print_fold_statistics,\n",
    ")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'fold_assignments.json'\n",
    "N_FOLDS = 4\n",
    "SEED = 42\n",
    "\n",
    "if FOLD_FILE.exists():\n",
    "    fold_assignments = load_fold_assignments(FOLD_FILE)\n",
    "    print(\"Loaded existing fold assignments\")\n",
    "else:\n",
    "    fold_assignments = create_piece_based_folds(DATA_ROOT, N_FOLDS, test_ratio=0.15, seed=SEED)\n",
    "    save_fold_assignments(fold_assignments, FOLD_FILE)\n",
    "    print(\"Created new fold assignments\")\n",
    "\n",
    "print_fold_statistics(fold_assignments, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from src.percepiano.training.kfold_trainer import (\n",
    "    MODEL_TYPE_BASELINE,\n",
    "    MODEL_TYPE_BASELINE_BEAT,\n",
    "    MODEL_TYPE_BASELINE_BEAT_MEASURE,\n",
    "    MODEL_TYPE_HAN,\n",
    ")\n",
    "\n",
    "CONFIG = {\n",
    "    'n_folds': N_FOLDS,\n",
    "    'test_ratio': 0.15,\n",
    "    'data_dir': str(DATA_ROOT),\n",
    "    'checkpoint_dir': str(CHECKPOINT_ROOT),\n",
    "    'log_dir': str(LOG_ROOT),\n",
    "    'input_size': 79,\n",
    "    'hidden_size': 256,\n",
    "    'note_layers': 2,\n",
    "    'voice_layers': 2,\n",
    "    'beat_layers': 2,\n",
    "    'measure_layers': 1,\n",
    "    'num_attention_heads': 8,\n",
    "    'learning_rate': 2.5e-5,\n",
    "    'weight_decay': 1e-5,\n",
    "    'dropout': 0.2,\n",
    "    'batch_size': 8,\n",
    "    'max_epochs': 200,\n",
    "    'early_stopping_patience': 20,\n",
    "    'gradient_clip_val': 2.0,\n",
    "    'precision': '32',\n",
    "    'max_notes': 5000,\n",
    "    'slice_len': 5000,\n",
    "    'num_workers': 4,\n",
    "    'augment_train': False,\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 2 MODEL TYPES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  {MODEL_TYPE_BASELINE:<25} 7-layer BiLSTM (expected R2 ~0.19)\")\n",
    "print(f\"  {MODEL_TYPE_BASELINE_BEAT:<25} + Beat hierarchy (expected R2 ~0.25-0.30)\")\n",
    "print(f\"  {MODEL_TYPE_BASELINE_BEAT_MEASURE:<25} + Measure hierarchy (expected R2 ~0.35-0.40)\")\n",
    "print(f\"  {MODEL_TYPE_HAN:<25} Full HAN (expected R2 ~0.40)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Pre-Training Data Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from src.percepiano.data.percepiano_vnet_dataset import PercePianoKFoldDataset\n",
    "from src.percepiano.training.diagnostics import analyze_indices\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PRE-TRAINING DATA DIAGNOSTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_ds = PercePianoKFoldDataset(\n",
    "    data_dir=DATA_ROOT, fold_assignments=fold_assignments, fold_id=0, mode=\"train\",\n",
    "    max_notes=CONFIG['max_notes'], slice_len=CONFIG['slice_len'],\n",
    ")\n",
    "batch = next(iter(DataLoader(test_ds, batch_size=4, shuffle=False)))\n",
    "\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"  input_features: {batch['input_features'].shape}\")\n",
    "print(f\"  beat indices: {batch['note_locations_beat'].shape}\")\n",
    "print(f\"  measure indices: {batch['note_locations_measure'].shape}\")\n",
    "\n",
    "idx_stats = analyze_indices(batch['note_locations_beat'], batch['note_locations_measure'])\n",
    "print(f\"\\nIndex analysis:\")\n",
    "print(f\"  Beat range: [{idx_stats['beat_min']}, {idx_stats['beat_max']}]\")\n",
    "print(f\"  Measure range: [{idx_stats['measure_min']}, {idx_stats['measure_max']}]\")\n",
    "\n",
    "issues = []\n",
    "if idx_stats['beat_min'] != 1:\n",
    "    issues.append(f\"Beat indices start from {idx_stats['beat_min']} (expected 1)\")\n",
    "if idx_stats['negative_beat_count'] > 0:\n",
    "    issues.append(f\"{idx_stats['negative_beat_count']} negative zero-shifted beat values\")\n",
    "\n",
    "if issues:\n",
    "    print(f\"\\n[ISSUES FOUND]\")\n",
    "    for issue in issues:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(f\"\\n[OK] Data pipeline looks correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Train Model\n",
    "\n",
    "Select model type and folds to train below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.percepiano.training.kfold_trainer import KFoldTrainer\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "#############################################\n",
    "# CONFIGURE TRAINING HERE\n",
    "#############################################\n",
    "MODEL_TYPE = MODEL_TYPE_BASELINE_BEAT  # Choose: baseline, baseline_beat, baseline_beat_measure, han\n",
    "FOLDS_TO_TRAIN = [2]  # Train fold 2 first (best fold - longest pieces)\n",
    "#############################################\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"TRAINING: {MODEL_TYPE}\")\n",
    "print(f\"FOLDS: {FOLDS_TO_TRAIN}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainer = KFoldTrainer(\n",
    "    config=CONFIG,\n",
    "    fold_assignments=fold_assignments,\n",
    "    data_dir=DATA_ROOT,\n",
    "    checkpoint_dir=CHECKPOINT_ROOT,\n",
    "    log_dir=LOG_ROOT,\n",
    "    n_folds=N_FOLDS,\n",
    "    model_type=MODEL_TYPE,\n",
    ")\n",
    "\n",
    "for fold_id in FOLDS_TO_TRAIN:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    metrics = trainer.train_fold(fold_id=fold_id, verbose=True, resume_from_checkpoint=False)\n",
    "    print(f\"\\nFold {fold_id} Best Val R2: {metrics.val_r2:+.4f}\")\n",
    "\n",
    "trainer.save_results()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "agg = trainer._compute_aggregate_metrics()\n",
    "print(f\"\\n  Mean R2: {agg.mean_r2:+.4f}\")\n",
    "print(f\"  Std R2:  {agg.std_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Step 8: Post-Training Analysis\n",
    "\n",
    "Copy/paste these results for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "POST-TRAINING ANALYSIS - COPY RESULTS FROM HERE\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from torch.nn.utils.rnn import PackedSequence\n",
    "\n",
    "from src.percepiano.data.percepiano_vnet_dataset import (\n",
    "    PercePianoKFoldDataset,\n",
    "    percepiano_pack_collate,\n",
    ")\n",
    "from src.percepiano.models.percepiano_replica import PERCEPIANO_DIMENSIONS\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"POST-TRAINING ANALYSIS: {MODEL_TYPE}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Get trained model\n",
    "model = None\n",
    "best_fold = FOLDS_TO_TRAIN[-1] if FOLDS_TO_TRAIN else 2\n",
    "\n",
    "# Try to get from trainer\n",
    "if 'trainer' in dir():\n",
    "    model = trainer.get_trained_model(best_fold)\n",
    "    if model:\n",
    "        model = model.to(device).eval()\n",
    "\n",
    "if model is None:\n",
    "    print(\"\\n[ERROR] No model available. Run training first.\")\n",
    "else:\n",
    "    # Create validation dataloader\n",
    "    val_ds = PercePianoKFoldDataset(\n",
    "        data_dir=DATA_ROOT, fold_assignments=fold_assignments, fold_id=best_fold,\n",
    "        mode=\"val\", max_notes=CONFIG['max_notes'], slice_len=CONFIG['slice_len'],\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=4, shuffle=False, num_workers=0, collate_fn=percepiano_pack_collate,\n",
    "    )\n",
    "    \n",
    "    # Collect predictions\n",
    "    all_preds, all_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch_on_device = {}\n",
    "            for k, v in batch.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    batch_on_device[k] = v.to(device)\n",
    "                elif isinstance(v, PackedSequence):\n",
    "                    batch_on_device[k] = PackedSequence(\n",
    "                        v.data.to(device), v.batch_sizes,\n",
    "                        v.sorted_indices.to(device) if v.sorted_indices is not None else None,\n",
    "                        v.unsorted_indices.to(device) if v.unsorted_indices is not None else None,\n",
    "                    )\n",
    "                else:\n",
    "                    batch_on_device[k] = v\n",
    "            \n",
    "            note_locations = {\n",
    "                'beat': batch_on_device['note_locations_beat'],\n",
    "                'measure': batch_on_device['note_locations_measure'],\n",
    "                'voice': batch_on_device['note_locations_voice'],\n",
    "            }\n",
    "            \n",
    "            outputs = model(\n",
    "                batch_on_device['input_features'], note_locations,\n",
    "                batch_on_device.get('attention_mask'), batch_on_device.get('lengths'),\n",
    "            )\n",
    "            all_preds.append(outputs['predictions'].cpu())\n",
    "            all_targets.append(batch_on_device['scores'].cpu())\n",
    "    \n",
    "    preds = torch.cat(all_preds).numpy()\n",
    "    targets = torch.cat(all_targets).numpy()\n",
    "    \n",
    "    # Overall metrics\n",
    "    r2 = r2_score(targets, preds)\n",
    "    pearson = np.mean([pearsonr(targets[:, i], preds[:, i])[0] for i in range(19)])\n",
    "    mae = np.mean(np.abs(targets - preds))\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"FOLD {best_fold} RESULTS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n  Model:   {MODEL_TYPE}\")\n",
    "    print(f\"  R2:      {r2:+.4f}\")\n",
    "    print(f\"  Pearson: {pearson:+.4f}\")\n",
    "    print(f\"  MAE:     {mae:.4f}\")\n",
    "    \n",
    "    # Prediction health\n",
    "    pred_std = preds.std()\n",
    "    target_std = targets.std()\n",
    "    print(f\"\\n  Prediction std: {pred_std:.4f} (target: {target_std:.4f})\")\n",
    "    if pred_std < target_std * 0.5:\n",
    "        print(f\"  [WARN] Prediction collapse detected!\")\n",
    "    \n",
    "    # Per-dimension R2\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"PER-DIMENSION R2\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    dim_r2s = [(dim, r2_score(targets[:, i], preds[:, i])) for i, dim in enumerate(PERCEPIANO_DIMENSIONS)]\n",
    "    dim_r2s.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n  {'Dimension':<30} {'R2':>10} {'Status':>10}\")\n",
    "    print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n",
    "    for dim, dim_r2 in dim_r2s:\n",
    "        status = \"[GOOD]\" if dim_r2 >= 0.3 else \"[OK]\" if dim_r2 >= 0.1 else \"[WEAK]\" if dim_r2 >= 0 else \"[NEG]\"\n",
    "        print(f\"  {dim:<30} {dim_r2:>+10.4f} {status:>10}\")\n",
    "    \n",
    "    positive_dims = sum(1 for _, r2 in dim_r2s if r2 > 0)\n",
    "    print(f\"\\n  Positive R2: {positive_dims}/19\")\n",
    "    \n",
    "    # Hierarchy diagnostics (for models with hierarchy)\n",
    "    if hasattr(model, 'beat_attention'):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"HIERARCHY DIAGNOSTICS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Run one batch with diagnose=True\n",
    "        batch = next(iter(val_loader))\n",
    "        batch_on_device = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        if isinstance(batch_on_device['input_features'], PackedSequence):\n",
    "            batch_on_device['input_features'] = PackedSequence(\n",
    "                batch['input_features'].data.to(device),\n",
    "                batch['input_features'].batch_sizes,\n",
    "                batch['input_features'].sorted_indices.to(device) if batch['input_features'].sorted_indices is not None else None,\n",
    "                batch['input_features'].unsorted_indices.to(device) if batch['input_features'].unsorted_indices is not None else None,\n",
    "            )\n",
    "        \n",
    "        note_locations = {\n",
    "            'beat': batch_on_device['note_locations_beat'],\n",
    "            'measure': batch_on_device['note_locations_measure'],\n",
    "            'voice': batch_on_device['note_locations_voice'],\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _ = model(batch_on_device['input_features'], note_locations, diagnose=True)\n",
    "        \n",
    "        # Contractor weight analysis\n",
    "        if hasattr(model, 'note_contractor'):\n",
    "            w = model.note_contractor.weight.data\n",
    "            if w.shape[1] == 1024:  # baseline_beat\n",
    "                lstm_w = w[:, :512].abs().mean().item()\n",
    "                beat_w = w[:, 512:].abs().mean().item()\n",
    "                print(f\"\\n  Contractor weights:\")\n",
    "                print(f\"    LSTM branch:  {lstm_w:.4f}\")\n",
    "                print(f\"    Beat branch:  {beat_w:.4f}\")\n",
    "                print(f\"    Ratio (Beat/LSTM): {beat_w/lstm_w:.2f}x\")\n",
    "                if beat_w < lstm_w * 0.1:\n",
    "                    print(f\"    [WARN] Contractor may be ignoring beat branch!\")\n",
    "            elif w.shape[1] == 1536:  # baseline_beat_measure\n",
    "                lstm_w = w[:, :512].abs().mean().item()\n",
    "                beat_w = w[:, 512:1024].abs().mean().item()\n",
    "                meas_w = w[:, 1024:].abs().mean().item()\n",
    "                print(f\"\\n  Contractor weights:\")\n",
    "                print(f\"    LSTM branch:    {lstm_w:.4f}\")\n",
    "                print(f\"    Beat branch:    {beat_w:.4f}\")\n",
    "                print(f\"    Measure branch: {meas_w:.4f}\")\n",
    "    \n",
    "    # Comparison to baseline\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"COMPARISON TO BASELINE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    baseline_r2 = 0.1931  # Validated baseline R2 on fold 2\n",
    "    hierarchy_gain = r2 - baseline_r2\n",
    "    \n",
    "    print(f\"\\n  {'Model':<30} {'R2':>10} {'Expected':>10}\")\n",
    "    print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n",
    "    print(f\"  {'Baseline (7-layer BiLSTM)':<30} {'+0.1931':>10} {'~0.19':>10}\")\n",
    "    print(f\"  {MODEL_TYPE:<30} {r2:>+10.4f} \", end=\"\")\n",
    "    \n",
    "    if MODEL_TYPE == MODEL_TYPE_BASELINE_BEAT:\n",
    "        print(f\"{'~0.25-0.30':>10}\")\n",
    "    elif MODEL_TYPE == MODEL_TYPE_BASELINE_BEAT_MEASURE:\n",
    "        print(f\"{'~0.35-0.40':>10}\")\n",
    "    elif MODEL_TYPE == MODEL_TYPE_HAN:\n",
    "        print(f\"{'~0.40':>10}\")\n",
    "    else:\n",
    "        print(f\"{'~0.19':>10}\")\n",
    "    \n",
    "    print(f\"  {'-'*30} {'-'*10} {'-'*10}\")\n",
    "    print(f\"  {'Hierarchy Gain':<30} {hierarchy_gain:>+10.4f}\")\n",
    "    \n",
    "    if hierarchy_gain > 0.15:\n",
    "        print(f\"\\n  [GOOD] Significant hierarchy contribution!\")\n",
    "    elif hierarchy_gain > 0.05:\n",
    "        print(f\"\\n  [PARTIAL] Some hierarchy contribution\")\n",
    "    elif hierarchy_gain > 0:\n",
    "        print(f\"\\n  [WEAK] Minimal hierarchy contribution\")\n",
    "    else:\n",
    "        print(f\"\\n  [NONE] No hierarchy contribution (may be hurting)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Step 9: Test Set Evaluation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if you trained all folds and want to evaluate on test set\n",
    "if len(FOLDS_TO_TRAIN) == 4:\n",
    "    print(\"=\"*60)\n",
    "    print(\"TEST SET EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    test_results = trainer.evaluate_on_test(verbose=True)\n",
    "else:\n",
    "    print(f\"Skipping test evaluation (trained {len(FOLDS_TO_TRAIN)} folds, need 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Step 10: Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SYNC TO GOOGLE DRIVE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if RCLONE_AVAILABLE:\n",
    "    print(f\"\\nSyncing checkpoints...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(CHECKPOINT_ROOT), GDRIVE_CHECKPOINT_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSyncing fold assignments...\")\n",
    "    subprocess.run(\n",
    "        ['rclone', 'copy', str(FOLD_FILE), GDRIVE_DATA_PATH, '--progress'],\n",
    "        capture_output=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSync complete!\")\n",
    "    print(f\"  Checkpoints: {GDRIVE_CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(\"rclone not available - skipping sync\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DONE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
