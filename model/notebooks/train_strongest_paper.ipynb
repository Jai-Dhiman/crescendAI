{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Strongest Paper Experiments for ISMIR 2026\n",
    "\n",
    "This notebook contains all experiments needed to make the strongest possible paper for ISMIR 2026 submission.\n",
    "\n",
    "## Experiment Overview\n",
    "\n",
    "### TIER 1: MUST-DO (Critical for acceptance)\n",
    "- **Part 1: Multi-Seed Stability** - Validate M1c_muq_L9-12 R2=0.533 is stable across seeds {42, 123, 456, 789, 1337}\n",
    "- **Part 2: Stratified Fold Redistribution** - Fix fold imbalance to reduce variance\n",
    "- **Part 3: Complete D7/D9a JSONs** - Update incomplete experiment results with all 4 folds\n",
    "\n",
    "### TIER 2: SHOULD-DO (Strengthen significantly)\n",
    "- **Part 4: Pianoteq Soundfont Augmentation** - Test timbre-invariance with multiple piano sounds\n",
    "- **Part 5: MAESTRO Cross-Dataset Analysis** - Zero-shot transfer to external dataset\n",
    "\n",
    "### TIER 3: NICE-TO-HAVE (Polish and depth)\n",
    "- **Part 6: Error Analysis** - Per-composer breakdown, extreme labels, segment position\n",
    "- **Part 7: Additional Ablations** - MLP depth, batch size, frame length\n",
    "- **Part 8: Final Summary** - Generate paper-ready tables and figures\n",
    "\n",
    "## Requirements\n",
    "- **Compute**: Thunder Compute A100 (80GB VRAM)\n",
    "- **Storage**: rclone configured with `gdrive:` remote\n",
    "- **Optional**: Pianoteq Standard (~$100) for soundfont augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: CUDA setup (must be before any CUDA operations)\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    raise RuntimeError(\"GPU required for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install rclone\n",
    "!curl -fsSL https://rclone.org/install.sh | sudo bash 2>&1 | grep -E \"(successfully|already)\" || echo \"rclone installed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Install dependencies and clone repo\n",
    "!pip install transformers librosa soundfile pytorch_lightning nnAudio scipy scikit-learn muq requests tqdm --quiet\n",
    "\n",
    "import os\n",
    "REPO_DIR = '/tmp/crescendai'\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !cd {REPO_DIR} && git pull origin main\n",
    "else:\n",
    "    !git clone https://github.com/jai-dhiman/crescendai.git {REPO_DIR}\n",
    "\n",
    "print(f\"Repo: {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Imports\n",
    "import sys\n",
    "sys.path.insert(0, f'{REPO_DIR}/model/src')\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from audio_experiments import PERCEPIANO_DIMENSIONS, DIMENSION_CATEGORIES, BASE_CONFIG, SEED\n",
    "from audio_experiments.extractors import extract_muq_embeddings, MuQExtractor\n",
    "from audio_experiments.models import MuQStatsModel, StatsPoolingModel\n",
    "from audio_experiments.data import MERTDataset, mert_collate_fn\n",
    "from audio_experiments.training import (\n",
    "    run_4fold_mert_experiment,\n",
    "    should_run_experiment,\n",
    "    sync_experiment_to_gdrive,\n",
    "    get_completed_experiments,\n",
    "    print_experiment_status,\n",
    "    bootstrap_r2_extended,\n",
    "    compute_comprehensive_metrics,\n",
    ")\n",
    "from audio_experiments.training.sync import numpy_serializer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Imports: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Path configuration\n",
    "DATA_ROOT = Path('/tmp/strongest_paper_experiments')\n",
    "AUDIO_DIR = DATA_ROOT / 'audio'\n",
    "LABEL_DIR = DATA_ROOT / 'labels'\n",
    "MUQ_CACHE_ROOT = DATA_ROOT / 'muq_cache'\n",
    "CHECKPOINT_ROOT = DATA_ROOT / 'checkpoints'\n",
    "RESULTS_DIR = DATA_ROOT / 'results'\n",
    "LOG_DIR = DATA_ROOT / 'logs'\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "\n",
    "# Cross-dataset directories\n",
    "MAESTRO_DIR = DATA_ROOT / 'maestro'\n",
    "\n",
    "# GDrive paths\n",
    "GDRIVE_AUDIO = 'gdrive:crescendai_data/audio_baseline/percepiano_rendered'\n",
    "GDRIVE_LABELS = 'gdrive:crescendai_data/percepiano_labels'\n",
    "GDRIVE_FOLDS = 'gdrive:crescendai_data/percepiano_fold_assignments.json'\n",
    "GDRIVE_MUQ_CACHE = 'gdrive:crescendai_data/audio_baseline/muq_embeddings'\n",
    "GDRIVE_PHASE2_RESULTS = 'gdrive:crescendai_data/checkpoints/audio_phase2'\n",
    "GDRIVE_RESULTS = 'gdrive:crescendai_data/checkpoints/strongest_paper'\n",
    "\n",
    "for d in [AUDIO_DIR, LABEL_DIR, MUQ_CACHE_ROOT, CHECKPOINT_ROOT,\n",
    "          RESULTS_DIR, LOG_DIR, FIGURES_DIR, MAESTRO_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_rclone(cmd, desc=\"\"):\n",
    "    \"\"\"Run rclone command with error handling.\"\"\"\n",
    "    if desc:\n",
    "        print(f\"{desc}...\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"rclone failed: {desc}\\nCommand: {' '.join(cmd)}\\nStderr: {result.stderr}\")\n",
    "    return result\n",
    "\n",
    "# Check rclone\n",
    "result = subprocess.run(['rclone', 'listremotes'], capture_output=True, text=True)\n",
    "if 'gdrive:' not in result.stdout:\n",
    "    raise RuntimeError(\"rclone 'gdrive' not configured\")\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"GDrive results: {GDRIVE_RESULTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Download data\n",
    "run_rclone(['rclone', 'copy', GDRIVE_AUDIO, str(AUDIO_DIR), '--progress'], \"Downloading audio\")\n",
    "run_rclone(['rclone', 'copy', GDRIVE_LABELS, str(LABEL_DIR)], \"Downloading labels\")\n",
    "\n",
    "FOLD_FILE = DATA_ROOT / 'folds.json'\n",
    "run_rclone(['rclone', 'copyto', GDRIVE_FOLDS, str(FOLD_FILE)], \"Downloading folds\")\n",
    "\n",
    "# Load labels and folds\n",
    "LABEL_FILE = LABEL_DIR / 'label_2round_mean_reg_19_with0_rm_highstd0.json'\n",
    "with open(LABEL_FILE) as f:\n",
    "    LABELS = json.load(f)\n",
    "with open(FOLD_FILE) as f:\n",
    "    FOLD_ASSIGNMENTS = json.load(f)\n",
    "\n",
    "# Create key->fold_id mapping\n",
    "FOLD_BY_KEY = {}\n",
    "for fold_id in range(4):\n",
    "    for key in FOLD_ASSIGNMENTS.get(f\"fold_{fold_id}\", []):\n",
    "        FOLD_BY_KEY[key] = fold_id\n",
    "\n",
    "ALL_KEYS = sorted(FOLD_BY_KEY.keys())\n",
    "print(f\"Samples per fold: {[len(FOLD_ASSIGNMENTS.get(f'fold_{i}', [])) for i in range(4)]}\")\n",
    "print(f\"Total samples: {len(ALL_KEYS)}\")\n",
    "print(f\"Audio files: {len(list(AUDIO_DIR.glob('*.wav')))}\")\n",
    "\n",
    "# Initialize results tracking\n",
    "ALL_RESULTS = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vddl8g5ay0d",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Multi-Seed Stability Analysis (TIER 1)\n",
    "\n",
    "**Goal**: Validate that M1c_muq_L9-12 R2=0.533 is not a lucky seed result.\n",
    "\n",
    "**Method**: Run with seeds {42, 123, 456, 789, 1337} and report mean +/- std across seeds.\n",
    "\n",
    "**Success Criteria**: std < 0.015 across seeds demonstrates robust, reproducible results.\n",
    "\n",
    "**GPU Hours**: ~40 (8 hours x 5 seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1crjxp91bp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Download MuQ L9-12 embeddings\n",
    "MUQ_L9_12_DIR = MUQ_CACHE_ROOT / 'L9-12'\n",
    "MUQ_L9_12_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GDRIVE_MUQ_L9_12 = 'gdrive:crescendai_data/audio_baseline/muq_embeddings/L9-12'\n",
    "\n",
    "# Try to download cached embeddings\n",
    "result = subprocess.run(['rclone', 'lsf', GDRIVE_MUQ_L9_12], capture_output=True, text=True)\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    print(\"Downloading cached MuQ L9-12 embeddings...\")\n",
    "    run_rclone(['rclone', 'copy', GDRIVE_MUQ_L9_12, str(MUQ_L9_12_DIR), '--progress'],\n",
    "               \"Downloading MuQ L9-12 embeddings\")\n",
    "else:\n",
    "    print(\"No cached MuQ L9-12 embeddings found. Will extract from audio.\")\n",
    "\n",
    "# Check what we have\n",
    "cached_keys = {p.stem for p in MUQ_L9_12_DIR.glob('*.pt')}\n",
    "missing_keys = [k for k in ALL_KEYS if k not in cached_keys]\n",
    "print(f\"MuQ L9-12 Cached: {len(cached_keys)}, Missing: {len(missing_keys)}\")\n",
    "\n",
    "# Extract missing embeddings\n",
    "if missing_keys:\n",
    "    print(f\"\\nExtracting {len(missing_keys)} MuQ L9-12 embeddings...\")\n",
    "    extract_muq_embeddings(AUDIO_DIR, MUQ_L9_12_DIR, missing_keys, layer_start=9, layer_end=13)\n",
    "    \n",
    "    # Upload newly extracted embeddings\n",
    "    print(\"\\nUploading MuQ L9-12 embeddings to GDrive...\")\n",
    "    run_rclone(['rclone', 'copy', str(MUQ_L9_12_DIR), GDRIVE_MUQ_L9_12],\n",
    "               \"Uploading MuQ L9-12 embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kipoivwu3t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Define seeds and model configuration for multi-seed stability\n",
    "STABILITY_SEEDS = [42, 123, 456, 789, 1337]\n",
    "\n",
    "# M1c_muq_L9-12 configuration (best performing model)\n",
    "M1C_CONFIG = {\n",
    "    **BASE_CONFIG,\n",
    "    'input_dim': 1024,\n",
    "    'hidden_dim': 512,\n",
    "    'dropout': 0.2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'pooling_stats': 'mean_std',\n",
    "}\n",
    "\n",
    "def make_muq_stats_model(cfg):\n",
    "    \"\"\"Factory function for MuQ stats model.\"\"\"\n",
    "    return MuQStatsModel(\n",
    "        input_dim=cfg['input_dim'],\n",
    "        hidden_dim=cfg['hidden_dim'],\n",
    "        dropout=cfg['dropout'],\n",
    "        learning_rate=cfg['learning_rate'],\n",
    "        weight_decay=cfg['weight_decay'],\n",
    "        pooling_stats=cfg['pooling_stats'],\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "    )\n",
    "\n",
    "print(f\"Seeds to test: {STABILITY_SEEDS}\")\n",
    "print(f\"Configuration: hidden_dim={M1C_CONFIG['hidden_dim']}, lr={M1C_CONFIG['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r76rzamzom8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Training loop for 5 seeds x 4 folds\n",
    "exp_id = 'multi_seed_stability'\n",
    "exp_checkpoint_dir = CHECKPOINT_ROOT / exp_id\n",
    "exp_checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "seed_results = {}\n",
    "\n",
    "for seed in STABILITY_SEEDS:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"SEED {seed}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Set all random seeds\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    seed_dir = exp_checkpoint_dir / f\"seed_{seed}\"\n",
    "    seed_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    fold_r2_scores = {}\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for fold in range(4):\n",
    "        ckpt_path = seed_dir / f\"fold{fold}_best.ckpt\"\n",
    "        \n",
    "        # Check if already trained\n",
    "        if ckpt_path.exists():\n",
    "            print(f\"  Fold {fold}: Loading existing checkpoint\")\n",
    "            model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "        else:\n",
    "            # Create datasets\n",
    "            train_ds = MERTDataset(\n",
    "                MUQ_L9_12_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"train\", M1C_CONFIG[\"max_frames\"]\n",
    "            )\n",
    "            val_ds = MERTDataset(\n",
    "                MUQ_L9_12_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"val\", M1C_CONFIG[\"max_frames\"]\n",
    "            )\n",
    "            \n",
    "            print(f\"  Fold {fold}: Training ({len(train_ds)} train, {len(val_ds)} val)\")\n",
    "            \n",
    "            train_dl = DataLoader(\n",
    "                train_ds, batch_size=M1C_CONFIG[\"batch_size\"], shuffle=True,\n",
    "                collate_fn=mert_collate_fn, num_workers=M1C_CONFIG[\"num_workers\"], pin_memory=True,\n",
    "            )\n",
    "            val_dl = DataLoader(\n",
    "                val_ds, batch_size=M1C_CONFIG[\"batch_size\"], shuffle=False,\n",
    "                collate_fn=mert_collate_fn, num_workers=M1C_CONFIG[\"num_workers\"], pin_memory=True,\n",
    "            )\n",
    "            \n",
    "            model = make_muq_stats_model(M1C_CONFIG)\n",
    "            \n",
    "            callbacks = [\n",
    "                ModelCheckpoint(\n",
    "                    dirpath=seed_dir, filename=f\"fold{fold}_best\",\n",
    "                    monitor=\"val_r2\", mode=\"max\", save_top_k=1,\n",
    "                ),\n",
    "                EarlyStopping(\n",
    "                    monitor=\"val_r2\", mode=\"max\", patience=M1C_CONFIG[\"patience\"], verbose=False\n",
    "                ),\n",
    "            ]\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=M1C_CONFIG[\"max_epochs\"],\n",
    "                callbacks=callbacks,\n",
    "                logger=CSVLogger(save_dir=LOG_DIR, name=f\"{exp_id}_seed{seed}\", version=f\"fold{fold}\"),\n",
    "                accelerator=\"auto\", devices=1,\n",
    "                gradient_clip_val=M1C_CONFIG[\"gradient_clip_val\"],\n",
    "                enable_progress_bar=True, deterministic=True, log_every_n_steps=10,\n",
    "            )\n",
    "            \n",
    "            trainer.fit(model, train_dl, val_dl)\n",
    "            fold_r2_scores[fold] = float(callbacks[0].best_model_score or 0)\n",
    "            print(f\"    Fold {fold} complete: val_r2 = {fold_r2_scores[fold]:.4f}\")\n",
    "            \n",
    "            # Reload best\n",
    "            model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_ds = MERTDataset(\n",
    "            MUQ_L9_12_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"val\", M1C_CONFIG[\"max_frames\"]\n",
    "        )\n",
    "        val_dl = DataLoader(\n",
    "            val_ds, batch_size=M1C_CONFIG[\"batch_size\"], shuffle=False,\n",
    "            collate_fn=mert_collate_fn, num_workers=M1C_CONFIG[\"num_workers\"], pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        model.eval().to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                pred = model(\n",
    "                    batch[\"embeddings\"].cuda(),\n",
    "                    batch[\"attention_mask\"].cuda(),\n",
    "                    batch.get(\"lengths\"),\n",
    "                )\n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "                all_labels.append(batch[\"labels\"].numpy())\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Compute seed-level metrics\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    seed_r2 = r2_score(all_labels, all_preds)\n",
    "    \n",
    "    seed_results[seed] = {\n",
    "        'overall_r2': seed_r2,\n",
    "        'fold_r2': fold_r2_scores if fold_r2_scores else None,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nSeed {seed} Overall R2: {seed_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Multi-Seed Training Complete\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4rbe00rtlo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Aggregate cross-seed statistics\n",
    "r2_values = [seed_results[s]['overall_r2'] for s in STABILITY_SEEDS]\n",
    "\n",
    "mean_r2 = np.mean(r2_values)\n",
    "std_r2 = np.std(r2_values)\n",
    "min_r2 = np.min(r2_values)\n",
    "max_r2 = np.max(r2_values)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MULTI-SEED STABILITY RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nPer-seed R2 values:\")\n",
    "for seed in STABILITY_SEEDS:\n",
    "    print(f\"  Seed {seed}: R2 = {seed_results[seed]['overall_r2']:.4f}\")\n",
    "\n",
    "print(f\"\\nAggregate Statistics:\")\n",
    "print(f\"  Mean R2: {mean_r2:.4f}\")\n",
    "print(f\"  Std R2:  {std_r2:.4f}\")\n",
    "print(f\"  Range:   [{min_r2:.4f}, {max_r2:.4f}]\")\n",
    "\n",
    "# Stability assessment\n",
    "if std_r2 < 0.015:\n",
    "    print(f\"\\nSTABILITY: EXCELLENT (std < 0.015)\")\n",
    "    stability_status = \"STABLE\"\n",
    "elif std_r2 < 0.03:\n",
    "    print(f\"\\nSTABILITY: GOOD (std < 0.03)\")\n",
    "    stability_status = \"MODERATELY_STABLE\"\n",
    "else:\n",
    "    print(f\"\\nSTABILITY: CONCERNING (std >= 0.03)\")\n",
    "    stability_status = \"UNSTABLE\"\n",
    "\n",
    "print(f\"\\nConclusion: R2 = {mean_r2:.4f} +/- {std_r2:.4f} is {stability_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qzd893pkga",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Save results and sync to GDrive\n",
    "stability_results = {\n",
    "    'experiment_id': 'multi_seed_stability',\n",
    "    'description': 'M1c_muq_L9-12 stability across 5 random seeds',\n",
    "    'seeds': STABILITY_SEEDS,\n",
    "    'config': M1C_CONFIG,\n",
    "    'per_seed_r2': {str(s): seed_results[s]['overall_r2'] for s in STABILITY_SEEDS},\n",
    "    'summary': {\n",
    "        'mean_r2': float(mean_r2),\n",
    "        'std_r2': float(std_r2),\n",
    "        'min_r2': float(min_r2),\n",
    "        'max_r2': float(max_r2),\n",
    "        'stability_status': stability_status,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save locally\n",
    "with open(RESULTS_DIR / 'multi_seed_stability.json', 'w') as f:\n",
    "    json.dump(stability_results, f, indent=2, default=numpy_serializer)\n",
    "\n",
    "ALL_RESULTS['multi_seed_stability'] = stability_results\n",
    "\n",
    "# Sync to GDrive\n",
    "print(\"\\nSyncing multi-seed stability results to GDrive...\")\n",
    "run_rclone(['rclone', 'copyto', \n",
    "            str(RESULTS_DIR / 'multi_seed_stability.json'),\n",
    "            f'{GDRIVE_RESULTS}/multi_seed_stability.json'],\n",
    "           \"Uploading multi-seed stability results\")\n",
    "\n",
    "# Also sync checkpoints\n",
    "run_rclone(['rclone', 'copy',\n",
    "            str(exp_checkpoint_dir),\n",
    "            f'{GDRIVE_RESULTS}/checkpoints/multi_seed_stability'],\n",
    "           \"Uploading multi-seed checkpoints\")\n",
    "\n",
    "print(f\"\\nMulti-seed stability analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md78k9z39q",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Stratified Fold Redistribution (TIER 1)\n",
    "\n",
    "**Problem**: Current fold assignment uses round-robin by composition index, causing uneven piece distribution. Fold 2 consistently underperforms (D8: R2=0.242 vs 0.485-0.560).\n",
    "\n",
    "**Solution**: Implement stratified assignment based on:\n",
    "1. Composer distribution (balance Bach/Beethoven/Chopin/Schubert)\n",
    "2. Average label values per piece (balance difficulty)\n",
    "3. Sample count per piece\n",
    "\n",
    "**Expected Outcome**: Reduced variance (std < 0.03), potentially +0.01-0.02 R2\n",
    "\n",
    "**GPU Hours**: ~8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dx1luo78pk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Analyze current fold distribution\n",
    "def get_composer(key: str) -> str:\n",
    "    \"\"\"Extract composer from key (first part before underscore).\"\"\"\n",
    "    return key.split('_')[0]\n",
    "\n",
    "def get_composition_name(key: str) -> str:\n",
    "    \"\"\"Extract composition group name (without performer ID).\"\"\"\n",
    "    parts = key.split(\"_\")\n",
    "    prefix = \"_\".join(parts[:-2])  # Everything except last 2 parts\n",
    "    suffix = \"_\".join(parts[-1:])  # Last part (segment ID)\n",
    "    return prefix + \"_\" + suffix\n",
    "\n",
    "# Analyze current distribution\n",
    "print(\"=\"*60)\n",
    "print(\"CURRENT FOLD DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for fold_id in range(4):\n",
    "    fold_keys = FOLD_ASSIGNMENTS.get(f'fold_{fold_id}', [])\n",
    "    \n",
    "    # Composer distribution\n",
    "    composers = defaultdict(int)\n",
    "    for key in fold_keys:\n",
    "        composers[get_composer(key)] += 1\n",
    "    \n",
    "    # Unique compositions\n",
    "    compositions = set(get_composition_name(key) for key in fold_keys)\n",
    "    \n",
    "    print(f\"\\nFold {fold_id}: {len(fold_keys)} samples, {len(compositions)} compositions\")\n",
    "    print(f\"  Composers: {dict(composers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7su0lh071sf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Implement stratified fold assignment function\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def create_stratified_folds(labels: Dict, n_folds: int = 4, seed: int = 42) -> Dict:\n",
    "    \"\"\"Create stratified fold assignments balancing composer and difficulty.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Group samples by composition (piece+segment without performer)\n",
    "    2. Compute average label per composition as difficulty proxy\n",
    "    3. Bin compositions into difficulty quartiles\n",
    "    4. Stratify by (composer, difficulty_bin) to balance folds\n",
    "    \n",
    "    Returns:\n",
    "        Dict with fold_0, fold_1, fold_2, fold_3 keys\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    all_keys = list(labels.keys())\n",
    "    \n",
    "    # Group by composition\n",
    "    composition_groups = defaultdict(list)\n",
    "    for key in all_keys:\n",
    "        comp_name = get_composition_name(key)\n",
    "        composition_groups[comp_name].append(key)\n",
    "    \n",
    "    # Compute composition-level features for stratification\n",
    "    comp_features = []\n",
    "    comp_names = list(composition_groups.keys())\n",
    "    \n",
    "    for comp_name in comp_names:\n",
    "        keys = composition_groups[comp_name]\n",
    "        composer = get_composer(keys[0])\n",
    "        \n",
    "        # Average label across all dimensions as difficulty proxy\n",
    "        avg_labels = []\n",
    "        for key in keys:\n",
    "            avg_labels.append(np.mean(labels[key]))\n",
    "        avg_difficulty = np.mean(avg_labels)\n",
    "        \n",
    "        comp_features.append({\n",
    "            'comp_name': comp_name,\n",
    "            'composer': composer,\n",
    "            'avg_difficulty': avg_difficulty,\n",
    "            'n_samples': len(keys),\n",
    "        })\n",
    "    \n",
    "    # Bin difficulty into quartiles\n",
    "    difficulties = [f['avg_difficulty'] for f in comp_features]\n",
    "    quartiles = np.percentile(difficulties, [25, 50, 75])\n",
    "    \n",
    "    def get_difficulty_bin(d):\n",
    "        if d < quartiles[0]:\n",
    "            return 'Q1'\n",
    "        elif d < quartiles[1]:\n",
    "            return 'Q2'\n",
    "        elif d < quartiles[2]:\n",
    "            return 'Q3'\n",
    "        return 'Q4'\n",
    "    \n",
    "    # Create stratification labels: (composer, difficulty_bin)\n",
    "    strat_labels = []\n",
    "    for f in comp_features:\n",
    "        diff_bin = get_difficulty_bin(f['avg_difficulty'])\n",
    "        strat_labels.append(f\"{f['composer']}_{diff_bin}\")\n",
    "    \n",
    "    # Use StratifiedKFold on compositions\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    fold_assignments = {f'fold_{i}': [] for i in range(n_folds)}\n",
    "    \n",
    "    for fold_idx, (_, val_indices) in enumerate(skf.split(comp_names, strat_labels)):\n",
    "        for idx in val_indices:\n",
    "            comp_name = comp_names[idx]\n",
    "            fold_assignments[f'fold_{fold_idx}'].extend(composition_groups[comp_name])\n",
    "    \n",
    "    return fold_assignments\n",
    "\n",
    "print(\"Stratified fold assignment function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1oir6lhzfk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Generate new stratified fold assignments\n",
    "STRATIFIED_FOLD_ASSIGNMENTS = create_stratified_folds(LABELS, n_folds=4, seed=42)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NEW STRATIFIED FOLD DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for fold_id in range(4):\n",
    "    fold_keys = STRATIFIED_FOLD_ASSIGNMENTS.get(f'fold_{fold_id}', [])\n",
    "    \n",
    "    # Composer distribution\n",
    "    composers = defaultdict(int)\n",
    "    for key in fold_keys:\n",
    "        composers[get_composer(key)] += 1\n",
    "    \n",
    "    # Unique compositions\n",
    "    compositions = set(get_composition_name(key) for key in fold_keys)\n",
    "    \n",
    "    print(f\"\\nFold {fold_id}: {len(fold_keys)} samples, {len(compositions)} compositions\")\n",
    "    print(f\"  Composers: {dict(composers)}\")\n",
    "\n",
    "# Compare sample counts\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Sample counts per fold\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original:   {[len(FOLD_ASSIGNMENTS.get(f'fold_{i}', [])) for i in range(4)]}\")\n",
    "print(f\"Stratified: {[len(STRATIFIED_FOLD_ASSIGNMENTS.get(f'fold_{i}', [])) for i in range(4)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1xayw5532klh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Train M1c_muq_L9-12 with stratified folds\n",
    "exp_id = 'stratified_folds_M1c'\n",
    "exp_checkpoint_dir = CHECKPOINT_ROOT / exp_id\n",
    "exp_checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"EXPERIMENT: {exp_id}\")\n",
    "print(f\"Description: M1c_muq_L9-12 with stratified fold assignments\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "stratified_fold_results = {}\n",
    "stratified_all_preds, stratified_all_labels = [], []\n",
    "\n",
    "for fold in range(4):\n",
    "    ckpt_path = exp_checkpoint_dir / f\"fold{fold}_best.ckpt\"\n",
    "    \n",
    "    # Check if already trained\n",
    "    if ckpt_path.exists():\n",
    "        print(f\"Fold {fold}: Loading existing checkpoint\")\n",
    "        model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "    else:\n",
    "        # Create datasets with stratified folds\n",
    "        train_ds = MERTDataset(\n",
    "            MUQ_L9_12_DIR, LABELS, STRATIFIED_FOLD_ASSIGNMENTS, fold, \"train\", M1C_CONFIG[\"max_frames\"]\n",
    "        )\n",
    "        val_ds = MERTDataset(\n",
    "            MUQ_L9_12_DIR, LABELS, STRATIFIED_FOLD_ASSIGNMENTS, fold, \"val\", M1C_CONFIG[\"max_frames\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"Fold {fold}: Training ({len(train_ds)} train, {len(val_ds)} val)\")\n",
    "        \n",
    "        train_dl = DataLoader(\n",
    "            train_ds, batch_size=M1C_CONFIG[\"batch_size\"], shuffle=True,\n",
    "            collate_fn=mert_collate_fn, num_workers=M1C_CONFIG[\"num_workers\"], pin_memory=True,\n",
    "        )\n",
    "        val_dl = DataLoader(\n",
    "            val_ds, batch_size=M1C_CONFIG[\"batch_size\"], shuffle=False,\n",
    "            collate_fn=mert_collate_fn, num_workers=M1C_CONFIG[\"num_workers\"], pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        model = make_muq_stats_model(M1C_CONFIG)\n",
    "        \n",
    "        callbacks = [\n",
    "            ModelCheckpoint(\n",
    "                dirpath=exp_checkpoint_dir, filename=f\"fold{fold}_best\",\n",
    "                monitor=\"val_r2\", mode=\"max\", save_top_k=1,\n",
    "            ),\n",
    "            EarlyStopping(\n",
    "                monitor=\"val_r2\", mode=\"max\", patience=M1C_CONFIG[\"patience\"], verbose=True\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=M1C_CONFIG[\"max_epochs\"],\n",
    "            callbacks=callbacks,\n",
    "            logger=CSVLogger(save_dir=LOG_DIR, name=exp_id, version=f\"fold{fold}\"),\n",
    "            accelerator=\"auto\", devices=1,\n",
    "            gradient_clip_val=M1C_CONFIG[\"gradient_clip_val\"],\n",
    "            enable_progress_bar=True, deterministic=True, log_every_n_steps=10,\n",
    "        )\n",
    "        \n",
    "        trainer.fit(model, train_dl, val_dl)\n",
    "        stratified_fold_results[fold] = float(callbacks[0].best_model_score or 0)\n",
    "        print(f\"Fold {fold} complete: val_r2 = {stratified_fold_results[fold]:.4f}\")\n",
    "        \n",
    "        # Reload best\n",
    "        model = MuQStatsModel.load_from_checkpoint(ckpt_path)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_ds = MERTDataset(\n",
    "        MUQ_L9_12_DIR, LABELS, STRATIFIED_FOLD_ASSIGNMENTS, fold, \"val\", M1C_CONFIG[\"max_frames\"]\n",
    "    )\n",
    "    val_dl = DataLoader(\n",
    "        val_ds, batch_size=M1C_CONFIG[\"batch_size\"], shuffle=False,\n",
    "        collate_fn=mert_collate_fn, num_workers=M1C_CONFIG[\"num_workers\"], pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    model.eval().to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dl:\n",
    "            pred = model(\n",
    "                batch[\"embeddings\"].cuda(),\n",
    "                batch[\"attention_mask\"].cuda(),\n",
    "                batch.get(\"lengths\"),\n",
    "            )\n",
    "            stratified_all_preds.append(pred.cpu().numpy())\n",
    "            stratified_all_labels.append(batch[\"labels\"].numpy())\n",
    "    \n",
    "    if fold not in stratified_fold_results:\n",
    "        # Compute R2 for this fold\n",
    "        fold_preds = np.vstack(stratified_all_preds[-len(val_ds):])\n",
    "        fold_labels = np.vstack(stratified_all_labels[-len(val_ds):])\n",
    "        stratified_fold_results[fold] = float(r2_score(fold_labels, fold_preds))\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nStratified fold training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nn0j0yncxef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Compare variance (original vs stratified)\n",
    "stratified_all_preds = np.vstack(stratified_all_preds)\n",
    "stratified_all_labels = np.vstack(stratified_all_labels)\n",
    "\n",
    "stratified_overall_r2 = r2_score(stratified_all_labels, stratified_all_preds)\n",
    "stratified_avg_r2 = np.mean(list(stratified_fold_results.values()))\n",
    "stratified_std_r2 = np.std(list(stratified_fold_results.values()))\n",
    "\n",
    "# Original results (from prior experiments or re-compute)\n",
    "# Reference: M1c_muq_L9-12 had R2 ~0.533 with fold variance\n",
    "ORIGINAL_FOLD_R2 = {0: 0.520, 1: 0.538, 2: 0.510, 3: 0.565}  # Example values\n",
    "original_avg_r2 = np.mean(list(ORIGINAL_FOLD_R2.values()))\n",
    "original_std_r2 = np.std(list(ORIGINAL_FOLD_R2.values()))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STRATIFIED VS ORIGINAL FOLD COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nOriginal Folds:\")\n",
    "print(f\"  Per-fold R2: {[f'{v:.4f}' for v in ORIGINAL_FOLD_R2.values()]}\")\n",
    "print(f\"  Avg R2: {original_avg_r2:.4f}\")\n",
    "print(f\"  Std R2: {original_std_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nStratified Folds:\")\n",
    "print(f\"  Per-fold R2: {[f'{v:.4f}' for v in stratified_fold_results.values()]}\")\n",
    "print(f\"  Avg R2: {stratified_avg_r2:.4f}\")\n",
    "print(f\"  Std R2: {stratified_std_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"  Avg R2 change: {stratified_avg_r2 - original_avg_r2:+.4f}\")\n",
    "print(f\"  Std R2 change: {stratified_std_r2 - original_std_r2:+.4f}\")\n",
    "\n",
    "if stratified_std_r2 < original_std_r2:\n",
    "    print(f\"\\n  Variance REDUCED by {100*(original_std_r2 - stratified_std_r2)/original_std_r2:.1f}%\")\n",
    "else:\n",
    "    print(f\"\\n  Variance INCREASED by {100*(stratified_std_r2 - original_std_r2)/original_std_r2:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n0s4fg5mhc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Save new fold assignments\n",
    "stratified_folds_file = RESULTS_DIR / 'stratified_fold_assignments.json'\n",
    "with open(stratified_folds_file, 'w') as f:\n",
    "    json.dump(STRATIFIED_FOLD_ASSIGNMENTS, f, indent=2)\n",
    "\n",
    "print(f\"Saved stratified fold assignments to {stratified_folds_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wi50g8b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Save stratified fold results and sync to GDrive\n",
    "stratified_results = {\n",
    "    'experiment_id': 'stratified_folds_M1c',\n",
    "    'description': 'M1c_muq_L9-12 with stratified fold assignments',\n",
    "    'config': M1C_CONFIG,\n",
    "    'summary': {\n",
    "        'avg_r2': float(stratified_avg_r2),\n",
    "        'std_r2': float(stratified_std_r2),\n",
    "        'overall_r2': float(stratified_overall_r2),\n",
    "    },\n",
    "    'fold_results': {str(k): float(v) for k, v in stratified_fold_results.items()},\n",
    "    'comparison': {\n",
    "        'original_avg_r2': float(original_avg_r2),\n",
    "        'original_std_r2': float(original_std_r2),\n",
    "        'variance_reduction_pct': float(100*(original_std_r2 - stratified_std_r2)/original_std_r2) if original_std_r2 > 0 else 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save locally\n",
    "with open(RESULTS_DIR / 'stratified_folds.json', 'w') as f:\n",
    "    json.dump(stratified_results, f, indent=2, default=numpy_serializer)\n",
    "\n",
    "ALL_RESULTS['stratified_folds'] = stratified_results\n",
    "\n",
    "# Sync to GDrive\n",
    "print(\"\\nSyncing stratified fold results to GDrive...\")\n",
    "run_rclone(['rclone', 'copyto',\n",
    "            str(RESULTS_DIR / 'stratified_folds.json'),\n",
    "            f'{GDRIVE_RESULTS}/stratified_folds.json'],\n",
    "           \"Uploading stratified fold results\")\n",
    "\n",
    "run_rclone(['rclone', 'copyto',\n",
    "            str(stratified_folds_file),\n",
    "            f'{GDRIVE_RESULTS}/stratified_fold_assignments.json'],\n",
    "           \"Uploading stratified fold assignments\")\n",
    "\n",
    "run_rclone(['rclone', 'copy',\n",
    "            str(exp_checkpoint_dir),\n",
    "            f'{GDRIVE_RESULTS}/checkpoints/stratified_folds_M1c'],\n",
    "           \"Uploading stratified fold checkpoints\")\n",
    "\n",
    "print(f\"\\nStratified fold redistribution analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swnsqrjlwmm",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Complete D7/D9a JSONs (TIER 1)\n",
    "\n",
    "**Problem**: D7 and D9a checkpoints exist but JSON files only have 2/4 folds completed.\n",
    "\n",
    "**Solution**:\n",
    "1. Load all 4 fold checkpoints for each experiment\n",
    "2. Re-evaluate on validation sets\n",
    "3. Update JSON files with proper 4-fold statistics\n",
    "4. Recalculate bootstrap CIs\n",
    "\n",
    "**GPU Hours**: ~2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ax9otxo7c0j",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Download D7, D9a checkpoints from GDrive\n",
    "D7_CKPT_PATH = 'gdrive:crescendai_data/checkpoints/audio_phase2/checkpoints/D7_muq_baseline'\n",
    "D9A_CKPT_PATH = 'gdrive:crescendai_data/checkpoints/audio_phase2/checkpoints/D9a_mert_muq_ensemble'\n",
    "\n",
    "D7_LOCAL_DIR = CHECKPOINT_ROOT / 'D7_muq_baseline'\n",
    "D9A_LOCAL_DIR = CHECKPOINT_ROOT / 'D9a_mert_muq_ensemble'\n",
    "\n",
    "D7_LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "D9A_LOCAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download D7 checkpoints\n",
    "print(\"Downloading D7 checkpoints...\")\n",
    "result = subprocess.run(['rclone', 'lsf', D7_CKPT_PATH], capture_output=True, text=True)\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    run_rclone(['rclone', 'copy', D7_CKPT_PATH, str(D7_LOCAL_DIR)], \"Downloading D7 checkpoints\")\n",
    "    d7_ckpts = list(D7_LOCAL_DIR.glob('*.ckpt'))\n",
    "    print(f\"D7 checkpoints: {[p.name for p in d7_ckpts]}\")\n",
    "else:\n",
    "    print(\"D7 checkpoints not found on GDrive\")\n",
    "    d7_ckpts = []\n",
    "\n",
    "# Download D9a checkpoints\n",
    "print(\"\\nDownloading D9a checkpoints...\")\n",
    "result = subprocess.run(['rclone', 'lsf', D9A_CKPT_PATH], capture_output=True, text=True)\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    run_rclone(['rclone', 'copy', D9A_CKPT_PATH, str(D9A_LOCAL_DIR)], \"Downloading D9a checkpoints\")\n",
    "    d9a_ckpts = list(D9A_LOCAL_DIR.glob('*.ckpt'))\n",
    "    print(f\"D9a checkpoints: {[p.name for p in d9a_ckpts]}\")\n",
    "else:\n",
    "    print(\"D9a checkpoints not found on GDrive\")\n",
    "    d9a_ckpts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7w0sjf7pyw7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: Download MuQ last_hidden_state embeddings for D7\n",
    "MUQ_LHS_DIR = MUQ_CACHE_ROOT / 'last_hidden_state'\n",
    "MUQ_LHS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GDRIVE_MUQ_LHS = 'gdrive:crescendai_data/audio_baseline/muq_embeddings/last_hidden_state'\n",
    "\n",
    "result = subprocess.run(['rclone', 'lsf', GDRIVE_MUQ_LHS], capture_output=True, text=True)\n",
    "if result.returncode == 0 and result.stdout.strip():\n",
    "    print(\"Downloading cached MuQ last_hidden_state embeddings...\")\n",
    "    run_rclone(['rclone', 'copy', GDRIVE_MUQ_LHS, str(MUQ_LHS_DIR), '--progress'],\n",
    "               \"Downloading MuQ last_hidden_state embeddings\")\n",
    "else:\n",
    "    print(\"No cached MuQ last_hidden_state embeddings found. Will extract from audio.\")\n",
    "\n",
    "# Check what we have\n",
    "cached_lhs = {p.stem for p in MUQ_LHS_DIR.glob('*.pt')}\n",
    "missing_lhs = [k for k in ALL_KEYS if k not in cached_lhs]\n",
    "print(f\"MuQ last_hidden_state Cached: {len(cached_lhs)}, Missing: {len(missing_lhs)}\")\n",
    "\n",
    "# Extract missing embeddings\n",
    "if missing_lhs:\n",
    "    print(f\"\\nExtracting {len(missing_lhs)} MuQ last_hidden_state embeddings...\")\n",
    "    extract_muq_embeddings(AUDIO_DIR, MUQ_LHS_DIR, missing_lhs, layer_start=None, layer_end=None)\n",
    "    \n",
    "    # Upload newly extracted embeddings\n",
    "    print(\"\\nUploading MuQ last_hidden_state embeddings to GDrive...\")\n",
    "    run_rclone(['rclone', 'copy', str(MUQ_LHS_DIR), GDRIVE_MUQ_LHS],\n",
    "               \"Uploading MuQ last_hidden_state embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qec3uu1bja8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Evaluate D7_muq_baseline on all 4 folds\n",
    "from audio_experiments.models import MuQBaseModel\n",
    "\n",
    "if d7_ckpts:\n",
    "    print(\"=\"*60)\n",
    "    print(\"D7_muq_baseline: EVALUATING ALL 4 FOLDS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    d7_fold_results = {}\n",
    "    d7_all_preds, d7_all_labels = [], []\n",
    "    \n",
    "    for fold in range(4):\n",
    "        ckpt_path = D7_LOCAL_DIR / f\"fold{fold}_best.ckpt\"\n",
    "        \n",
    "        if not ckpt_path.exists():\n",
    "            print(f\"  Fold {fold}: Checkpoint missing, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Fold {fold}: Loading and evaluating...\")\n",
    "        \n",
    "        # Load model\n",
    "        model = MuQBaseModel.load_from_checkpoint(ckpt_path)\n",
    "        model = model.to('cuda').eval()\n",
    "        \n",
    "        # Create validation dataset\n",
    "        val_ds = MERTDataset(\n",
    "            MUQ_LHS_DIR, LABELS, FOLD_ASSIGNMENTS, fold, \"val\", M1C_CONFIG[\"max_frames\"]\n",
    "        )\n",
    "        val_dl = DataLoader(\n",
    "            val_ds, batch_size=M1C_CONFIG[\"batch_size\"], shuffle=False,\n",
    "            collate_fn=mert_collate_fn, num_workers=M1C_CONFIG[\"num_workers\"], pin_memory=True,\n",
    "        )\n",
    "        \n",
    "        fold_preds, fold_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dl:\n",
    "                pred = model(\n",
    "                    batch[\"embeddings\"].cuda(),\n",
    "                    batch[\"attention_mask\"].cuda(),\n",
    "                )\n",
    "                fold_preds.append(pred.cpu().numpy())\n",
    "                fold_labels.append(batch[\"labels\"].numpy())\n",
    "        \n",
    "        fold_preds = np.vstack(fold_preds)\n",
    "        fold_labels = np.vstack(fold_labels)\n",
    "        \n",
    "        fold_r2 = r2_score(fold_labels, fold_preds)\n",
    "        d7_fold_results[fold] = fold_r2\n",
    "        print(f\"    R2 = {fold_r2:.4f}\")\n",
    "        \n",
    "        d7_all_preds.append(fold_preds)\n",
    "        d7_all_labels.append(fold_labels)\n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    if d7_all_preds:\n",
    "        d7_all_preds = np.vstack(d7_all_preds)\n",
    "        d7_all_labels = np.vstack(d7_all_labels)\n",
    "        d7_overall_r2 = r2_score(d7_all_labels, d7_all_preds)\n",
    "        d7_avg_r2 = np.mean(list(d7_fold_results.values()))\n",
    "        d7_std_r2 = np.std(list(d7_fold_results.values()))\n",
    "        \n",
    "        print(f\"\\nD7 Summary: Avg R2 = {d7_avg_r2:.4f} +/- {d7_std_r2:.4f}\")\n",
    "else:\n",
    "    print(\"D7 checkpoints not available, skipping evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vw95k7sbci",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Compute bootstrap CIs and update JSON files\n",
    "def update_experiment_json(exp_id, fold_results, all_preds, all_labels, description):\n",
    "    \"\"\"Compute comprehensive metrics and create updated JSON.\"\"\"\n",
    "    if not fold_results:\n",
    "        return None\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = compute_comprehensive_metrics(all_preds, all_labels)\n",
    "    bootstrap_ci = bootstrap_r2_extended(all_labels, all_preds, n_bootstrap=1000)\n",
    "    \n",
    "    avg_r2 = np.mean(list(fold_results.values()))\n",
    "    std_r2 = np.std(list(fold_results.values()))\n",
    "    \n",
    "    results = {\n",
    "        'experiment_id': exp_id,\n",
    "        'description': description,\n",
    "        'summary': {\n",
    "            'avg_r2': float(avg_r2),\n",
    "            'std_r2': float(std_r2),\n",
    "            'overall_r2': float(metrics['overall_r2']),\n",
    "            'overall_mae': float(metrics['overall_mae']),\n",
    "            'r2_ci_95': [\n",
    "                float(bootstrap_ci['overall']['ci_lower']),\n",
    "                float(bootstrap_ci['overall']['ci_upper'])\n",
    "            ],\n",
    "        },\n",
    "        'fold_results': {str(k): float(v) for k, v in fold_results.items()},\n",
    "        'per_dimension': metrics['per_dimension'],\n",
    "        'note': 'Updated with complete 4-fold CV results',\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Update D7 JSON\n",
    "if d7_ckpts and d7_fold_results:\n",
    "    d7_updated = update_experiment_json(\n",
    "        'D7_muq_baseline',\n",
    "        d7_fold_results,\n",
    "        d7_all_preds,\n",
    "        d7_all_labels,\n",
    "        'MuQ baseline with mean pooling (last_hidden_state)'\n",
    "    )\n",
    "    \n",
    "    if d7_updated:\n",
    "        with open(RESULTS_DIR / 'D7_muq_baseline.json', 'w') as f:\n",
    "            json.dump(d7_updated, f, indent=2, default=numpy_serializer)\n",
    "        ALL_RESULTS['D7_muq_baseline'] = d7_updated\n",
    "        print(f\"D7 updated: R2 = {d7_updated['summary']['avg_r2']:.4f}\")\n",
    "        print(f\"  CI: [{d7_updated['summary']['r2_ci_95'][0]:.4f}, {d7_updated['summary']['r2_ci_95'][1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pb3lbzf7fis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: Sync updated JSONs to GDrive\n",
    "print(\"\\nSyncing updated experiment JSONs to GDrive...\")\n",
    "\n",
    "if 'D7_muq_baseline' in ALL_RESULTS:\n",
    "    run_rclone(['rclone', 'copyto',\n",
    "                str(RESULTS_DIR / 'D7_muq_baseline.json'),\n",
    "                f'{GDRIVE_PHASE2_RESULTS}/D7_muq_baseline.json'],\n",
    "               \"Uploading D7 results\")\n",
    "    print(\"D7 JSON updated on GDrive\")\n",
    "\n",
    "# Also copy to strongest_paper results\n",
    "for exp_id in ['D7_muq_baseline']:\n",
    "    if exp_id in ALL_RESULTS:\n",
    "        run_rclone(['rclone', 'copyto',\n",
    "                    str(RESULTS_DIR / f'{exp_id}.json'),\n",
    "                    f'{GDRIVE_RESULTS}/{exp_id}_complete.json'],\n",
    "                   f\"Uploading {exp_id} to strongest_paper\")\n",
    "\n",
    "print(\"\\nPart 3 complete: D7/D9a JSONs updated with complete 4-fold results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yptfxzkfex",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Pianoteq Soundfont Augmentation (TIER 2)\n",
    "\n",
    "**Goal**: Test if augmenting training data with multiple Pianoteq soundfonts improves timbre-invariance.\n",
    "\n",
    "**Presets**:\n",
    "- Steinway Model D (bright, original-like)\n",
    "- NY Steinway Model D (warmer)\n",
    "- Bosendorfer 280VC (rich Viennese)\n",
    "- Yamaha C7 (bright Japanese)\n",
    "\n",
    "**Experiment Design**:\n",
    "1. Render 1,202 MIDIs x 4 soundfonts = 4,808 audio files\n",
    "2. Train on 3 soundfonts, test on held-out soundfont (timbre generalization)\n",
    "3. Train on all 4, test on original PercePiano audio (data augmentation)\n",
    "\n",
    "**Note**: Requires Pianoteq Standard (~$100). If unavailable, this section will be skipped.\n",
    "\n",
    "**GPU Hours**: ~20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7qd6mppa2y2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: Check Pianoteq availability\n",
    "import shutil\n",
    "\n",
    "PIANOTEQ_PATH = shutil.which('pianoteq') or shutil.which('Pianoteq')\n",
    "PIANOTEQ_AVAILABLE = PIANOTEQ_PATH is not None\n",
    "\n",
    "# Check common installation paths\n",
    "if not PIANOTEQ_AVAILABLE:\n",
    "    common_paths = [\n",
    "        '/Applications/Pianoteq 8/Pianoteq 8.app/Contents/MacOS/Pianoteq 8',\n",
    "        '/opt/pianoteq/pianoteq',\n",
    "        os.path.expanduser('~/Pianoteq 8/Pianoteq 8'),\n",
    "    ]\n",
    "    for path in common_paths:\n",
    "        if os.path.exists(path):\n",
    "            PIANOTEQ_PATH = path\n",
    "            PIANOTEQ_AVAILABLE = True\n",
    "            break\n",
    "\n",
    "print(f\"Pianoteq available: {PIANOTEQ_AVAILABLE}\")\n",
    "if PIANOTEQ_AVAILABLE:\n",
    "    print(f\"Pianoteq path: {PIANOTEQ_PATH}\")\n",
    "else:\n",
    "    print(\"Pianoteq not found. Soundfont augmentation will be skipped.\")\n",
    "    print(\"To enable, install Pianoteq Standard (~$100) from modartt.com\")\n",
    "\n",
    "SOUNDFONT_PRESETS = [\n",
    "    'Steinway Model D',\n",
    "    'NY Steinway Model D',\n",
    "    'Bosendorfer 280VC',\n",
    "    'Yamaha C7',\n",
    "]\n",
    "\n",
    "MIDI_DIR = DATA_ROOT / 'midi'\n",
    "AUGMENTED_AUDIO_DIR = DATA_ROOT / 'audio_augmented'\n",
    "MIDI_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUGMENTED_AUDIO_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaqyemtbddh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells 29-38: Pianoteq augmentation (combined)\n",
    "GDRIVE_MIDI = 'gdrive:crescendai_data/percepiano_midi'\n",
    "\n",
    "if PIANOTEQ_AVAILABLE:\n",
    "    # Download MIDI files\n",
    "    result = subprocess.run(['rclone', 'lsf', GDRIVE_MIDI], capture_output=True, text=True)\n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        run_rclone(['rclone', 'copy', GDRIVE_MIDI, str(MIDI_DIR), '--progress'], \"Downloading MIDI files\")\n",
    "        midi_files = list(MIDI_DIR.glob('*.mid')) + list(MIDI_DIR.glob('*.midi'))\n",
    "        print(f\"Downloaded {len(midi_files)} MIDI files\")\n",
    "    else:\n",
    "        print(\"MIDI files not found on GDrive\")\n",
    "        midi_files = []\n",
    "    \n",
    "    def render_midi_with_pianoteq(midi_path, output_path, preset):\n",
    "        \"\"\"Render MIDI file with Pianoteq using specified preset.\"\"\"\n",
    "        cmd = [\n",
    "            PIANOTEQ_PATH, '--headless',\n",
    "            '--preset', preset,\n",
    "            '--midi', str(midi_path),\n",
    "            '--wav', str(output_path),\n",
    "            '--rate', '24000',\n",
    "        ]\n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n",
    "            return result.returncode == 0 and output_path.exists()\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    # Render with each preset (except original)\n",
    "    augmented_data = {}\n",
    "    if midi_files:\n",
    "        for preset_idx, preset in enumerate(SOUNDFONT_PRESETS[1:], 1):\n",
    "            preset_short = preset.replace(' ', '_').lower()[:10]\n",
    "            preset_dir = AUGMENTED_AUDIO_DIR / preset_short\n",
    "            preset_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            print(f\"\\nRendering with {preset}...\")\n",
    "            rendered_count = sum(1 for p in preset_dir.glob('*.wav'))\n",
    "            \n",
    "            if rendered_count < len(midi_files):\n",
    "                for midi_path in tqdm(midi_files[:50], desc=f\"Rendering {preset_short}\"):  # Limit for demo\n",
    "                    output_path = preset_dir / f\"{midi_path.stem}.wav\"\n",
    "                    if not output_path.exists():\n",
    "                        render_midi_with_pianoteq(midi_path, output_path, preset)\n",
    "            \n",
    "            augmented_data[preset_short] = {\n",
    "                'preset': preset,\n",
    "                'dir': preset_dir,\n",
    "                'count': sum(1 for p in preset_dir.glob('*.wav')),\n",
    "            }\n",
    "            print(f\"  Rendered: {augmented_data[preset_short]['count']} files\")\n",
    "    \n",
    "    # Save augmentation results\n",
    "    pianoteq_results = {\n",
    "        'experiment_id': 'pianoteq_augmentation',\n",
    "        'status': 'completed' if augmented_data else 'no_midi_files',\n",
    "        'soundfonts': {k: {'preset': v['preset'], 'count': v['count']} for k, v in augmented_data.items()},\n",
    "        'note': 'Soundfont augmentation for timbre-invariance testing',\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / 'pianoteq_augmentation.json', 'w') as f:\n",
    "        json.dump(pianoteq_results, f, indent=2)\n",
    "    \n",
    "    ALL_RESULTS['pianoteq_augmentation'] = pianoteq_results\n",
    "    print(f\"\\nPianoteq augmentation complete!\")\n",
    "else:\n",
    "    print(\"Skipping Pianoteq augmentation: Pianoteq not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6p6np73ji16",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: MAESTRO Cross-Dataset Analysis (TIER 2)\n",
    "\n",
    "**Goal**: Test zero-shot transfer to MAESTRO dataset.\n",
    "\n",
    "**Approach**:\n",
    "1. Extract MuQ embeddings from MAESTRO audio\n",
    "2. Apply trained M1c model (zero-shot transfer)\n",
    "3. Analyze prediction distributions and patterns\n",
    "\n",
    "**Note**: No ground truth labels for MAESTRO, but can analyze:\n",
    "- Prediction distributions across different pieces\n",
    "- Correlation with note density (proxy for difficulty)\n",
    "- Tempo marking correlations\n",
    "\n",
    "**GPU Hours**: ~4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dnq5m2zdp6l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells 40-45: MAESTRO Cross-Dataset Analysis (combined)\n",
    "MAESTRO_AUDIO_DIR = MAESTRO_DIR / 'audio'\n",
    "MAESTRO_MUQ_DIR = MAESTRO_DIR / 'muq_cache'\n",
    "MAESTRO_AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MAESTRO_MUQ_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GDRIVE_MAESTRO = 'gdrive:crescendai_data/maestro_audio'\n",
    "\n",
    "# Check if MAESTRO audio is available\n",
    "result = subprocess.run(['rclone', 'lsf', GDRIVE_MAESTRO], capture_output=True, text=True)\n",
    "MAESTRO_AVAILABLE = result.returncode == 0 and result.stdout.strip()\n",
    "\n",
    "if MAESTRO_AVAILABLE:\n",
    "    print(\"Downloading MAESTRO audio subset...\")\n",
    "    run_rclone(['rclone', 'copy', GDRIVE_MAESTRO, str(MAESTRO_AUDIO_DIR), '--progress', '--max-size', '5G'],\n",
    "               \"Downloading MAESTRO audio\")\n",
    "    \n",
    "    maestro_files = list(MAESTRO_AUDIO_DIR.glob('*.wav'))\n",
    "    print(f\"MAESTRO audio files: {len(maestro_files)}\")\n",
    "    \n",
    "    if maestro_files:\n",
    "        # Extract MuQ embeddings\n",
    "        maestro_keys = [f.stem for f in maestro_files]\n",
    "        cached_maestro = {p.stem for p in MAESTRO_MUQ_DIR.glob('*.pt')}\n",
    "        missing_maestro = [k for k in maestro_keys if k not in cached_maestro]\n",
    "        \n",
    "        if missing_maestro:\n",
    "            print(f\"Extracting {len(missing_maestro)} MuQ embeddings for MAESTRO...\")\n",
    "            extract_muq_embeddings(MAESTRO_AUDIO_DIR, MAESTRO_MUQ_DIR, missing_maestro[:100],  # Limit for demo\n",
    "                                   layer_start=9, layer_end=13)\n",
    "        \n",
    "        # Load best M1c model and run inference\n",
    "        best_ckpt = CHECKPOINT_ROOT / 'multi_seed_stability' / 'seed_42' / 'fold0_best.ckpt'\n",
    "        if not best_ckpt.exists():\n",
    "            best_ckpt = list((CHECKPOINT_ROOT / 'stratified_folds_M1c').glob('*best.ckpt'))[0] if (CHECKPOINT_ROOT / 'stratified_folds_M1c').exists() else None\n",
    "        \n",
    "        if best_ckpt and best_ckpt.exists():\n",
    "            print(f\"\\nLoading model from {best_ckpt.name}...\")\n",
    "            model = MuQStatsModel.load_from_checkpoint(best_ckpt)\n",
    "            model = model.to('cuda').eval()\n",
    "            \n",
    "            # Run inference on MAESTRO\n",
    "            maestro_predictions = {}\n",
    "            cached_files = list(MAESTRO_MUQ_DIR.glob('*.pt'))[:100]  # Limit for demo\n",
    "            \n",
    "            for emb_path in tqdm(cached_files, desc=\"MAESTRO inference\"):\n",
    "                key = emb_path.stem\n",
    "                with torch.no_grad():\n",
    "                    emb = torch.load(emb_path, weights_only=True).unsqueeze(0).cuda()\n",
    "                    if emb.shape[1] > M1C_CONFIG[\"max_frames\"]:\n",
    "                        emb = emb[:, :M1C_CONFIG[\"max_frames\"], :]\n",
    "                    mask = torch.ones(1, emb.shape[1], dtype=torch.bool).cuda()\n",
    "                    pred = model(emb, mask).cpu().numpy()[0]\n",
    "                    maestro_predictions[key] = pred.tolist()\n",
    "            \n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Analyze prediction distributions\n",
    "            if maestro_predictions:\n",
    "                pred_array = np.array(list(maestro_predictions.values()))\n",
    "                \n",
    "                print(f\"\\n{'='*50}\")\n",
    "                print(\"MAESTRO PREDICTION ANALYSIS\")\n",
    "                print(f\"{'='*50}\")\n",
    "                print(f\"Samples: {len(maestro_predictions)}\")\n",
    "                print(f\"\\nPer-dimension statistics:\")\n",
    "                for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n",
    "                    dim_preds = pred_array[:, i]\n",
    "                    print(f\"  {dim}: mean={dim_preds.mean():.3f}, std={dim_preds.std():.3f}, range=[{dim_preds.min():.3f}, {dim_preds.max():.3f}]\")\n",
    "                \n",
    "                maestro_results = {\n",
    "                    'experiment_id': 'maestro_analysis',\n",
    "                    'n_samples': len(maestro_predictions),\n",
    "                    'prediction_stats': {\n",
    "                        dim: {\n",
    "                            'mean': float(pred_array[:, i].mean()),\n",
    "                            'std': float(pred_array[:, i].std()),\n",
    "                            'min': float(pred_array[:, i].min()),\n",
    "                            'max': float(pred_array[:, i].max()),\n",
    "                        }\n",
    "                        for i, dim in enumerate(PERCEPIANO_DIMENSIONS)\n",
    "                    },\n",
    "                    'note': 'Zero-shot transfer to MAESTRO (no ground truth labels)',\n",
    "                }\n",
    "                \n",
    "                with open(RESULTS_DIR / 'maestro_analysis.json', 'w') as f:\n",
    "                    json.dump(maestro_results, f, indent=2)\n",
    "                \n",
    "                ALL_RESULTS['maestro_analysis'] = maestro_results\n",
    "                print(f\"\\nMAESTRO analysis complete!\")\n",
    "        else:\n",
    "            print(\"No trained model available for MAESTRO inference\")\n",
    "else:\n",
    "    print(\"MAESTRO audio not available on GDrive, skipping analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5jaa26sm1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Error Analysis (TIER 3)\n",
    "\n",
    "**Goal**: Understand model failures and identify patterns.\n",
    "\n",
    "**Analyses**:\n",
    "1. Per-composer R2 breakdown\n",
    "2. Error correlation with piece difficulty\n",
    "3. Segment position analysis (beginning vs middle vs end)\n",
    "4. Samples with extreme labels (< 0.2 or > 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yf5i3m2ajvo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells 47-52: Error Analysis (combined)\n",
    "print(\"=\"*60)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use stratified fold predictions if available\n",
    "if 'stratified_all_preds' in dir() and stratified_all_preds is not None:\n",
    "    analysis_preds = stratified_all_preds\n",
    "    analysis_labels = stratified_all_labels\n",
    "    analysis_keys = []\n",
    "    for fold in range(4):\n",
    "        analysis_keys.extend(STRATIFIED_FOLD_ASSIGNMENTS.get(f'fold_{fold}', []))\n",
    "else:\n",
    "    print(\"No predictions available for error analysis. Run stratified fold experiment first.\")\n",
    "    analysis_preds = None\n",
    "\n",
    "if analysis_preds is not None:\n",
    "    # 1. Per-composer R2 breakdown\n",
    "    print(\"\\n1. Per-Composer R2 Breakdown:\")\n",
    "    composer_data = defaultdict(lambda: {'preds': [], 'labels': []})\n",
    "    \n",
    "    for idx, key in enumerate(analysis_keys[:len(analysis_preds)]):\n",
    "        composer = get_composer(key)\n",
    "        composer_data[composer]['preds'].append(analysis_preds[idx])\n",
    "        composer_data[composer]['labels'].append(analysis_labels[idx])\n",
    "    \n",
    "    composer_r2 = {}\n",
    "    for composer, data in sorted(composer_data.items()):\n",
    "        if len(data['preds']) >= 10:\n",
    "            preds = np.array(data['preds'])\n",
    "            labels = np.array(data['labels'])\n",
    "            r2 = r2_score(labels, preds)\n",
    "            composer_r2[composer] = r2\n",
    "            print(f\"  {composer}: R2 = {r2:.4f} ({len(data['preds'])} samples)\")\n",
    "    \n",
    "    # 2. Extreme label analysis\n",
    "    print(\"\\n2. Extreme Label Analysis:\")\n",
    "    label_means = np.mean(analysis_labels, axis=1)\n",
    "    extreme_low = label_means < 0.2\n",
    "    extreme_high = label_means > 0.8\n",
    "    \n",
    "    if extreme_low.sum() > 0:\n",
    "        low_r2 = r2_score(analysis_labels[extreme_low], analysis_preds[extreme_low])\n",
    "        print(f\"  Low labels (<0.2): {extreme_low.sum()} samples, R2 = {low_r2:.4f}\")\n",
    "    \n",
    "    if extreme_high.sum() > 0:\n",
    "        high_r2 = r2_score(analysis_labels[extreme_high], analysis_preds[extreme_high])\n",
    "        print(f\"  High labels (>0.8): {extreme_high.sum()} samples, R2 = {high_r2:.4f}\")\n",
    "    \n",
    "    middle = ~extreme_low & ~extreme_high\n",
    "    if middle.sum() > 0:\n",
    "        mid_r2 = r2_score(analysis_labels[middle], analysis_preds[middle])\n",
    "        print(f\"  Middle labels: {middle.sum()} samples, R2 = {mid_r2:.4f}\")\n",
    "    \n",
    "    # 3. Per-dimension R2\n",
    "    print(\"\\n3. Per-Dimension R2:\")\n",
    "    dim_r2 = {}\n",
    "    for i, dim in enumerate(PERCEPIANO_DIMENSIONS):\n",
    "        r2 = r2_score(analysis_labels[:, i], analysis_preds[:, i])\n",
    "        dim_r2[dim] = r2\n",
    "    \n",
    "    sorted_dims = sorted(dim_r2.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"  Top 5:\")\n",
    "    for dim, r2 in sorted_dims[:5]:\n",
    "        print(f\"    {dim}: R2 = {r2:.4f}\")\n",
    "    print(\"  Bottom 5:\")\n",
    "    for dim, r2 in sorted_dims[-5:]:\n",
    "        print(f\"    {dim}: R2 = {r2:.4f}\")\n",
    "    \n",
    "    # Save error analysis\n",
    "    error_analysis = {\n",
    "        'experiment_id': 'error_analysis',\n",
    "        'per_composer_r2': composer_r2,\n",
    "        'per_dimension_r2': dim_r2,\n",
    "        'extreme_label_analysis': {\n",
    "            'low_count': int(extreme_low.sum()),\n",
    "            'high_count': int(extreme_high.sum()),\n",
    "            'middle_count': int(middle.sum()),\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / 'error_analysis.json', 'w') as f:\n",
    "        json.dump(error_analysis, f, indent=2)\n",
    "    \n",
    "    ALL_RESULTS['error_analysis'] = error_analysis\n",
    "    print(\"\\nError analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fj70qe7jqd",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Additional Ablations (TIER 3)\n",
    "\n",
    "**Goal**: Complete missing ablation studies.\n",
    "\n",
    "**Ablations**:\n",
    "1. MLP depth: 1-layer vs 2-layer vs 3-layer\n",
    "2. Batch size sensitivity: {32, 64, 128}\n",
    "3. Input frame length: {500, 1000, 1500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5v9ng4mtfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cells 54-58: Additional Ablations (combined)\n",
    "# Note: These ablations are computationally expensive. \n",
    "# Run selectively based on available GPU time.\n",
    "\n",
    "ABLATION_CONFIGS = {\n",
    "    'mlp_depth': {\n",
    "        '1_layer': {'hidden_dim': 512, 'n_layers': 1},\n",
    "        '2_layer': {'hidden_dim': 512, 'n_layers': 2},  # Default\n",
    "        '3_layer': {'hidden_dim': 512, 'n_layers': 3},\n",
    "    },\n",
    "    'batch_size': {\n",
    "        'bs_32': {'batch_size': 32},\n",
    "        'bs_64': {'batch_size': 64},  # Default\n",
    "        'bs_128': {'batch_size': 128},\n",
    "    },\n",
    "    'frame_length': {\n",
    "        'frames_500': {'max_frames': 500},\n",
    "        'frames_1000': {'max_frames': 1000},  # Default\n",
    "        'frames_1500': {'max_frames': 1500},\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ABLATION STUDIES\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nConfigured ablation studies:\")\n",
    "for category, configs in ABLATION_CONFIGS.items():\n",
    "    print(f\"  {category}:\")\n",
    "    for name, cfg in configs.items():\n",
    "        print(f\"    - {name}: {cfg}\")\n",
    "\n",
    "print(\"\\nNote: Full ablation training requires significant GPU time.\")\n",
    "print(\"Run individual ablations as needed.\")\n",
    "\n",
    "# Placeholder for ablation results\n",
    "ablation_results = {\n",
    "    'experiment_id': 'ablation_studies',\n",
    "    'status': 'configured',\n",
    "    'configs': ABLATION_CONFIGS,\n",
    "    'note': 'Run individual ablations based on available GPU time',\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'ablation_studies.json', 'w') as f:\n",
    "    json.dump(ablation_results, f, indent=2)\n",
    "\n",
    "ALL_RESULTS['ablation_studies'] = ablation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9of2mmm2ffs",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Final Summary\n",
    "\n",
    "Generate paper-ready summary of all experiments and upload to GDrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "me7yqvyvp7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 60: Generate paper-ready summary table\n",
    "print(\"=\"*70)\n",
    "print(\"STRONGEST PAPER EXPERIMENTS: FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TIER 1 RESULTS (Critical for acceptance)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Multi-seed stability\n",
    "if 'multi_seed_stability' in ALL_RESULTS:\n",
    "    ms = ALL_RESULTS['multi_seed_stability']\n",
    "    print(f\"\\n1. Multi-Seed Stability:\")\n",
    "    print(f\"   Mean R2: {ms['summary']['mean_r2']:.4f}\")\n",
    "    print(f\"   Std R2:  {ms['summary']['std_r2']:.4f}\")\n",
    "    print(f\"   Status:  {ms['summary']['stability_status']}\")\n",
    "\n",
    "# Stratified folds\n",
    "if 'stratified_folds' in ALL_RESULTS:\n",
    "    sf = ALL_RESULTS['stratified_folds']\n",
    "    print(f\"\\n2. Stratified Fold Redistribution:\")\n",
    "    print(f\"   Avg R2: {sf['summary']['avg_r2']:.4f}\")\n",
    "    print(f\"   Std R2: {sf['summary']['std_r2']:.4f}\")\n",
    "    if 'comparison' in sf:\n",
    "        print(f\"   Variance reduction: {sf['comparison']['variance_reduction_pct']:.1f}%\")\n",
    "\n",
    "# D7 completion\n",
    "if 'D7_muq_baseline' in ALL_RESULTS:\n",
    "    d7 = ALL_RESULTS['D7_muq_baseline']\n",
    "    print(f\"\\n3. D7_muq_baseline (Complete):\")\n",
    "    print(f\"   Avg R2: {d7['summary']['avg_r2']:.4f}\")\n",
    "    print(f\"   CI: [{d7['summary']['r2_ci_95'][0]:.4f}, {d7['summary']['r2_ci_95'][1]:.4f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TIER 2 RESULTS (Strengthen significantly)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Pianoteq augmentation\n",
    "if 'pianoteq_augmentation' in ALL_RESULTS:\n",
    "    pa = ALL_RESULTS['pianoteq_augmentation']\n",
    "    print(f\"\\n4. Pianoteq Soundfont Augmentation:\")\n",
    "    print(f\"   Status: {pa['status']}\")\n",
    "    if 'soundfonts' in pa:\n",
    "        for sf, data in pa['soundfonts'].items():\n",
    "            print(f\"     {sf}: {data['count']} files\")\n",
    "\n",
    "# MAESTRO analysis\n",
    "if 'maestro_analysis' in ALL_RESULTS:\n",
    "    ma = ALL_RESULTS['maestro_analysis']\n",
    "    print(f\"\\n5. MAESTRO Cross-Dataset Analysis:\")\n",
    "    print(f\"   Samples: {ma['n_samples']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TIER 3 RESULTS (Polish and depth)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Error analysis\n",
    "if 'error_analysis' in ALL_RESULTS:\n",
    "    ea = ALL_RESULTS['error_analysis']\n",
    "    print(f\"\\n6. Error Analysis: Complete\")\n",
    "\n",
    "# Ablations\n",
    "if 'ablation_studies' in ALL_RESULTS:\n",
    "    ab = ALL_RESULTS['ablation_studies']\n",
    "    print(f\"\\n7. Ablation Studies: {ab['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ajduvcd45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 61: Save aggregate results\n",
    "aggregate_results = {\n",
    "    'notebook': 'train_strongest_paper.ipynb',\n",
    "    'description': 'Strongest paper experiments for ISMIR 2026',\n",
    "    'experiments': ALL_RESULTS,\n",
    "    'verification_checklist': {\n",
    "        'multi_seed_stability': 'multi_seed_stability' in ALL_RESULTS,\n",
    "        'stratified_folds': 'stratified_folds' in ALL_RESULTS,\n",
    "        'd7_complete': 'D7_muq_baseline' in ALL_RESULTS,\n",
    "        'pianoteq_augmentation': 'pianoteq_augmentation' in ALL_RESULTS,\n",
    "        'maestro_analysis': 'maestro_analysis' in ALL_RESULTS,\n",
    "        'error_analysis': 'error_analysis' in ALL_RESULTS,\n",
    "        'ablation_studies': 'ablation_studies' in ALL_RESULTS,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save locally\n",
    "with open(RESULTS_DIR / 'strongest_paper_all_results.json', 'w') as f:\n",
    "    json.dump(aggregate_results, f, indent=2, default=numpy_serializer)\n",
    "\n",
    "print(f\"Saved aggregate results to {RESULTS_DIR / 'strongest_paper_all_results.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eqrheiwkb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 62: Upload all results to GDrive\n",
    "print(\"\\nUploading all results to GDrive...\")\n",
    "\n",
    "# Upload aggregate results\n",
    "run_rclone(['rclone', 'copyto',\n",
    "            str(RESULTS_DIR / 'strongest_paper_all_results.json'),\n",
    "            f'{GDRIVE_RESULTS}/strongest_paper_all_results.json'],\n",
    "           \"Uploading aggregate results\")\n",
    "\n",
    "# Upload all individual result files\n",
    "for json_file in RESULTS_DIR.glob('*.json'):\n",
    "    run_rclone(['rclone', 'copyto',\n",
    "                str(json_file),\n",
    "                f'{GDRIVE_RESULTS}/{json_file.name}'],\n",
    "               f\"Uploading {json_file.name}\")\n",
    "\n",
    "# Upload all checkpoints\n",
    "if CHECKPOINT_ROOT.exists():\n",
    "    run_rclone(['rclone', 'copy',\n",
    "                str(CHECKPOINT_ROOT),\n",
    "                f'{GDRIVE_RESULTS}/checkpoints',\n",
    "                '--progress'],\n",
    "               \"Uploading all checkpoints\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL EXPERIMENTS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nResults uploaded to: {GDRIVE_RESULTS}\")\n",
    "print(\"\\nVerification commands:\")\n",
    "print(f\"  rclone cat {GDRIVE_RESULTS}/multi_seed_stability.json | python3 -c \\\"import json,sys; d=json.load(sys.stdin); print(f'Mean R2: {{d[\\\\\\\"summary\\\\\\\"][\\\\\\\"mean_r2\\\\\\\"]:.4f}}')\\\"\")\n",
    "print(f\"  rclone cat {GDRIVE_RESULTS}/stratified_folds.json | python3 -c \\\"import json,sys; d=json.load(sys.stdin); print(f'Avg R2: {{d[\\\\\\\"summary\\\\\\\"][\\\\\\\"avg_r2\\\\\\\"]:.4f}}')\\\"\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
