{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Piano Performance Evaluation - Pseudo-Label Pre-training\n\nThis notebook trains a baseline model on MAESTRO pseudo-labels.\n\n**Goal**: Production-ready baseline model to compare against future expert labels\n\n**Requirements:**\n- Colab Pro (recommended for T4/V100 GPU)\n- Google Drive for data and checkpoints\n- HuggingFace account for MERT model\n- Git repository pushed to GitHub\n\n**Note**: This notebook installs packages directly into Colab's system Python (no venv needed)\n\n---\n\n## Google Drive Setup\n\n```\nMyDrive/\n  piano_eval_data/\n    maestro_pseudo_labels_train.jsonl  # Pseudo-label annotations\n    maestro_pseudo_labels_val.jsonl\n    maestro/                           # (Optional) Audio/MIDI files if not using URLs\n      2004/\n        audio/\n        midi/\n      2006/\n        ...\n  piano_eval_checkpoints/              # Empty folder (checkpoints will be saved here)\n    pseudo_pretrain/\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to HF\n",
    "import os\n",
    "os.environ.pop(\"HF_TOKEN\", None)\n",
    "os.environ.pop(\"HUGGINGFACEHUB_API_TOKEN\", None)\n",
    "from huggingface_hub import login, HfApi\n",
    "try:\n",
    "    import getpass as gp\n",
    "    raw = gp.getpass(\"Paste your Hugging Face token (input hidden): \")\n",
    "    token = raw.decode() if isinstance(raw, (bytes, bytearray)) else raw\n",
    "    if not isinstance(token, str):\n",
    "        raise TypeError(f\"Unexpected token type: {type(token).__name__}\")\n",
    "    token = token.strip()\n",
    "    if not token:\n",
    "        raise ValueError(\"Empty token provided\")\n",
    "    login(token=token, add_to_git_credential=False)\n",
    "    who = HfApi().whoami(token=token)\n",
    "    print(f\"Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
    "except Exception as e:\n",
    "    print(f\"[HF Login] getpass flow failed: {e}\")\n",
    "    print(\"Falling back to interactive login widget...\")\n",
    "    login()\n",
    "    try:\n",
    "        who = HfApi().whoami()\n",
    "        print(f\"Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"[HF Login] Verification skipped: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for data and checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify data exists\n",
    "import os\n",
    "data_dir = '/content/drive/MyDrive/piano_eval_data'\n",
    "checkpoint_dir = '/content/drive/MyDrive/piano_eval_checkpoints'\n",
    "\n",
    "assert os.path.exists(data_dir), f\"Data directory not found: {data_dir}\"\n",
    "assert os.path.exists(checkpoint_dir), f\"Checkpoint directory not found: {checkpoint_dir}\"\n",
    "\n",
    "print(f\"✓ Data directory: {data_dir}\")\n",
    "print(f\"  Contents: {os.listdir(data_dir)}\")\n",
    "print(f\"✓ Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = \"https://github.com/Jai-Dhiman/crescendai.git\"\n",
    "BRANCH = \"main\"\n",
    "\n",
    "# Remove old clone if exists\n",
    "!rm -rf /content/crescendai\n",
    "\n",
    "# Clone fresh\n",
    "!git clone --branch {BRANCH} {REPO_URL} /content/crescendai\n",
    "\n",
    "# Navigate to model directory\n",
    "%cd /content/crescendai/model\n",
    "\n",
    "# Show git status\n",
    "!git log -1 --oneline\n",
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Add to PATH for this session\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['HOME']}/.cargo/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies directly into system Python (no venv needed in Colab)\n# Using uv pip for faster installation\n!uv pip install --system -e .\n\n# Verify installation\nimport os\nos.environ['MPLBACKEND'] = 'Agg'\n\nimport torch\nimport pytorch_lightning\n\nprint(f\"Dependencies installed\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"Lightning: {pytorch_lightning.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check GPU and PyTorch setup\nimport torch\nimport pytorch_lightning as pl\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"Lightning version: {pl.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nprint(f\"CUDA version: {torch.version.cuda}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    print(f\"\\nGPU ready for training\")\nelse:\n    print(\"\\nWARNING: No GPU detected! Go to Runtime > Change runtime type > T4 GPU\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MERT model download (this will cache the model)\n",
    "from transformers import AutoModel\n",
    "\n",
    "print(\"Downloading MERT-95M model (one-time, ~380MB)...\")\n",
    "model = AutoModel.from_pretrained(\"m-a-p/MERT-v1-95M\", trust_remote_code=True)\n",
    "print(f\"✓ MERT-95M loaded: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M parameters\")\n",
    "del model  # Free memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify annotation files exist\n",
    "import json\n",
    "\n",
    "train_path = f'{data_dir}/maestro_pseudo_labels_train.jsonl'\n",
    "val_path = f'{data_dir}/maestro_pseudo_labels_val.jsonl'\n",
    "\n",
    "# Check files exist\n",
    "assert os.path.exists(train_path), f\"Train annotations not found: {train_path}\"\n",
    "assert os.path.exists(val_path), f\"Val annotations not found: {val_path}\"\n",
    "\n",
    "# Count samples\n",
    "with open(train_path, 'r') as f:\n",
    "    train_count = sum(1 for line in f if line.strip())\n",
    "with open(val_path, 'r') as f:\n",
    "    val_count = sum(1 for line in f if line.strip())\n",
    "\n",
    "print(f\"✓ Train annotations: {train_count} segments\")\n",
    "print(f\"✓ Val annotations: {val_count} segments\")\n",
    "\n",
    "# Show sample annotation\n",
    "with open(train_path, 'r') as f:\n",
    "    sample = json.loads(f.readline())\n",
    "print(f\"\\nSample annotation:\")\n",
    "print(f\"  Audio: {sample['audio_path']}\")\n",
    "print(f\"  MIDI: {sample.get('midi_path', 'N/A')}\")\n",
    "print(f\"  Duration: {sample.get('end_time', 0) - sample.get('start_time', 0):.1f}s\")\n",
    "print(f\"  Labels: {list(sample['labels'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base config and update paths for Colab\n",
    "import yaml\n",
    "\n",
    "config_path = 'configs/pseudo_pretrain.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update data paths to Google Drive\n",
    "config['data']['train_path'] = f'{data_dir}/maestro_pseudo_labels_train.jsonl'\n",
    "config['data']['val_path'] = f'{data_dir}/maestro_pseudo_labels_val.jsonl'\n",
    "config['data']['test_path'] = None  # No test set for pseudo-label training\n",
    "\n",
    "# Update checkpoint directory to Google Drive (for persistence)\n",
    "config['callbacks']['checkpoint']['dirpath'] = f'{checkpoint_dir}/pseudo_pretrain'\n",
    "\n",
    "# Update logging directory (local is fine, checkpoints are what matter)\n",
    "config['logging']['tensorboard_logdir'] = 'logs/pseudo_pretrain'\n",
    "\n",
    "# Optionally enable WandB for experiment tracking\n",
    "config['logging']['use_wandb'] = False  # Set to True if you want WandB logging\n",
    "\n",
    "# Save updated config\n",
    "colab_config_path = 'configs/pseudo_pretrain_colab.yaml'\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "with open(colab_config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"✓ Config updated for Colab:\")\n",
    "print(f\"  Train: {config['data']['train_path']}\")\n",
    "print(f\"  Val: {config['data']['val_path']}\")\n",
    "print(f\"  Checkpoints: {config['callbacks']['checkpoint']['dirpath']}\")\n",
    "print(f\"  Max epochs: {config['training']['max_epochs']}\")\n",
    "print(f\"  Batch size: {config['data']['batch_size']}\")\n",
    "print(f\"  Dimensions: {config['data']['dimensions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Model\n",
    "\n",
    "This will take approximately **12 GPU hours** on a T4.\n",
    "\n",
    "**Important**: \n",
    "- Checkpoints are saved to Google Drive every epoch\n",
    "- If Colab disconnects, re-run this cell - training will resume from last checkpoint\n",
    "- Early stopping will trigger if validation loss doesn't improve for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test setup with fast dev run\n!python train.py --config {colab_config_path} --fast-dev-run"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run training\n!python train.py --config {colab_config_path}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load best checkpoint\nimport sys\nsys.path.insert(0, '/content/crescendai/model')\n\nfrom src.models.lightning_module import PerformanceEvaluationModel\n\n# Find best checkpoint\ncheckpoint_path = f'{checkpoint_dir}/pseudo_pretrain'\ncheckpoints = [f for f in os.listdir(checkpoint_path) if f.endswith('.ckpt') and not f.startswith('last')]\nbest_ckpt = sorted(checkpoints)[0]  # First by name (lowest val_loss in filename)\nbest_ckpt_path = os.path.join(checkpoint_path, best_ckpt)\n\nprint(f\"Loading best checkpoint: {best_ckpt}\")\nmodel = PerformanceEvaluationModel.load_from_checkpoint(best_ckpt_path)\nmodel.eval()\nmodel = model.cuda()\n\nprint(f\"\\nModel loaded successfully\")\nprint(f\"  Dimensions: {model.dimension_names}\")\nprint(f\"  Parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on a validation sample\n",
    "import torch\n",
    "import json\n",
    "from src.data.audio_processing import load_audio, normalize_audio\n",
    "from src.data.midi_processing import load_midi, encode_octuple_midi, align_midi_to_audio\n",
    "import numpy as np\n",
    "\n",
    "# Load a random validation sample\n",
    "val_path = f'{data_dir}/maestro_pseudo_labels_val.jsonl'\n",
    "with open(val_path, 'r') as f:\n",
    "    annotations = [json.loads(line) for line in f if line.strip()]\n",
    "sample = annotations[0]  # First validation sample\n",
    "\n",
    "print(f\"Testing on: {sample['audio_path']}\")\n",
    "print(f\"Segment: {sample.get('start_time', 0):.1f}s - {sample.get('end_time', 0):.1f}s\")\n",
    "\n",
    "# Load audio\n",
    "audio, sr = load_audio(sample['audio_path'], sr=24000)\n",
    "\n",
    "# Extract segment\n",
    "if 'start_time' in sample and 'end_time' in sample:\n",
    "    start_sample = int(sample['start_time'] * sr)\n",
    "    end_sample = int(sample['end_time'] * sr)\n",
    "    audio = audio[start_sample:end_sample]\n",
    "\n",
    "# Normalize\n",
    "audio = normalize_audio(audio)\n",
    "\n",
    "# Pad/truncate to 10 seconds\n",
    "max_length = 240000\n",
    "if len(audio) > max_length:\n",
    "    audio = audio[:max_length]\n",
    "elif len(audio) < max_length:\n",
    "    audio = np.pad(audio, (0, max_length - len(audio)))\n",
    "\n",
    "# Convert to tensor\n",
    "audio_tensor = torch.from_numpy(audio).float().unsqueeze(0).cuda()  # [1, samples]\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(audio_waveform=audio_tensor, midi_tokens=None)\n",
    "\n",
    "# Extract predictions\n",
    "scores = output['scores'][0].cpu().numpy()\n",
    "uncertainties = output['uncertainties'].cpu().numpy()\n",
    "ground_truth = [sample['labels'][dim] for dim in model.dimension_names]\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPredictions vs Ground Truth (Pseudo-labels):\")\n",
    "print(f\"{'Dimension':<25s} {'Predicted':<12s} {'Ground Truth':<12s} {'Error':<8s}\")\n",
    "print(\"-\" * 65)\n",
    "for dim_name, pred, gt, unc in zip(model.dimension_names, scores, ground_truth, uncertainties):\n",
    "    error = abs(pred - gt)\n",
    "    print(f\"{dim_name:<25s} {pred:5.1f} ± {unc:4.2f}  {gt:5.1f}         {error:5.1f}\")\n",
    "\n",
    "mae = np.mean([abs(p - g) for p, g in zip(scores, ground_truth)])\n",
    "print(f\"\\nMean Absolute Error: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check final checkpoint sizes\n",
    "checkpoint_path = f'{checkpoint_dir}/pseudo_pretrain'\n",
    "total_size = 0\n",
    "for f in os.listdir(checkpoint_path):\n",
    "    if f.endswith('.ckpt'):\n",
    "        size = os.path.getsize(os.path.join(checkpoint_path, f))\n",
    "        total_size += size\n",
    "\n",
    "print(f\"✓ Training complete!\")\n",
    "print(f\"\\nCheckpoints saved to: {checkpoint_path}\")\n",
    "print(f\"Total size: {total_size / 1e6:.1f} MB\")\n",
    "print(f\"\\nBest model: {best_ckpt}\")\n",
    "print(f\"\\nThis model is trained on pseudo-labels only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Session Disconnected\n",
    "- Re-run cells 1-2 (mount Drive, clone repo)\n",
    "- Re-run cell 4 (training) - will automatically resume from last checkpoint\n",
    "- All checkpoints are in Google Drive (persistent)\n",
    "\n",
    "### Out of Memory (OOM)\n",
    "- Reduce batch size in config: `config['data']['batch_size'] = 4`\n",
    "- Increase gradient accumulation: `config['training']['accumulate_grad_batches'] = 8`\n",
    "- This keeps effective batch size = 4 × 8 = 32\n",
    "\n",
    "### Slow Training\n",
    "- Check you have T4 or better GPU (not K80)\n",
    "- Verify data is in Google Drive (not Colab Files)\n",
    "- Check num_workers: `config['data']['num_workers'] = 2` (lower if I/O bottleneck)\n",
    "\n",
    "### MERT Download Fails\n",
    "- Verify HuggingFace authentication\n",
    "- Check internet connection\n",
    "- Try manual download: `huggingface-cli download m-a-p/MERT-v1-95M`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}