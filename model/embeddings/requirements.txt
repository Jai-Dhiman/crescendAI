# Core FastAPI dependencies
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.4.0

# ML backends - PyTorch with CPU/GPU support
torch>=2.1.0
transformers>=4.35.0
tokenizers>=0.15.0
sentence-transformers>=2.2.0

# High-performance alternatives for Intel Macs
onnxruntime>=1.16.0  # ONNX Runtime for optimized inference

# Utilities
numpy>=1.24.0
httpx>=0.25.0  # For HTTP client calls
requests>=2.31.0  # For testing

# Optional: distributed caching
# redis>=4.5.0
